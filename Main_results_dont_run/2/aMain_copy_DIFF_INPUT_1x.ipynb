{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "已连接到 base (Python 3.8.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MR\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MR'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16143, 100])\n",
      "16143\n",
      "16143\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 3,604,601 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.691 | Train Acc: 53.21%\n",
      "\t test  Loss: 0.685 | test  Acc: 56.17%\n",
      "\t best  test acc: 56.17%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.665 | Train Acc: 61.36%\n",
      "\t test  Loss: 0.658 | test  Acc: 60.05%\n",
      "\t best  test acc: 60.05%\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.585 | Train Acc: 70.31%\n",
      "\t test  Loss: 0.670 | test  Acc: 61.82%\n",
      "\t best  test acc: 61.82%\n",
      "Epoch: 04 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.478 | Train Acc: 78.94%\n",
      "\t test  Loss: 0.627 | test  Acc: 69.24%\n",
      "\t best  test acc: 69.24%\n",
      "Epoch: 05 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.362 | Train Acc: 86.15%\n",
      "\t test  Loss: 0.636 | test  Acc: 71.66%\n",
      "\t best  test acc: 71.66%\n",
      "Epoch: 06 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.268 | Train Acc: 90.96%\n",
      "\t test  Loss: 0.698 | test  Acc: 71.57%\n",
      "\t best  test acc: 71.66%\n",
      "Epoch: 07 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.201 | Train Acc: 93.74%\n",
      "\t test  Loss: 0.765 | test  Acc: 71.66%\n",
      "\t best  test acc: 71.66%\n",
      "Epoch: 08 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.152 | Train Acc: 95.68%\n",
      "\t test  Loss: 0.823 | test  Acc: 71.38%\n",
      "\t best  test acc: 71.66%\n",
      "Epoch: 09 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.122 | Train Acc: 96.70%\n",
      "\t test  Loss: 0.925 | test  Acc: 71.23%\n",
      "\t best  test acc: 71.66%\n",
      "Epoch: 10 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.098 | Train Acc: 97.55%\n",
      "\t test  Loss: 0.979 | test  Acc: 71.38%\n",
      "\t best  test acc: 71.66%\n",
      "Epoch: 11 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.087 | Train Acc: 97.85%\n",
      "\t test  Loss: 0.965 | test  Acc: 71.94%\n",
      "\t best  test acc: 71.94%\n",
      "Epoch: 12 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.079 | Train Acc: 97.95%\n",
      "\t test  Loss: 0.974 | test  Acc: 72.73%\n",
      "\t best  test acc: 72.73%\n",
      "Epoch: 13 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.058 | Train Acc: 98.62%\n",
      "\t test  Loss: 1.007 | test  Acc: 72.26%\n",
      "\t best  test acc: 72.73%\n",
      "Epoch: 14 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.052 | Train Acc: 98.78%\n",
      "\t test  Loss: 1.070 | test  Acc: 71.29%\n",
      "\t best  test acc: 72.73%\n",
      "Epoch: 15 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.051 | Train Acc: 98.79%\n",
      "\t test  Loss: 1.043 | test  Acc: 73.29%\n",
      "\t best  test acc: 73.29%\n",
      "Epoch: 16 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.050 | Train Acc: 98.79%\n",
      "\t test  Loss: 1.044 | test  Acc: 72.50%\n",
      "\t best  test acc: 73.29%\n",
      "Epoch: 17 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.029 | Train Acc: 99.36%\n",
      "\t test  Loss: 1.163 | test  Acc: 71.90%\n",
      "\t best  test acc: 73.29%\n",
      "Epoch: 18 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.036 | Train Acc: 99.15%\n",
      "\t test  Loss: 1.132 | test  Acc: 71.99%\n",
      "\t best  test acc: 73.29%\n",
      "Epoch: 19 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.030 | Train Acc: 99.25%\n",
      "\t test  Loss: 1.151 | test  Acc: 73.81%\n",
      "\t best  test acc: 73.81%\n",
      "Epoch: 20 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.023 | Train Acc: 99.51%\n",
      "\t test  Loss: 1.189 | test  Acc: 73.10%\n",
      "\t best  test acc: 73.81%\n",
      "Epoch: 21 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.016 | Train Acc: 99.70%\n",
      "\t test  Loss: 1.285 | test  Acc: 72.78%\n",
      "\t best  test acc: 73.81%\n",
      "Epoch: 22 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.015 | Train Acc: 99.73%\n",
      "\t test  Loss: 1.215 | test  Acc: 73.71%\n",
      "\t best  test acc: 73.81%\n",
      "Epoch: 23 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.022 | Train Acc: 99.36%\n",
      "\t test  Loss: 1.218 | test  Acc: 73.30%\n",
      "\t best  test acc: 73.81%\n",
      "Epoch: 24 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.016 | Train Acc: 99.72%\n",
      "\t test  Loss: 1.286 | test  Acc: 73.52%\n",
      "\t best  test acc: 73.81%\n",
      "Epoch: 25 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.014 | Train Acc: 99.68%\n",
      "\t test  Loss: 1.307 | test  Acc: 74.19%\n",
      "\t best  test acc: 74.19%\n",
      "Epoch: 26 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.023 | Train Acc: 99.41%\n",
      "\t test  Loss: 1.226 | test  Acc: 73.06%\n",
      "\t best  test acc: 74.19%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,489,601 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.627 | Train Acc: 67.74%\n",
      "\t test  Loss: 0.621 | test  Acc: 68.38%\n",
      "\t best  test acc: 68.38%\n",
      "Epoch: 02 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.607 | Train Acc: 69.17%\n",
      "\t test  Loss: 0.582 | test  Acc: 73.41%\n",
      "\t best  test acc: 73.41%\n",
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.557 | Train Acc: 74.68%\n",
      "\t test  Loss: 0.552 | test  Acc: 74.53%\n",
      "\t best  test acc: 74.53%\n",
      "Epoch: 04 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.514 | Train Acc: 77.85%\n",
      "\t test  Loss: 0.526 | test  Acc: 77.33%\n",
      "\t best  test acc: 77.33%\n",
      "Epoch: 05 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.465 | Train Acc: 80.92%\n",
      "\t test  Loss: 0.510 | test  Acc: 77.89%\n",
      "\t best  test acc: 77.89%\n",
      "Epoch: 06 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.402 | Train Acc: 83.49%\n",
      "\t test  Loss: 0.507 | test  Acc: 79.01%\n",
      "\t best  test acc: 79.01%\n",
      "Epoch: 07 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.336 | Train Acc: 87.09%\n",
      "\t test  Loss: 0.473 | test  Acc: 80.60%\n",
      "\t best  test acc: 80.60%\n",
      "Epoch: 08 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.274 | Train Acc: 90.29%\n",
      "\t test  Loss: 0.491 | test  Acc: 82.00%\n",
      "\t best  test acc: 82.00%\n",
      "Epoch: 09 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.228 | Train Acc: 92.24%\n",
      "\t test  Loss: 0.484 | test  Acc: 82.37%\n",
      "\t best  test acc: 82.37%\n",
      "Epoch: 10 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.184 | Train Acc: 94.20%\n",
      "\t test  Loss: 0.481 | test  Acc: 83.68%\n",
      "\t best  test acc: 83.68%\n",
      "Epoch: 11 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.159 | Train Acc: 95.03%\n",
      "\t test  Loss: 0.513 | test  Acc: 81.81%\n",
      "\t best  test acc: 83.68%\n",
      "Epoch: 12 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.135 | Train Acc: 96.03%\n",
      "\t test  Loss: 0.528 | test  Acc: 83.02%\n",
      "\t best  test acc: 83.68%\n",
      "Epoch: 13 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.119 | Train Acc: 96.50%\n",
      "\t test  Loss: 0.537 | test  Acc: 83.02%\n",
      "\t best  test acc: 83.68%\n",
      "Epoch: 14 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.117 | Train Acc: 96.59%\n",
      "\t test  Loss: 0.532 | test  Acc: 82.18%\n",
      "\t best  test acc: 83.68%\n",
      "Epoch: 15 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.101 | Train Acc: 97.14%\n",
      "\t test  Loss: 0.552 | test  Acc: 83.12%\n",
      "\t best  test acc: 83.68%\n",
      "Epoch: 16 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.090 | Train Acc: 97.52%\n",
      "\t test  Loss: 0.574 | test  Acc: 82.09%\n",
      "\t best  test acc: 83.68%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.081 | Train Acc: 97.67%\n",
      "\t test  Loss: 0.595 | test  Acc: 81.90%\n",
      "\t best  test acc: 83.68%\n",
      "Epoch: 18 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.075 | Train Acc: 97.88%\n",
      "\t test  Loss: 0.594 | test  Acc: 82.65%\n",
      "\t best  test acc: 83.68%\n",
      "Epoch: 19 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.068 | Train Acc: 98.21%\n",
      "\t test  Loss: 0.614 | test  Acc: 82.56%\n",
      "\t best  test acc: 83.68%\n",
      "Epoch: 20 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.066 | Train Acc: 98.21%\n",
      "\t test  Loss: 0.617 | test  Acc: 82.28%\n",
      "\t best  test acc: 83.68%\n",
      "Epoch: 21 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.068 | Train Acc: 97.96%\n",
      "\t test  Loss: 0.617 | test  Acc: 82.56%\n",
      "\t best  test acc: 83.68%\n",
      "Epoch: 22 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.066 | Train Acc: 98.15%\n",
      "\t test  Loss: 0.626 | test  Acc: 81.34%\n",
      "\t best  test acc: 83.68%\n",
      "Epoch: 23 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.059 | Train Acc: 98.27%\n",
      "\t test  Loss: 0.597 | test  Acc: 82.09%\n",
      "\t best  test acc: 83.68%\n",
      "Epoch: 24 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.059 | Train Acc: 98.22%\n",
      "\t test  Loss: 0.546 | test  Acc: 83.86%\n",
      "\t best  test acc: 83.86%\n",
      "Epoch: 25 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.056 | Train Acc: 98.36%\n",
      "\t test  Loss: 0.586 | test  Acc: 84.14%\n",
      "\t best  test acc: 84.14%\n",
      "Epoch: 26 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.047 | Train Acc: 98.72%\n",
      "\t test  Loss: 0.623 | test  Acc: 82.84%\n",
      "\t best  test acc: 84.14%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: SUBJ\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'SUBJ'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18512, 100])\n",
      "18512\n",
      "18512\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 4,078,401 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.644 | Train Acc: 66.34%\n",
      "\t test  Loss: 0.540 | test  Acc: 79.37%\n",
      "\t best  test acc: 79.37%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.430 | Train Acc: 83.81%\n",
      "\t test  Loss: 0.357 | test  Acc: 87.10%\n",
      "\t best  test acc: 87.10%\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.266 | Train Acc: 91.26%\n",
      "\t test  Loss: 0.344 | test  Acc: 87.90%\n",
      "\t best  test acc: 87.90%\n",
      "Epoch: 04 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.170 | Train Acc: 95.17%\n",
      "\t test  Loss: 0.308 | test  Acc: 88.59%\n",
      "\t best  test acc: 88.59%\n",
      "Epoch: 05 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.112 | Train Acc: 97.21%\n",
      "\t test  Loss: 0.324 | test  Acc: 88.89%\n",
      "\t best  test acc: 88.89%\n",
      "Epoch: 06 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.073 | Train Acc: 98.31%\n",
      "\t test  Loss: 0.323 | test  Acc: 90.28%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 07 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.050 | Train Acc: 98.95%\n",
      "\t test  Loss: 0.353 | test  Acc: 89.48%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 08 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.041 | Train Acc: 99.10%\n",
      "\t test  Loss: 0.383 | test  Acc: 89.38%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 09 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.027 | Train Acc: 99.50%\n",
      "\t test  Loss: 0.412 | test  Acc: 89.19%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 10 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.020 | Train Acc: 99.66%\n",
      "\t test  Loss: 0.436 | test  Acc: 88.49%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 11 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.020 | Train Acc: 99.58%\n",
      "\t test  Loss: 0.416 | test  Acc: 89.98%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 12 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.018 | Train Acc: 99.61%\n",
      "\t test  Loss: 0.587 | test  Acc: 87.30%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 13 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.023 | Train Acc: 99.41%\n",
      "\t test  Loss: 0.422 | test  Acc: 88.89%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 14 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.017 | Train Acc: 99.58%\n",
      "\t test  Loss: 0.394 | test  Acc: 90.58%\n",
      "\t best  test acc: 90.58%\n",
      "Epoch: 15 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.007 | Train Acc: 99.90%\n",
      "\t test  Loss: 0.408 | test  Acc: 90.97%\n",
      "\t best  test acc: 90.97%\n",
      "Epoch: 16 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.006 | Train Acc: 99.91%\n",
      "\t test  Loss: 0.413 | test  Acc: 91.17%\n",
      "\t best  test acc: 91.17%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.004 | Train Acc: 99.96%\n",
      "\t test  Loss: 0.462 | test  Acc: 90.38%\n",
      "\t best  test acc: 91.17%\n",
      "Epoch: 18 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.014 | Train Acc: 99.65%\n",
      "\t test  Loss: 0.406 | test  Acc: 91.67%\n",
      "\t best  test acc: 91.67%\n",
      "Epoch: 19 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.011 | Train Acc: 99.74%\n",
      "\t test  Loss: 0.432 | test  Acc: 91.47%\n",
      "\t best  test acc: 91.67%\n",
      "Epoch: 20 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.005 | Train Acc: 99.92%\n",
      "\t test  Loss: 0.454 | test  Acc: 91.17%\n",
      "\t best  test acc: 91.67%\n",
      "Epoch: 21 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.003 | Train Acc: 99.98%\n",
      "\t test  Loss: 0.445 | test  Acc: 90.87%\n",
      "\t best  test acc: 91.67%\n",
      "Epoch: 22 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.002 | Train Acc: 99.98%\n",
      "\t test  Loss: 0.473 | test  Acc: 91.17%\n",
      "\t best  test acc: 91.67%\n",
      "Epoch: 23 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.002 | Train Acc: 99.98%\n",
      "\t test  Loss: 0.513 | test  Acc: 90.77%\n",
      "\t best  test acc: 91.67%\n",
      "Epoch: 24 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.002 | Train Acc: 99.99%\n",
      "\t test  Loss: 0.500 | test  Acc: 90.77%\n",
      "\t best  test acc: 91.67%\n",
      "Epoch: 25 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.001 | Train Acc: 99.99%\n",
      "\t test  Loss: 0.507 | test  Acc: 90.87%\n",
      "\t best  test acc: 91.67%\n",
      "Epoch: 26 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.001 | Train Acc: 99.99%\n",
      "\t test  Loss: 0.516 | test  Acc: 90.97%\n",
      "\t best  test acc: 91.67%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MR\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MR'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16143, 100])\n",
      "16143\n",
      "16143\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MR\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MR'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16143, 100])\n",
      "16143\n",
      "16143\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16143, 100])\n",
      "16143\n",
      "16143\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 3,604,601 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.693 | Train Acc: 50.53%\n",
      "\t test  Loss: 0.693 | test  Acc: 48.96%\n",
      "\t best  test acc: 48.96%\n",
      "Epoch: 02 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.684 | Train Acc: 56.16%\n",
      "\t test  Loss: 0.676 | test  Acc: 61.59%\n",
      "\t best  test acc: 61.59%\n",
      "Epoch: 03 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.629 | Train Acc: 66.25%\n",
      "\t test  Loss: 0.633 | test  Acc: 64.80%\n",
      "\t best  test acc: 64.80%\n",
      "Epoch: 04 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.515 | Train Acc: 76.79%\n",
      "\t test  Loss: 0.580 | test  Acc: 70.77%\n",
      "\t best  test acc: 70.77%\n",
      "Epoch: 05 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.391 | Train Acc: 84.05%\n",
      "\t test  Loss: 0.587 | test  Acc: 73.01%\n",
      "\t best  test acc: 73.01%\n",
      "Epoch: 06 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.284 | Train Acc: 90.10%\n",
      "\t test  Loss: 0.653 | test  Acc: 72.54%\n",
      "\t best  test acc: 73.01%\n",
      "Epoch: 07 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.216 | Train Acc: 93.02%\n",
      "\t test  Loss: 0.670 | test  Acc: 73.39%\n",
      "\t best  test acc: 73.39%\n",
      "Epoch: 08 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.171 | Train Acc: 94.96%\n",
      "\t test  Loss: 0.732 | test  Acc: 73.62%\n",
      "\t best  test acc: 73.62%\n",
      "Epoch: 09 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.132 | Train Acc: 96.37%\n",
      "\t test  Loss: 0.752 | test  Acc: 73.62%\n",
      "\t best  test acc: 73.62%\n",
      "Epoch: 10 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.111 | Train Acc: 96.91%\n",
      "\t test  Loss: 0.817 | test  Acc: 73.34%\n",
      "\t best  test acc: 73.62%\n",
      "Epoch: 11 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.080 | Train Acc: 97.81%\n",
      "\t test  Loss: 0.954 | test  Acc: 72.88%\n",
      "\t best  test acc: 73.62%\n",
      "Epoch: 12 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.065 | Train Acc: 98.43%\n",
      "\t test  Loss: 0.967 | test  Acc: 73.02%\n",
      "\t best  test acc: 73.62%\n",
      "Epoch: 13 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.064 | Train Acc: 98.40%\n",
      "\t test  Loss: 0.956 | test  Acc: 73.90%\n",
      "\t best  test acc: 73.90%\n",
      "Epoch: 14 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.054 | Train Acc: 98.71%\n",
      "\t test  Loss: 1.015 | test  Acc: 72.68%\n",
      "\t best  test acc: 73.90%\n",
      "Epoch: 15 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.044 | Train Acc: 98.98%\n",
      "\t test  Loss: 1.041 | test  Acc: 73.24%\n",
      "\t best  test acc: 73.90%\n",
      "Epoch: 16 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.038 | Train Acc: 99.18%\n",
      "\t test  Loss: 1.014 | test  Acc: 73.10%\n",
      "\t best  test acc: 73.90%\n",
      "Epoch: 17 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.049 | Train Acc: 98.72%\n",
      "\t test  Loss: 1.079 | test  Acc: 72.04%\n",
      "\t best  test acc: 73.90%\n",
      "Epoch: 18 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.029 | Train Acc: 99.29%\n",
      "\t test  Loss: 1.192 | test  Acc: 71.89%\n",
      "\t best  test acc: 73.90%\n",
      "Epoch: 19 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.036 | Train Acc: 99.13%\n",
      "\t test  Loss: 1.124 | test  Acc: 74.50%\n",
      "\t best  test acc: 74.50%\n",
      "Epoch: 20 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.023 | Train Acc: 99.49%\n",
      "\t test  Loss: 1.243 | test  Acc: 73.34%\n",
      "\t best  test acc: 74.50%\n",
      "Epoch: 21 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.014 | Train Acc: 99.77%\n",
      "\t test  Loss: 1.211 | test  Acc: 74.87%\n",
      "\t best  test acc: 74.87%\n",
      "Epoch: 22 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.021 | Train Acc: 99.54%\n",
      "\t test  Loss: 1.303 | test  Acc: 71.85%\n",
      "\t best  test acc: 74.87%\n",
      "Epoch: 23 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.023 | Train Acc: 99.37%\n",
      "\t test  Loss: 1.210 | test  Acc: 72.22%\n",
      "\t best  test acc: 74.87%\n",
      "Epoch: 24 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.019 | Train Acc: 99.44%\n",
      "\t test  Loss: 1.197 | test  Acc: 74.64%\n",
      "\t best  test acc: 74.87%\n",
      "Epoch: 25 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.015 | Train Acc: 99.66%\n",
      "\t test  Loss: 1.240 | test  Acc: 73.90%\n",
      "\t best  test acc: 74.87%\n",
      "Epoch: 26 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.009 | Train Acc: 99.78%\n",
      "\t test  Loss: 1.259 | test  Acc: 73.67%\n",
      "\t best  test acc: 74.87%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 3,604,601 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.694 | Train Acc: 50.61%\n",
      "\t test  Loss: 0.689 | test  Acc: 47.56%\n",
      "\t best  test acc: 47.56%\n",
      "Epoch: 02 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.680 | Train Acc: 57.81%\n",
      "\t test  Loss: 0.676 | test  Acc: 58.74%\n",
      "\t best  test acc: 58.74%\n",
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.634 | Train Acc: 65.41%\n",
      "\t test  Loss: 0.645 | test  Acc: 64.06%\n",
      "\t best  test acc: 64.06%\n",
      "Epoch: 04 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.553 | Train Acc: 73.70%\n",
      "\t test  Loss: 0.633 | test  Acc: 68.02%\n",
      "\t best  test acc: 68.02%\n",
      "Epoch: 05 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.454 | Train Acc: 81.09%\n",
      "\t test  Loss: 0.638 | test  Acc: 69.79%\n",
      "\t best  test acc: 69.79%\n",
      "Epoch: 06 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.364 | Train Acc: 86.17%\n",
      "\t test  Loss: 0.692 | test  Acc: 69.76%\n",
      "\t best  test acc: 69.79%\n",
      "Epoch: 07 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.297 | Train Acc: 89.75%\n",
      "\t test  Loss: 0.736 | test  Acc: 69.38%\n",
      "\t best  test acc: 69.79%\n",
      "Epoch: 08 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.242 | Train Acc: 92.39%\n",
      "\t test  Loss: 0.824 | test  Acc: 69.47%\n",
      "\t best  test acc: 69.79%\n",
      "Epoch: 09 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.195 | Train Acc: 94.01%\n",
      "\t test  Loss: 0.811 | test  Acc: 70.91%\n",
      "\t best  test acc: 70.91%\n",
      "Epoch: 10 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.159 | Train Acc: 95.20%\n",
      "\t test  Loss: 0.842 | test  Acc: 71.71%\n",
      "\t best  test acc: 71.71%\n",
      "Epoch: 11 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.130 | Train Acc: 96.48%\n",
      "\t test  Loss: 0.861 | test  Acc: 72.03%\n",
      "\t best  test acc: 72.03%\n",
      "Epoch: 12 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.113 | Train Acc: 97.02%\n",
      "\t test  Loss: 0.961 | test  Acc: 67.78%\n",
      "\t best  test acc: 72.03%\n",
      "Epoch: 13 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.108 | Train Acc: 97.04%\n",
      "\t test  Loss: 0.905 | test  Acc: 71.29%\n",
      "\t best  test acc: 72.03%\n",
      "Epoch: 14 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.084 | Train Acc: 97.76%\n",
      "\t test  Loss: 0.993 | test  Acc: 71.10%\n",
      "\t best  test acc: 72.03%\n",
      "Epoch: 15 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.071 | Train Acc: 98.24%\n",
      "\t test  Loss: 1.103 | test  Acc: 69.79%\n",
      "\t best  test acc: 72.03%\n",
      "Epoch: 16 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.052 | Train Acc: 98.88%\n",
      "\t test  Loss: 1.106 | test  Acc: 71.38%\n",
      "\t best  test acc: 72.03%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.053 | Train Acc: 98.75%\n",
      "\t test  Loss: 1.099 | test  Acc: 70.73%\n",
      "\t best  test acc: 72.03%\n",
      "Epoch: 18 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.058 | Train Acc: 98.57%\n",
      "\t test  Loss: 1.079 | test  Acc: 71.57%\n",
      "\t best  test acc: 72.03%\n",
      "Epoch: 19 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.053 | Train Acc: 98.70%\n",
      "\t test  Loss: 1.136 | test  Acc: 71.01%\n",
      "\t best  test acc: 72.03%\n",
      "Epoch: 20 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.041 | Train Acc: 99.06%\n",
      "\t test  Loss: 1.166 | test  Acc: 71.47%\n",
      "\t best  test acc: 72.03%\n",
      "Epoch: 21 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.037 | Train Acc: 99.19%\n",
      "\t test  Loss: 1.247 | test  Acc: 71.10%\n",
      "\t best  test acc: 72.03%\n",
      "Epoch: 22 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.039 | Train Acc: 99.15%\n",
      "\t test  Loss: 1.123 | test  Acc: 71.62%\n",
      "\t best  test acc: 72.03%\n",
      "Epoch: 23 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.038 | Train Acc: 99.09%\n",
      "\t test  Loss: 1.227 | test  Acc: 72.78%\n",
      "\t best  test acc: 72.78%\n",
      "Epoch: 24 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.030 | Train Acc: 99.36%\n",
      "\t test  Loss: 1.222 | test  Acc: 73.06%\n",
      "\t best  test acc: 73.06%\n",
      "Epoch: 25 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.016 | Train Acc: 99.71%\n",
      "\t test  Loss: 1.395 | test  Acc: 72.78%\n",
      "\t best  test acc: 73.06%\n",
      "Epoch: 26 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.023 | Train Acc: 99.51%\n",
      "\t test  Loss: 1.333 | test  Acc: 71.19%\n",
      "\t best  test acc: 73.06%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MR'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16143, 100])\n",
      "16143\n",
      "16143\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 3,604,601 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.692 | Train Acc: 52.19%\n",
      "\t test  Loss: 0.685 | test  Acc: 57.44%\n",
      "\t best  test acc: 57.44%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.672 | Train Acc: 61.40%\n",
      "\t test  Loss: 0.678 | test  Acc: 58.09%\n",
      "\t best  test acc: 58.09%\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.613 | Train Acc: 68.79%\n",
      "\t test  Loss: 0.628 | test  Acc: 68.35%\n",
      "\t best  test acc: 68.35%\n",
      "Epoch: 04 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.497 | Train Acc: 78.36%\n",
      "\t test  Loss: 0.590 | test  Acc: 72.22%\n",
      "\t best  test acc: 72.22%\n",
      "Epoch: 05 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.367 | Train Acc: 86.61%\n",
      "\t test  Loss: 0.607 | test  Acc: 73.66%\n",
      "\t best  test acc: 73.66%\n",
      "Epoch: 06 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.283 | Train Acc: 90.45%\n",
      "\t test  Loss: 0.632 | test  Acc: 74.59%\n",
      "\t best  test acc: 74.59%\n",
      "Epoch: 07 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.204 | Train Acc: 93.77%\n",
      "\t test  Loss: 0.681 | test  Acc: 74.97%\n",
      "\t best  test acc: 74.97%\n",
      "Epoch: 08 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.159 | Train Acc: 95.47%\n",
      "\t test  Loss: 0.699 | test  Acc: 74.83%\n",
      "\t best  test acc: 74.97%\n",
      "Epoch: 09 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.116 | Train Acc: 97.19%\n",
      "\t test  Loss: 0.765 | test  Acc: 74.92%\n",
      "\t best  test acc: 74.97%\n",
      "Epoch: 10 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.096 | Train Acc: 97.72%\n",
      "\t test  Loss: 0.852 | test  Acc: 74.87%\n",
      "\t best  test acc: 74.97%\n",
      "Epoch: 11 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.091 | Train Acc: 97.79%\n",
      "\t test  Loss: 0.920 | test  Acc: 74.87%\n",
      "\t best  test acc: 74.97%\n",
      "Epoch: 12 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.084 | Train Acc: 97.87%\n",
      "\t test  Loss: 0.923 | test  Acc: 74.79%\n",
      "\t best  test acc: 74.97%\n",
      "Epoch: 13 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.070 | Train Acc: 98.48%\n",
      "\t test  Loss: 0.888 | test  Acc: 75.91%\n",
      "\t best  test acc: 75.91%\n",
      "Epoch: 14 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.060 | Train Acc: 98.71%\n",
      "\t test  Loss: 0.912 | test  Acc: 76.04%\n",
      "\t best  test acc: 76.04%\n",
      "Epoch: 15 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.056 | Train Acc: 98.78%\n",
      "\t test  Loss: 1.018 | test  Acc: 74.31%\n",
      "\t best  test acc: 76.04%\n",
      "Epoch: 16 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.050 | Train Acc: 98.85%\n",
      "\t test  Loss: 0.957 | test  Acc: 75.71%\n",
      "\t best  test acc: 76.04%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.042 | Train Acc: 99.02%\n",
      "\t test  Loss: 1.045 | test  Acc: 74.03%\n",
      "\t best  test acc: 76.04%\n",
      "Epoch: 18 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.040 | Train Acc: 99.01%\n",
      "\t test  Loss: 1.080 | test  Acc: 75.25%\n",
      "\t best  test acc: 76.04%\n",
      "Epoch: 19 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.032 | Train Acc: 99.31%\n",
      "\t test  Loss: 1.078 | test  Acc: 74.69%\n",
      "\t best  test acc: 76.04%\n",
      "Epoch: 20 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.042 | Train Acc: 98.95%\n",
      "\t test  Loss: 1.027 | test  Acc: 75.02%\n",
      "\t best  test acc: 76.04%\n",
      "Epoch: 21 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.030 | Train Acc: 99.27%\n",
      "\t test  Loss: 1.138 | test  Acc: 74.87%\n",
      "\t best  test acc: 76.04%\n",
      "Epoch: 22 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.020 | Train Acc: 99.57%\n",
      "\t test  Loss: 1.205 | test  Acc: 74.69%\n",
      "\t best  test acc: 76.04%\n",
      "Epoch: 23 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.016 | Train Acc: 99.67%\n",
      "\t test  Loss: 1.270 | test  Acc: 74.31%\n",
      "\t best  test acc: 76.04%\n",
      "Epoch: 24 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.030 | Train Acc: 99.15%\n",
      "\t test  Loss: 1.238 | test  Acc: 74.18%\n",
      "\t best  test acc: 76.04%\n",
      "Epoch: 25 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.023 | Train Acc: 99.31%\n",
      "\t test  Loss: 1.164 | test  Acc: 74.46%\n",
      "\t best  test acc: 76.04%\n",
      "Epoch: 26 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.017 | Train Acc: 99.52%\n",
      "\t test  Loss: 1.206 | test  Acc: 75.02%\n",
      "\t best  test acc: 76.04%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MR\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MR'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16143, 100])\n",
      "16143\n",
      "16143\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 3,604,601 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.694 | Train Acc: 51.38%\n",
      "\t test  Loss: 0.692 | test  Acc: 47.56%\n",
      "\t best  test acc: 47.56%\n",
      "Epoch: 02 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.688 | Train Acc: 54.68%\n",
      "\t test  Loss: 0.690 | test  Acc: 55.39%\n",
      "\t best  test acc: 55.39%\n",
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.672 | Train Acc: 59.19%\n",
      "\t test  Loss: 0.674 | test  Acc: 59.12%\n",
      "\t best  test acc: 59.12%\n",
      "Epoch: 04 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.643 | Train Acc: 64.21%\n",
      "\t test  Loss: 0.657 | test  Acc: 61.58%\n",
      "\t best  test acc: 61.58%\n",
      "Epoch: 05 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.550 | Train Acc: 73.75%\n",
      "\t test  Loss: 0.665 | test  Acc: 63.50%\n",
      "\t best  test acc: 63.50%\n",
      "Epoch: 06 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.442 | Train Acc: 81.14%\n",
      "\t test  Loss: 0.648 | test  Acc: 68.53%\n",
      "\t best  test acc: 68.53%\n",
      "Epoch: 07 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.325 | Train Acc: 87.71%\n",
      "\t test  Loss: 0.674 | test  Acc: 69.00%\n",
      "\t best  test acc: 69.00%\n",
      "Epoch: 08 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.237 | Train Acc: 91.94%\n",
      "\t test  Loss: 0.708 | test  Acc: 71.23%\n",
      "\t best  test acc: 71.23%\n",
      "Epoch: 09 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.188 | Train Acc: 93.97%\n",
      "\t test  Loss: 0.777 | test  Acc: 71.70%\n",
      "\t best  test acc: 71.70%\n",
      "Epoch: 10 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.137 | Train Acc: 96.02%\n",
      "\t test  Loss: 0.874 | test  Acc: 71.75%\n",
      "\t best  test acc: 71.75%\n",
      "Epoch: 11 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.124 | Train Acc: 96.04%\n",
      "\t test  Loss: 0.884 | test  Acc: 70.78%\n",
      "\t best  test acc: 71.75%\n",
      "Epoch: 12 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.085 | Train Acc: 97.75%\n",
      "\t test  Loss: 0.974 | test  Acc: 71.01%\n",
      "\t best  test acc: 71.75%\n",
      "Epoch: 13 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.066 | Train Acc: 98.29%\n",
      "\t test  Loss: 1.073 | test  Acc: 70.49%\n",
      "\t best  test acc: 71.75%\n",
      "Epoch: 14 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.063 | Train Acc: 98.30%\n",
      "\t test  Loss: 1.088 | test  Acc: 70.22%\n",
      "\t best  test acc: 71.75%\n",
      "Epoch: 15 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.063 | Train Acc: 98.10%\n",
      "\t test  Loss: 1.047 | test  Acc: 72.31%\n",
      "\t best  test acc: 72.31%\n",
      "Epoch: 16 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.039 | Train Acc: 99.11%\n",
      "\t test  Loss: 1.159 | test  Acc: 71.85%\n",
      "\t best  test acc: 72.31%\n",
      "Epoch: 17 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.032 | Train Acc: 99.33%\n",
      "\t test  Loss: 1.140 | test  Acc: 71.61%\n",
      "\t best  test acc: 72.31%\n",
      "Epoch: 18 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.061 | Train Acc: 98.28%\n",
      "\t test  Loss: 1.057 | test  Acc: 73.06%\n",
      "\t best  test acc: 73.06%\n",
      "Epoch: 19 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.044 | Train Acc: 98.83%\n",
      "\t test  Loss: 1.117 | test  Acc: 71.66%\n",
      "\t best  test acc: 73.06%\n",
      "Epoch: 20 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.029 | Train Acc: 99.19%\n",
      "\t test  Loss: 1.162 | test  Acc: 71.75%\n",
      "\t best  test acc: 73.06%\n",
      "Epoch: 21 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.025 | Train Acc: 99.40%\n",
      "\t test  Loss: 1.218 | test  Acc: 72.13%\n",
      "\t best  test acc: 73.06%\n",
      "Epoch: 22 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.029 | Train Acc: 99.16%\n",
      "\t test  Loss: 1.214 | test  Acc: 72.50%\n",
      "\t best  test acc: 73.06%\n",
      "Epoch: 23 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.022 | Train Acc: 99.46%\n",
      "\t test  Loss: 1.197 | test  Acc: 72.59%\n",
      "\t best  test acc: 73.06%\n",
      "Epoch: 24 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.020 | Train Acc: 99.45%\n",
      "\t test  Loss: 1.309 | test  Acc: 71.47%\n",
      "\t best  test acc: 73.06%\n",
      "Epoch: 25 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.014 | Train Acc: 99.66%\n",
      "\t test  Loss: 1.376 | test  Acc: 72.96%\n",
      "\t best  test acc: 73.06%\n",
      "Epoch: 26 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.009 | Train Acc: 99.85%\n",
      "\t test  Loss: 1.468 | test  Acc: 71.62%\n",
      "\t best  test acc: 73.06%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVbUlEQVR4nO3deXgT1f4G8HeSJum+UbpBaUFkkaVAgYJcFKVY4IoCIohctqvwQ1FBLl5AdlxQryJeQFEUERVQEMEFEaygyCqbwLUsQoFCN0qXtKVrcn5/TBtauiU07aTT9/M88ySZTCbfpNPO2zPnzEhCCAEiIiIildAoXQARERGRPTHcEBERkaow3BAREZGqMNwQERGRqjDcEBERkaow3BAREZGqMNwQERGRqjDcEBERkaow3BAREZGqMNwQERGRqigabn799VcMGjQIwcHBkCQJW7ZsqfY1u3fvRpcuXWAwGNCyZUusWbOm1uskIiKi+kPRcJOTk4Pw8HCsWLHCquXj4uLw97//Hffddx+OHz+OqVOn4sknn8SPP/5Yy5USERFRfSE5yoUzJUnC119/jcGDB1e6zIwZM/D999/j1KlTlnmPPfYYMjIysH379jqokoiIiBydk9IF2GL//v2IiooqMy86OhpTp06t9DX5+fnIz8+3PDabzUhLS0OjRo0gSVJtlUpERER2JIRAVlYWgoODodFUfeCpXoWbpKQkBAQElJkXEBAAo9GI3NxcuLi4lHvN4sWLsXDhwroqkYiIiGpRfHw8mjZtWuUy9Src3I5Zs2Zh2rRplseZmZlo1qwZ4uPj4enpqWBlRASTCdi3D0hKAgIDgbvvBrRa5ddlDyYT0L49kJBQ+TJNmgAnT8p1mkzAjRvylJNT9n5WFvDcc0B6unXrsqXGmn5n33wDjB5d+fOffgo89JB1tVT3ffn7Axs2APn58neTm3vze8rNlb+r3Fzg3Dm5ruqMGSO/p7s74OYmT7fed3YGevSouq7AQGDzZvn9MzMBo7H8lJkJxMUBhw5VX5eLC6DTASVHF269BYCiInm7cBQGA+DqCggBZGRUv/yHHwKPPmrTWxiNRoSEhMDDw6PaZetVuAkMDERycnKZecnJyfD09Kyw1QYADAYDDAZDufmenp4MN0RK2rwZmDIFuHLl5rymTYF33gGGDlVuXYC8o92zB0hMBIKCgN69bd/p79pV9Q4RAK5eBUJDgYICeYddE1evAu++C4wfDwQHV7+8Pb4zkwmYNavy5yUJePFFOdxkZgJpaXJAS0srO6WnA6dPV/99paQA999vXW3WWLvWPutJSpKDob3k5sqTPej1gJeXHDxKJje3svczMoBvv61+XStWAH/7mxy+XF3lWxcXOQCWBK/du4H77qt+XXfcAdzmPtiaLiX1rkPxtm3bcPLkScu8xx9/HGlpaVZ3KDYajfDy8kJmZibDDdHtsMeOf/NmYNgw+b+80kr+aG3aZP0O1p7rKlmfrTt9sxm4cAE4dkyejh4F9u+X/2O3lSTdbDko2Qnl5gLnz1u/jqAgICIC6Nr15lT6kH5NvzOzWQ4aW7cCkyZZX5c9+PoCfn7ld9Cl71+7BqxbV/26BgwAPDyA7OzKJ7PZurrc3OSWJS+vyqekJGDJkurX9emnQPfu8v2Sn1HpWyHkFqDx46tf165dQJ8+VS9jMgFhYXJArigSSJL8OxAXV/3vuj3XdQub9t9CQVlZWeLYsWPi2LFjAoBYsmSJOHbsmLh06ZIQQoiZM2eK0aNHW5a/cOGCcHV1FS+88IKIjY0VK1asEFqtVmzfvt3q98zMzBQARGZmpt0/D5HqffWVEE2blvx5laemTeX51ioqKr+O0pMkCRESIi9Xl+sq+XySVPF6JEl+vrBQiJMnhfjkEyGmThXinnuE8PSsvIbqpo8/FuLiRSGuXRPixg0hzObyde3aZd26mjcXQqOp+LmmTYV4+GEhFi4Uws+v6u8sKEiIn34S4rPPhHj9dSGee06IRx4RokcP+ft0crL9c+p0QgQECNG2rRC9egkxaJAQY8fK3+GiRfJ7WLOeXbus3y4q+lnasl2YzUL88IPj1WXvdQlxc9u/dX2lt31r2XNdpdiy/1Y03OzatUsAKDeNHTtWCCHE2LFjxb333lvuNZ06dRJ6vV60aNFCfPzxxza9J8MN0W2yZsdfFbNZiNRUIT780LqdRa9eQgweLO+QH3pIngYNkqcHH5SnHj2sW9eoUUK8/LIQS5YIsXKlEGvXCrFpkxDffy/vlA4eFOL4cSECA6tej14vhMFQ8XMGgxDdugkxcaL8Hvv2CdGkSd3vyHJyhNi7V4j//leIMWOEuOuuyl9Xk0mjEcLX17plt22rOLTd7me0ZXut6Q7WUeuy97pK1nfrPwshIbcXRuy5rmK27L8d5rBUXeFhKaLbUNLUXPpQTWmSJHeq/PRTIDlZbpJOSLh5WzLVtF+Jo/DwADp1Arp0ATp3lm/btJE7gZZWcvgHkP+8l6jJ4bfbWVd2NnD8OHD4sLzc3r3Vv19gINC2rdxRuaIpMFB+b3segqjh92UymVBYWHhzxo4dwKuvyoeDSgQFyf2EHnig+npKr2fKlMrreucd29dnj7rsvS5A/l0/ckQ+7OjvLx/erEknfxvXpdfrKx3mbcv+m+GGiKpnbSdBa3h6WtcX5fnngdat5fuSVPHIkdOngTffrH5dQ4bIfTVKj665dbRNWpp1o0+WLJF3dNWcZ8Oioj48ISHA0qX26Tht67qs/Vla01ejpCZ7BbiS9dn4GYUQSEpKQkZFo3SEkEO1ySTvWA2GsqOOrFWyjZhMN+dptfJ25epq+/rsVZe916UwjUaD5s2bQ6/Xl3uO4aYKDDdENhJC/s9wzpzqlw0MlFswmjSRR+yU3JbcDwoCnJwcs/OivXf6t9ZZ007Y9lpXbXT4tGeAK6nRhs+YmJiIjIwM+Pv7w9XVtfZO0CqEHHIKCuRRSK6u9TZEOCKz2YyEhATodDo0a9as3M+R4aYKDDdEVjCb5dEYmzYBX30FXLxo3euU+G/fXuuqxVEeDsferS2AfQOcTW9rwtmzZ+Hv749GjRrV+vtR7crMzERCQgJatmwJ3S2HeW3Zfyt64UwiqoLJJLcmrF8v35ZuDq+NdZnNwG+/AVOnyude6dkTeOstOdiUnM+iMpIk/6feu7d19QwdKu9AmzQpO79pU9t3rPZal1Yr950Ayv83XvJ46dL6H2wA+37/JbRaOdiOHCnf1tH3VNLHxvV2Dg2Rwyk5HGWqyd87sOVG6XKIKlZXJ7h7+GH5v+1Nm+TlEhNvLuPuDgwaJP+H378/sH27Y/+3b6912fsQiyNTqLXFnvLy8hAXF4fmzZvD2dlZ6XKohqr6efKwVBUYbsjh1cUJ7krc2rnXy0s+m+ywYfJIi1t3Fg1lx6+CnX5DwXCjLvYKN/Xq8gtEqmcyyeGhojBSMm/CBHnUhiTJh5IqOvuG2Syva8GCyoMNIAcbb295NNGwYUDfvvJIi8oMHXqztUfNO/6SQyxE9URYWBimTp2KqVOn1nhdu3fvxn333Yf09HR4e3vXeH1KYLghciR79lR+LpkSaWlywLGXjRuBqCjrl+eOn9Sqjlvs+vTpg06dOmHp0qU1Xtfvv/8ONze3mhelEgw3RI5ACLkz79y51i3fqZPcb0aS5POtlJwHpvR05Qpw4ED167p2rUalE6mCvS++agdCCJhMJjg5Vb+rbty4cR1UVH9wtBSRkq5dk09C17YtcM89csCxxttvy1fx/eYbYMsW4Ouv5T/OX30l98nZuBFYvNi6dQUF3Xb5RKpQ0jft1lbTq1fl+Zs32/0tx40bh19++QXvvPMOJEmCJElYs2YNJEnCDz/8gIiICBgMBvz22284f/48Hn74YQQEBMDd3R3dunXDTz/9VGZ9YWFhZVqAJEnChx9+iCFDhsDV1RV33nknvvnmm9uu96uvvkK7du1gMBgQFhaGt956q8zz7777Lu688044OzsjICAAw0oGHwDYtGkTOnToABcXFzRq1AhRUVHIycm57VqswXBDZE/WDrnesQN49FF5KO4LLwBnzshXFR4/Xj5NeWUnBrNlyHXv3jdbd2q6LqL6RAggJ8e6yWgEnnuu6n5uU6bIy1mzPivH6Lzzzjvo2bMnJkyYgMTERCQmJiIkJAQAMHPmTLz22muIjY1Fx44dkZ2djYEDByImJgbHjh1D//79MWjQIFy+fLnK91i4cCGGDx+OEydOYODAgRg1ahTS0tJs+ioB4MiRIxg+fDgee+wxnDx5EgsWLMDcuXOxZs0aAMDhw4fx3HPPYdGiRThz5gy2b9+Oe+65B4B8gsWRI0fin//8J2JjY7F7924MHToUtT6W6bavYFVP8cKZVGuqu2J2fLx89ePQ0LLLdOsmxAcfCGE03lyPo15Yj8jB5Obmij///FPk5ubenJmdbf8LhVo7ZWdbXfu9994rpkyZYnlccjHpLVu2VPvadu3aiWXLllkeh4aGirffftvyGICYM2dOqa8kWwAQP/zwQ7XrLqkjPT1dCCHE448/Lvr161dmmRdeeEHcddddQgghvvrqK+Hp6SmMJX/DSjly5IgAIC5evFjt+wpRyc+zmC37b7bcENlDVc3ajzwiXzAuNBSYNw+4dEkeofTMM/LFDA8dkjsIe3jIr3HEE9wRUZ3p2rVrmcfZ2dmYPn062rZtC29vb7i7uyM2NrbalpuOHTta7ru5ucHT0xMpKSk21xMbG4tevXqVmderVy+cO3cOJpMJ/fr1Q2hoKFq0aIHRo0fj888/x40bNwAA4eHh6Nu3Lzp06IBHH30Uq1atQnp6us012Iodiolqyprh20ePyrf33CMHmUceqfqMv/Ycct1Qhm8TlXB1la+Ebo1ffwUGDqx+uW3b5N9fa967hm4d9TR9+nTs3LkTb775Jlq2bAkXFxcMGzYMBQUFVa7n1ssXSJIEs9lc4/pu5eHhgaNHj2L37t3YsWMH5s2bhwULFuD333+Ht7c3du7ciX379mHHjh1YtmwZZs+ejYMHD6J58+Z2r6UEww1RTVkzfBsA1q4FRo+2fr32HHLN4dvUkEiS3IfNGg88ILdkVndNsQcesPs/BHq93qrLDOzduxfjxo3DkCFDAMgtORetvd6bHbRt2xZ79+4tV1OrVq2gLf5OnJycEBUVhaioKMyfPx/e3t74+eefMXToUEiShF69eqFXr16YN28eQkND8fXXX2PatGm1VjPDDVFNHTxo3XJWDOckojpWck2xYcPkIFPRpUVq6ZpiYWFhOHjwIC5evAh3d/dKW1XuvPNObN68GYMGDYIkSZg7d26ttMBU5l//+he6deuGl156CSNGjMD+/fuxfPlyvPvuuwCA7777DhcuXMA999wDHx8fbNu2DWazGa1bt8bBgwcRExODBx54AP7+/jh48CCuXbuGtm3b1mrN7HNDdDuysoAPPwR69ABmzrTuNRxyTeSYFOqbNn36dGi1Wtx1111o3LhxpX1olixZAh8fH9x9990YNGgQoqOj0aVLl1qpqSJdunTBl19+iQ0bNqB9+/aYN28eFi1ahHHjxgEAvL29sXnzZtx///1o27YtVq5cifXr16Ndu3bw9PTEr7/+ioEDB6JVq1aYM2cO3nrrLQwYMKBWa+a1pYisJYTcSvPhh8CGDfKwT0D+j06vB3JzK35dSbN2XBz7uRDZmV2vLcVriimO15Yispfq/qClpgKffSaHmv/97+b81q2BJ5+U+9Hs3Vv1FbNrqVmbiOyIfdNUg+GGGrbKTrn+9tvycO0PP5TP/lsyKsHFBRg+XA41vXrdDC8lzdoVrUttV8wmonpt0qRJ+Oyzzyp87h//+AdWrlxZxxXZHw9LUcNVcm4aa34FIiLkQDNyJODlVflybNYmqlN2PSzVQKSkpMBoNFb4nKenJ/z9/eu4opt4WIqoJqo6N00JSQImTZLPS9O5s3XrZbM2ETk4f39/RQNMXeBoKWqYrDk3jRDyIShrgw0RETkEhhtqmBIT7bscERE5DIYbapgKC61bjuemISKqd9jnhhqe776TL1pZlZJz0/TuXTc1ERGR3bDlhhoOIYBXXwUeekg+w/Bdd8khpmQ4dwmem4aIqF5juKGGIScHGDECmD1bDjlPPw0cP67IKdeJiBzBxYsXIUkSjh8/rnQpdsfDUqR+Fy8CDz8MnDgB6HTAihXy8G5ADjAPP8xz0xBRnevTpw86deqEpUuX2mV948aNQ0ZGBrZs2WKX9dVnDDekbrt3yyfqu34dCAgAvvpKPrNwaTw3DREVO2w04t8XLuCNFi3QlSd6rbd4WIrUSQhg2TIgKkoONl27AocPlw82RESlrE1Oxq6MDHyanFyr7zNu3Dj88ssveOeddyBJEiRJwsWLF3Hq1CkMGDAA7u7uCAgIwOjRo5Gammp53aZNm9ChQwe4uLigUaNGiIqKQk5ODhYsWIBPPvkEW7dutaxv9+7dNtf1yy+/oHv37jAYDAgKCsLMmTNRVFRU7fsDwO7du9G9e3e4ubnB29sbvXr1wqVLl2r8Xd0OttyQ+uTny31qVq+WH//jH8AHH8jXhSIi1RNC4IbZbPXyl/PycL2wEJIkYUNKCgBgfUoKhvv7QwiBRjodmll5aQdXjQbSrYMUKvDOO+/g7NmzaN++PRYtWgQA0Ol06N69O5588km8/fbbyM3NxYwZMzB8+HD8/PPPSExMxMiRI/HGG29gyJAhyMrKwp49eyCEwPTp0xEbGwuj0YiPP/4YAODr62v1dwAAV69excCBAzFu3DisXbsWp0+fxoQJE+Ds7IwFCxZU+f5FRUUYPHgwJkyYgPXr16OgoACHDh2y6ruoDQw3pC6JiXI/mgMHAI0G+M9/gOefLz8iiohU64bZDPc9e2q0jmuFhfjbsWM2vy67d2+4WdFnz8vLC3q9Hq6urggMDAQAvPzyy+jcuTNeffVVy3KrV69GSEgIzp49i+zsbBQVFWHo0KEIDQ0FAHTo0MGyrIuLC/Lz8y3rs9W7776LkJAQLF++HJIkoU2bNkhISMCMGTMwb948JCYmVvr+aWlpyMzMxIMPPog77rgDANC2bdvbqsMeeFiK6ieTSe5Ps369fGsyAYcOyYefDhyQr+j9ww/AtGkMNkRUL/zxxx/YtWsX3N3dLVObNm0AAOfPn0d4eDj69u2LDh064NFHH8WqVauQnp5ut/ePjY1Fz549y7S29OrVC9nZ2bhy5UqV7+/r64tx48YhOjoagwYNwjvvvINEBc/wzpYbqn82b5Yveln62lA+PvK5a4qK5PPXbN0KtGypXI1EpBhXjQbZNp6A83h2doUtNb917oxO7u42vfftys7OxqBBg/D666+Xey4oKAharRY7d+7Evn37sGPHDixbtgyzZ8/GwYMH0bx589t+X2tV9/4ff/wxnnvuOWzfvh1ffPEF5syZg507d6JHjx61Xtut2HJD9cvmzfLop1svepmeLgebbt3klhsGG6IGS5IkuGm1Nk0uxaGkZKdYcuui0di0Hlv6mOj1ephMJsvjLl264H//+x/CwsLQsmXLMpObm5vls/Xq1QsLFy7EsWPHoNfr8fXXX1e4Plu1bdsW+/fvhxDCMm/v3r3w8PBA06ZNq31/AOjcuTNmzZqFffv2oX379li3bt1t11MTDDdUf5hMcotNqV+8cpKSAFfXuquJiFTBX6dDoE6HCA8PrGzVChEeHgjU6eCv09Xae4aFheHgwYO4ePEiUlNTMXnyZKSlpWHkyJH4/fffcf78efz4448YP348TCYTDh48iFdffRWHDx/G5cuXsXnzZly7ds3StyUsLAwnTpzAmTNnkJqaikJrr6FX7Omnn0Z8fDyeffZZnD59Glu3bsX8+fMxbdo0aDSaKt8/Li4Os2bNwv79+3Hp0iXs2LED586dU67fjWhgMjMzBQCRmZmpdClkq127hJCjTdXTrl1KV0pEdSQ3N1f8+eefIjc3t8bryjOZhNlsFkIIYTabRZ7JVON1VuXMmTOiR48ewsXFRQAQcXFx4uzZs2LIkCHC29tbuLi4iDZt2oipU6cKs9ks/vzzTxEdHS0aN24sDAaDaNWqlVi2bJllfSkpKaJfv37C3d1dABC7qvlbGBcXJwCIY8eOWebt3r1bdOvWTej1ehEYGChmzJghCgsLhRCiyvdPSkoSgwcPFkFBQUKv14vQ0FAxb948YbLxO6zq52nL/lsSoqp/g9XHaDTCy8sLmZmZ8OQJmuqX9euBxx+vfrl164CRI2u/HiJSXF5eHuLi4tC8eXM4WzlcmxxXVT9PW/bfPCxF9UdQkH2XIyIiVWK4ofqjd2+gqpNSSRIQEiIvR0TUwL366qtlhpWXngYMGKB0ebWKQ8Gp/jhxQh7uXZGSEQpLl/Kil0REACZNmoThw4dX+JyLys/YznBD9cP16/KZhwsLgc6dgWvXyg4Hb9pUDjZDhypWIhGRI/H19bX5EgxqwXBDjs9kkjsIX7wI3HEHEBMDeHoCe/bIl1sICpIPRbHFhoiIwHBD9cHs2cDOnfL5a77+Wj4bMQD06aNoWUTkOMw2XCiTHJe9BnAz3JBj27gRKDkV+erVQKmLxBER6fV6aDQaJCQkoHHjxtDr9YpdiZpqRgiBa9euQZIk6Gp48kSGG3Jcp04B48fL96dPB0aMULYeInI4Go0GzZs3R2JiIhISEpQuh2pIkiQ0bdoU2hp2M2C4IceUkQEMGQLk5AB9+wKLFytdERE5KL1ej2bNmqGoqKhG11Yi5el0uhoHG4DhhhyR2QyMHg389RfQrBmwYQPgxE2ViCpXciijpoczSB14Ej9yPIsWAd99BxgM8lXA/fyUroiIiOoRhhtyLN98AyxcKN9//30gIkLZeoiIqN5huCHHceaMfDgKACZPBsaOVbYeIiKqlxhuyDFkZckdiI1G4G9/A5YsUboiIiKqpxhuSHlCyEO+Y2OB4GD53DZ6vdJVERFRPcVwQ8p7/XXgq68AnQ7YtAkIDFS6IiIiqscYbkhZP/4IvPiifH/ZMqBnT2XrISKieo/hhpRz4YJ8QUwhgCeeACZOVLoiIiJSAZ4ZjeqOyXTzSt4+PsCMGUB6OtCtG7B8OcDrwRARkR0w3FDd2LwZmDIFuHKl7HxPT7m/jbOzMnUREZHq8LAU1b7Nm4Fhw8oHG0Ae+v3773VfExERqRbDDdUuk0lusRGi4uclCZg6VV6OiIjIDhhuqHbt2VNxi00JIYD4eHk5IiIiO1A83KxYsQJhYWFwdnZGZGQkDh06VOXyS5cuRevWreHi4oKQkBA8//zzyMvLq6NqyWaJifZdjoiIqBqKhpsvvvgC06ZNw/z583H06FGEh4cjOjoaKSkpFS6/bt06zJw5E/Pnz0dsbCw++ugjfPHFF3ix5Dwp5HiCguy7HBERUTUkISrrDFH7IiMj0a1bNyxfvhwAYDabERISgmeffRYzZ84st/wzzzyD2NhYxMTEWOb961//wsGDB/Hbb79Z9Z5GoxFeXl7IzMyEp6enfT4IVc5kApo0AZKTK35ekoCmTYG4OECrrdvaiIio3rBl/61Yy01BQQGOHDmCqKiom8VoNIiKisL+/fsrfM3dd9+NI0eOWA5dXbhwAdu2bcPAgQMrfZ/8/HwYjcYyE9WhoqLKh3mXnNdm6VIGGyIishvFznOTmpoKk8mEgICAMvMDAgJw+vTpCl/z+OOPIzU1FX/7298ghEBRUREmTZpU5WGpxYsXY+HChXatnWwwezZw6RLg4QG4u5ftW9O0qRxshg5VrDwiIlIfxTsU22L37t149dVX8e677+Lo0aPYvHkzvv/+e7z00kuVvmbWrFnIzMy0TPHx8XVYcQMXEwO89ZZ8/7PP5FFRu3YB69bJt3FxDDZERGR3irXc+Pn5QavVIvmWvhjJyckIrOSq0HPnzsXo0aPx5JNPAgA6dOiAnJwcTJw4EbNnz4ZGUz6rGQwGGAwG+38AqlpaGjB2rHx/4kTgoYfk+336KFYSERE1DIq13Oj1ekRERJTpHGw2mxETE4OelVwZ+saNG+UCjLa4r4aC/aLpVkIAkyYBV68Cd94JLFmidEVERNSAKHptqWnTpmHs2LHo2rUrunfvjqVLlyInJwfjx48HAIwZMwZNmjTB4sWLAQCDBg3CkiVL0LlzZ0RGRuKvv/7C3LlzMWjQIEvIIQfw2WfAxo1yJ+HPPwfc3JSuiIiIGhBFw82IESNw7do1zJs3D0lJSejUqRO2b99u6WR8+fLlMi01c+bMgSRJmDNnDq5evYrGjRtj0KBBeOWVV5T6CHSruDhg8mT5/oIF8hW/iYiI6pCi57lRAs9zU4tMJuDee4G9e4FevYBffuEQbyIisot6cZ4bUqHXX5eDjYcH8OmnDDZERKQIhhuyj8OHgfnz5fvLlgHNmytbDxERNVgMN1RzOTnAqFHy2YgffRQYM0bpioiIqAFjuKGamz4dOHsWCA4GVq68eVkFIiIiBTDcUM18+60caADgk08AX19l6yEiogaP4YZuX3Iy8MQT8v1p04BSF0ElIiJSCsMN3R4h5GBz7RrQoQPAcw0REZGDYLih27NyJfD994DBIJ+F2NlZ6YqIiIgAMNzQ7Th9GvjXv+T7r70mt9wQERE5CIYbsk1BgTzsOzdX7mPz3HNKV0RERFQGww3ZZsEC4OhReVTUmjWAhpsQERE5FkUvnEn1gMkE7NkDJCbKnYeLr9CO998HmjRRtjYiIqIKMNxQ5TZvBqZMAa5cKTv/vvuAYcOUqYmIiKgaPKZAFdu8WQ4wtwYbANi9W36eiIjIATHcUHkmk9xiI0Tly0ydKi9HRETkYBhuqLw9eypusSkhBBAfLy9HRPXaYaMR9x8/jsNGo9KlkINQwzbBcEPlJSbadzkiclhrk5OxKyMDnyYnK11Kg+OoIUIN2wTDDZUXFGTf5YjqIUfd8djDpbw8HMnKwu70dHyalAQA2JCSgqNZWTiSlYVLeXkKV+i47LldOFKIKNkmjmZl4YuUFAD1e5vgaCkqr3dvoGnTyg9NSZL8fO/edVsXUR0qvePp6umpdDl2YRICh7Oy0OPo0XLPpRQWIuLIEctj0adPHVZWuw4bjfj3hQt4o0WLGv8sa7pdXMrLQ2phISSgTIgYGxgIAcBPp0OoApezCTtwoNy8+rxNMNxQeVot8OST8gn7biVJ8u3SpfJyVKvs+UeZqlebOx6lfpZX8/OxIy0N29PS8FN6OtKKiqx6XdfDhxHl44N+vr7o5ekJ5zr+fXekQHI6JwcXcnORZTJZWlk+SUpCE70eRULARauFl5MTioRAoRAoNJst9y3ziu+/GR9fbv1KhYi43FxsS0vDD9evQy9JKKhiEImPVosxsbG439sb9/v4oJmDX0+Q4YbKM5uB776T77u5ATk5N59r2lQONkOHKlJafeBIf5TJNtb893q6e3cE6HTwcnKCVBL2rWDPn2VV21ieyYTfMjOxPS0NP6an41Tp318AXlotonx80NbVFS9fvlxu3Xc4O+N8Xh6OZGfjSHY2Xo+Ph7NGg3u8vOSw4+ODju7u0FTw2R1p268oqK5PScEAX19kFAc8vUaD64WFSCsqQlphYdn7xbdpRUXIM5vLrT/TZMKMuLgafcaKdHV3x+uXLyPSwwNdPTzg7mS/3XS+2YxfMzIsgeZMbm6Z5/2cnJBaQfjVAUgvDnYl4e4OZ2fc7+ODvj4+uM/bG/56fYXvqVSoZ7ih8r78Ejh8GHB3B86eBc6ckTsPBwXJh6JU2GLj6H+UHaHZuiH4b8uWmPrXXyi/K7upzaFDAAC9JCFAr5cnne7mfb0e/sWPTUJAA8DLycmuP8vS21iEhwfO3LiBH9PT8WNaGnZnZCC31M5YAtDNwwP9fX0R7euL7h4ecNJocDQrCy9fvgwNADNguf2yXTsE6fX4KT0dO9PT8VN6OhILCrAjPR070tMBAI11OkT5+FjCTkjxZ6irbT/XZKowkKQVFVkef1jBgIdrhYUYcPKkzXVVRQLQ3tUVzZyd4SRJ0Gk08m3x5FT6VqOBTpJwraAAHxb3dbrV4exsHM7OBiD/TNq5uSHS0xORHh6I9PTEXW5u0NoQLC/m5uKHtDRsS0vDz+npuFFq29AC6OXlhQG+vhjQqBGKzGZ0PXq03Daxu3Nn5JrN+Dk9HT9nZOB3oxHn8/JwPjERq4q/5/Zubrjf2xt9fXxwj5cXvHU6AMr9gyYJUdXJTNTHaDTCy8sLmZmZ8OR/wuXl5wNt2wJxccBLLwFz5ihdUZ147tw5LLt6Fc81aYJ37rzTptcKIfC/nBycy81FWmEh/nX+PDJNJnhotZjSpAnMAFw0GvjodDAJAbMQMAHyrRAwA5ZbsxBYdOlS9e+p8LFvNR0uMwmB7WlpeD8hAd9fv15psAl3c8MNsxnJBQUw2vEcT+MCA+Gu1cJdq4WbRnPz/i23xuIWBFetFiP+/BOphYVw1mjgrdUiqbCwzDqD9XpEF4eZKB8fNCre0ZR2JS8P3Y4cQYizM54ICsJHiYmIz8vD7xERaFoqcAkh8OeNG9hZfFhrd0YGcm5pyQg1GBDp6Ykf09KQaTLB28kJi5s3R5EQcC3e9m89TFNUweGbF61oCXHRaMqEt9sVpNejubMzGul08HVygq9OV/Z+8a2vkxMa6XQ4e+MGulbQV+lIRAS6eHjY9N5Hs7IQceRIuRCxqlUrZBQV4WBWFg4ajYjPzy/3WnetFl09PCxhJ9LTE8EGg+Vv2OTgYAz287MEmtM3bpT73AN8fTGgeNvwLrVtWLtNGIuKsCczEzHp6fg5PR1/3NI6KAFo6+qKbh4e2JqaigyTCf46HX7o2LFGod6W/TfDDZW1dCnw/PNyK825c/JhKZUq/V/igBMnkFJYaPkFNAsBnSRBr9EguaAAyYWF8m3JVOpxSmFhhc3WtaWtqyuifX3Ryd0dndzd0dbVFXorLmBqz0BSkzDoKK7m5+OjxER8mJhYZifSxd0dR7Ozy+14Su/Eck0mpFSxTZQ8vpyXV+Y/5dr2nxYtEO3ri/ZublYdMss3m6GXJEiSBCEECoSAoZptqcBsxgGj0dKqc0Ch0WRaoEz4KHO/OJgYi4owq4LAZM9AcjvrsjZEJObn46DRaAk7v2dlIbuCYO2v0yGzqAj5FezOtQDuLmmd8fVFuLt7ldvG7WwTqQUF2J2RgZ8zMhCTno6ztxzuqsjt/IPGcFMFhpsqZGQALVsC168DH3wATJigdEW1Stq9u27eB0CEuzuau7hAA0ArSdBIErSAfCtJN+cX36YWFmJdcbN8dXSShHZubpaw08ndHeFubmX+IwNqHkiqCoM1+W+sLluBTEJgR3ErzXfXr6NkN+Hr5IRxgYGYEBQEd63Wqh2PtQ5mZqLHsWPl5s8PDYWfToccsxnZJhOyTSbkFN9W9DitsBDZlQQlJ0nCmjZtMCogwOb6auqDq1fx9LlzqKwtq4WzMwL0+rKHaUodurn1Nr2oCF9eu1ZuPStatkSkl5clwHhotdUGOCUCibVuJ0SYhEBsTo4l7Kyy4lxj6b16lftbUNuWXblS6eHdmmyrDDdVYLipwqxZwGuvyYelTpwA7NiRzdEIIfDihQt4PT4eVf0CeGm1ZfpS3Nq3ovTj0zdulOl4WsKe/yWua9sW+WYzjmdnW6bMSg6RhDk7405nZ4Q5O6O1qysWX76M60VFaKzTYV3btsgxm+EsSfBycrLsYHNKT7fMW11JH4HStrZvj2C9HkEGAwJ0OjhZ0aJkz1agyoJSYn4+ViclYVVCAi6VaqXp7eWF/wsOxiN+fmVGA93Ojqcy9tzBlqzrVrezLnuyZ11qCyS16fPkZIw7fRpFFezGlQy8QO1sq7bsv9W79yLbxMfLh6QA4PXXVRtsckwmfJqUhGVXr+LPW45Fl/Zdhw7o6+19W8Nfb/2jfDv8dToE6nTl/ij39vIq1x/iUl5embBzPDsbl/LzcTEvDxcrOPHWtcJC9Dtx4jYrq9rDp05Z7kvFnyPYYECQXo8gvd5y36n4kF9jnQ4baqmjbRcPD/yUno73ExLwzfXrlh2At5MTxgYEYGJwMO6q5LBr6R2WJEkw2DAq6laV/Sz9a/DftD22sdpQm9v+7XxfTZ2dcbFnT0sgmRgUVKNAYs/twh5GBQSgratrhSHiYJcuigbeEkptq+rcg5Ht5s0D8vKAe+4BHnxQ6WrsLi43FyuuXsVHSUmWYaDuWi0G+vriy2vXyv0CBun1NgcbJf4oS5KEMBcXhLm4YHDjxpb56YWFOJGTgw8TE/F5cnKlrVMeWi0a6XSWzqxuxR1Y3Up1cC39OLWwEC9V0OF5qJ8fCoVAYkEBEvLzkVxQABMg90MpLET5gzLl3TrkenjjxvB0coKHVgsPrbbS+1kmE/LNZrhrtZYRNh8lJuKra9dwtaDAsr67PT3xf8HBeLRxY7jU4Yg/e+5gayMo2QMDifIcLfAqva3ysBTJh6A6dZIviHnwINC9u9IV2YUQArsyMvDfK1fwzfXrlh38Hc7OeLZpU4wLDERWUZGqm60BZQ4ZmIRAamEhEvLzLYEnsaDAcv9kTg4u1OHp3E907YoO7u519n61yRG3MUeuS+3sfejNnuy9TfCwFNlmxgw52Awfropgk2My4fPkZPz3yhX8r9Shpwd8fPBc06YY4OtrOQGZl5NTg/kvsS4PGWhLnQOmcyXrqix0vdGiBfx0OmSZTMgymWAsKqrwflZREYzFHW0rGiUC3Ox3oJZgAzjuNuaodamdvVu67EnJbYLhpqGLiQG2bwd0OuDVV5Wuxia3dh69mJuLdxMS8GFiItKLDz25aTQYGxiIZ5o0Qds66F/hiBz5kAFQPnT19fGxuUXpsNGIbhWcg8RR+h0Q1Sa1/w27HQw3DZnZDPz73/L9p54C7rij1t+yNs4EvPjyZQgAW1NTLS0SLZyd8WyTJhgXGFjnwyAdjaP2YbBn6CppiXO0fgdEpAyGm4Zswwbg6FHAw6POzkR8u6fiNguBtMJCHMvOxvniMwGvLj7Hw+bUVMtyf/P0xIxmzTCgUaMKT1HeUDnif3YNoaMtESmD4aahys8HXnxRvj9zJlBqpI29VXa9mFH+/kgvKoIZch+Nqs70eq149E11fjMascfPr9Y+C9mXvUKXI/c7IKK6x3DTUK1YAVy6BAQHA1On1upbVXal5cgKztpaHVeNptLT2Zd0HqWGyRFbp4hIGQw3DVF6OvDyy/L9l14CXF1r9e0+a9u20rNoAoCnVovQ4lO0l1xNuaKzATfW6aAvvpqxI5+0ioiIlMVw0xAtXiwHnHbtgLFja/3t+nh7o4leX+a09yUOdemCbrfZsZidR4mIqCI8IN3QXL4M/Pe/8v033gBq+Uytl/LycM+xY5ZgU3KgoGTDu51OvyWdRyM8PLCyVStEeHggUKdj51EiIgLAlpuGZ+5cuTPxffcBAwbU6lv9deMG7v/jD8Tn56OZwYBcsxlhDnquFSIiUg+Gm4bk+HHg00/l+2+8AdRih8vYnBz0/eMPJBYUoI2rK34KD4efTudw51ohIiL1YbhpSEous/DYY0DXrrX2Nn9kZ6PfH3/gWmEhOri5YWd4OAL0+jLLMJAQEVFtYbhpKHbskCedDnjllVp7m8NGIx44cQLpRUXo4u6OHeHhaMS+MEREVIcYbhqC0pdZmDwZaNGiVt5mX2YmBpw4AaPJhB6envihQ4cGf+kDIiKqeww3DcHnnwN//AF4edXaZRZ2p6fjwZMnkWM24x4vL3zXoQM8nLh5ERFR3ePwErXLy7sZaGbNAho1svtb/JiWhgHFwaafjw9+6NiRwYaIiBTDcKN2y5fL57Zp2hR47jm7r/6b1FQ8dPIk8sxmPNioEb5p3x6utXzuHCIioqrw32s1MpmAPXuAc+eABQvkeS+9BLi42PVtNqak4PHYWBQJgUf8/LDurrug57lmiIhIYQw3arN5MzBlCnDlys15Oh3g7m7Xt/k0KQnjTp+GGcAof3+sadMGTgw2RETkALg3UpPNm4Fhw8oGGwAoLASGD5eft4NVCQkYWxxsnggMxCdt2zLYEBGRw+AeSS1MJrnFppIrbwMApk6Vl6uBZVeuYOLZsxAAng4OxgetW9/W9aGIiIhqC8ONWuzZU77FpjQhgPh4eTkbHTYacf/x43ju3Dk899dfAIB/NW2K5XfeCQ2DDRERORj2uVGLxET7LlfKJ8nJ2JWRgV0ZGQCAuaGhWBgWBonBhoiIHBDDjVoEBdl1uUt5eUgtLESB2YzVpQLR08HBeNjPD5fz8xHq7Hw7lRIREdUqhhu1qK5FRpLkc9307l3tqoQQCDtwoMLn3k1IwLsJCfJyffrYWiUREVGtY7hRg08+Af75z5uPJalsx+KSw0dLlwJVnGDvQm4uPk1OxtqkpCrfzkmSsKZNmxoUTEREVHsYbuq7lSuBp56S70+cCPTrBzz/fNnOxU2bysFm6NByL88sKsKXKSlYm5yM3zIzLfPdtVrc5+2Nb69fL/eag126oIuHh70/CRERkV0w3NRnS5fKQQaQL62wdKncSjNkiDwqKjFR7mPTu3eZFpsisxk70tOxNikJW1JTkV/cyiMB6OfjgzGBgRjs54czN27g2+vXoQFgBiy3REREjozhpr569VVg9mz5/owZwOLFNw8/abU43KUL/n3hAt5o0QJdi4PN8awsrE1OxrrkZCQXFlpWdZerK8YGBmJUQACaGAyW+f46HQJ1OoQ4O+OJoCB8lJiI+Lw8+Ot0dfYxiYiIbMVwU98IAcybB7z8svx44UJg7tybwabY2uLh2ysTEtA2MxNrk5JwIifH8ryfTofH/f0xNjAQnd3dKxzW3dTZGRd79oRekiBJEiYGBaFACBh4NmIiInJgDDf1iRDACy8Ab70lP37jDflxsZLh2yazGZ8Udwr+qFTnYB2Ahxs3xpiAAPT39YXOipBSOshIkgQDz21DREQOjuGmvjCbgWefBd59V368bBnwzDNlFqls+HaJQgAb27WrpQKJiIgcA8NNfWAyySOhVq+WDz998AHw5JOWpzMKC/FuQgI8tFpkVXLtKA7fJiKihkLxzhMrVqxAWFgYnJ2dERkZiUOHDlW5fEZGBiZPnoygoCAYDAa0atUK27Ztq6NqFVBUBIwZIwcbjQZYu9YSbJILCjDz/HmEHjiA2XFxyDKZEKTXV7iag126YFRAQF1WTkREpAhFW26++OILTJs2DStXrkRkZCSWLl2K6OhonDlzBv7+/uWWLygoQL9+/eDv749NmzahSZMmuHTpEry9veu++LpQUACMHAls3gw4OQHr1wPDhiEuNxf/iY/H6sREyzDudq6umNmsGVq5uCDy2DEO3yYiogZL0XCzZMkSTJgwAePHjwcArFy5Et9//z1Wr16NmTNnllt+9erVSEtLw759+6ArHo4cFhZWlyXXHpOp7LlpunUDhg8Htm0D9Hrgq6/wv/vuw2uxsVifnIySg0+RHh54MTQUDzZqBI0k4UpeHodvExFRgyYJUfo8/XWnoKAArq6u2LRpEwYPHmyZP3bsWGRkZGDr1q3lXjNw4ED4+vrC1dUVW7duRePGjfH4449jxowZ0FZyWYH8/Hzk5+dbHhuNRoSEhCAzMxOenp52/1y3ZfNmYMqUsmcVNhiA/HzAxQUHv/kGiwMCsLXU2YL7+fhgVrNm6OPtXW4Yd77ZbBm+LYTg8G0iIqr3jEYjvLy8rNp/K7bHS01NhclkQsAt/UACAgKQVMm1jS5cuIBNmzbBZDJh27ZtmDt3Lt566y28XHLOlwosXrwYXl5elikkJMSun6PGNm8Ghg0DrlzB4VatcP9bb+Fwq1YQ+fnYGRGB+9etQw8nJ2y9fh0SgEf8/PB7ly7YER6O+3x8Kjw/jUGjscyXJInBhoiIGpR6NVrKbDbD398fH3zwAbRaLSIiInD16lX85z//wfz58yt8zaxZszBt2jTL45KWG4dgMsktNsWNZ2ujo7GrSxfMHz8eyT4+ONK6NQB5pNPogAD8OyQEbdzclKyYiIjI4SkWbvz8/KDVapGcnFxmfnJyMgIDAyt8TVBQEHQ6XZlDUG3btkVSUhIKCgqgr2CkkMFggKHUJQUcyp49uFRYiNRWrWCWJKyJjgYAbOvRAwBgyM/HyJ9/xsIBA9CMw7iJiIisotjxCr1ej4iICMTExFjmmc1mxMTEoGfPnhW+plevXvjrr79gNt8c/3P27FkEBQVVGGwcXmIiwjZsQNf330f3lSuRVdIqU9ySk28wYM2AAWiWmKhgkURERPWLop0xpk2bhlWrVuGTTz5BbGwsnnrqKeTk5FhGT40ZMwazZs2yLP/UU08hLS0NU6ZMwdmzZ/H999/j1VdfxeTJk5X6CDUTFITnNm2yhBmL4v4yTkVF+OyVV+TRU0RERGQVRfvcjBgxAteuXcO8efOQlJSETp06Yfv27ZZOxpcvX4amVGfYkJAQ/Pjjj3j++efRsWNHNGnSBFOmTMGMGTOU+gi3LbuoCFOys7F62LBKlzk4eTK65OYCvXvXYWVERET1m2JDwZViy1Cy2nLYaMTjv/2Gc66ukMxmjN++HasHDoTGbIZZo7HcHvm//0OXxYuBoUMVqZOIiMhR2LL/rlejpeo7sxD4T1wc5ly8iCJXVzRNScFncXG4o0cPbMvIQEhSEp7Ytg0fDRyI+MBA+L/2GjBkiNJlExER1SsMN3XkSl4expw6hV3Z2YBGg2G//IL3mzSBb/EhtYuFhdDv3QvJywsTg4JQ0KsXDDyrMBERkc0YburA5mvX8GRsLNLNZrjm5mLZBx9g/P/9H6T+/S3LGHQ6oE8fAIAEwEEHrxMRETk8hptalGMy4fm//sKq4qHcEWfOYN2qVWj10UdAeLjC1REREakTw00tOZqVhcf//BNncnMhmc3494YNWHT0KPRbtwJNmihdHhERkWrZHG7i4+MhSRKaNm0KADh06BDWrVuHu+66CxMnTrR7gfWNWQgsiY/Hi3FxKBQCwamp+PTVV3F/YCCwaxfg4aF0iURERKpm80n8Hn/8cezatQsAkJSUhH79+uHQoUOYPXs2Fi1aZPcCHd1hoxH3Hz+Ow0YjEvLzEX3iBF64cAGFQmDIr7/ixBNP4P7ISOCbbxhsiIiI6oDN4ebUqVPo3r07AODLL79E+/btsW/fPnz++edYs2aNvetzeGuTk7ErIwMLL11Cx99/x0/p6XApLMT7b72Fr+bPR6O5c4F33wWceASQiIioLti8xy0sLLRciPKnn37CQw89BABo06YNEhvINZAu5eUhtbAQktmMDVevAgC+u34dANA6ORkrXnsNfU+fBjZuBKo4AzERERHZn83hpl27dli5ciX+/ve/Y+fOnXjppZcAAAkJCWjUqJHdC3REYQcO3HwghOVaUABwJiAAUW+/DeHsDBRf3ZuIiIjqjs2HpV5//XW8//776NOnD0aOHInw4iHN33zzjeVwldp9lp0Np6Ii+UGpYAMUX+zy6lUGGyIiIoXc1rWlTCYTjEYjfHx8LPMuXrwIV1dX+Pv727VAe6vxtaVMJiAsDFMefhj/reCQ05H/+z/5YpdxcYBWa4eKiYiIyJb9t80tN7m5ucjPz7cEm0uXLmHp0qU4c+aMwwcbu9izB6clCe89/DAAQDKbAQCa4lsIAcTHA3v2KFUhERFRg2ZzuHn44Yexdu1aAEBGRgYiIyPx1ltvYfDgwXjvvffsXqCjMSUkYPyMGSjU6aAvKEDE2bNYuWQJIs6eReD16/BPT5cXbCCdq4mIiByNzR2Kjx49irfffhsAsGnTJgQEBODYsWP46quvMG/ePDz11FN2L9JhxMXh7aNHceDBB+GZnY2jEyagRVISJAATv/0WBTodDIWF8rJBQYqWSkRE1FDZ3HJz48YNeBSfjG7Hjh0YOnQoNBoNevTogUuXLtm9QIdQVAS8+SZOR0djzgMPAADefvdd3FEcbIDii10WFsodjENCgN69FSuXiIioIbM53LRs2RJbtmxBfHw8fvzxRzxQvLNPSUm5vQ66ju7IEaB7d5hmzMD4KVOQr9ejf1YWxm/fXm6klOXx0qXsTExERKQQm8PNvHnzMH36dISFhaF79+7o2bMnALkVp3PnznYvUDHZ2cC0aUD37sCxY3h7zBgcaNcOnlotPujXD9KmTeUvgNm0KbBpEzB0qDI1ExER0e0NBU9KSkJiYiLCw8Oh0cj56NChQ/D09ESbNm3sXqQ9WTWUbNs24OmngeLDbKcnTUKnxx5DvhD4sHVrPFHSn8ZkkkdFJSbKfWx692aLDRERUS2wZSj4bYWbEleuXAEAyxXC64Mqv5zkZGDqVGDDBvlxaChM772H3gEB2G80ItrHBz907Ajp1sNRREREVKtq9Tw3ZrMZixYtgpeXF0JDQxEaGgpvb2+89NJLMJec66U+2LNHbnkB5HPTfPQR0KaNHGw0GuBf/wL+9z8sbd8e+41GeGi1WNW6NYMNERGRg7N5KPjs2bPx0Ucf4bXXXkOvXr0AAL/99hsWLFiAvLw8vPLKK3YvslY8+KDcR2bGDLmfzC+/yPM7dwZWrQIiInDmxg3MiYsDACy54w6EODsrWDARERFZw+bDUsHBwVi5cqXlauAltm7diqeffhpXi6+S7agszVoAyjRquboCixYBU6YATk4wCYHex45hv9GIB3x8sJ2Ho4iIiBRjy2Epm1tu0tLSKuw03KZNG6Slpdm6Osfg7Az88QfQsqVl1jtXrvBwFBERUT1kc5+b8PBwLF++vNz85cuXW64QXu/k5QHFnaMB4MyNG5hd6nBUMx6OIiIiqjdsbrl544038Pe//x0//fST5Rw3+/fvR3x8PLZt22b3AutM8bWgTELgn6dPI89sxgM+PjeHfRMREVG9YHPLzb333ouzZ89iyJAhyMjIQEZGBoYOHYozZ86gd32+5EBxiPnvlSvYx8NRRERE9VaNznNT2pUrV7Bo0SJ88MEH9lhdrSnXoViS5FFTcXE4m5+P8MOHkWc244NWrTAhOFjhaomIiAio5fPcVOb69ev46KOP7LW6ulHqWlAmjcZyOKqfjw+e5OEoIiKieslu4aZeKnUtqP9euYK9xYejPuThKCIionrL5g7FqvHdd0D//oBWi3M3buDF4tFRb3J0FBERUb3WcFtuii9yaRIC44sPR0X5+GACD0cRERHVa1a33AwdOrTK5zMyMmpaiyKW8XAUERGRqlgdbry8vKp9fsyYMTUuqC7dejgqlIejiIiI6j2rw83HH39cm3XUObMQ+OeZM8jl4SgiIiJVabB9buZcuIDfMjPhzsNRREREqtJgw817CQkAeDiKiIhIbRpsuDED6O7hgQh3d1zKy1O6HCIiIrKThnueGwCHsrLQ7ehRAIDo00fZYoiIiMgu7Npyk5uba8/V1QknScJnbdsqXQYRERHZiV3CTX5+Pt566y00b97cHqurUwe7dMGogAClyyAiIiI7sTrc5OfnY9asWejatSvuvvtubNmyBYA8RLx58+ZYunQpnn/++dqq0+44NoqIiEidrO5zM2/ePLz//vuIiorCvn378Oijj2L8+PE4cOAAlixZgkcffRRarbY2a7Wrzu7uSHBygr9Op3QpREREZEdWh5uNGzdi7dq1eOihh3Dq1Cl07NgRRUVF+OOPP+rlOWJ+7tQJzh4eMGga7IAxIiIiVbJ6z37lyhVEREQAANq3bw+DwYDnn3++XgYbAJAkicGGiIhIhazeu5tMJuj1estjJycnuLu710pRRERERLfL6sNSQgiMGzcOBoMBAJCXl4dJkybBzc2tzHKbN2+2b4VERERENrA63IwdO7bM43/84x92L4aIiIiophrsVcGJiIhIndijloiIiFTF6pabf/7zn1Ytt3r16tsuhoiIiKimrA43a9asQWhoKDp37gwhRG3WRERERHTbrA43Tz31FNavX4+4uDiMHz8e//jHP+Dr61ubtRERERHZzOo+NytWrEBiYiL+/e9/49tvv0VISAiGDx+OH3/8kS05RERE5DAkcZvJ5NKlS1izZg3Wrl2LoqIi/O9//6sXJ/UzGo3w8vJCZmYmPD09lS6HiIiIrGDL/vu2R0tpNBpIkgQhBEwm0+2uhoiIiMiubAo3+fn5WL9+Pfr164dWrVrh5MmTWL58OS5fvlwvWm2IiIhI/azuUPz0009jw4YNCAkJwT//+U+sX78efn5+tVkbERERkc2s7nOj0WjQrFkzdO7cucorgTv6taXY54aIiKj+sWX/bXXLzZgxY6oMNURERESOwKaT+BERERE5Ol5bioiIiFSF4YaIiIhUxSHCzYoVKxAWFgZnZ2dERkbi0KFDVr1uw4YNkCQJgwcPrt0CiYiIqN5QPNx88cUXmDZtGubPn4+jR48iPDwc0dHRSElJqfJ1Fy9exPTp09G7d+86qpSIiIjqA8XDzZIlSzBhwgSMHz8ed911F1auXAlXV1esXr260teYTCaMGjUKCxcuRIsWLeqwWiIiInJ0ioabgoICHDlyBFFRUZZ5Go0GUVFR2L9/f6WvW7RoEfz9/fHEE09U+x75+fkwGo1lJiIiIlIvRcNNamoqTCYTAgICyswPCAhAUlJSha/57bff8NFHH2HVqlVWvcfixYvh5eVlmUJCQmpcNxERETkuxQ9L2SIrKwujR4/GqlWrrL70w6xZs5CZmWmZ4uPja7lKIiIiUpLVJ/GrDX5+ftBqtUhOTi4zPzk5GYGBgeWWP3/+PC5evIhBgwZZ5pnNZgCAk5MTzpw5gzvuuKPMawwGAwwGQy1UT0RERI5I0ZYbvV6PiIgIxMTEWOaZzWbExMSgZ8+e5ZZv06YNTp48iePHj1umhx56CPfddx+OHz/OQ05ERESkbMsNAEybNg1jx45F165d0b17dyxduhQ5OTkYP348APmaVk2aNMHixYvh7OyM9u3bl3m9t7c3AJSbT0RERA2T4uFmxIgRuHbtGubNm4ekpCR06tQJ27dvt3Qyvnz5MjSaetU1iIiIiBQkCSGE0kXUJVsumU5ERESOwZb9N5tEiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVHCLcrFixAmFhYXB2dkZkZCQOHTpU6bKrVq1C79694ePjAx8fH0RFRVW5PBERETUsioebL774AtOmTcP8+fNx9OhRhIeHIzo6GikpKRUuv3v3bowcORK7du3C/v37ERISggceeABXr16t48qJiIjIEUlCCKFkAZGRkejWrRuWL18OADCbzQgJCcGzzz6LmTNnVvt6k8kEHx8fLF++HGPGjKl2eaPRCC8vL2RmZsLT07PG9RMREVHts2X/rWjLTUFBAY4cOYKoqCjLPI1Gg6ioKOzfv9+qddy4cQOFhYXw9fWt8Pn8/HwYjcYyExEREamXouEmNTUVJpMJAQEBZeYHBAQgKSnJqnXMmDEDwcHBZQJSaYsXL4aXl5dlCgkJqXHdRERE5LgU73NTE6+99ho2bNiAr7/+Gs7OzhUuM2vWLGRmZlqm+Pj4Oq6SiIiI6pKTkm/u5+cHrVaL5OTkMvOTk5MRGBhY5WvffPNNvPbaa/jpp5/QsWPHSpczGAwwGAx2qZeIiIgcn6ItN3q9HhEREYiJibHMM5vNiImJQc+ePSt93RtvvIGXXnoJ27dvR9euXeuiVCIiIqonFG25AYBp06Zh7Nix6Nq1K7p3746lS5ciJycH48ePBwCMGTMGTZo0weLFiwEAr7/+OubNm4d169YhLCzM0jfH3d0d7u7uin0OIiIicgyKh5sRI0bg2rVrmDdvHpKSktCpUyds377d0sn48uXL0GhuNjC99957KCgowLBhw8qsZ/78+ViwYEFdlk5EREQOSPHz3NQ1nueGiIio/qk357khIiIisjeGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhwg3K1asQFhYGJydnREZGYlDhw5VufzGjRvRpk0bODs7o0OHDti2bVsdVUpERESOTvFw88UXX2DatGmYP38+jh49ivDwcERHRyMlJaXC5fft24eRI0fiiSeewLFjxzB48GAMHjwYp06dquPKiYiIyBFJQgihZAGRkZHo1q0bli9fDgAwm80ICQnBs88+i5kzZ5ZbfsSIEcjJycF3331nmdejRw906tQJK1eurPb9jEYjvLy8kJmZCU9PT/t9ECIiIqo1tuy/FW25KSgowJEjRxAVFWWZp9FoEBUVhf3791f4mv3795dZHgCio6MrXT4/Px9Go7HMREREROqlaLhJTU2FyWRCQEBAmfkBAQFISkqq8DVJSUk2Lb948WJ4eXlZppCQEPsUT0RERA5J8T43tW3WrFnIzMy0TPHx8UqXRERERLXISck39/Pzg1arRXJycpn5ycnJCAwMrPA1gYGBNi1vMBhgMBjsUzARERE5PEXDjV6vR0REBGJiYjB48GAAcofimJgYPPPMMxW+pmfPnoiJicHUqVMt83bu3ImePXta9Z4l/afZ94aIiKj+KNlvWzUOSihsw4YNwmAwiDVr1og///xTTJw4UXh7e4ukpCQhhBCjR48WM2fOtCy/d+9e4eTkJN58800RGxsr5s+fL3Q6nTh58qRV73f+/HkBgBMnTpw4ceJUD6f4+Phq9/WKttwA8tDua9euYd68eUhKSkKnTp2wfft2S6fhy5cvQ6O52TXo7rvvxrp16zBnzhy8+OKLuPPOO7Flyxa0b9/eqvfz9fW1rNfLy8v+H4iqZDQaERISgvj4eA7Fr2P87pXF7185/O6VY8/vXgiBrKwsBAcHV7us4ue5qWs8z42y+P0rh9+9svj9K4ffvXKU+u5VP1qKiIiIGhaGGyIiIlKVBhduDAYD5s+fz+HhCuH3rxx+98ri968cfvfKUeq7b3B9boiIiEjdGlzLDREREakbww0RERGpCsMNERERqQrDDREREalKgws3K1asQFhYGJydnREZGYlDhw4pXVKDsGDBAkiSVGZq06aN0mWp0q+//opBgwYhODgYkiRhy5YtZZ4XQmDevHkICgqCi4sLoqKicO7cOWWKVZnqvvtx48aV+z3o37+/MsWqzOLFi9GtWzd4eHjA398fgwcPxpkzZ8osk5eXh8mTJ6NRo0Zwd3fHI488Uu5CzGQ7a777Pn36lNv2J02aVGs1Nahw88UXX2DatGmYP38+jh49ivDwcERHRyMlJUXp0hqEdu3aITEx0TL99ttvSpekSjk5OQgPD8eKFSsqfP6NN97Af//7X6xcuRIHDx6Em5sboqOjkZeXV8eVqk913z0A9O/fv8zvwfr16+uwQvX65ZdfMHnyZBw4cAA7d+5EYWEhHnjgAeTk5FiWef755/Htt99i48aN+OWXX5CQkIChQ4cqWLU6WPPdA8CECRPKbPtvvPFG7RVl64Uu67Pu3buLyZMnWx6bTCYRHBwsFi9erGBVDcP8+fNFeHi40mU0OADE119/bXlsNptFYGCg+M9//mOZl5GRIQwGg1i/fr0CFarXrd+9EEKMHTtWPPzww4rU09CkpKQIAOKXX34RQsjbuU6nExs3brQsExsbKwCI/fv3K1WmKt363QshxL333iumTJlSZzU0mJabgoICHDlyBFFRUZZ5Go0GUVFR2L9/v4KVNRznzp1DcHAwWrRogVGjRuHy5ctKl9TgxMXFISkpqczvgZeXFyIjI/l7UEd2794Nf39/tG7dGk899RSuX7+udEmqlJmZCeDmxZKPHDmCwsLCMtt+mzZt0KxZM277dnbrd1/i888/h5+fH9q3b49Zs2bhxo0btVaD4lcFryupqakwmUyWq42XCAgIwOnTpxWqquGIjIzEmjVr0Lp1ayQmJmLhwoXo3bs3Tp06BQ8PD6XLazCSkpIAoMLfg5LnqPb0798fQ4cORfPmzXH+/Hm8+OKLGDBgAPbv3w+tVqt0eaphNpsxdepU9OrVC+3btwcgb/t6vR7e3t5lluW2b18VffcA8PjjjyM0NBTBwcE4ceIEZsyYgTNnzmDz5s21UkeDCTekrAEDBljud+zYEZGRkQgNDcWXX36JJ554QsHKiOrOY489ZrnfoUMHdOzYEXfccQd2796Nvn37KliZukyePBmnTp1ivz4FVPbdT5w40XK/Q4cOCAoKQt++fXH+/Hnccccddq+jwRyW8vPzg1arLdczPjk5GYGBgQpV1XB5e3ujVatW+Ouvv5QupUEp2db5e+AYWrRoAT8/P/4e2NEzzzyD7777Drt27ULTpk0t8wMDA1FQUICMjIwyy3Pbt5/KvvuKREZGAkCtbfsNJtzo9XpEREQgJibGMs9sNiMmJgY9e/ZUsLKGKTs7G+fPn0dQUJDSpTQozZs3R2BgYJnfA6PRiIMHD/L3QAFXrlzB9evX+XtgB0IIPPPMM/j666/x888/o3nz5mWej4iIgE6nK7PtnzlzBpcvX+a2X0PVffcVOX78OADU2rbfoA5LTZs2DWPHjkXXrl3RvXt3LF26FDk5ORg/frzSpane9OnTMWjQIISGhiIhIQHz58+HVqvFyJEjlS5NdbKzs8v8NxQXF4fjx4/D19cXzZo1w9SpU/Hyyy/jzjvvRPPmzTF37lwEBwdj8ODByhWtElV9976+vli4cCEeeeQRBAYG4vz58/j3v/+Nli1bIjo6WsGq1WHy5MlYt24dtm7dCg8PD0s/Gi8vL7i4uMDLywtPPPEEpk2bBl9fX3h6euLZZ59Fz5490aNHD4Wrr9+q++7Pnz+PdevWYeDAgWjUqBFOnDiB559/Hvfccw86duxYO0XV2bgsB7Fs2TLRrFkzodfrRffu3cWBAweULqlBGDFihAgKChJ6vV40adJEjBgxQvz1119Kl6VKu3btEgDKTWPHjhVCyMPB586dKwICAoTBYBB9+/YVZ86cUbZolajqu79x44Z44IEHROPGjYVOpxOhoaFiwoQJIikpSemyVaGi7x2A+Pjjjy3L5Obmiqefflr4+PgIV1dXMWTIEJGYmKhc0SpR3Xd/+fJlcc899whfX19hMBhEy5YtxQsvvCAyMzNrrSapuDAiIiIiVWgwfW6IiIioYWC4ISIiIlVhuCEiIiJVYbghIiIiVWG4ISIiIlVhuCEiIiJVYbghIiIiVWG4IaIGT5IkbNmyRekyiMhOGG6ISFHjxo2DJEnlpv79+ytdGhHVUw3q2lJE5Jj69++Pjz/+uMw8g8GgUDVEVN+x5YaIFGcwGBAYGFhm8vHxASAfMnrvvfcwYMAAuLi4oEWLFti0aVOZ1588eRL3338/XFxc0KhRI0ycOBHZ2dllllm9ejXatWsHg8GAoKAgPPPMM2WeT01NxZAhQ+Dq6oo777wT33zzTe1+aCKqNQw3ROTw5s6di0ceeQR//PEHRo0ahcceewyxsbEAgJycHERHR8PHxwe///47Nm7ciJ9++qlMeHnvvfcwefJkTJw4ESdPnsQ333yDli1blnmPhQsXYvjw4Thx4gQGDhyIUaNGIS0trU4/JxHZSa1dkpOIyApjx44VWq1WuLm5lZleeeUVIYR8xeFJkyaVeU1kZKR46qmnhBBCfPDBB8LHx0dkZ2dbnv/++++FRqOxXHE7ODhYzJ49u9IaAIg5c+ZYHmdnZwsA4ocffrDb5ySiusM+N0SkuPvuuw/vvfdemXm+vr6W+z179izzXM+ePXH8+HEAQGxsLMLDw+Hm5mZ5vlevXjCbzThz5gwkSUJCQgL69u1bZQ0dO3a03Hdzc4OnpydSUlJu9yMRkYIYbohIcW5ubuUOE9mLi4uLVcvpdLoyjyVJgtlsro2SiKiWsc8NETm8AwcOlHvctm1bAEDbtm3xxx9/ICcnx/L83r17odFo0Lp1a3h4eCAsLAwxMTF1WjMRKYctN0SkuPz8fCQlJZWZ5+TkBD8/PwDAxo0b0bVrV/ztb3/D559/jkOHDuGjjz4CAIwaNQrz58/H2LFjsWDBAly7dg3PPvssRo8ejYCAAADAggULMGnSJPj7+2PAgAHIysrC3r178eyzz9btByWiOsFwQ0SK2759O4KCgsrMa926NU6fPg1AHsm0YcMGPP300wgKCsL69etx1113AQBcXV3x448/YsqUKejWrRtcXV3xyCOPYMmSJZZ1jR07Fnl5eXj77bcxffp0+Pn5YdiwYXX3AYmoTklCCKF0EURElZEkCV9//TUGDx6sdClEVE+wzw0RERGpCsMNERERqQr73BCRQ+ORcyKyFVtuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVf4f2yculdf248sAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MR\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MR'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16143, 100])\n",
      "16143\n",
      "16143\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 3,604,601 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.692 | Train Acc: 50.95%\n",
      "\t test  Loss: 0.683 | test  Acc: 60.19%\n",
      "\t best  test acc: 60.19%\n",
      "Epoch: 02 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.666 | Train Acc: 62.44%\n",
      "\t test  Loss: 0.659 | test  Acc: 61.26%\n",
      "\t best  test acc: 61.26%\n",
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.599 | Train Acc: 70.33%\n",
      "\t test  Loss: 0.636 | test  Acc: 64.43%\n",
      "\t best  test acc: 64.43%\n",
      "Epoch: 04 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.492 | Train Acc: 78.50%\n",
      "\t test  Loss: 0.597 | test  Acc: 71.16%\n",
      "\t best  test acc: 71.16%\n",
      "Epoch: 05 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.394 | Train Acc: 84.89%\n",
      "\t test  Loss: 0.605 | test  Acc: 71.66%\n",
      "\t best  test acc: 71.66%\n",
      "Epoch: 06 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.315 | Train Acc: 88.93%\n",
      "\t test  Loss: 0.632 | test  Acc: 72.50%\n",
      "\t best  test acc: 72.50%\n",
      "Epoch: 07 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.254 | Train Acc: 91.95%\n",
      "\t test  Loss: 0.666 | test  Acc: 72.91%\n",
      "\t best  test acc: 72.91%\n",
      "Epoch: 08 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.203 | Train Acc: 93.79%\n",
      "\t test  Loss: 0.692 | test  Acc: 73.98%\n",
      "\t best  test acc: 73.98%\n",
      "Epoch: 09 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.157 | Train Acc: 95.85%\n",
      "\t test  Loss: 0.759 | test  Acc: 74.59%\n",
      "\t best  test acc: 74.59%\n",
      "Epoch: 10 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.146 | Train Acc: 95.95%\n",
      "\t test  Loss: 0.757 | test  Acc: 74.26%\n",
      "\t best  test acc: 74.59%\n",
      "Epoch: 11 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.124 | Train Acc: 96.82%\n",
      "\t test  Loss: 0.784 | test  Acc: 74.45%\n",
      "\t best  test acc: 74.59%\n",
      "Epoch: 12 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.110 | Train Acc: 97.38%\n",
      "\t test  Loss: 0.855 | test  Acc: 75.28%\n",
      "\t best  test acc: 75.28%\n",
      "Epoch: 13 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.109 | Train Acc: 97.33%\n",
      "\t test  Loss: 0.863 | test  Acc: 73.05%\n",
      "\t best  test acc: 75.28%\n",
      "Epoch: 14 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.102 | Train Acc: 97.58%\n",
      "\t test  Loss: 0.844 | test  Acc: 74.82%\n",
      "\t best  test acc: 75.28%\n",
      "Epoch: 15 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.080 | Train Acc: 98.24%\n",
      "\t test  Loss: 0.904 | test  Acc: 75.28%\n",
      "\t best  test acc: 75.28%\n",
      "Epoch: 16 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.079 | Train Acc: 98.21%\n",
      "\t test  Loss: 0.981 | test  Acc: 74.91%\n",
      "\t best  test acc: 75.28%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.072 | Train Acc: 98.35%\n",
      "\t test  Loss: 0.974 | test  Acc: 74.02%\n",
      "\t best  test acc: 75.28%\n",
      "Epoch: 18 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.076 | Train Acc: 98.12%\n",
      "\t test  Loss: 0.993 | test  Acc: 74.08%\n",
      "\t best  test acc: 75.28%\n",
      "Epoch: 19 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.067 | Train Acc: 98.31%\n",
      "\t test  Loss: 0.984 | test  Acc: 74.78%\n",
      "\t best  test acc: 75.28%\n",
      "Epoch: 20 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.058 | Train Acc: 98.64%\n",
      "\t test  Loss: 1.034 | test  Acc: 75.06%\n",
      "\t best  test acc: 75.28%\n",
      "Epoch: 21 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.054 | Train Acc: 98.69%\n",
      "\t test  Loss: 1.003 | test  Acc: 75.62%\n",
      "\t best  test acc: 75.62%\n",
      "Epoch: 22 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.050 | Train Acc: 98.71%\n",
      "\t test  Loss: 1.032 | test  Acc: 73.98%\n",
      "\t best  test acc: 75.62%\n",
      "Epoch: 23 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.041 | Train Acc: 99.01%\n",
      "\t test  Loss: 1.033 | test  Acc: 75.53%\n",
      "\t best  test acc: 75.62%\n",
      "Epoch: 24 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.045 | Train Acc: 98.92%\n",
      "\t test  Loss: 1.067 | test  Acc: 75.33%\n",
      "\t best  test acc: 75.62%\n",
      "Epoch: 25 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.036 | Train Acc: 99.10%\n",
      "\t test  Loss: 1.134 | test  Acc: 75.38%\n",
      "\t best  test acc: 75.62%\n",
      "Epoch: 26 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.036 | Train Acc: 99.03%\n",
      "\t test  Loss: 1.140 | test  Acc: 74.45%\n",
      "\t best  test acc: 75.62%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: SUBJ\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'SUBJ'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18512, 100])\n",
      "18512\n",
      "18512\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 4,078,401 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.644 | Train Acc: 66.97%\n",
      "\t test  Loss: 0.518 | test  Acc: 81.15%\n",
      "\t best  test acc: 81.15%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.462 | Train Acc: 81.66%\n",
      "\t test  Loss: 0.365 | test  Acc: 87.30%\n",
      "\t best  test acc: 87.30%\n",
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.295 | Train Acc: 89.79%\n",
      "\t test  Loss: 0.318 | test  Acc: 87.70%\n",
      "\t best  test acc: 87.70%\n",
      "Epoch: 04 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.197 | Train Acc: 93.91%\n",
      "\t test  Loss: 0.292 | test  Acc: 89.78%\n",
      "\t best  test acc: 89.78%\n",
      "Epoch: 05 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.125 | Train Acc: 96.58%\n",
      "\t test  Loss: 0.302 | test  Acc: 89.78%\n",
      "\t best  test acc: 89.78%\n",
      "Epoch: 06 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.085 | Train Acc: 97.88%\n",
      "\t test  Loss: 0.311 | test  Acc: 90.18%\n",
      "\t best  test acc: 90.18%\n",
      "Epoch: 07 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.067 | Train Acc: 98.41%\n",
      "\t test  Loss: 0.338 | test  Acc: 89.09%\n",
      "\t best  test acc: 90.18%\n",
      "Epoch: 08 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.048 | Train Acc: 98.85%\n",
      "\t test  Loss: 0.321 | test  Acc: 90.48%\n",
      "\t best  test acc: 90.48%\n",
      "Epoch: 09 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.052 | Train Acc: 98.67%\n",
      "\t test  Loss: 0.388 | test  Acc: 89.58%\n",
      "\t best  test acc: 90.48%\n",
      "Epoch: 10 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.036 | Train Acc: 99.25%\n",
      "\t test  Loss: 0.316 | test  Acc: 91.67%\n",
      "\t best  test acc: 91.67%\n",
      "Epoch: 11 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.021 | Train Acc: 99.62%\n",
      "\t test  Loss: 0.348 | test  Acc: 90.67%\n",
      "\t best  test acc: 91.67%\n",
      "Epoch: 12 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.016 | Train Acc: 99.70%\n",
      "\t test  Loss: 0.354 | test  Acc: 91.67%\n",
      "\t best  test acc: 91.67%\n",
      "Epoch: 13 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.020 | Train Acc: 99.56%\n",
      "\t test  Loss: 0.373 | test  Acc: 91.77%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 14 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.024 | Train Acc: 99.36%\n",
      "\t test  Loss: 0.395 | test  Acc: 90.48%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 15 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.021 | Train Acc: 99.54%\n",
      "\t test  Loss: 0.413 | test  Acc: 90.97%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 16 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.021 | Train Acc: 99.52%\n",
      "\t test  Loss: 0.417 | test  Acc: 90.87%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.010 | Train Acc: 99.85%\n",
      "\t test  Loss: 0.380 | test  Acc: 91.17%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 18 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.008 | Train Acc: 99.86%\n",
      "\t test  Loss: 0.479 | test  Acc: 89.78%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 19 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.010 | Train Acc: 99.83%\n",
      "\t test  Loss: 0.438 | test  Acc: 91.07%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 20 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.011 | Train Acc: 99.79%\n",
      "\t test  Loss: 0.428 | test  Acc: 90.67%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 21 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.005 | Train Acc: 99.94%\n",
      "\t test  Loss: 0.431 | test  Acc: 91.27%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 22 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.012 | Train Acc: 99.71%\n",
      "\t test  Loss: 0.406 | test  Acc: 90.77%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 23 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.011 | Train Acc: 99.76%\n",
      "\t test  Loss: 0.437 | test  Acc: 90.28%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 24 | Epoch Time: 0m 6s\n",
      "\t Train Loss: 0.005 | Train Acc: 99.94%\n",
      "\t test  Loss: 0.480 | test  Acc: 91.07%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 25 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.003 | Train Acc: 99.98%\n",
      "\t test  Loss: 0.500 | test  Acc: 91.17%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 26 | Epoch Time: 0m 6s\n",
      "\t Train Loss: 0.002 | Train Acc: 99.98%\n",
      "\t test  Loss: 0.510 | test  Acc: 90.97%\n",
      "\t best  test acc: 91.77%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: SUBJ\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'SUBJ'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18512, 100])\n",
      "18512\n",
      "18512\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 4,078,401 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.635 | Train Acc: 69.09%\n",
      "\t test  Loss: 0.554 | test  Acc: 77.28%\n",
      "\t best  test acc: 77.28%\n",
      "Epoch: 02 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.428 | Train Acc: 83.12%\n",
      "\t test  Loss: 0.356 | test  Acc: 85.81%\n",
      "\t best  test acc: 85.81%\n",
      "Epoch: 03 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.257 | Train Acc: 91.40%\n",
      "\t test  Loss: 0.292 | test  Acc: 88.79%\n",
      "\t best  test acc: 88.79%\n",
      "Epoch: 04 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.172 | Train Acc: 95.05%\n",
      "\t test  Loss: 0.298 | test  Acc: 89.38%\n",
      "\t best  test acc: 89.38%\n",
      "Epoch: 05 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.109 | Train Acc: 97.32%\n",
      "\t test  Loss: 0.370 | test  Acc: 88.10%\n",
      "\t best  test acc: 89.38%\n",
      "Epoch: 06 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.081 | Train Acc: 98.09%\n",
      "\t test  Loss: 0.288 | test  Acc: 90.28%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 07 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.059 | Train Acc: 98.76%\n",
      "\t test  Loss: 0.318 | test  Acc: 90.67%\n",
      "\t best  test acc: 90.67%\n",
      "Epoch: 08 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.050 | Train Acc: 98.95%\n",
      "\t test  Loss: 0.344 | test  Acc: 89.78%\n",
      "\t best  test acc: 90.67%\n",
      "Epoch: 09 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.046 | Train Acc: 98.95%\n",
      "\t test  Loss: 0.311 | test  Acc: 89.98%\n",
      "\t best  test acc: 90.67%\n",
      "Epoch: 10 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.035 | Train Acc: 99.33%\n",
      "\t test  Loss: 0.338 | test  Acc: 90.67%\n",
      "\t best  test acc: 90.67%\n",
      "Epoch: 11 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.027 | Train Acc: 99.45%\n",
      "\t test  Loss: 0.371 | test  Acc: 90.38%\n",
      "\t best  test acc: 90.67%\n",
      "Epoch: 12 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.024 | Train Acc: 99.55%\n",
      "\t test  Loss: 0.429 | test  Acc: 88.39%\n",
      "\t best  test acc: 90.67%\n",
      "Epoch: 13 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.024 | Train Acc: 99.42%\n",
      "\t test  Loss: 0.419 | test  Acc: 90.18%\n",
      "\t best  test acc: 90.67%\n",
      "Epoch: 14 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.023 | Train Acc: 99.52%\n",
      "\t test  Loss: 0.404 | test  Acc: 89.58%\n",
      "\t best  test acc: 90.67%\n",
      "Epoch: 15 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.014 | Train Acc: 99.75%\n",
      "\t test  Loss: 0.487 | test  Acc: 89.78%\n",
      "\t best  test acc: 90.67%\n",
      "Epoch: 16 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.014 | Train Acc: 99.71%\n",
      "\t test  Loss: 0.443 | test  Acc: 89.68%\n",
      "\t best  test acc: 90.67%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.011 | Train Acc: 99.81%\n",
      "\t test  Loss: 0.464 | test  Acc: 90.18%\n",
      "\t best  test acc: 90.67%\n",
      "Epoch: 18 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.007 | Train Acc: 99.88%\n",
      "\t test  Loss: 0.500 | test  Acc: 89.88%\n",
      "\t best  test acc: 90.67%\n",
      "Epoch: 19 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.008 | Train Acc: 99.83%\n",
      "\t test  Loss: 0.491 | test  Acc: 88.99%\n",
      "\t best  test acc: 90.67%\n",
      "Epoch: 20 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.012 | Train Acc: 99.70%\n",
      "\t test  Loss: 0.487 | test  Acc: 90.77%\n",
      "\t best  test acc: 90.77%\n",
      "Epoch: 21 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.008 | Train Acc: 99.85%\n",
      "\t test  Loss: 0.473 | test  Acc: 90.48%\n",
      "\t best  test acc: 90.77%\n",
      "Epoch: 22 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.005 | Train Acc: 99.92%\n",
      "\t test  Loss: 0.519 | test  Acc: 90.48%\n",
      "\t best  test acc: 90.77%\n",
      "Epoch: 23 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.008 | Train Acc: 99.79%\n",
      "\t test  Loss: 0.516 | test  Acc: 90.38%\n",
      "\t best  test acc: 90.77%\n",
      "Epoch: 24 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.005 | Train Acc: 99.89%\n",
      "\t test  Loss: 0.512 | test  Acc: 89.58%\n",
      "\t best  test acc: 90.77%\n",
      "Epoch: 25 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.006 | Train Acc: 99.84%\n",
      "\t test  Loss: 0.511 | test  Acc: 89.98%\n",
      "\t best  test acc: 90.77%\n",
      "Epoch: 26 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.007 | Train Acc: 99.83%\n",
      "\t test  Loss: 0.477 | test  Acc: 90.48%\n",
      "\t best  test acc: 90.77%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: SUBJ\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'SUBJ'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18512, 100])\n",
      "18512\n",
      "18512\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 4,078,401 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.616 | Train Acc: 71.20%\n",
      "\t test  Loss: 0.476 | test  Acc: 81.75%\n",
      "\t best  test acc: 81.75%\n",
      "Epoch: 02 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.375 | Train Acc: 86.41%\n",
      "\t test  Loss: 0.342 | test  Acc: 87.20%\n",
      "\t best  test acc: 87.20%\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.227 | Train Acc: 92.65%\n",
      "\t test  Loss: 0.287 | test  Acc: 89.09%\n",
      "\t best  test acc: 89.09%\n",
      "Epoch: 04 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.139 | Train Acc: 95.97%\n",
      "\t test  Loss: 0.309 | test  Acc: 89.88%\n",
      "\t best  test acc: 89.88%\n",
      "Epoch: 05 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.093 | Train Acc: 97.66%\n",
      "\t test  Loss: 0.385 | test  Acc: 88.00%\n",
      "\t best  test acc: 89.88%\n",
      "Epoch: 06 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.067 | Train Acc: 98.32%\n",
      "\t test  Loss: 0.359 | test  Acc: 88.89%\n",
      "\t best  test acc: 89.88%\n",
      "Epoch: 07 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.049 | Train Acc: 98.85%\n",
      "\t test  Loss: 0.408 | test  Acc: 88.19%\n",
      "\t best  test acc: 89.88%\n",
      "Epoch: 08 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.039 | Train Acc: 99.14%\n",
      "\t test  Loss: 0.399 | test  Acc: 88.69%\n",
      "\t best  test acc: 89.88%\n",
      "Epoch: 09 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.039 | Train Acc: 99.12%\n",
      "\t test  Loss: 0.404 | test  Acc: 89.58%\n",
      "\t best  test acc: 89.88%\n",
      "Epoch: 10 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.033 | Train Acc: 99.31%\n",
      "\t test  Loss: 0.399 | test  Acc: 89.48%\n",
      "\t best  test acc: 89.88%\n",
      "Epoch: 11 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.023 | Train Acc: 99.54%\n",
      "\t test  Loss: 0.439 | test  Acc: 88.69%\n",
      "\t best  test acc: 89.88%\n",
      "Epoch: 12 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.019 | Train Acc: 99.66%\n",
      "\t test  Loss: 0.453 | test  Acc: 88.89%\n",
      "\t best  test acc: 89.88%\n",
      "Epoch: 13 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.016 | Train Acc: 99.75%\n",
      "\t test  Loss: 0.489 | test  Acc: 88.99%\n",
      "\t best  test acc: 89.88%\n",
      "Epoch: 14 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.021 | Train Acc: 99.49%\n",
      "\t test  Loss: 0.477 | test  Acc: 88.89%\n",
      "\t best  test acc: 89.88%\n",
      "Epoch: 15 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.020 | Train Acc: 99.58%\n",
      "\t test  Loss: 0.450 | test  Acc: 89.78%\n",
      "\t best  test acc: 89.88%\n",
      "Epoch: 16 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.009 | Train Acc: 99.88%\n",
      "\t test  Loss: 0.466 | test  Acc: 90.08%\n",
      "\t best  test acc: 90.08%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.008 | Train Acc: 99.90%\n",
      "\t test  Loss: 0.486 | test  Acc: 90.28%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 18 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.008 | Train Acc: 99.90%\n",
      "\t test  Loss: 0.503 | test  Acc: 90.28%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 19 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.007 | Train Acc: 99.91%\n",
      "\t test  Loss: 0.520 | test  Acc: 90.28%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 20 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.007 | Train Acc: 99.91%\n",
      "\t test  Loss: 0.540 | test  Acc: 90.08%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 21 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.005 | Train Acc: 99.94%\n",
      "\t test  Loss: 0.565 | test  Acc: 89.68%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 22 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.013 | Train Acc: 99.78%\n",
      "\t test  Loss: 0.498 | test  Acc: 88.59%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 23 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.026 | Train Acc: 99.25%\n",
      "\t test  Loss: 0.501 | test  Acc: 88.99%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 24 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.009 | Train Acc: 99.78%\n",
      "\t test  Loss: 0.492 | test  Acc: 89.58%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 25 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.005 | Train Acc: 99.92%\n",
      "\t test  Loss: 0.578 | test  Acc: 89.09%\n",
      "\t best  test acc: 90.28%\n",
      "Epoch: 26 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.004 | Train Acc: 99.96%\n",
      "\t test  Loss: 0.612 | test  Acc: 88.69%\n",
      "\t best  test acc: 90.28%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLgElEQVR4nO3deXwTdf4/8NckbdI7pS09gNKCnEopd62IohQKKCuHC7IsAuvxQ4EVu3xXUDl1wWNlUUF5LJ6oHILA4gW6FRCwgnKzloLQ0go9qNCk95F8fn+kDU2btkmbdtrJ6/l4zCNtMsc7k2Ne+cxnZiQhhAARERGRQqjkLoCIiIjImRhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIUWQNN99//z3GjRuHDh06QJIk7Nq1q8Fp9u/fjwEDBkCr1aJbt2744IMPmr1OIiIiajtkDTeFhYWIjo7GunXr7Bo/NTUV9913H+655x6cPHkS8+fPx6OPPoq9e/c2c6VERETUVkit5cKZkiRh586dGD9+fJ3jPPPMM/jyyy9x9uxZy30PPfQQ8vLysGfPnhaokoiIiFo7N7kLcERSUhLi4uKs7ouPj8f8+fPrnKa0tBSlpaWW/00mE65fv47AwEBIktRcpRIREZETCSGQn5+PDh06QKWqf8dTmwo3WVlZCAkJsbovJCQEBoMBxcXF8PT0rDXNqlWrsHz58pYqkYiIiJpRRkYGOnXqVO84bSrcNMaiRYuQkJBg+V+v16Nz587IyMiAn5+fjJW5IKMR+OEHICsLCA0F7rgDUKsdm8fu3cD06XU//tFHwB/+YF8tffoAV6/WPU7HjsCZMw3X6Oi8hADKyoDiYqCkxHxbNRQWAjNmANev1z0vLy9g7Fjz+EVF5mmqbqv/3Tr2OLsejQbw8wNUKiAnp+Hx774b6NYNkKS6h6tXATsOuMCDDwINfOnjt9+A7dsbntfkyUDnzjdrAKz/BoD0dGDTpobn9ec/AxER9Y9z+TLw8ccNz2vWLKBrV3MdKpX1egLM9128CKxf3/C8xo0DAgPNn8PSUtu3167Z9zrWxc/P/H0XFgYEBwNffw0UFNQ9vqcnMGgQkJ1t/q40GBq/bADo0AFo3978vvTwALTam39X3ebmAl980fC85swBevY0r+OqoWrdV/1//jzw0ksNz+uLL4Bhwxx6KgaDAeHh4fD19W1w3DbV5+auu+7CgAEDsGbNGst977//PubPnw+9Xm/XcgwGA3Q6HfR6PcNNS9qxA3jqKfMXa5VOnYDXXwcmTrRvHkYjEBlpPY/qJMk8z5QU88bdYLg56PXW/585A3zyScPL7NsXaNfO+su95u2NG8Dx4w3Py88PqKgwh5LW8bEz69PHvOHRaMxD1Zdf9eHqVfs2PC+8APTvD7i7A25uN4fq/584YQ5wDVm82Lxxzc+3PRQUAGlpQGpqw/PSas0bDVv1VP1vMJjn15CHHwbuvRfQ6cyvqU53c/DzMy8LAPbvB+65p+H57dsHDB9e/zhV7/0rV2y/d6re+6mp9oVxzsv+edn7Ov7xj+Z5Xb16cygqang6e3h5mX8ghYWZw0qHDuZ52xPg2vL7qwaHtt+ilQAgdu7cWe84f//730WfPn2s7ps6daqIj4+3ezl6vV4AEHq9vjFlUmN89pkQkiSE+a1+c5Ak8/DZZ3VPazIJkZsrxOnTQrz8cu15tPVBpRLC21uIoCAhwsOFCA21b7pp04R4+20hPvpIiB07hNi7V4hDh4Q4cUKI8+eFuHJFiM8/t29e+/Y1/BpWVAjRqZPt17HqtQwPN4/XkvPat895z9GZ83L28xTi5ueo5vzs+RxxXo2fV2NfR5NJCL1eiORkIRIThfj4YyGmTrXvPfbkk+ZpkpPN8zCZnFdXc68vZ8+rGke232jUEpwkPz9fnDhxQpw4cUIAEKtXrxYnTpwQly9fFkIIsXDhQjF9+nTL+JcuXRJeXl7i//7v/0RycrJYt26dUKvVYs+ePXYvk+HGQRUV5i/zTZvMt/Z+UKpP36lT3R9iSRKifXsh3ntPiJUrhZg7V4hJk4SIjRUiIkIIjabxwcHbW4iwMCF69hRi8GAh4uKEmDhRiJkzzbf2zGPpUiG2bhViyxbzsHmzedi0SYhPPjEPzz5r37zee0+IixeFuHpViBs3hCgpqf2l5cwNrCt8+bXW0OXs51l9fjU/T+HhjdtYcF6OzccZr6OzA7SrvL8qtZlws2/fPgGg1jBjxgwhhBAzZswQd999d61p+vXrJzQajejatat4//33HVomw40DbL05O3Wy781ZXi5EaqoQq1c3PpxUH4KChOjSxb5xP//cvPz6tNaNYmsOJFXza21ffq0xdNWcpzO/5Jv6g4Pzatx8nPE6NleAdoX3l3Bs+91q+ty0FPa5sdOOHebOiTXfHlV9TT79FLj99pt9Hqpuq/7OyDDve7VXVBQwYMDN/ckdOtzcvxwaau7H4Ox9uVXPEbCeX9Vz3L7d/v5ArXVeVfOr2d8pPBxYs8ax+VQxGoGDB4HMTPNrNGyY4x3DnT0vZz5HZ68vwLnrjOTjjNfR2Z9vZ9XVBrTJPjcthS03dmhoV5K9g0Zj/3zYDNt88xLC6b+gWqVW/IuTyEoz7LJxBWy5qQdbbuywezfwwAMNj6dSmVtSIiOBLl1q34aGmj+2zu457wotEc6eFxG1Lvx8O8yR7TfDDZllZ5vPo/HZZ0BiImAyNTzNRx+Zz1/REDbDEhFREzmy/Vb8Sfxckr0b/t9+MwePzz4zj+9ozm3oZGFVJk40Bxhb57lpbGuLWt3wuRuIiMglseVGaRo6Wd7FizcDzZEj1tMOGgRMmgSMHw+MHOn8kzCxtYWIiBqJLTeuqq4jnK5cMYeWiAjzKc6rSBIwdKg59EycaH169NdfN89LkmzvSlqzxvFgwtYWIiJqAQw3SmE0mltsbLW0VN13+bK5E/A999xsoQkLsz2/5tiVRERE1AIYbpTi4MG6r7lU3Y4d9h0JBZgDzAMPcFcSERG1KQw3SlHfFamrc/RCbtyVREREbYxK7gLICVJTgX/9y75x69oNRUREpBAMN21ZRQWwejXQpw/w88/1jytJ5hPdDRvWMrURERHJhOGmrTp50nxtp7/9zbyrafhw4M03zSGm6oimKk05womIiKiNYbhpa4qKgGeeMZ+T5tgxwN8feOcd4LvvgLlzzUc4dexoPU2nTo07CzAREVEbxA7FbUliIvD//p/5RHwA8Mc/Am+8Yb6GUxUe4URERC6O4aYtuH4dWLAAeP998/+dOgFvvQWMG2d7fB7hRERELozhprWwdWkClQrYutV8Ir2cHHPfmSefBFauBJR46QgiIiInYLhpDWxdDyoszDwcP27+/9ZbgQ0bgDvukKdGIiKiNoLhRm51XQ8qM9M8uLkBixebOxFrtfLUSERE1IYw3MipvutBVQkKAp57jh2CiYiI7MRDweVkz/WgsrLM4xEREZFdGG7klJnp3PGIiIiI4UZW9l7nideDIiIishvDjZwGDgTc3et+nNeDIiIichjDjVyEAB59FCgvN//P60ERERE5BcONXFasAD791Nxy88ILvB4UERGRkzDcyGHrVmDZMvPfb78NPP88kJYG7NsHbNpkvk1NZbAhUpCfDQbce/IkfjYYOK8Wnhe5HoablvbTT8DMmea///Y34JFHzH9XXQ9q6lTzbRN3RfGLgah12ZidjX15efgoO5vzauF5kevhSfxa0pUr5it2l5QA990HvPxysy2q+hfDIF6HqkX9bDDg75cu4ZWuXbnu2zBnvI6XS0qQW14OCcDWnBwAwJacHMwIDYUAEOTujggPD6tpTEKgxGRCscmEIqMRRZW3l0pKkF1ailIh8GFWFgDgg6wshLq7QwDwdXND+/oOUKjmWnk58isqIAHNMq+NWVmI8vaGVqVCmEaDbp6e8FKr4alSwUuthrpmH8MmrC97uMJn0hWeoyMYblpKURHwhz+Yz1lz223m3U9O7ijcXF8M5BhnBkt+YcnHntdRCIFCoxF6oxGGigroKyqs/n7s/Pla0+SUl2PgsWOW/3t4eqLIZEJxZZApNpnsrtFgNOLZtDSHn1tzzyvPaLT53KtoJOlm2KkMPF4qFY7k59cat+b6OjFwIILc3RHo7g5PO79DXeHHnis8R0cw3LQEkwmYMcN8EcygIODzz21e1bsxGzKTEPittBQpRUUYdfp0rcdrfjGI4cMb/TSobs0VLF3hC6s1BbjLJSVILylBakkJPqhshdiQmYmUoiIUGo0oEQKlJpM5vFSGGPujiG3ni4vrfKwqBHipVKgQAjlVR1fWIAHo5eWFUI3GrmVmlZXhXFERbF34xZnzAgAflQpGwCq0lQmBsooK5Nm1BGv9q32fealUCHR3t4SdIHd3BLq5IcjdHRIAN0mCv5sbPq7ctdXafuw19b3Plq66Mdy0hGXLzEc+ubsDO3cCXbrYHK2+DVl+RQVSioqQUlxsvq0czhcX2/VLTwKwNDISQghIdTQJtwQlfGhqyq+oQOSPP9a6v2awvD8wEO6SBDdJgnvVoFLd/Lvy/wKjEeUmE9wkydLM/1F2NsYFBsLfzQ3tNZo2/6VcnVwtXSVGI1KKi3G2sNAyfPH777XGKzaZsPfGjXrnpQagc3OzDH5qteW2zGTCttzcWtP8s2tX9PHxsbRc1GzF8LSx++Z4fr7Ve8ryvAcOxABf33prrKkl5nWs2rxMlcGwqNrutuJqu92qWq2SCwux/PLlWvMa4OODUpMJv1dUILe8HBVCmKctLUVGaaldddb8TBYPGwYPGU+10Zj3vr6iAuklJcgoLcV9Z87Uerzmc/wiKgphGg1CNRoEu7vDTdVwV1sl/KhiuGlumzaZD/UGgH//G7jzTquHqyfvLZXJ+8OsLLhJEtJKSnC1rAyXS0qQWVZW5yLcJAm3eHigp5cX/N3csNFGBzwBYFlaGj7JzsafQ0Lw55AQdPX0dNaztFtr/dDYs1EsMRpxrqgI/ysqstogppWU2LUMWxtOe92oqMDIai1zD4eEoKeXl3nw9EQ3T88Gv6RbUyBpyZauCpMJv9YIMf8rKsKFoiIYHZi3CsDcjh1xf2BgrRDjqVLV+aPheH4+tuXmQgXAVDkfE4B72rVzOERUr6X6vJqipealkiR4qtXwVKsRWE9/nuP5+Vh++XKteW3o2dOyvoQQyDcakVtejt/Ly61vK8PP8fx8/JSfX2eLEgD4HjqEaG9vDPbzwxBfXwz29UVvb+86+wQBzdvaUmw0olwIGAFkVAaYjNJSS5jJKC1FvtGRdy1wf7UAJAFo7+6OUI3GEnjCtFqEajRQA9CqVAhyd7dsi9pyKxDDTXM6cgT4y1/Mf//97zePkqrG1i9+vdGI1TYuqBni7n5zg1a5Uevp5YUuHh6WNH48Px8bs7NrfTGMbtcOB/R6XCguxtK0NCxNS8NQPz/8OSQEk4ODEWBn58HGqPowFxqNlubhza3sQ1N9o9jPx6fWxvBsYSEuFBfX+eUfqtGgs1aLozb6DPwjMhKdPDxQLgTKTSbzbdVgMqGi+v9C4GxBARLz8ur9Uq4ZYCUAkZUBt+p9UTV00GggSVKjAolJCEvH1vPFxcgqLUWJEJbX8cOsLERWPjdPlQr+bm4oF+Lmc7LxfMuFwCsZGbWWVfMX58LOnWu1alm1elXel1dejuLKlq6NlS1d72Zm4kJREX4tLkZaSQls78wB/N3cEOXtjT6Vw23e3qgwmRBnYxfvT41o0QCAYHd3hLq7I9zDA4+EheHdzExklJQguBGfOc7LTJIk+Lm5wc/Nrd4faXW1KN3p54eU4mJcKy/HsYICHCsowPrKx7xVKgzy9bUKPBEeHpbw6sjnSAgBg9FoFcDG2tHa0pAANzeEa7Xo7OEBD0my2TL4h8BAVAiBzLIyZJWVIbusDKbKZeWUl+N0YWGDy6lZ15MdOtS5GzDQ3R0+anWtkC/XD1pJCFHfd6jiGAwG6HQ66PV6+DXnis7IAAYPBrKzzR2Jd+ywdCAWQuDn/Hx8nJ2N97Oy6kziKgCPh4VhVlgYenh6wt+OL4rfSkow+NixWl8MPw0cCJ2bG3bm5uLj7Gwk3rhh2VC7SxLuCwzE9JAQ3BcYCG2NZktHQ0Sx0Yjkaq0br9rYkNX0fEQEunp4oKunJ7p6eKCDVlvvrycA+OuFC3jzyhX8tWNHvN69e4PLqFJmMiGrrAwn8vNxsaQEv5eX4/XffkOhyWRJ+xV1TNvOzc2yIay+QQx0d7d8kdYMlsec2My/pXdvqCWp1u5JfT2/5jxVKkRotUgtKUFpZQgZ4e+PEpPJ8h6o2jVQ8widUoV8PXirVLit8rWq/tqFVQa/6pz5OlYpNZmgkSRIkgQhBMqEqPU547ycP6/6Xsv+Pj5ILy3FUYMBP+Xn46jBgJ/z81FoYzd/gJsbent54TZvb2zNyYHeaIROrcbT4eHIq6hAWWVot9WKVOHgZ0grSeji6WkOL1otwj08EK7VWsJMJ60W3tVaae19vxqFQG55ObLKypBZWoqsytBTFX5OFRQgpZ7+X/bQSBIC3d3hq1bDt7JV8weDASUmEwLd3PBNdHSTftA6sv1muGkOBQXm3U+nTgF9+wKHDgG+vkgrLsbH2dn4ODvb6k3Uzs0NNypqb04b+2VqzxfD1dJSbM7JwUdZWThVLcH7u7lhcvv2mB4SgqE6HSRJqjNElJtMOF+theN/lbe/FhfX2+pgD40kIbJa2Km69VCp4K1Ww0etxpjTp5FTXo5gd3d8FRUFvdEIU2WfIssH18aH+LqNdV2Xv4SGWm0QbW0Mq9QXLDs5+EF2ZAMrKjuaVg87VeHnQhO/rKpzlySU1/F1UdUJNVyrvdmvyEZ/oqq/3SQJueXleK+ypaW6WaGhCHJ3r7flp3pr128lJUip4z2nBvDqLbfgqU6doLKzr5kzX0eSl6OvpVEInCsqwlGDAUfz8/GTwYBThYUOB5SaanZ8VgH4xkY/rn3R0bjb39+hfpHN8b1T0wuRkfBzc6t3N2CJA0f5AY07uIXhph7NHm5MJmDSJGDXLiA4GDeSkrDNwwMfZWfjkF5vGc1TpcL4oCD8OSQEQW5uiDlxwqm/FB1xpqAAH2dn45PsbFyp1rcnTKPB2IAA7MzNxfWKCujUakwLCbE09aeWlNS5sQus0cLhLkl41Mahoa907QoAuFRSgkvFxbhUUoK0kpImf5k0xF2S4KtW1xl03CQJH/TqhWkhIQ7N11m/OJ31hfVhZiYeSUmx2bdEBeAvYWG419//ZifWah1aq5+XxFOlgkqS7Oo4aq+WaOlqzh8I1DY09bUsMRrxckYGVqSl2dwtLQEY2a4dhup0de6uqXnIurNbB1uipauhuoqq9YHampODf2Zk2Pzeaex3K+DY9pt9bpqo1i6b559H6Zdf4qvhw/Hx8uX4IiMDZZUbagnAvf7+mB4aiglBQfBzM6/+30pKnLa/ujGifHzwso8PVnbtigOV+0Y/yMpCZlkZ3q32y1pvNOKtq1etpvVRq2vtpunj7Y1gd3erXx/HK/ui1PzQjLDRqdJYeXh7Vdi5VFyMi5V/JxcWoqCeXwheKhUiPTwQWtVZrvK2ese5UI0GAW5ukOrZWB8ZMKBRXzLVv1AkSYK2kUemdfLwQFpsrOUL6/GwsEZ9Yc0IC0OUj4/N59jYPiSAczqhOrOfhjPrApz3OpL8mvpaeqjVWBoZiXGBgU47uszZ731nvV+bUpeXWo3OajU6e3igv68vJgcHO/W71VEMN01U1VlqY3Y2SvfswUclJfh0+3bc8PMzt+IAiPL2xvSQEPwpJAQdtdpa83DWhqyp1JKEe9u1w73t2mGYTofH6/nF/3SnTpjXqRM6a7V2NaE68qFRSxIiPDwQ4eGBe2zM60BeHoafPFnr/qT+/XG7TtdgLbY484gRZ3H2Bra1BRJnvu+bIygR2eKMz1Fr+c5vibrk+m5luGkEy6F8JhM2XbkCAFj32294MzjY3HkYQAeNBn8KCcH0kBD09fFpcJ6t7ZfiX8LC0M+Jv/id+aHxrWzirfmh0XCjaFNrDSRA62vpIqpLa21tcbbW0ArkDOxz0wjS/v0NjlNx990NHu3T2jXHUSPO4OwOn67Qv8IVniNRc+PnyDHOXl/sc9PMPi4owMOenjDZOGmaW0UFPigpafPBBpA/edeltbYetGau8ByJmhs/R46Rc30x3DjKaETJli0wPfqozYePzJmDAcXFwJgxTr8wZktrzU39/JIhIqK6yL+VamM2HzyIx6rOOgxAVdlpuOoWQphP4HfwoBzlOZ222mnlJUlqFcGGiIioPtxSOWDXtWuYLgSESoU/792L0N9/x8Dz57F+9WoMPH8eob//juCqEzNlZspbLBERkYvibik77b1+HVN++QVGScLDe/fi/ZdfRrmbGzSVF0B7/PPPUebuDm155VVswsJkrZeIiMhVMdzY4fu8PEw4exZlQuDBoCC8u2kTVELcDDIwn6BPW14OSBLQqRMwbJh8BRMREbkw7pZqwFGDAfedOYNikwn3BQTgk1tvhdu//mV75KpOrWvWtPnOxERERG0Vw009ThUUIP70aRQYjbjX3x/bbrvNfKK4Xr1sT9CpE7B9OzBxYssWSkRERBbcLVWHc4WFGHnqFPIqKhDr54f/9Olz8+JnW7eab++7D1iwwNx5OCzMvCuKLTZERESyYrix4VJxMUacOoVr5eUY4OODr6Ki4FN5kUsIAWzZYv77oYeARly2nYiIiJoPd0vV8FtJCUacOoWrZWW41csLe/v2hX/1M/KeOgWcPw94eFiuI0VEREStB8NNNdllZRhx6hTSSkrQzdMT/42ORpBGYz1SVavNffcBjbw2FRERETUfhptK18vLMfLUKZwvLkZnrRaJ0dEI02qtR6q5S4qIiIhaHYYbAIaKCow+fRpnCgsRqtEgMToanW1dXfrIEeDyZcDbGxg7tuULJSIioga5fLgpNBpx35kz+Ck/H4FubvhvdDS6eXnZHrnqKKkHHgDqGoeIiIhk5dLhpsRoxISzZ3FIr4dOrcY30dG4zdvb9shG481ww11SRERErZbLhpuf9HpM+eUXfHvjBrxVKnzVty8G+PrWPcGhQ+bz2eh0wKhRLVcoEREROcRlz3Pz+IULuKRSQStJ2B0VhTt0uvonqGq1mTgRqNnRmIiIiFoNl225uVRcDDcAL99yC27x9Kx/5IoKYNs289/cJUVERNSquWy4AYAKAPN//RWRP/5Y/4jffQfk5gJBQcC997ZIbURERNQ4Lh1uAMBNkvBx7971j1S1S+rBBwE3l92TR0RE1Ca4/Jb6yIAB9XckLi0Fduww/81dUkRERK2e7C0369atQ2RkJDw8PBATE4OjR4/WO/6aNWvQs2dPeHp6Ijw8HE8//TRKSkocXq5k74jffAPk5Zmv+n3nnQ4vh4iIiFqWrOFm69atSEhIwNKlS3H8+HFER0cjPj4eOTk5NsfftGkTFi5ciKVLlyI5ORnvvvsutm7dimeffdbhZff38UGouzuCq18U03aR5tvJkwG12uHlEBERUcuShBBCroXHxMRg8ODBWLt2LQDAZDIhPDwc8+bNw8KFC2uNP3fuXCQnJyMxMdFy39/+9jccOXIEhw4dsmuZBoMBOp0OeXl58PD1hVZVT74rKgJCQoCCAiApCbj9dseeIBERETlF1fZbr9fDr4ELV8vWclNWVoZjx44hLi7uZjEqFeLi4pCUlGRzmjvuuAPHjh2z7Lq6dOkSvvrqK4yt5zpPpaWlMBgMVgMASJJUf7ABgK++MgebiAggJsbBZ0hERERykK1DcW5uLoxGI0JCQqzuDwkJwblz52xO86c//Qm5ubm48847IYRARUUFZs+eXe9uqVWrVmH58uWNK7Jql9SUKYBkdy8dIiIikpHsHYodsX//fqxcuRJvvfUWjh8/jh07duDLL7/ECy+8UOc0ixYtgl6vtwwZGRn2LSw/H/jiC/PfPEqKiIiozZCt5SYoKAhqtRrZ2dlW92dnZyM0NNTmNIsXL8b06dPx6KOPAgCioqJQWFiIxx9/HM899xxUNnYzabVaaBtzuYTdu4GSEqBHD6BfP8enJyIiIlnI1nKj0WgwcOBAq87BJpMJiYmJiI2NtTlNUVFRrQCjrjyCyen9orlLioiIqE2S9SR+CQkJmDFjBgYNGoQhQ4ZgzZo1KCwsxKxZswAADz/8MDp27IhVq1YBAMaNG4fVq1ejf//+iImJwa+//orFixdj3LhxlpDjFDduAHv2mP/mLikiIqI2RdZwM2XKFFy7dg1LlixBVlYW+vXrhz179lg6Gaenp1u11Dz//POQJAnPP/88rly5gvbt22PcuHH4xz/+4dzCdu4EysuBqCjg1ludO28iIiJqVrKe50YOdh0nP2oU8O23wIsvAs8917IFEhERUS1t4jw3rVZOjvkq4IC5vw0RERG1KQw3NX32GWA0AoMGAd26yV0NEREROYjhpqYtW8y3bLUhIiJqkxhuqrtyBTh40Pz35Mny1kJERESNwnBT3bZtgBDA0KFA585yV0NERESNwHBTHXdJERERtXkMN1VSU4EjRwCVCvjjH+WuhoiIiBqJ4abKp5+ab4cPB+q4thURERG1fgw3VbhLioiISBEYbgAgJQU4eRJwcwMmTpS7GiIiImoChhvg5hXAR44EgoLkrYWIiIiahOFGiJu7pHgFcCIiojaP4ebsWSA5GdBogAcekLsaIiIiaiKGm6pWm7FjAZ1O3lqIiIioyVw73HCXFBERkeK4drg5dgy4dAnw8gLuv1/uaoiIiMgJXDvcVLXajBsHeHvLWwsRERE5heuGG5Pp5iHg3CVFRESkGK4bbo4cAX77DfDzA0aPlrsaIiIichLXDTc7dphvx48HPDxkLYWIiIich+GGu6SIiIgUxXXDTW4u0K4dEBcndyVERETkRK4bbgCgrAz4/HO5qyAiIiIncu1wU1gIPPjgzV1URERE1Oa5dripMn8+YDTKXQURERE5AcONEEBGBnDwoNyVEBERkRMw3FTJzJS7AiIiInIChpsqYWFyV0BERERO4CZ3AbKTJKBTJ2DYMLkrISIiIidw7ZYbSTLfrlkDqNWylkJERETO4drhplMnYPt2YOJEuSshIiIiJ3Hd3VJffGG+YCZbbIiIiBTFdVtuhg1jsCEiIlIg1w03REREpEgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQosoebdevWITIyEh4eHoiJicHRo0frHT8vLw9z5sxBWFgYtFotevToga+++qqFqiUiIqLWzk3OhW/duhUJCQlYv349YmJisGbNGsTHxyMlJQXBwcG1xi8rK8PIkSMRHByM7du3o2PHjrh8+TL8/f1bvngiIiJqlSQhhJBr4TExMRg8eDDWrl0LADCZTAgPD8e8efOwcOHCWuOvX78er776Ks6dOwd3d/dGLdNgMECn00Gv18PPz69J9RMREVHLcGT7LdtuqbKyMhw7dgxxcXE3i1GpEBcXh6SkJJvT7N69G7GxsZgzZw5CQkLQp08frFy5Ekajsc7llJaWwmAwWA1ERESkXLKFm9zcXBiNRoSEhFjdHxISgqysLJvTXLp0Cdu3b4fRaMRXX32FxYsX47XXXsOLL75Y53JWrVoFnU5nGcLDw536PIiIiKh1kb1DsSNMJhOCg4Px73//GwMHDsSUKVPw3HPPYf369XVOs2jRIuj1esuQkZHRghUTERFRS5OtQ3FQUBDUajWys7Ot7s/OzkZoaKjNacLCwuDu7g61Wm25r3fv3sjKykJZWRk0Gk2tabRaLbRarXOLJyIiolZLtpYbjUaDgQMHIjEx0XKfyWRCYmIiYmNjbU4zdOhQ/PrrrzCZTJb7zp8/j7CwMJvBhoiIiFyPrLulEhISsGHDBnz44YdITk7GE088gcLCQsyaNQsA8PDDD2PRokWW8Z944glcv34dTz31FM6fP48vv/wSK1euxJw5c+R6CkRERNTKyHqemylTpuDatWtYsmQJsrKy0K9fP+zZs8fSyTg9PR0q1c38FR4ejr179+Lpp59G37590bFjRzz11FN45pln5HoKRERE1MrIep4bOfA8N0RERG1Ps57npri4GEVFRZb/L1++jDVr1uCbb75xvFIiIiIiJ3M43DzwwAPYuHEjAPN1nmJiYvDaa6/hgQcewNtvv+30AomIiIgc4XC4OX78OIYNGwYA2L59O0JCQnD58mVs3LgRb7zxhtMLJCIiInKEw+GmqKgIvr6+AIBvvvkGEydOhEqlwu23347Lly87vUAiIiIiRzgcbrp164Zdu3YhIyMDe/fuxahRowAAOTk57KBLREREsnM43CxZsgQLFixAZGQkYmJiLCfc++abb9C/f3+nF0hERETkiEYdCp6VlYXMzExER0dbzkNz9OhR+Pn5oVevXk4v0pl4KDgREVHb48j2u1En8QsNDbVc/8lgMOC7775Dz549W32wISIiIuVzeLfU5MmTsXbtWgDmc94MGjQIkydPRt++ffHZZ585vUAiIiIiRzgcbr7//nvLoeA7d+6EEAJ5eXl444038OKLLzq9QCIiIiJHOBxu9Ho9AgICAAB79uzBpEmT4OXlhfvuuw8XLlxweoFEREREjnA43ISHhyMpKQmFhYXYs2eP5VDwGzduwMPDw+kFEhERETnC4Q7F8+fPx7Rp0+Dj44OIiAgMHz4cgHl3VVRUlLPrIyIiInKIw+HmySefxJAhQ5CRkYGRI0daDgXv2rUr+9wQERGR7Bp1npsqVZNKkuS0gpobz3NDRETU9jiy/Xa4zw0AbNy4EVFRUfD09ISnpyf69u2Ljz76qFHFEhERETmTw7ulVq9ejcWLF2Pu3LkYOnQoAODQoUOYPXs2cnNz8fTTTzu9SCIiIiJ7ObxbqkuXLli+fDkefvhhq/s//PBDLFu2DKmpqU4t0Nm4W4qIiKjtadbdUpmZmbjjjjtq3X/HHXcgMzPT0dkREREROZXD4aZbt2749NNPa92/detWdO/e3SlFERERETWWw31uli9fjilTpuD777+39Lk5fPgwEhMTbYYeIiIiopbkcMvNpEmTcOTIEQQFBWHXrl3YtWsXgoKCcPToUUyYMKE5aiQiIiKyW5POc1NdTk4O3nnnHTz77LPOmF2zYYdiIiKitqfZz3NjS2ZmJhYvXuys2RERERE1itPCDREREVFrwHBDREREisJwQ0RERIpi96HgCQkJ9T5+7dq1JhdDRERE1FR2h5sTJ040OM5dd93VpGKIiIiImsrucLNv377mrIOIiIjIKdjnhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUxe6jpU6fPt3wzNzcEBoaioCAgCYVRURERNRYdoebfv36QZIkNHQRcUmSEB0djY0bN6JPnz5NLpCIiIjIEXaHm9TU1AbHMZlMyM7OxquvvoonnngCBw8ebFJxRERERI6SRENNMY3w66+/Ijo6GoWFhc6edZMZDAbodDro9Xr4+fnJXQ4RERHZwZHtt90tN7YUFhZi69atKC4uxqhRo9C9e3cAQJcuXfDDDz80ZdZEREREjWL30VLp6em4++674evri5EjRyI9PR0DBgzAo48+innz5qFfv374/vvvAQBqtRrR0dHNVjQRERFRXewONwsWLEBZWRnWr18PLy8vxMfHo3v37sjMzER2djbGjBmDZcuWNWOpRERERA2zu89NaGgodu/ejSFDhuD69esICgrC4cOHERsbCwA4deoURowYgdzc3GYtuKnY54aIiKjtcWT7bXfLTU5ODiIiIgAAAQEB8PLyQkhIiOXx0NBQ3Lhxo5ElExERETmHQ2coliTJ5t9ERERErYVDR0stWbIEXl5eAICysjL84x//gE6nAwAUFRU5vzoiIiIiB9nd52b48OF2tdbs27evyUU1J/a5ISIianua5Tw3+/fvb2pdRERERM2OVwUnIiIiRbG75WbixIk279fpdOjRowceffRRtG/f3mmFERERETWG3S03Op3O5pCXl4cNGzagZ8+eOHv2bHPWSkRERNQgp1w402Qy4bHHHkNOTg4+//xzZ9TVbNihmIiIqO1plpP41TsTlQp//etfcezYMWfMjoiIiKjRnNah2Nvbm+e6ISIiItk5Ldx8++236NGjh7NmR0RERNQodh8ttXv3bpv36/V6HDt2DO+88w7eeecdpxVGRERE1Bh2h5vx48fbvN/X1xc9e/bEO++8g4ceeshZdRERERE1it3hxmQyNWcdRERERE7BMxQTERGRotgdbpKSkvDFF19Y3bdx40Z06dIFwcHBePzxx1FaWur0AomIiIgcYXe4WbFiBf73v/9Z/j9z5gweeeQRxMXFYeHChfj888+xatWqZimSiIiIyF52h5uTJ09ixIgRlv+3bNmCmJgYbNiwAQkJCXjjjTfw6aefNkuRRERERPayO9zcuHEDISEhlv8PHDiAMWPGWP4fPHgwMjIynFsdERERkYPsDjchISFITU0FAJSVleH48eO4/fbbLY/n5+fD3d29UUWsW7cOkZGR8PDwQExMDI4ePWrXdFu2bIEkSXUepk5ERESux+5wM3bsWCxcuBAHDx7EokWL4OXlhWHDhlkeP336NG655RaHC9i6dSsSEhKwdOlSHD9+HNHR0YiPj0dOTk6906WlpWHBggVWNRARERHZHW5eeOEFuLm54e6778aGDRuwYcMGaDQay+PvvfceRo0a5XABq1evxmOPPYZZs2bh1ltvxfr16+Hl5YX33nuvzmmMRiOmTZuG5cuXo2vXrg4vk4iIiJTL7pP4BQUF4fvvv4der4ePjw/UarXV49u2bYOPj49DCy8rK8OxY8ewaNEiy30qlQpxcXFISkqqc7oVK1YgODgYjzzyCA4ePFjvMkpLS60OUTcYDA7VSERERG2Lwyfx0+l0tYINAAQEBFi15NgjNzcXRqPRqqMyYO7fk5WVZXOaQ4cO4d1338WGDRvsWsaqVaug0+ksQ3h4uEM1EhERUdvSps5QnJ+fj+nTp2PDhg0ICgqya5pFixZBr9dbBh7RRUREpGx275ZqDkFBQVCr1cjOzra6Pzs7G6GhobXGv3jxItLS0jBu3DjLfVXXvHJzc0NKSkqtTs1arRZarbYZqiciIqLWSNaWG41Gg4EDByIxMdFyn8lkQmJiImJjY2uN36tXL5w5cwYnT560DH/4wx9wzz334OTJk9zlRERERPK23ABAQkICZsyYgUGDBmHIkCFYs2YNCgsLMWvWLADAww8/jI4dO2LVqlXw8PBAnz59rKb39/cHgFr3ExERkWuSPdxMmTIF165dw5IlS5CVlYV+/fphz549lk7G6enpUKnaVNcgIiIikpEkhBByF9GSDAYDdDod9Ho9/Pz85C6HiIiI7ODI9ptNIkRERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKK0i3Kxbtw6RkZHw8PBATEwMjh49Wue4GzZswLBhw9CuXTu0a9cOcXFx9Y5PRERErkX2cLN161YkJCRg6dKlOH78OKKjoxEfH4+cnByb4+/fvx9Tp07Fvn37kJSUhPDwcIwaNQpXrlxp4cqJiIioNZKEEELOAmJiYjB48GCsXbsWAGAymRAeHo558+Zh4cKFDU5vNBrRrl07rF27Fg8//HCD4xsMBuh0Ouj1evj5+TW5fiIiImp+jmy/ZW25KSsrw7FjxxAXF2e5T6VSIS4uDklJSXbNo6ioCOXl5QgICLD5eGlpKQwGg9VAREREyiVruMnNzYXRaERISIjV/SEhIcjKyrJrHs888ww6dOhgFZCqW7VqFXQ6nWUIDw9vct1ERETUesne56YpXnrpJWzZsgU7d+6Eh4eHzXEWLVoEvV5vGTIyMlq4SiIiImpJbnIuPCgoCGq1GtnZ2Vb3Z2dnIzQ0tN5p//nPf+Kll17Cf//7X/Tt27fO8bRaLbRarVPqJSIiotZP1pYbjUaDgQMHIjEx0XKfyWRCYmIiYmNj65zulVdewQsvvIA9e/Zg0KBBLVEqERERtRGyttwAQEJCAmbMmIFBgwZhyJAhWLNmDQoLCzFr1iwAwMMPP4yOHTti1apVAICXX34ZS5YswaZNmxAZGWnpm+Pj4wMfHx/ZngcRERG1DrKHmylTpuDatWtYsmQJsrKy0K9fP+zZs8fSyTg9PR0q1c0GprfffhtlZWV48MEHreazdOlSLFu2rCVLJyIiolZI9vPctDSe54aIiKjtaTPnuSEiIiJyNoYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUN7kLaK2MRiPKy8vlLoOaQKPRQKVificicjUMNzUIIZCVlYW8vDy5S6EmUqlU6NKlCzQajdylEBFRC2K4qaEq2AQHB8PLywuSJMldEjWCyWTC1atXkZmZic6dO/N1JCJyIQw31RiNRkuwCQwMlLscaqL27dvj6tWrqKiogLu7u9zlEBFRC2GHhGqq+th4eXnJXAk5Q9XuKKPRKHMlRETUkhhubOAuDGXg60hE5JoYboiIiEhRGG6IiIhIURhumovRCOzfD2zebL5tQ/0+IiMjsWbNGqfMa//+/ZAkiYfWExFRi+HRUs1hxw7gqaeA3367eV+nTsDrrwMTJzbLIocPH45+/fo5JZT89NNP8Pb2bnpRREREMmDLjbPt2AE8+KB1sAGAK1fM9+/YIUtZQghUVFTYNW779u15xBgREbVZDDcNEQIoLLRvMBiAv/7VPI2t+QDmFh2Dwb752ZqPDTNnzsSBAwfw+uuvQ5IkSJKEDz74AJIk4euvv8bAgQOh1Wpx6NAhXLx4EQ888ABCQkLg4+ODwYMH47///a/V/GrulpIkCe+88w4mTJgALy8vdO/eHbt3727sGsVnn32G2267DVqtFpGRkXjttdesHn/rrbfQvXt3eHh4ICQkBA8++KDlse3btyMqKgqenp4IDAxEXFwcCgsLG10LEREpD8NNQ4qKAB8f+wadztxCUxchzC06Op198ysqsqvE119/HbGxsXjssceQmZmJzMxMhIeHAwAWLlyIl156CcnJyejbty8KCgowduxYJCYm4sSJExg9ejTGjRuH9PT0epexfPlyTJ48GadPn8bYsWMxbdo0XL9+3e7VWOXYsWOYPHkyHnroIZw5cwbLli3D4sWL8cEHHwAAfv75Z/z1r3/FihUrkJKSgj179uCuu+4CAGRmZmLq1Kn4y1/+guTkZOzfvx8TJ06EsDMEEhGRa2CfGwXQ6XTQaDTw8vJCaGgoAODcuXMAgBUrVmDkyJGWcQMCAhAdHW35/4UXXsDOnTuxe/duzJ07t85lzJw5E1OnTgUArFy5Em+88QaOHj2K0aNHO1Tr6tWrMWLECCxevBgA0KNHD/zyyy949dVXMXPmTKSnp8Pb2xv3338/fH19ERERgf79+wMwh5uKigpMnDgRERERAICoqCiHlk9ERMrHlpuGeHkBBQX2DV99Zd88v/rKvvk5od/LoEGDrP4vKCjAggUL0Lt3b/j7+8PHxwfJyckNttz07dvX8re3tzf8/PyQk5PjcD3JyckYOnSo1X1Dhw7FhQsXYDQaMXLkSERERKBr166YPn06PvnkExRVtmBFR0djxIgRiIqKwh//+Eds2LABN27ccLgGIiJSNoabhkgS4O1t3zBqlPmoqLrOjCtJQHi4eTx75ueEM+zWPOppwYIF2LlzJ1auXImDBw/i5MmTiIqKQllZWb3zqXltJkmSYDKZmlxfTb6+vjh+/Dg2b96MsLAwLFmyBNHR0cjLy4Narca3336Lr7/+GrfeeivefPNN9OzZE6mpqU6vg4iI2i6GG2dSq82HewO1g0nV/2vWmMdzMo1GY9c1lA4fPoyZM2diwoQJiIqKQmhoKNLS0pxeT1169+6Nw4cP16qpR48eUFeuFzc3N8TFxeGVV17B6dOnkZaWhu+++w6AOVQNHToUy5cvx4kTJ6DRaLBz584Wq5+IiFo/9rlxtokTge3bbZ/nZs2aZjvPTWRkJI4cOYK0tDT4+PjU2arSvXt37NixA+PGjYMkSVi8eHGztMDU5W9/+xsGDx6MF154AVOmTEFSUhLWrl2Lt956CwDwxRdf4NKlS7jrrrvQrl07fPXVVzCZTOjZsyeOHDmCxMREjBo1CsHBwThy5AiuXbuG3r17t1j9RETU+rHlpjlMnAikpQH79gGbNplvU1ObLdgA5t1NarUat956K9q3b19nH5rVq1ejXbt2uOOOOzBu3DjEx8djwIABzVZXTQMGDMCnn36KLVu2oE+fPliyZAlWrFiBmTNnAgD8/f2xY8cO3HvvvejduzfWr1+PzZs347bbboOfnx++//57jB07Fj169MDzzz+P1157DWPGjGmx+omIqPWThIsdR2swGKDT6aDX6+Hn52f1WElJCVJTU9GlSxd4eHjIVCE5C19PIiLlqG/7XRNbboiIiEhRGG6oSWbPng0fHx+bw+zZs+Uuj4iIXBA7FFOTrFixAgsWLLD5WEPNhkRERM2B4YaaJDg4GMHBwXKXQUREZMHdUkRERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw35BRpaWmQJAknT56UuxQiInJxDDfN6GeDAfeePImfDYZmX9bw4cMxf/58p81v5syZGD9+vNPmR0RE1FIYbprRxuxs7MvLw0fZ2XKXQkRE5DIYbhoghECh0Wj3kFxYiEN5eTis12NLTg4AYHNODg7r9TiUl4fkwkK752XvNU1nzpyJAwcO4PXXX4ckSZAkCWlpaTh79izGjBkDHx8fhISEYPr06cjNzbVMt337dkRFRcHT0xOBgYGIi4tDYWEhli1bhg8//BD/+c9/LPPbv3+/w+vuwIEDGDJkCLRaLcLCwrBw4UJUVFQ0uHwA2L9/P4YMGQJvb2/4+/tj6NChuHz5ssM1EBGR6+EZihtQZDLB5+DBJs3jWnk57jxxwuHpCoYNg7da3eB4r7/+Os6fP48+ffpgxYoVAAB3d3cMGTIEjz76KP71r3+huLgYzzzzDCZPnozvvvsOmZmZmDp1Kl555RVMmDAB+fn5OHjwIIQQWLBgAZKTk2EwGPD+++8DAAICAhyq/cqVKxg7dixmzpyJjRs34ty5c3jsscfg4eGBZcuW1bv8iooKjB8/Ho899hg2b96MsrIyHD16FJIkObwOiYjI9TDcKIBOp4NGo4GXlxdCQ0MBAC+++CL69++PlStXWsZ77733EB4ejvPnz6OgoAAVFRWYOHEiIiIiAABRUVGWcT09PVFaWmqZn6PeeusthIeHY+3atZAkCb169cLVq1fxzDPPYMmSJcjMzKxz+devX4der8f999+PW265BQDQu3fvRtVBRESuh+GmAV4qFQqGDXNompMFBTZbag71749+Pj4OLbuxTp06hX379sHHxvIuXryIUaNGYcSIEYiKikJ8fDxGjRqFBx98EO3atWv0MqtLTk5GbGysVWvL0KFDUVBQgN9++w3R0dF1Lj8gIAAzZ85EfHw8Ro4cibi4OEyePBlhYWFOqY2IiJSNfW4aIEkSvNVqhwbPylBStXKrbj1VKofm05TdMAUFBRg3bhxOnjxpNVy4cAF33XUX1Go1vv32W3z99de49dZb8eabb6Jnz55ITU1t2gqzU0PLf//995GUlIQ77rgDW7duRY8ePfDjjz+2SG1ERNS2Mdw0g2B3d4S6u2Ogry/W9+iBgb6+CHV3R7C7e7MtU6PRwGg0Wv4fMGAA/ve//yEyMhLdunWzGry9vQGYg9vQoUOxfPlynDhxAhqNBjt37rQ5P0f17t0bSUlJVp2iDx8+DF9fX3Tq1KnB5QNA//79sWjRIvzwww/o06cPNm3a1Oh6iIjIdTDcNINOHh5Ii43FkQED8P86dMCRAQOQFhuLTh4ezbbMyMhIHDlyBGlpacjNzcWcOXNw/fp1TJ06FT/99BMuXryIvXv3YtasWTAajThy5AhWrlyJn3/+Genp6dixYweuXbtm6dsSGRmJ06dPIyUlBbm5uSgvL3eonieffBIZGRmYN28ezp07h//85z9YunQpEhISoFKp6l1+amoqFi1ahKSkJFy+fBnffPMNLly4wH43RERkH+Fi9Hq9ACD0en2tx4qLi8Uvv/wiiouLZaisaVJSUsTtt98uPD09BQCRmpoqzp8/LyZMmCD8/f2Fp6en6NWrl5g/f74wmUzil19+EfHx8aJ9+/ZCq9WKHj16iDfffNMyv5ycHDFy5Ejh4+MjAIh9+/bVu/zU1FQBQJw4ccJy3/79+8XgwYOFRqMRoaGh4plnnhHl5eVCCFHv8rOyssT48eNFWFiY0Gg0IiIiQixZskQYjUaH1klbfj2JiMhafdvvmiQh7DyZikIYDAbodDro9Xr4+flZPVZSUoLU1FR06dIFHs3YykItg68nEZFy1Lf9rom7pYiIiEhRGG7ILitXroSPj4/NYcyYMXKXR0REZMHz3JBdZs+ejcmTJ9t8zNPTs4WrISIiqhvDDdklICDA4UswEBERyYG7pWxwsT7WisXXkYjINTHcVONeeZK9oqIimSshZygrKwNgPhsyERG5jlaxW2rdunV49dVXkZWVhejoaLz55psYMmRIneNv27YNixcvRlpaGrp3746XX34ZY8eObXIdarUa/v7+yMnJAQB4eXnxStRtlMlkwrVr1+Dl5QU3t1bxNiciohYi+7f+1q1bkZCQgPXr1yMmJgZr1qxBfHw8UlJSEBwcXGv8H374AVOnTsWqVatw//33Y9OmTRg/fjyOHz+OPn36NLmeqqtgVwUcartUKhU6d+7MgEpE5GJkP4lfTEwMBg8ejLVr1wIw/+IODw/HvHnzsHDhwlrjT5kyBYWFhfjiiy8s991+++3o168f1q9f3+Dy7D0JkNFodPiSA9S6aDQaqJpwZXUiImo9HDmJn6wtN2VlZTh27BgWLVpkuU+lUiEuLg5JSUk2p0lKSkJCQoLVffHx8di1a5fN8UtLS1FaWmr532Aw2FWbWq1mXw0iIqI2SNaftbm5uTAajQgJCbG6PyQkBFlZWTanycrKcmj8VatWQafTWYbw8HDnFE9EREStkuLb7BctWgS9Xm8ZMjIy5C6JiIiImpGsu6WCgoKgVquRnZ1tdX92dralY29NoaGhDo2v1Wqh1WqdUzARERG1erKGG41Gg4EDByIxMRHjx48HYO5QnJiYiLlz59qcJjY2FomJiZg/f77lvm+//RaxsbF2LbOq/7S9fW+IiIhIflXbbbuOgxIy27Jli9BqteKDDz4Qv/zyi3j88ceFv7+/yMrKEkIIMX36dLFw4ULL+IcPHxZubm7in//8p0hOThZLly4V7u7u4syZM3Yt7+LFiwIABw4cOHDgwKENDhkZGQ1u62U/z82UKVNw7do1LFmyBFlZWejXrx/27Nlj6TScnp5udTjvHXfcgU2bNuH555/Hs88+i+7du2PXrl12n+Om6vpI6enp0Ol0zn9CVC+DwYDw8HBkZGQ0eCgfORfXvby4/uXDdS8fZ657IQTy8/PRoUOHBseV/Tw3Lc2R4+TJ+bj+5cN1Ly+uf/lw3ctHrnWv+KOliIiIyLUw3BAREZGiuFy40Wq1WLp0KQ8PlwnXv3y47uXF9S8frnv5yLXuXa7PDRERESmby7XcEBERkbIx3BAREZGiMNwQERGRojDcEBERkaK4XLhZt24dIiMj4eHhgZiYGBw9elTuklzCsmXLIEmS1dCrVy+5y1Kk77//HuPGjUOHDh0gSRJ27dpl9bgQAkuWLEFYWBg8PT0RFxeHCxcuyFOswjS07mfOnFnrczB69Gh5ilWYVatWYfDgwfD19UVwcDDGjx+PlJQUq3FKSkowZ84cBAYGwsfHB5MmTap1IWZynD3rfvjw4bXe+7Nnz262mlwq3GzduhUJCQlYunQpjh8/jujoaMTHxyMnJ0fu0lzCbbfdhszMTMtw6NAhuUtSpMLCQkRHR2PdunU2H3/llVfwxhtvYP369Thy5Ai8vb0RHx+PkpKSFq5UeRpa9wAwevRoq8/B5s2bW7BC5Tpw4ADmzJmDH3/8Ed9++y3Ky8sxatQoFBYWWsZ5+umn8fnnn2Pbtm04cOAArl69iokTJ8pYtTLYs+4B4LHHHrN677/yyivNV5SjF7psy4YMGSLmzJlj+d9oNIoOHTqIVatWyViVa1i6dKmIjo6WuwyXA0Ds3LnT8r/JZBKhoaHi1VdftdyXl5cntFqt2Lx5swwVKlfNdS+EEDNmzBAPPPCALPW4mpycHAFAHDhwQAhhfp+7u7uLbdu2WcZJTk4WAERSUpJcZSpSzXUvhBB33323eOqpp1qsBpdpuSkrK8OxY8cQFxdnuU+lUiEuLg5JSUkyVuY6Lly4gA4dOqBr166YNm0a0tPT5S7J5aSmpiIrK8vqc6DT6RATE8PPQQvZv38/goOD0bNnTzzxxBP4/fff5S5JkfR6PYCbF0s+duwYysvLrd77vXr1QufOnfned7Ka677KJ598gqCgIPTp0weLFi1CUVFRs9Ug+1XBW0pubi6MRqPlauNVQkJCcO7cOZmqch0xMTH44IMP0LNnT2RmZmL58uUYNmwYzp49C19fX7nLcxlZWVkAYPNzUPUYNZ/Ro0dj4sSJ6NKlCy5evIhnn30WY8aMQVJSEtRqtdzlKYbJZML8+fMxdOhQ9OnTB4D5va/RaODv7281Lt/7zmVr3QPAn/70J0RERKBDhw44ffo0nnnmGaSkpGDHjh3NUofLhBuS15gxYyx/9+3bFzExMYiIiMCnn36KRx55RMbKiFrOQw89ZPk7KioKffv2xS233IL9+/djxIgRMlamLHPmzMHZs2fZr08Gda37xx9/3PJ3VFQUwsLCMGLECFy8eBG33HKL0+twmd1SQUFBUKvVtXrGZ2dnIzQ0VKaqXJe/vz969OiBX3/9Ve5SXErVe52fg9aha9euCAoK4ufAiebOnYsvvvgC+/btQ6dOnSz3h4aGoqysDHl5eVbj873vPHWte1tiYmIAoNne+y4TbjQaDQYOHIjExETLfSaTCYmJiYiNjZWxMtdUUFCAixcvIiwsTO5SXEqXLl0QGhpq9TkwGAw4cuQIPwcy+O233/D777/zc+AEQgjMnTsXO3fuxHfffYcuXbpYPT5w4EC4u7tbvfdTUlKQnp7O934TNbTubTl58iQANNt736V2SyUkJGDGjBkYNGgQhgwZgjVr1qCwsBCzZs2SuzTFW7BgAcaNG4eIiAhcvXoVS5cuhVqtxtSpU+UuTXEKCgqsfg2lpqbi5MmTCAgIQOfOnTF//ny8+OKL6N69O7p06YLFixejQ4cOGD9+vHxFK0R96z4gIADLly/HpEmTEBoaiosXL+Lvf/87unXrhvj4eBmrVoY5c+Zg06ZN+M9//gNfX19LPxqdTgdPT0/odDo88sgjSEhIQEBAAPz8/DBv3jzExsbi9ttvl7n6tq2hdX/x4kVs2rQJY8eORWBgIE6fPo2nn34ad911F/r27ds8RbXYcVmtxJtvvik6d+4sNBqNGDJkiPjxxx/lLsklTJkyRYSFhQmNRiM6duwopkyZIn799Ve5y1Kkffv2CQC1hhkzZgghzIeDL168WISEhAitVitGjBghUlJS5C1aIepb90VFRWLUqFGiffv2wt3dXURERIjHHntMZGVlyV22Itha7wDE+++/bxmnuLhYPPnkk6Jdu3bCy8tLTJgwQWRmZspXtEI0tO7T09PFXXfdJQICAoRWqxXdunUT//d//yf0en2z1SRVFkZERESkCC7T54aIiIhcA8MNERERKQrDDRERESkKww0REREpCsMNERERKQrDDRERESkKww0REREpCsMNEbk8SZKwa9cuucsgIidhuCEiWc2cOROSJNUaRo8eLXdpRNRGudS1pYiodRo9ejTef/99q/u0Wq1M1RBRW8eWGyKSnVarRWhoqNXQrl07AOZdRm+//TbGjBkDT09PdO3aFdu3b7ea/syZM7j33nvh6emJwMBAPP744ygoKLAa57333sNtt90GrVaLsLAwzJ071+rx3NxcTJgwAV5eXujevTt2797dvE+aiJoNww0RtXqLFy/GpEmTcOrUKUybNg0PPfQQkpOTAQCFhYWIj49Hu3bt8NNPP2Hbtm3473//axVe3n77bcyZMwePP/44zpw5g927d6Nbt25Wy1i+fDkmT56M06dPY+zYsZg2bRquX7/eos+TiJyk2S7JSURkhxkzZgi1Wi28vb2thn/84x9CCPMVh2fPnm01TUxMjHjiiSeEEEL8+9//Fu3atRMFBQWWx7/88kuhUqksV9zu0KGDeO655+qsAYB4/vnnLf8XFBQIAOLrr7922vMkopbDPjdEJLt77rkHb7/9ttV9AQEBlr9jY2OtHouNjcXJkycBAMnJyYiOjoa3t7fl8aFDh8JkMiElJQWSJOHq1asYMWJEvTX07dvX8re3tzf8/PyQk5PT2KdERDJiuCEi2Xl7e9faTeQsnp6edo3n7u5u9b8kSTCZTM1REhE1M/a5IaJW78cff6z1f+/evQEAvXv3xqlTp1BYWGh5/PDhw1CpVOjZsyd8fX0RGRmJxMTEFq2ZiOTDlhsikl1paSmysrKs7nNzc0NQUBAAYNu2bRg0aBDuvPNOfPLJJzh69CjeffddAMC0adOwdOlSzJgxA8uWLcO1a9cwb948TJ8+HSEhIQCAZcuWYfbs2QgODsaYMWOQn5+Pw4cPY968eS37RImoRTDcEJHs9uzZg7CwMKv7evbsiXPnzgEwH8m0ZcsWPPnkkwgLC8PmzZtx6623AgC8vLywd+9ePPXUUxg8eDC8vLwwadIkrF692jKvGTNmoKSkBP/617+wYMECBAUF4cEHH2y5J0hELUoSQgi5iyAiqoskSdi5cyfGjx8vdylE1Eawzw0REREpCsMNERERKQr73BBRq8Y950TkKLbcEBERkaIw3BAREZGiMNwQERGRojDcEBERkaIw3BAREZGiMNwQERGRojDcEBERkaIw3BAREZGiMNwQERGRovx/6TsfMxOfU8AAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,489,601 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.628 | Train Acc: 67.83%\n",
      "\t test  Loss: 0.618 | test  Acc: 68.38%\n",
      "\t best  test acc: 68.38%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.591 | Train Acc: 70.90%\n",
      "\t test  Loss: 0.562 | test  Acc: 73.60%\n",
      "\t best  test acc: 73.60%\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.515 | Train Acc: 78.19%\n",
      "\t test  Loss: 0.513 | test  Acc: 78.36%\n",
      "\t best  test acc: 78.36%\n",
      "Epoch: 04 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.465 | Train Acc: 81.83%\n",
      "\t test  Loss: 0.512 | test  Acc: 78.08%\n",
      "\t best  test acc: 78.36%\n",
      "Epoch: 05 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.439 | Train Acc: 82.90%\n",
      "\t test  Loss: 0.509 | test  Acc: 78.73%\n",
      "\t best  test acc: 78.73%\n",
      "Epoch: 06 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.398 | Train Acc: 85.33%\n",
      "\t test  Loss: 0.507 | test  Acc: 79.20%\n",
      "\t best  test acc: 79.20%\n",
      "Epoch: 07 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.370 | Train Acc: 86.50%\n",
      "\t test  Loss: 0.485 | test  Acc: 81.34%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 08 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.343 | Train Acc: 88.14%\n",
      "\t test  Loss: 0.497 | test  Acc: 81.06%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 09 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.312 | Train Acc: 89.48%\n",
      "\t test  Loss: 0.528 | test  Acc: 79.94%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 10 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.289 | Train Acc: 90.60%\n",
      "\t test  Loss: 0.558 | test  Acc: 79.94%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 11 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.263 | Train Acc: 91.54%\n",
      "\t test  Loss: 0.604 | test  Acc: 78.17%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 12 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.268 | Train Acc: 91.34%\n",
      "\t test  Loss: 0.576 | test  Acc: 79.29%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 13 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.244 | Train Acc: 91.88%\n",
      "\t test  Loss: 0.518 | test  Acc: 80.22%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 14 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.218 | Train Acc: 92.74%\n",
      "\t test  Loss: 0.529 | test  Acc: 80.69%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 15 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.201 | Train Acc: 92.83%\n",
      "\t test  Loss: 0.558 | test  Acc: 79.48%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 16 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.176 | Train Acc: 93.91%\n",
      "\t test  Loss: 0.585 | test  Acc: 78.54%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.162 | Train Acc: 93.96%\n",
      "\t test  Loss: 0.567 | test  Acc: 79.94%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 18 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.145 | Train Acc: 94.59%\n",
      "\t test  Loss: 0.558 | test  Acc: 81.06%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 19 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.132 | Train Acc: 95.28%\n",
      "\t test  Loss: 0.586 | test  Acc: 80.41%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 20 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.136 | Train Acc: 95.04%\n",
      "\t test  Loss: 0.588 | test  Acc: 80.04%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 21 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.130 | Train Acc: 95.23%\n",
      "\t test  Loss: 0.652 | test  Acc: 79.10%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 22 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.116 | Train Acc: 95.85%\n",
      "\t test  Loss: 0.628 | test  Acc: 79.94%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 23 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.130 | Train Acc: 95.42%\n",
      "\t test  Loss: 0.603 | test  Acc: 80.60%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 24 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.117 | Train Acc: 95.94%\n",
      "\t test  Loss: 0.626 | test  Acc: 79.48%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 25 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.098 | Train Acc: 96.45%\n",
      "\t test  Loss: 0.645 | test  Acc: 80.97%\n",
      "\t best  test acc: 81.34%\n",
      "Epoch: 26 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.099 | Train Acc: 96.36%\n",
      "\t test  Loss: 0.652 | test  Acc: 80.22%\n",
      "\t best  test acc: 81.34%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSfklEQVR4nO3deXwTZf4H8M8kTdK7tJReUCj3TblrYUGUQoGVlWs5RDlUXBAQtvLjUDkVWGVVUK5dXWVVLkHAGxcroGA5BCso5S620hto07tNMr8/pg090jZp0yadfN6v17zSTCYz306T5pNnnplHEEVRBBEREZFMKGxdABEREZE1MdwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGs2DTcfP/99xg9ejSCgoIgCAIOHTpU43OOHTuG3r17Q6PRoF27dtixY0e910lERESNh03DTW5uLkJDQ7Flyxazlo+Pj8ef//xnPPTQQ4iNjcXChQvx9NNP45tvvqnnSomIiKixEOxl4ExBEHDw4EGMGTOmymWWLFmCL7/8Er/++qtx3uTJk5GZmYnDhw83QJVERERk75xsXYAlYmJiEBERUW5eZGQkFi5cWOVzCgsLUVhYaLxvMBhw9+5dNG3aFIIg1FepREREZEWiKCI7OxtBQUFQKKo/8NSowk1KSgr8/f3LzfP394dWq0V+fj5cXFwqPWf9+vVYvXp1Q5VIRERE9SgxMREtWrSodplGFW5qY9myZYiKijLez8rKQsuWLZGYmAhPT08bVkZERETm0mq1CA4OhoeHR43LNqpwExAQgNTU1HLzUlNT4enpabLVBgA0Gg00Gk2l+Z6engw3REREjYw5XUoa1XVuwsPDER0dXW7ekSNHEB4ebqOKiIiIyN7YNNzk5OQgNjYWsbGxAKRTvWNjY5GQkABAOqQ0bdo04/KzZ8/GzZs3sXjxYly+fBlbt27Fxx9/jL///e+2KJ+IiIjskE3DzU8//YRevXqhV69eAICoqCj06tULK1asAAAkJycbgw4AtG7dGl9++SWOHDmC0NBQvP7663j33XcRGRlpk/qJiIjI/tjNdW4ailarhZeXF7KystjnhoiIqJGw5PO7UfW5ISIiIqpJozpbioiIiOqRXg/88AOQnAwEBgKDBgFKpe3XZSGGGyIiIgIOHAAWLAD++OP+vBYtgE2bgHHjbLeuWmCfGyIiInPYsCWi3us6cACYMAGoGAlKrymzf7/5ocSa6yrDks9vhhsiIqKa2Lglol7r0uuBkJDy6yhLEKR1xsfXHJqsua4KGG6qwXBDRFQP7LVVwxrqoyXCVq0tBgNw54603ZQU6fbkSeCdd2reXkgI4OUFODlVPWVmSuurydGjwJAhZvyS9zHcVIPhhojIyqzdqmFPnVrroyWiIVpbAMDTE5g0CUhNlX7/0kCj05m3jfq0axcwZYpFT7Hk85sdiomIqPaqaj24fVuab2mrhr10ahVFID0dOHiw+gAhikBiIvDmm0BEBNCsGeDrC5gY09BYkyX7q6jofgtLUtL92/Pnq68LALTaqltkfH2lsBcYKAW0b76pfl0A8MYbQLduUjiqavrtN+D112teV2BgzcvUAVtuiIgclb21ajRkp9adO4E+fYCEBNNTYiJQUGDetkzx9JQCRLNm96emTaWwkZVV9fNcXYE//el+S0tGRu1rAKT9NXw4EBBwP8z4+wNq9f1lSv+Ot29X3l9A7frcWGNdFfCwVDUYboiIUPcWElGUWjXGj6952UWLpCDh7g64uZm+VSqB1q1rDko3b0otBPn5QF6edFs6ld7PyQFmzwbu3jVvX1RFEAAfH6mPSk1CQqRtZ2RIH/DWpFLdDyZBQdJtQQHw3ns1P9fcvi2lYRAoH0rqEiytsa4yGG6qwXBDRA3OnvqQAOa3kOTnS9+wb940PeXn1+53MEWhkDq7NiRnZ6BNG6BlS9NT8+bSvrWkJcJgkDrVZmRIh7VKp4wM6e/29dc11/W3vwFjx94PMz4+0v4pqz5aSEwF3uBgYONG6xwSrO26SjDcVIPhhogalL30ISllTkdUtVr6QE1JqX5dgmD6g7Wi8HApSOTmSq0qZW/rcuhHqZQO47i4SFPpzzk5wNWrNT9/507gscdqXs5aLRHHjgEPPVTzcrZobSllb0G8DIabajDcEFGDsfWF0QoLpb4jv/8u9SP5/Xfg1CnzOo+W8vQE2raVWjhKp9L7zZsD7dvXrfVAp5NCzpEjwF//WnM9n3widdx1cZEO15hi7RABWKclwt5bW+wcw001GG6IqEE05IXRAKBJE+DJJ6UwUxpkamp5qc4rrwBz5gDe3vcDlCnWaj1oDJ1arXlIELDP1hY7xnBTDYYbIqqRNT4szG096N9fChAGgzTp9ZV/zswErlypzW8itXC0aiVNLVtK67RmR1TAeq0HjaBTq1U4UGuLNTHcVIPhhkimrPXttbb9WgoKgNhY4MwZ4OxZIDpaqqUhjRgBREZKIaY00DRtWr7lxZ5bNQC779RqNQ7S2mJNDDfVYLghkiFrddo1t1+LTgdcunQ/yJw9C1y8WLsrvy5ZAnTpIp0No1BIH3AVf/7tN+CFF2pely07olqTHXdqJdthuKkGww2RzFir0645/Vrc3YEePYCffzZ9GrSfH9Cvn3SoqXdv6ZTe5GT77ENiz60aRCYw3FSD4YbIjtT3FXIBqaPtSy9JfVeKi6VJp6v8c0IC8OWX5m/bwwPo21cKMv36SVNwcPlDQPbeh4StGtSIMNxUg+GGHJI9fojV9lDSvXvSIaFLl6RTmj/5pP5rLWvOHOC554AOHSpfWM0UR+lDQlTPGG6qwXBDDsceR2w251DSgw9KAea33+6HmUuXatdJNzxcuh6LSgU4OUm3FX9OTLT+WUSl2IeEqM4YbqrBcEMOxZoXkStdX0NcIbemS/G3aAF07SodGtq/v+ZtmhNI6nHAPyKqO4abajDckMOw5YjNBoM0ls7t20BSUvnbCxeks4zM0aqVdCZR167SbZcuQOfO0lVzy/6O1gok9n4WEZEDs+Tz26mBaiIiS9Xl8IMoAvv2Vd86IorSoZg+faTB+VxdK0+l4/U4O0udck0FiNJ5jz8OhIZKISY5WeqkWxfvvQfMnFn9Mkql1Go0YULlcY5KA8nGjebvt3HjpABjqnWK/VqIGg223BDZI0sO/2RnA7/+KrWI/PKLdHvxIqDVNmzNFQmCdGp0UJA0BlHz5tLP2dnAP/9Z8/NtcYXcUuzXQmR3eFiqGgw3ZPdqOvyzaJHUmlIaZm7eNL0eJyfzLiq3YgXQujWQlydN+fn3fy6drl4Ffvqp5nUtXAhMmiQFmYAA0wMb2vsVconILjHcVIPhhuyaOZ1tTQkKki4uFxoq3fboAbRrV/cRm0tZe5Rl9m0hIguxzw2RrdSm9aC078vp09KHujnBpnQModBQoHt3wNfX9HLW6o8yaJAUhGoKSoMG1bwugH1biKheseWGyFrM7Sej1UqHeE6fvj+lpFi2rV27gClTal+XrUdsLsVDSURkJh6WqgbDDdWLmvrJPPMMUFQkBZm4uMrLKZXSoaQWLYDPP695e5ZeSM4eR2wmIrIAw001GG7I6mrTT6ZVKyAs7P7Uq5fUSbgxXEiOrS1EZAPsc0PUULKzga1bzQs2U6cCEydKAy0GBJhextrXbakPSqXlww8QETUghhsiS1oi8vOBmBjgu++kQ0Nnzph3ujUA/PnPwF/+UvNy7GxLRFQnDDfk2GrqBFxcDJw9K4WZ774DfvwRKCwsv46AAPM6BAcGml/XuHHAo4/y8A8RUS2wzw05rqo6AZfq1Uu6eF1ubvn5gYHAww9L00MPAS1b2n8/GSKiRo59bohqotdLLTbVZfuff5ZumzaVQsxDD0mBpmPH+/1fStl7PxkiIgfCcEOO6aOPzOsE/M47wJNPAgpF9cuxnwwRkd1guCHHYDBIfWcOHgQOHQKuXDHveW5uNQebUuwnQ0RkFxhuqHEy5wynoiJpTKSDB4FPP5WWLWXuoJKWdAIGeJo0EZEdYLihxqe6M5yGDQMOH5ZaZ778EsjKur+Mh4d0OvaYMcDw4dIVga01VhIREdkNhhtqXKo6w+mPP4Dx4yu3yAQESIeKxoyROgRrNPcfYydgIiJZYrihxsOcM5x0OqBtW6n/y9ix0tAGVfWZYSdgIiJZYrihhlObMYlEEUhMlK4KvG+f+Wc4PfSQeTWxEzARkeww3FDDqOlKwKUKC4Hz56UwExMjXRE4KcmybZlzteCy2AmYiEhWGG6o/lXVT+b2bWn+889Lp2r/+KMUbIqKyi+nVAI9e0pXAj54sObtWXqGExERyQqHX6D6pddLQxOYczipVLNmQHg4MGCAdNu3L+Dqen9dHOaAiMjhcPgFsh8//GBesPnLX6RWnAEDgDZtKg9vAEiBhWc4ERFRDcy89CpRLeh0wCefmLfs5MnAE09IZzqZCjalSs9wat68/PwWLaT5PMOJiMjhseWGrC8/H9ixA/jnP4GbN817jiX9ZHiGExERVYPhhqwnMxPYtk06NJSWJs1r2hQoLgays617JWCe4URERFXgYSmqu6QkYPFi6WymF16Qgk2rVsDbbwMJCcD770vLVTzcxH4yRERUDxhuqHp6vTT45O7d0q1ef/+xq1eBWbOA1q2BDRuk1plu3YAPPwSuXQPmzZPOcmI/GSIiakA8LEVVq+rCe/PnA2fPSp2FSw81/elPwNKlwKhRpjsEs58MERE1EF7nhkyr6sJ7FY0eDSxZAgwc2DB1ERGRQ+J1bqhuzBmg0tVVuqJwaGjD1UVERGQGhhs5qs0AlQCQkQH89BPw8cc1X3gvLw+4d8869RIREVkRw43cmDtAZVaWNI7T2bNSoDl7Frh1y7JtJSdbpWQiIiJrYriRk+oGqBw/Hpg5U7rmzNmzwJUrptfRoYN0Sve339a8PRsPUPmTVovFN2/itTZt0Jf9p4iIqATDjVxU10+mdF7p9WZKtWoF9OsnDUzZrx/Qpw/g5WX+AJWWXnjPyj5ITcXRzEx8mJpa53DDoESOiq99kiOGG7kwd4DKGTOAiROlQNOsmell7HiAyt8LCpBRXAwBwN6SqyDvSUvD9IAAiAB8VSq0cna2eL3WDEpEjQlf+1SRHAIvw41c3L5t3nLDhwMjR9a8XOmF90z139m40WYX3gs5darSvLTiYvQ5d854f1fnzvBQKuHp5ATPktvS+xrF/etW1ldQItuRwz/lhsDXvn2w19erHAIvw40c3L4NvPmmecs24gEqiwwGzA0KwtakJFR39Z3H4uKqfEwtCMawE19QUOnxikFJ5PhV9c6a/+Dl8E+5IZjzJaE2r317/bC2V/b0ei0beHelpgIlt9P8/QFBqHXgtdVrwubhZsuWLdiwYQNSUlIQGhqKt99+G/37969y+Y0bN2Lbtm1ISEiAr68vJkyYgPXr18PZUb9l7N0LzJlT82nZjXiAyt8LCvDvpCS8m5yMtOLiKpcb5eMDtUIBrU4HrV4PrU6H7JLbXIMBAFAkisgoLkZGNesp1dfdHa8lJCDM0xN93N3h7mTzt4ss1fUf/O8FBUgpLESmToedJf+Ud7MVwkgURSQWFuK0VitN2dlQCQKKa7hAZ9CPPyLE2dnk1FKjgbOJLznsB1cze2w1y9frTQbeDJ0Ofc+fN95f2rIl2ru4oL2LC9q5uCBArYZg6or0ZdgqwNn0CsV79+7FtGnTsH37doSFhWHjxo3Yt28frly5Aj8/v0rL79q1C08++STee+89DBgwAFevXsWMGTMwefJkvPHGG2ZtUzZXKM7MlMZu2rlTut+3LzBtmnQYCTDdT6YRjeNkEEV8c/cutiUl4cs7d2AomR+oVuMRHx+8k5ICBQADYLw916cPent4mFyfXhSRUxJ0tHo9sktuY7OzsSQ+vsZ6FAC6ubkhzNNTmjw80NnNDUoTb2xr/lN2hH/wIy9cQFpxMfxUKnzdo4fxH3yAWo20oiKkFhUhtbhYuq1wP62oCL/l5dW4vaTwcARqNPX+ezWU6l4X2TodfsrOxmmtFqdKwkxKUVGldbgpFMbQX5aLQoF8E/MrClSrEeLsjGYqFXxUKjRXq7Hl9m1k6vVo6uSET7t3h0YQ0EytrtWH9XPXruHt27fxXPPm2NS+vcXPry+Wvif1oojkwkLcKijArYICPHH5co3PaYgW4+t5efj67l18dfcujmVmosCMv3lF7kol2pUEnbKhx1mhgABAIQhVvr9r85qw5PPbpuEmLCwM/fr1w+bNmwEABoMBwcHBmD9/PpYuXVpp+Xnz5iEuLg7R0dHGec8//zxOnz6NEydOmLVNWYSbo0eB6dOBxERAoQBefBFYvhxQqUxf5yY42Kb9ZCyRUVSE91JS8K+kJNwsc9jo4SZNMCcoCI/6+iK1qAj9zp1DsLMzngoMxH+Sk5FYUICzffqghYVvmPPZ2ehz7lyloPTvDh1wT6czftu9beLDwUOpRF8PD2PYCfP0RKBGY9V/yvb6D76uhGPHGnybbZ2dMdDLC3/y8sJALy90cnWFoppvnfYcLEtfF/ObN8fTgYHlWmV+y82tdNhWCaCHu3u512quXo9+589Xeu3/1Ls3QlxcjB/GFaf4/HyToag63dzc4OPkBB+VCk1Lb1WqSvPyDQboDAa4KJVW/VC0porvyYrhpeKUUFhYYytZWSpBKPd3CvP0RLBGU2MLSU2v13y9HsczM42B5np+frnHW2g06O/hgQMZGZWeu7FdO4iiiGv5+bien49r+fn4vaAAlseh+2oT4BrF8AtFRUU4d+4cli1bZpynUCgQERGBmJgYk88ZMGAAPvroI5w5cwb9+/fHzZs38dVXX+GJJ56ocjuFhYUoLCw03tdqtdb7JRpaYaEUZN54Q2qZadsW+Ogj4IEH7i9jZ/1kKjL1BhRFETFaLbYlJWFfWhoKS/4ReCmVmBEQgNlBQejk5mZcRwtnZ9wKD4daECAIAp4JDESRKJbrLGwuP5UKASpVpaA00senXFC6XbZZX6vFT9nZyNbrcTQzE0czM43L+atUyNTpAADvJidDWzKKuotCAS8zD2tl6XTGb84flzRb70xNtavDLJZ88BcbDLiSl4cLubm4kJODC7m58FYqca/sCPNVUAkC/FQq+KvVxqnc/ZKfU4uKMOzChUrPn+jriyv5+biQm4sbBQW4UVCAD0oOXfk4OWFASdj5k5cX+ri7lzvUYk/9IQCpteuPggLE5uTgPyUX0Hz79m28beJkgpYaTblWxt4eHnCt8D/gj4ICk699f7UaTUvCRx8TLaGiKOKuTmf88P4kLQ170tOr7Qf3a25urX9ve+gHdyMvD7G5ubiVn4/3Svb9tqQkHEhPR0pREXQ1PN9JENBSo0HrksN6akHANhMXQXVXKJBjMOBEVhZOZGUZ5weo1eXCTj8PD3hU+H9i6vV6Iz8fX9+5g6/v3sXRzMxyLXJOgoA/eXlhlI8PRvr4oKubG37OycGBjIxKgXeQl1elVvEigwHxBQW4lpdnDDyl4edWQUGVrwcnQcCOTp1q2GN1Z7OWm6SkJDRv3hw//vgjwsPDjfMXL16M48eP4/Tp0yaf99Zbb2HRokUQRRE6nQ6zZ8/Gtm3bqtzOqlWrsHr16krzG13LzYULwOOPAxcvSvdnzZJCjru7beuyUNlvPWtbt8bOtDRsu30bv5T559fb3R3PNm+OyX5+cGuAUFZoMBiDkiiKZgUlncGAS3l5xrDzn5SUeq+zLFt3dDbVoiSKIlKKisqFmAs5OYjLy7Pom+u/2rfHoCZN4K9Ww9vJqcZvrEDVLXClhyqzdDqc0mpxIisLJ7OycEqrrXToRS0I6O7mhm5ubujp7o61CQnIsHHLgV4U8XN2Nr69dw/LzDh8eqhbN4R5eCDAzENwtXntm1K6/yv6ont3BKnVuFNcjLs6He4WF+NOya3xfpmf04uLa2wNaOPsjB7u7uju5oYebm7o4e6Oti4uJg8RlzI3jOfr9bian49LubmIy8uTptxcsw59tqmif1KIszOCNJpy9VX1ej3buzfclUqcLjmseFqrxS85Oaj4NUAA0MXVFV3d3NDOxQXd3dzw3PXrSC8uRhOlEiN9fHBSq0VCmS/2ANBcrcaopk0x0scHQ7294VkhIP1RUGCVVvFCgwFf3rmD8b/9Vumx6roP1KRRtNzUxrFjx7Bu3Tps3boVYWFhuH79OhYsWICXX34Zy5cvN/mcZcuWISoqynhfq9UiODi4oUquO4NBCjEvvggUFUnXpnn3XeAvf2mwEuraPG+qA907ycl4NzkZeSUfMM4KBSb7+WFOUBD6eXiY9YFmLWX/mQuCAI0Z23ZSKNDD3R093N0xKygID3l7Y8bly9CZ+BBXABju44NOrq5m1XM5Lw//u3u32n/yQ37+GZP8/DC+WTP4qdVmrbeuyv4d95T8Hd9PSUF6URGu5efjRkEB7ulMf4f1VCqlDyN3d+MHkk4U8WBsbKV/8H09PdG5TEudOapqgfNTqQAAXk5OiPTxQaSPDwCpNSk2J8f4DflkVhZSi4txLicH53Jy8N+S1h2gcsuB4cEH6/X1GZ+fj2/v3cORe/cQfe8e7laxT8sq/Tb8qK+vRduqzWu/OhX/loFqNXpZ8EEmiiJOZGVhcGxspcd8nZyQodPhZkEBbhYU4FCZwycuCgW6ublVeo01Lfn7V2zVyNLpEFcmwJSGmfhqWhyq4iQI+E+HDphmwZmoVb1eA9RqtHB2Ric3N0wPCAAA5On1OJ+dXS7wJBQW4re8PJOhK1Ovx+70dOP9B728jIGmm5tbta9da7WKaxQKhJSEoYqviYZis5aboqIiuLq6Yv/+/RgzZoxx/vTp05GZmYlPP/200nMGDRqEBx54ABs2bDDO++ijj/DMM88gJycHCjP+AHbb50avx08//IDFhYV4TaNB30GDpFO8p08HSvsnjB4tBRsTna3rk7n9PkRRhFavr9Txc961azVu487AgfAp+UfUWFX17bU231SqWld3NzdcLNPKpQDwsLc3JjVrhnHNmtXLPiw91t7xzJkal1UA6ODqavxwKb1taaLPgLW+JZaqSyuEKIq4kZ+PDYmJeCc5udoPOG8np0ofol1dXWs8m66qLwn3iotxNDMTR+7dw5G7d3GjwiUKPJVKPNSkCYb5+CBQrbb6t2FrsObfsrpWuFbOzrhYplXwQm4ufs3NrbIDtK+TE9q7uuKXnBzkGQxQCQK8lEpkVBMYvZ2c0MXVFZ3d3NDZ1RWdXV3Rxc0N6UVF6FfmzKFStd33dXm9phQW4nR2Nv6TnIwv7twx+XpVAtjWoQNmBQVZXJs1WPv9DTSSlhu1Wo0+ffogOjraGG4MBgOio6Mxb948k8/Jy8urFGCUJYctbNgvuu5KOgF/MHYsjo4bhw8/+QR9x48HCgqk0bfd3KTr2Dz99P0zn2pgrdYWiCJ2l3xL/yA1FQEqFe6U9AkpNBgqncVSaOHfofQbZ2MPNmVZ85tKxXXt6NQJTVUqfJyWhr1paTiXk4Nv793Dt/fuYc61axjm7Y1Jfn4Y4+tbqY+Pua+JjKIinCnzLfFMdnaVLTJl61wdEoLng4PhYuahRGv2nQLq1gohCALaubriXx074m9BQSaDZVtnZ/xeWIh7Oh2+z8rC92X6RAi4f7ikbLBr4+Ji7LRc2nqwIyUFuQYDjty9iyP37uGn7OxyrxMnQcADnp4Y5u2NCG9v9PfwgFPJ73Y+OxuA7b4NV6Uh+sH5lfQDGuLtjSHe3sbl9SXB9EJODi7m5hqDz82CAmTodMgo08+yWBTLBZuhTZqgs5ubFGZKAo2fSmWydeNOyeUjrLXv6/J6DdBo8KhGg0d9fav8InTGxoHX2u9vS9n0sFRUVBSmT5+Ovn37on///ti4cSNyc3Mxc+ZMAMC0adPQvHlzrF+/HgAwevRovPHGG+jVq5fxsNTy5csxevRoY8hpbH4/dAgZy5ZBcHHB3oceAgDsefhhTP/mG4iCAF8fH7T68EOgXTuL1mtuZ0hRFJFZpnNg6fSWiU6KmTodXjBj5HB3pdLY0bN0MhgM+LeJfimne/e26RvQmmo6NGKtdbVwdsb/tWyJ/2vZEtfz8vBxejr2pqXhQm4uvr57F1/fvQu1IGCkjw8m+flhdNOmcHdyMvmaKCw5PFO2s3TFlgNAOmzY290dIc7O2FUSdss6W8t/pNY+LGJNFT/EPu7aFV3d3HA5L69cn6KLublILioydlg+WOZwibMgoK2LC9q7uuLI3bsAgC1JSdiSlFRuW51dXY1hZkiTJpU6i5ay5mvM2qz1t7T0Q1EpCOjg6ooOrq6YUGb+u0lJmH31aqX+KsD9L1VT/f3Nrsue9z1gf4EXsO3726anggPA5s2bjRfx69mzJ9566y2EhYUBAIYMGYKQkBDs2LEDAKDT6bB27Vp8+OGHuH37Npo1a4bRo0dj7dq1aNKkiVnbs6vDUno9hB9+uH9fFO+P5VTmRbC1bVt4qFQmhxPwVCqlawoIQpXXDvm4SxfcLixEjl6PPINBOp2zTJDRmnHWSlkCgAhvbwz28ioXYPxVKvip1ZXOygBq7vApF9bqoFmbdV3OzcXekqATV+ZYvKbkrIiz2dnQ6vXwLOlw+GtuLq7m5cHU5Qw7urjcP9vG0xM93NygUigc4u9Ym+b09KIiqdWgJPRcLDlcYs61QxIfeMDizprWeo3JnTUPFQP2ue/r4/CPvWo017mxBbsKN8eOYefatZi+dCn0dWh5chIEeCiVNR46qI6/SlWph79OFDH/+vVKy9bmH4MjvQFtTRRF/Jqbi71paVibkFDj8r4qVaXTTL2r+DbqKH9Ha3yI6UURbyYmYunNm1ZrPSDLOEIYB+wzdNWHRtHnhgAkJ8M3Kwuq4mKT4WbSd9/BuagI2Q8+CG1QUKWr62aXtLjoRNGsYNPG2Rl9PTwqhZhWzs5VtrYA1mnutPXxV0ciCAK6u7uju7s7Orm6YsblyyY/XJUANrRti4UtWph99o+j/B2t0ZyuFAQsatkSD3t7m2w9kNMhWXtl74eSrMWeD+/aCsONDe0KDMT0deugKzm+rjAYYFAojLeL9+xB72vXgBEjgNDQSs83lAwpkF1mWIFzWi3mWqm1xdr/GPgGbHiPBwSgi5ubVTsc8u9YO/bYJ0LuHCWMU2UMNzby1h9/YAEAODnh0RMncKpLF7RMS8NTX32F/4wahcRmzeCXmSkNnVDFYJeKkhGuPZ2c0Lzkol2qkg8atrZQRfxwtQ1HaT2wVwzjjonhpoGJooiX4uOxrqQvxHOffII3t2xBsZMT1CWdgZ/5/HMUqdXQFBdLg11a0B+HrS1UET9cbYtfEogaHjsUNyCdwYA5167h3ZIxRdbu24dlW7dCGDIEuH7daoNdOkrnMjIfXxNE1NixQ7EdKtDrMSUuDodKBiXbfvw4Zm3dKg1++dlngKur1Qa7ZGsLVcTXBBE5EoabBpCl0+HRixdxPCsLGkHA7tRUjF21SgovO3cCpZ06bTwYIhERkRww3NSzlMJCjLhwAb/k5sJTqcSn3t4Y8sgj0oOrVwMlFywkIiIi62C4qUc38vMx/JdfcLOgAP4qFQ536YKeI0YAOTnA4MHA0qW2LpGIiEh2GG7qSWx2NkZcuIDU4mK0cXbG/0JD0XbtWuDMGaBJE+Cjj2rdp4aIiIiqxnBTD47du4dHf/0VWr0eoW5uONyjBwJOnwbWrZMW+Pe/pbOhiIiIyOp4LqiVHUxPx4gLF6DV6/GglxeO9+qFgLw84PHHpQExZ84E/vpXW5dJREQkWww3VvRuUhIm/PYbCkURY3x9cbhHD3gplcDf/gYkJgLt2gFvvWXrMomIiGSNh6Xq6CetFotv3EAnNzdsS0oCADwdGIht7dvDSaEA3n8f2LcPcHICdu0C3N1tXDEREZG8MdzU0X9TU3E0KwtHs7IAAC+0bIlXWreWRlm+dg2YP19acM0aoF8/G1ZKRETkGBhuauH3ggJkFBdDZzDgnZLWGgB4vkULjGvWDAmFhWilVAJTpwK5ucCDDwKLF9uwYiIiIsfBcFMLIadOmZz/+h9/4PWS8aHE//0POHsW8PYGPvyQp30TERE1EHYoroUdHTuiqpF5nAQBHwHAP/4hzeBp30RERA2KLTcWKjIYcOjOHVQ1lPrptm3ROzxcOu37qaeACRMatD4iIiJHx5YbCxQZDJh06RIOZWRAVTJPUeEWa9cCf/wBtG8PbNzY4DUSERE5OoYbMxUbDJhcEmw0goD3OnVCgEqFPh4e2N6hA/p4eCBAp4Pf/v087ZuIiMiGeFjKDMUlLTYHS4LNoW7dMKJpU/zVzw9qQYAgCHgmJwdFQ4dCk5Ul9bfp29fWZRMRETkkhpsaVBVsAEAjisD33wOJiRBeeUUKNg89BPzf/9m4aiIiIsfFcFON0kNRpoINDhwAFiyQ+teUEgRgyhRAwaN9REREtsJwU4VigwFTLl3CgYwMqE0FmwkTpDOiyhJFaRyppk2BceMavmgiIiJih2JTSoPNJ6aCjV4vtdhUDDZlLVwoLUdEREQNjuGmgmKDAY/FxRmDzcFu3TCyNNgAwA8/lD8UVZEoSiOA//BD/RdLRERElTDclFFsMGBqXBz2p6cbg82ossEGAI4eNW9lycnWL5CIiIhqxD43JUqDzb6SYHOgYrC5fVs6C2r3bvNWGBhYP4USERFRtdhyA0BnItj8uTTYFBZK163p2PF+sHFzk86MMkUQpLGkBg1qmOKJiIioHIcPN7qSPjb70tOhEgR80rXr/WDz1VdA9+7AsmVAbi4wYABw7hzwwQfS4xUDTun9jRs5CjgREZGNOHS4KdtioxIEHOjaFY/4+gLXrwOjRwN//jNw7RoQECAFmhMngN69pdO89+8Hmjcvv8IWLaT5PA2ciIjIZgRRrO6cZvnRarXw8vLCtwkJeEerxd6ywcbFBVi3DvjnP4GiImmMqIULgeXLAU/PyivT66WzopKTpT42gwaxxYaIiKgelH5+Z2VlwdPUZ3IZDtuh+JkLF3DTzU06FNWlCx6JjgYWLbp/mvfw4cCmTUCnTlWvRKkEhgxpkHqJiIjIPA4bbm4CcNLp8GpyMnq8+Sbw6afSAyEhwJtvAo8+WnWnYSIiIrJbjtvnRhShc3JCVHAwQhYuBJydgdWrgUuXgDFjGGyIiIgaKYdtuSkNL046HXa88Qbw229AmzY2LoqIiIjqynHDTYnTzz6L3teuAQkJDDdEREQy4LCHpQSDofwMDpdAREQkCw4bbnpdv46AO3fgd++eNIPDJRAREcmCw17nJhOAs0oFjU4nXXwvPp7XqCEiIrJTllznxmFbbgRACjYAh0sgIiKSEYcNNwA4XAIREZEMOe7ZUl98AYwYwRYbIiIimXHclhuOA0VERCRLjhtuiIiISJYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWbB5utmzZgpCQEDg7OyMsLAxnzpypdvnMzEzMnTsXgYGB0Gg06NChA7766qsGqpaIiIjsnZMtN753715ERUVh+/btCAsLw8aNGxEZGYkrV67Az8+v0vJFRUUYNmwY/Pz8sH//fjRv3hy///47mjRp0vDFExERkV0SRFEUbbXxsLAw9OvXD5s3bwYAGAwGBAcHY/78+Vi6dGml5bdv344NGzbg8uXLUKlUtdqmVquFl5cXsrKy4OnpWaf6iYiIqGFY8vlts8NSRUVFOHfuHCIiIu4Xo1AgIiICMTExJp/z2WefITw8HHPnzoW/vz+6deuGdevWQa/XV7mdwsJCaLXachMRERHJl83CTUZGBvR6Pfz9/cvN9/f3R0pKisnn3Lx5E/v374der8dXX32F5cuX4/XXX8crr7xS5XbWr18PLy8v4xQcHGzV34OIiIjsi807FFvCYDDAz88P//73v9GnTx9MmjQJL774IrZv317lc5YtW4asrCzjlJiY2IAVExERUUOzWYdiX19fKJVKpKamlpufmpqKgIAAk88JDAyESqWCUqk0zuvcuTNSUlJQVFQEtVpd6TkajQYajca6xRMREZHdqlXLzfnz53Hx4kXj/U8//RRjxozBCy+8gKKiIrPWoVar0adPH0RHRxvnGQwGREdHIzw83ORzBg4ciOvXr8NgMBjnXb16FYGBgSaDDRERETmeWoWbv/3tb7h69SoAqR/M5MmT4erqin379mHx4sVmrycqKgrvvPMO/vvf/yIuLg5z5sxBbm4uZs6cCQCYNm0ali1bZlx+zpw5uHv3LhYsWICrV6/iyy+/xLp16zB37tza/BpEREQkQ7U6LHX16lX07NkTALBv3z4MHjwYu3btwsmTJzF58mRs3LjRrPVMmjQJ6enpWLFiBVJSUtCzZ08cPnzY2Mk4ISEBCsX9/BUcHIxvvvkGf//739GjRw80b94cCxYswJIlS2rzaxAREZEM1eo6N56enjh37hzat2+PYcOG4ZFHHsGCBQuQkJCAjh07Ij8/vz5qtQpe54aIiKjxqffr3PTt2xevvPIKPvzwQxw/fhx//vOfAQDx8fGVTu0mIiIiaki1CjcbN27E+fPnMW/ePLz44oto164dAGD//v0YMGCAVQskIiIisoRVh18oKCiAUqms9dAIDYGHpYiIiBqfej8slZiYiD/++MN4/8yZM1i4cCE++OADuw42REREJH+1CjePPfYYjh49CgBISUnBsGHDcObMGbz44otYs2aNVQskIiIiskStws2vv/6K/v37AwA+/vhjdOvWDT/++CN27tyJHTt2WLM+IiIiIovUKtwUFxcbhzT49ttv8Ze//AUA0KlTJyQnJ1uvOiIiIiIL1SrcdO3aFdu3b8cPP/yAI0eOYMSIEQCApKQkNG3a1KoFEhEREVmiVuHm1Vdfxb/+9S8MGTIEU6ZMQWhoKADgs88+Mx6uIiIiIrKFWp8KrtfrodVq4e3tbZx369YtuLq6ws/Pz2oFWhtPBSciImp8LPn8rtXYUgCgVCqh0+lw4sQJAEDHjh0REhJS29URERERWUWtDkvl5ubiySefRGBgIAYPHozBgwcjKCgITz31FPLy8qxdIxEREZHZahVuoqKicPz4cXz++efIzMxEZmYmPv30Uxw/fhzPP/+8tWskIiIiMlut+tz4+vpi//79GDJkSLn5R48excSJE5Genm6t+qyOfW6IiIgan3offiEvL8/k6N9+fn48LEVEREQ2VatwEx4ejpUrV6KgoMA4Lz8/H6tXr0Z4eLjViiMiIiKyVK3Oltq0aRMiIyPRokUL4zVufvnlF2g0Gvzvf/+zaoFERERElqj1dW7y8vKwc+dOXL58GQDQuXNnTJ06FS4uLlYt0NrY54aIiKjxaZDr3Li6umLWrFnl5t28eROzZ89m6w0RERHZTK363FQlOzsb0dHR1lwlERERkUWsGm6IiIiIbI3hhoiIiGSF4YaIiIhkxaIOxb169YIgCFU+zgv4ERERka1ZFG7GjBlTT2UQERERWUetr3PTWPE6N0RERI1PvY8tRURERGSvGG6IiIhIVhhuiIiISFYYboiIiEhWrBpuMjMzsXnzZmuukoiIiMgiVgk30dHReOyxxxAYGIiVK1daY5VEREREtVLrcJOYmIg1a9agdevWGD58OARBwMGDB5GSkmLN+oiIiIgsYlG4KS4uxr59+xAZGYmOHTsiNjYWGzZsgEKhwIsvvogRI0ZApVLVV61ERERENbLoCsXNmzdHp06d8Pjjj2PPnj3w9vYGAEyZMqVeiiMiIiKylEUtNzqdDoIgQBAEKJXK+qqJiIiIqNYsCjdJSUl45plnsHv3bgQEBGD8+PE4ePBgtYNpEhERETUki8KNs7Mzpk6diu+++w4XL15E586d8dxzz0Gn02Ht2rU4cuQI9Hp9fdVKREREVKNany3Vtm1bvPLKK/j999/xxRdfoLCwEI888gj8/f2tWR8RERGRRSzqUGyKQqHAqFGjMGrUKKSnp+PDDz+0Rl1EREREtSKIoiha+qT8/HwcOXIEV69ehVqtRocOHTBs2LBG0cnYkiHTiYiIyD5Y8vltccvNZ599hqeffhoZGRnl5jdv3hw7d+7E4MGDAQDx8fFo3bq1pasnIiIiqhOL+tz8+OOPmDBhAgYPHoyTJ0/i7t27uHv3Lk6cOIH+/fsjMjISly9fxpIlS3h4ioiIiGzCosNSo0aNQnBwMP71r3+ZfPxvf/sbDhw4AFEUER0djdDQUKsVai08LEVERNT4WPL5bVHLzalTpzBv3rwqH587dy7u3LmDb7/91i6DDREREcmfReEmPz+/2rTk5eUFjUaDnj171rUuIiIiolqxKNy0b98e3333XZWPR0dHo3379nUuioiIiKi2LAo3M2fOxKJFi/DVV19VeuzLL7/E4sWLMWPGDGvVRkRERGQxi04FX7BgAX788Uc88sgj6NixIzp37gxRFBEXF4dr167h0UcfxcKFC+upVCIiIqKaWdRyo1AosG/fPuzevRsdOnTA5cuXceXKFXTs2BE7d+7EgQMHoFDUekQHIiIiojqr1RWKGzOeCk5ERNT41Nup4AaDAa+++ioGDhyIfv36YenSpcjPz69TsURERETWZFG4Wbt2LV544QW4u7ujefPm2LRpE+bOnVtftRERERFZzKJw88EHH2Dr1q345ptvcOjQIXz++efYuXMnDAZDfdVHREREZBGLwk1CQgJGjRplvB8REQFBEJCUlGT1woiIiIhqw6Jwo9Pp4OzsXG6eSqVCcXGxVYsiIiIiqi2LrnMjiiJmzJgBjUZjnFdQUIDZs2fDzc3NOO/AgQPWq5CIiIjIAhaFm+nTp1ea9/jjj1utGCIiIqK6sijcvP/++/VVBxEREZFV8HLCREREJCsWtdw8+eSTZi333nvv1aoYIiIiorqyKNzs2LEDrVq1Qq9eveBgozYQERFRI2FRuJkzZw52796N+Ph4zJw5E48//jh8fHzqqzYiIiIii1nU52bLli1ITk7G4sWL8fnnnyM4OBgTJ07EN998U6eWnC1btiAkJATOzs4ICwvDmTNnzHrenj17IAgCxowZU+ttExERkbxY3KFYo9FgypQpOHLkCC5duoSuXbvi2WefRUhICHJyciwuYO/evYiKisLKlStx/vx5hIaGIjIyEmlpadU+79atW1i0aBEGDRpk8TaJiIhIvup0tpRCoYAgCBBFEXq9vlbreOONNzBr1izMnDkTXbp0wfbt2+Hq6lptp2S9Xo+pU6di9erVaNOmTW3LJyIiIhmyONwUFhZi9+7dGDZsGDp06ICLFy9i8+bNSEhIgLu7u0XrKioqwrlz5xAREXG/IIUCERERiImJqfJ5a9asgZ+fH5566imz6tVqteUmIiIiki+LOhQ/++yz2LNnD4KDg/Hkk09i9+7d8PX1rfXGMzIyoNfr4e/vX26+v78/Ll++bPI5J06cwH/+8x/ExsaatY3169dj9erVta6RiIiIGheLws327dvRsmVLtGnTBsePH8fx48dNLldfY0tlZ2fjiSeewDvvvGN2qFq2bBmioqKM97VaLYKDg+ulPiIiIrI9i8LNtGnTIAiC1Tbu6+sLpVKJ1NTUcvNTU1MREBBQafkbN27g1q1bGD16tHGewWAAADg5OeHKlSto27ZtuedoNJpyA30SERGRvFl8ET9rUqvV6NOnD6Kjo42ncxsMBkRHR2PevHmVlu/UqRMuXrxYbt5LL72E7OxsbNq0iS0yREREZFm4qQ9RUVGYPn06+vbti/79+2Pjxo3Izc3FzJkzAUitRc2bN8f69evh7OyMbt26lXt+kyZNAKDSfCIiInJMNg83kyZNQnp6OlasWIGUlBT07NkThw8fNnYyTkhIgELB8T2JiIjIPILoYINEabVaeHl5ISsrC56enrYuh4iIiMxgyec3m0SIiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFbsItxs2bIFISEhcHZ2RlhYGM6cOVPlsu+88w4GDRoEb29veHt7IyIiotrliYiIyLHYPNzs3bsXUVFRWLlyJc6fP4/Q0FBERkYiLS3N5PLHjh3DlClTcPToUcTExCA4OBjDhw/H7du3G7hyIiIiskeCKIqiLQsICwtDv379sHnzZgCAwWBAcHAw5s+fj6VLl9b4fL1eD29vb2zevBnTpk2rcXmtVgsvLy9kZWXB09OzzvUTERFR/bPk89umLTdFRUU4d+4cIiIijPMUCgUiIiIQExNj1jry8vJQXFwMHx8fk48XFhZCq9WWm4iIiEi+bBpuMjIyoNfr4e/vX26+v78/UlJSzFrHkiVLEBQUVC4glbV+/Xp4eXkZp+Dg4DrXTURERPbL5n1u6uIf//gH9uzZg4MHD8LZ2dnkMsuWLUNWVpZxSkxMbOAqiYiIqCE52XLjvr6+UCqVSE1NLTc/NTUVAQEB1T73n//8J/7xj3/g22+/RY8ePapcTqPRQKPRWKVeIiIisn82bblRq9Xo06cPoqOjjfMMBgOio6MRHh5e5fNee+01vPzyyzh8+DD69u3bEKUSERFRI2HTlhsAiIqKwvTp09G3b1/0798fGzduRG5uLmbOnAkAmDZtGpo3b47169cDAF599VWsWLECu3btQkhIiLFvjru7O9zd3W32exAREZF9sHm4mTRpEtLT07FixQqkpKSgZ8+eOHz4sLGTcUJCAhSK+w1M27ZtQ1FRESZMmFBuPStXrsSqVasasnQiIiKyQza/zk1D43VuiIiIGp9Gc50bIiIiImtjuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWXGydQH2Sq/Xo7i42NZlUB2o1WooFMzvRESOhuGmAlEUkZKSgszMTFuXQnWkUCjQunVrqNVqW5dCREQNiOGmgtJg4+fnB1dXVwiCYOuSqBYMBgOSkpKQnJyMli1b8u9IRORAGG7K0Ov1xmDTtGlTW5dDddSsWTMkJSVBp9NBpVLZuhwiImog7JBQRmkfG1dXVxtXQtZQejhKr9fbuBIiImpIDDcm8BCGPPDvSETkmBhuiIiISFYYboiIiEhWGG7qi14PHDsG7N4t3Taifh8hISHYuHGjVdZ17NgxCILAU+uJiKjB8Gyp+nDgALBgAfDHH/fntWgBbNoEjBtXL5scMmQIevbsaZVQcvbsWbi5udW9KCIiIhtgy421HTgATJhQPtgAwO3b0vwDB2xSliiK0Ol0Zi3brFkznjFGRESNFsNNTUQRyM01b9Jqgeeek55jaj2A1KKj1Zq3PlPrMWHGjBk4fvw4Nm3aBEEQIAgCduzYAUEQ8PXXX6NPnz7QaDQ4ceIEbty4gUcffRT+/v5wd3dHv3798O2335ZbX8XDUoIg4N1338XYsWPh6uqK9u3b47PPPqvtHsUnn3yCrl27QqPRICQkBK+//nq5x7du3Yr27dvD2dkZ/v7+mDBhgvGx/fv3o3v37nBxcUHTpk0RERGB3NzcWtdCRETyw3BTk7w8wN3dvMnLS2qhqYooSi06Xl7mrS8vz6wSN23ahPDwcMyaNQvJyclITk5GcHAwAGDp0qX4xz/+gbi4OPTo0QM5OTkYNWoUoqOj8fPPP2PEiBEYPXo0EhISqt3G6tWrMXHiRFy4cAGjRo3C1KlTcffuXbN3Y6lz585h4sSJmDx5Mi5evIhVq1Zh+fLl2LFjBwDgp59+wnPPPYc1a9bgypUrOHz4MAYPHgwASE5OxpQpU/Dkk08iLi4Ox44dw7hx4yCaGQKJiMgxsM+NDHh5eUGtVsPV1RUBAQEAgMuXLwMA1qxZg2HDhhmX9fHxQWhoqPH+yy+/jIMHD+Kzzz7DvHnzqtzGjBkzMGXKFADAunXr8NZbb+HMmTMYMWKERbW+8cYbGDp0KJYvXw4A6NChAy5duoQNGzZgxowZSEhIgJubGx555BF4eHigVatW6NWrFwAp3Oh0OowbNw6tWrUCAHTv3t2i7RMRkfyx5aYmrq5ATo5501dfmbfOr74yb31W6PfSt2/fcvdzcnKwaNEidO7cGU2aNIG7uzvi4uJqbLnp0aOH8Wc3Nzd4enoiLS3N4nri4uIwcODAcvMGDhyIa9euQa/XY9iwYWjVqhXatGmDJ554Ajt37kReSQtWaGgohg4diu7du+Ovf/0r3nnnHdy7d8/iGoiISN4YbmoiCICbm3nT8OHSWVFVXRlXEIDgYGk5c9ZnhSvsVjzradGiRTh48CDWrVuHH374AbGxsejevTuKioqqXU/FsZkEQYDBYKhzfRV5eHjg/Pnz2L17NwIDA7FixQqEhoYiMzMTSqUSR44cwddff40uXbrg7bffRseOHREfH2/1OoiIqPFiuLEmpVI63RuoHExK72/cKC1nZWq12qwxlE6ePIkZM2Zg7Nix6N69OwICAnDr1i2r11OVzp074+TJk5Vq6tChA5Ql+8XJyQkRERF47bXXcOHCBdy6dQvfffcdAClUDRw4EKtXr8bPP/8MtVqNgwcPNlj9RERk/9jnxtrGjQP27zd9nZuNG+vtOjchISE4ffo0bt26BXd39ypbVdq3b48DBw5g9OjREAQBy5cvr5cWmKo8//zz6NevH15++WVMmjQJMTEx2Lx5M7Zu3QoA+OKLL3Dz5k0MHjwY3t7e+Oqrr2AwGNCxY0ecPn0a0dHRGD58OPz8/HD69Gmkp6ejc+fODVY/ERHZP7bc1Idx44Bbt4CjR4Fdu6Tb+Ph6CzaAdLhJqVSiS5cuaNasWZV9aN544w14e3tjwIABGD16NCIjI9G7d+96q6ui3r174+OPP8aePXvQrVs3rFixAmvWrMGMGTMAAE2aNMGBAwfw8MMPo3Pnzti+fTt2796Nrl27wtPTE99//z1GjRqFDh064KWXXsLrr7+OkSNHNlj9RERk/wTRwc6j1Wq18PLyQlZWFjw9Pcs9VlBQgPj4eLRu3RrOzs42qpCshX9PIiL5qO7zuyK23BAREZGsMNxQncyePRvu7u4mp9mzZ9u6PCIickDsUEx1smbNGixatMjkYzU1GxIREdUHhhuqEz8/P/j5+dm6DCIiIiMeliIiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4Iau4desWBEFAbGysrUshIiIHx3BTj37SavFwbCx+0mrrfVtDhgzBwoULrba+GTNmYMyYMVZbHxERUUNhuKlHH6Sm4mhmJj5MTbV1KURERA6D4aYGoigiV683e4rLzcWJzEyczMrCnrQ0AMDutDSczMrCicxMxOXmmr0uc8c0nTFjBo4fP45NmzZBEAQIgoBbt27h119/xciRI+Hu7g5/f3888cQTyMjIMD5v//796N69O1xcXNC0aVNEREQgNzcXq1atwn//+198+umnxvUdO3bM4n13/Phx9O/fHxqNBoGBgVi6dCl0Ol2N2weAY8eOoX///nBzc0OTJk0wcOBA/P777xbXQEREjodXKK5BnsEA9x9+qNM60ouL8aeff7b4eTmDBsFNqaxxuU2bNuHq1avo1q0b1qxZAwBQqVTo378/nn76abz55pvIz8/HkiVLMHHiRHz33XdITk7GlClT8Nprr2Hs2LHIzs7GDz/8AFEUsWjRIsTFxUGr1eL9998HAPj4+FhU++3btzFq1CjMmDEDH3zwAS5fvoxZs2bB2dkZq1atqnb7Op0OY8aMwaxZs7B7924UFRXhzJkzEATB4n1IRESOh+FGBry8vKBWq+Hq6oqAgAAAwCuvvIJevXph3bp1xuXee+89BAcH4+rVq8jJyYFOp8O4cePQqlUrAED37t2Ny7q4uKCwsNC4Pktt3boVwcHB2Lx5MwRBQKdOnZCUlIQlS5ZgxYoVSE5OrnL7d+/eRVZWFh555BG0bdsWANC5c+da1UFERI6H4aYGrgoFcgYNsug5sTk5JltqTvTqhZ7u7hZtu7Z++eUXHD16FO4mtnfjxg0MHz4cQ4cORffu3REZGYnhw4djwoQJ8Pb2rvU2y4qLi0N4eHi51paBAwciJycHf/zxB0JDQ6vcvo+PD2bMmIHIyEgMGzYMERERmDhxIgIDA61SGxERyRv73NRAEAS4KZUWTS4loaR055beuigUFq2nLodhcnJyMHr0aMTGxpabrl27hsGDB0OpVOLIkSP4+uuv0aVLF7z99tvo2LEj4uPj67bDzFTT9t9//33ExMRgwIAB2Lt3Lzp06IBTp041SG1ERNS4MdzUAz+VCgEqFfp4eGB7hw7o4+GBAJUKfipVvW1TrVZDr9cb7/fu3Ru//fYbQkJC0K5du3KTm5sbACm4DRw4EKtXr8bPP/8MtVqNgwcPmlyfpTp37oyYmJhynaJPnjwJDw8PtGjRosbtA0CvXr2wbNky/Pjjj+jWrRt27dpV63qIiMhxMNzUgxbOzrgVHo7TvXvjb0FBON27N26Fh6OFs3O9bTMkJASnT5/GrVu3kJGRgblz5+Lu3buYMmUKzp49ixs3buCbb77BzJkzodfrcfr0aaxbtw4//fQTEhIScODAAaSnpxv7toSEhODChQu4cuUKMjIyUFxcbFE9zz77LBITEzF//nxcvnwZn376KVauXImoqCgoFIpqtx8fH49ly5YhJiYGv//+O/73v//h2rVr7HdDRETmER1MVlaWCEDMysqq9Fh+fr546dIlMT8/3waV1c2VK1fEBx54QHRxcREBiPHx8eLVq1fFsWPHik2aNBFdXFzETp06iQsXLhQNBoN46dIlMTIyUmzWrJmo0WjEDh06iG+//bZxfWlpaeKwYcNEd3d3EYB49OjRarcfHx8vAhB//vln47xjx46J/fr1E9VqtRgQECAuWbJELC4uFkVRrHb7KSkp4pgxY8TAwEBRrVaLrVq1ElesWCHq9XqL9klj/nsSEVF51X1+VySIopkXU5EJrVYLLy8vZGVlwdPTs9xjBQUFiI+PR+vWreFcj60s1DD49yQiko/qPr8r4mEpIiIikhWGGzLLunXr4O7ubnIaOXKkrcsjIiIy4nVuyCyzZ8/GxIkTTT7m4uLSwNUQERFVjeGGzOLj42PxEAxERES2wMNSJjhYH2vZ4t+RiMgxMdyUoSq5yF5eXp6NKyFrKCoqAiBdDZmIiByHXRyW2rJlCzZs2ICUlBSEhobi7bffRv/+/atcft++fVi+fDlu3bqF9u3b49VXX8WoUaPqXIdSqUSTJk2QlpYGAHB1deVI1I2UwWBAeno6XF1d4eRkFy9zIiJqIDb/r793715ERUVh+/btCAsLw8aNGxEZGYkrV67Az8+v0vI//vgjpkyZgvXr1+ORRx7Brl27MGbMGJw/fx7dunWrcz2lo2CXBhxqvBQKBVq2bMmASkTkYGx+Eb+wsDD069cPmzdvBiB94w4ODsb8+fOxdOnSSstPmjQJubm5+OKLL4zzHnjgAfTs2RPbt2+vcXvmXgRIr9dbPOQA2Re1Wg1FHUZWJyIi+2HJRfxs2nJTVFSEc+fOYdmyZcZ5CoUCERERiImJMfmcmJgYREVFlZsXGRmJQ4cOmVy+sLAQhYWFxvtardas2pRKJftqEBERNUI2/VqbkZEBvV4Pf3//cvP9/f2RkpJi8jkpKSkWLb9+/Xp4eXkZp+DgYOsUT0RERHZJ9m32y5YtQ1ZWlnFKTEy0dUlERERUj2x6WMrX1xdKpRKpqanl5qempho79lYUEBBg0fIajQYajcY6BRMREZHds2m4UavV6NOnD6KjozFmzBgAUofi6OhozJs3z+RzwsPDER0djYULFxrnHTlyBOHh4WZts7T/tLl9b4iIiMj2Sj+3zToPSrSxPXv2iBqNRtyxY4d46dIl8ZlnnhGbNGkipqSkiKIoik888YS4dOlS4/InT54UnZycxH/+859iXFycuHLlSlGlUokXL140a3s3btwQAXDixIkTJ06cGuGUmJhY42e9za9zM2nSJKSnp2PFihVISUlBz549cfjwYWOn4YSEhHKn8w4YMAC7du3CSy+9hBdeeAHt27fHoUOHzL7GTen4SAkJCfDy8rL+L0TV0mq1CA4ORmJiYo2n8pF1cd/bFve/7XDf2441970oisjOzkZQUFCNy9r8OjcNzZLz5Mn6uP9th/vetrj/bYf73nZste9lf7YUERERORaGGyIiIpIVhws3Go0GK1eu5OnhNsL9bzvc97bF/W873Pe2Y6t973B9boiIiEjeHK7lhoiIiOSN4YaIiIhkheGGiIiIZIXhhoiIiGTF4cLNli1bEBISAmdnZ4SFheHMmTO2LskhrFq1CoIglJs6depk67Jk6fvvv8fo0aMRFBQEQRBw6NChco+LoogVK1YgMDAQLi4uiIiIwLVr12xTrMzUtO9nzJhR6X0wYsQI2xQrM+vXr0e/fv3g4eEBPz8/jBkzBleuXCm3TEFBAebOnYumTZvC3d0d48ePrzQQM1nOnH0/ZMiQSq/92bNn11tNDhVu9u7di6ioKKxcuRLnz59HaGgoIiMjkZaWZuvSHELXrl2RnJxsnE6cOGHrkmQpNzcXoaGh2LJli8nHX3vtNbz11lvYvn07Tp8+DTc3N0RGRqKgoKCBK5WfmvY9AIwYMaLc+2D37t0NWKF8HT9+HHPnzsWpU6dw5MgRFBcXY/jw4cjNzTUu8/e//x2ff/459u3bh+PHjyMpKQnjxo2zYdXyYM6+B4BZs2aVe+2/9tpr9VeUpQNdNmb9+/cX586da7yv1+vFoKAgcf369TasyjGsXLlSDA0NtXUZDgeAePDgQeN9g8EgBgQEiBs2bDDOy8zMFDUajbh7924bVChfFfe9KIri9OnTxUcffdQm9TiatLQ0EYB4/PhxURSl17lKpRL37dtnXCYuLk4EIMbExNiqTFmquO9FURQffPBBccGCBQ1Wg8O03BQVFeHcuXOIiIgwzlMoFIiIiEBMTIwNK3Mc165dQ1BQENq0aYOpU6ciISHB1iU5nPj4eKSkpJR7H3h5eSEsLIzvgwZy7Ngx+Pn5oWPHjpgzZw7u3Llj65JkKSsrC8D9wZLPnTuH4uLicq/9Tp06oWXLlnztW1nFfV9q586d8PX1Rbdu3bBs2TLk5eXVWw02HxW8oWRkZECv1xtHGy/l7++Py5cv26gqxxEWFoYdO3agY8eOSE5OxurVqzFo0CD8+uuv8PDwsHV5DiMlJQUATL4PSh+j+jNixAiMGzcOrVu3xo0bN/DCCy9g5MiRiImJgVKptHV5smEwGLBw4UIMHDgQ3bp1AyC99tVqNZo0aVJuWb72rcvUvgeAxx57DK1atUJQUBAuXLiAJUuW4MqVKzhw4EC91OEw4YZsa+TIkcafe/TogbCwMLRq1Qoff/wxnnrqKRtWRtRwJk+ebPy5e/fu6NGjB9q2bYtjx45h6NChNqxMXubOnYtff/2V/fpsoKp9/8wzzxh/7t69OwIDAzF06FDcuHEDbdu2tXodDnNYytfXF0qlslLP+NTUVAQEBNioKsfVpEkTdOjQAdevX7d1KQ6l9LXO94F9aNOmDXx9ffk+sKJ58+bhiy++wNGjR9GiRQvj/ICAABQVFSEzM7Pc8nztW09V+96UsLAwAKi3177DhBu1Wo0+ffogOjraOM9gMCA6Ohrh4eE2rMwx5eTk4MaNGwgMDLR1KQ6ldevWCAgIKPc+0Gq1OH36NN8HNvDHH3/gzp07fB9YgSiKmDdvHg4ePIjvvvsOrVu3Lvd4nz59oFKpyr32r1y5goSEBL7266imfW9KbGwsANTba9+hDktFRUVh+vTp6Nu3L/r374+NGzciNzcXM2fOtHVpsrdo0SKMHj0arVq1QlJSElauXAmlUokpU6bYujTZycnJKfdtKD4+HrGxsfDx8UHLli2xcOFCvPLKK2jfvj1at26N5cuXIygoCGPGjLFd0TJR3b738fHB6tWrMX78eAQEBODGjRtYvHgx2rVrh8jISBtWLQ9z587Frl278Omnn8LDw8PYj8bLywsuLi7w8vLCU089haioKPj4+MDT0xPz589HeHg4HnjgARtX37jVtO9v3LiBXbt2YdSoUWjatCkuXLiAv//97xg8eDB69OhRP0U12HlZduLtt98WW7ZsKarVarF///7iqVOnbF2SQ5g0aZIYGBgoqtVqsXnz5uKkSZPE69ev27osWTp69KgIoNI0ffp0URSl08GXL18u+vv7ixqNRhw6dKh45coV2xYtE9Xt+7y8PHH48OFis2bNRJVKJbZq1UqcNWuWmJKSYuuyZcHUfgcgvv/++8Zl8vPzxWeffVb09vYWXV1dxbFjx4rJycm2K1omatr3CQkJ4uDBg0UfHx9Ro9GI7dq1E//v//5PzMrKqreahJLCiIiIiGTBYfrcEBERkWNguCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEihycIAg4dOmTrMojIShhuiMimZsyYAUEQKk0jRoywdWlE1Eg51NhSRGSfRowYgffff7/cPI1GY6NqiKixY8sNEdmcRqNBQEBAucnb2xuAdMho27ZtGDlyJFxcXNCmTRvs37+/3PMvXryIhx9+GC4uLmjatCmeeeYZ5OTklFvmvffeQ9euXaHRaBAYGIh58+aVezwjIwNjx46Fq6sr2rdvj88++6x+f2kiqjcMN0Rk95YvX47x48fjl19+wdSpUzF58mTExcUBAHJzcxEZGQlvb2+cPXsW+/btw7ffflsuvGzbtg1z587FM888g4sXL+Kzzz5Du3btym1j9erVmDhxIi5cuIBRo0Zh6tSpuHv3boP+nkRkJfU2JCcRkRmmT58uKpVK0c3Nrdy0du1aURSlEYdnz55d7jlhYWHinDlzRFEUxX//+9+it7e3mJOTY3z8yy+/FBUKhXHE7aCgIPHFF1+ssgYA4ksvvWS8n5OTIwIQv/76a6v9nkTUcNjnhohs7qGHHsK2bdvKzfPx8TH+HB4eXu6x8PBwxMbGAgDi4uIQGhoKNzc34+MDBw6EwWDAlStXIAgCkpKSMHTo0Gpr6NGjh/FnNzc3eHp6Ii0trba/EhHZEMMNEdmcm5tbpcNE1uLi4mLWciqVqtx9QRBgMBjqoyQiqmfsc0NEdu/UqVOV7nfu3BkA0LlzZ/zyyy/Izc01Pn7y5EkoFAp07NgRHh4eCAkJQXR0dIPWTES2w5YbIrK5wsJCpKSklJvn5OQEX19fAMC+ffvQt29f/OlPf8LOnTtx5swZ/Oc//wEATJ06FStXrsT06dOxatUqpKenY/78+XjiiSfg7+8PAFi1ahVmz54NPz8/jBw5EtnZ2Th58iTmz5/fsL8oETUIhhsisrnDhw8jMDCw3LyOHTvi8uXLAKQzmfbs2YNnn30WgYGB2L17N7p06QIAcHV1xTfffIMFCxagX79+cHV1xfjx4/HGG28Y1zV9+nQUFBTgzTffxKJFi+Dr64sJEyY03C9IRA1KEEVRtHURRERVEQQBBw8exJgxY2xdChE1EuxzQ0RERLLCcENERESywj43RGTXeOSciCzFlhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpKV/weTlCZXdSi4qwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,489,601 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.630 | Train Acc: 67.70%\n",
      "\t test  Loss: 0.622 | test  Acc: 68.38%\n",
      "\t best  test acc: 68.38%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.604 | Train Acc: 69.52%\n",
      "\t test  Loss: 0.594 | test  Acc: 71.92%\n",
      "\t best  test acc: 71.92%\n",
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.548 | Train Acc: 74.86%\n",
      "\t test  Loss: 0.577 | test  Acc: 72.20%\n",
      "\t best  test acc: 72.20%\n",
      "Epoch: 04 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.526 | Train Acc: 76.17%\n",
      "\t test  Loss: 0.560 | test  Acc: 72.39%\n",
      "\t best  test acc: 72.39%\n",
      "Epoch: 05 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.445 | Train Acc: 81.74%\n",
      "\t test  Loss: 0.499 | test  Acc: 79.01%\n",
      "\t best  test acc: 79.01%\n",
      "Epoch: 06 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.366 | Train Acc: 86.53%\n",
      "\t test  Loss: 0.496 | test  Acc: 79.38%\n",
      "\t best  test acc: 79.38%\n",
      "Epoch: 07 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.300 | Train Acc: 89.80%\n",
      "\t test  Loss: 0.497 | test  Acc: 81.62%\n",
      "\t best  test acc: 81.62%\n",
      "Epoch: 08 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.257 | Train Acc: 91.25%\n",
      "\t test  Loss: 0.489 | test  Acc: 81.34%\n",
      "\t best  test acc: 81.62%\n",
      "Epoch: 09 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.210 | Train Acc: 92.90%\n",
      "\t test  Loss: 0.496 | test  Acc: 82.28%\n",
      "\t best  test acc: 82.28%\n",
      "Epoch: 10 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.172 | Train Acc: 94.63%\n",
      "\t test  Loss: 0.543 | test  Acc: 81.06%\n",
      "\t best  test acc: 82.28%\n",
      "Epoch: 11 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.152 | Train Acc: 95.26%\n",
      "\t test  Loss: 0.538 | test  Acc: 82.37%\n",
      "\t best  test acc: 82.37%\n",
      "Epoch: 12 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.140 | Train Acc: 95.92%\n",
      "\t test  Loss: 0.572 | test  Acc: 81.16%\n",
      "\t best  test acc: 82.37%\n",
      "Epoch: 13 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.127 | Train Acc: 96.07%\n",
      "\t test  Loss: 0.580 | test  Acc: 82.18%\n",
      "\t best  test acc: 82.37%\n",
      "Epoch: 14 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.113 | Train Acc: 96.56%\n",
      "\t test  Loss: 0.602 | test  Acc: 81.81%\n",
      "\t best  test acc: 82.37%\n",
      "Epoch: 15 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.091 | Train Acc: 97.34%\n",
      "\t test  Loss: 0.639 | test  Acc: 81.90%\n",
      "\t best  test acc: 82.37%\n",
      "Epoch: 16 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.091 | Train Acc: 97.27%\n",
      "\t test  Loss: 0.627 | test  Acc: 81.81%\n",
      "\t best  test acc: 82.37%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.097 | Train Acc: 97.15%\n",
      "\t test  Loss: 0.616 | test  Acc: 83.30%\n",
      "\t best  test acc: 83.30%\n",
      "Epoch: 18 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.091 | Train Acc: 97.26%\n",
      "\t test  Loss: 0.605 | test  Acc: 82.28%\n",
      "\t best  test acc: 83.30%\n",
      "Epoch: 19 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.077 | Train Acc: 97.74%\n",
      "\t test  Loss: 0.666 | test  Acc: 82.00%\n",
      "\t best  test acc: 83.30%\n",
      "Epoch: 20 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.066 | Train Acc: 98.02%\n",
      "\t test  Loss: 0.664 | test  Acc: 81.62%\n",
      "\t best  test acc: 83.30%\n",
      "Epoch: 21 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.065 | Train Acc: 98.14%\n",
      "\t test  Loss: 0.679 | test  Acc: 82.09%\n",
      "\t best  test acc: 83.30%\n",
      "Epoch: 22 | Epoch Time: 0m 6s\n",
      "\t Train Loss: 0.064 | Train Acc: 98.15%\n",
      "\t test  Loss: 0.687 | test  Acc: 81.81%\n",
      "\t best  test acc: 83.30%\n",
      "Epoch: 23 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.059 | Train Acc: 98.25%\n",
      "\t test  Loss: 0.676 | test  Acc: 82.84%\n",
      "\t best  test acc: 83.30%\n",
      "Epoch: 24 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.052 | Train Acc: 98.38%\n",
      "\t test  Loss: 0.700 | test  Acc: 82.46%\n",
      "\t best  test acc: 83.30%\n",
      "Epoch: 25 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.053 | Train Acc: 98.21%\n",
      "\t test  Loss: 0.679 | test  Acc: 82.18%\n",
      "\t best  test acc: 83.30%\n",
      "Epoch: 26 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.054 | Train Acc: 98.20%\n",
      "\t test  Loss: 0.718 | test  Acc: 81.44%\n",
      "\t best  test acc: 83.30%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,489,601 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.629 | Train Acc: 67.50%\n",
      "\t test  Loss: 0.621 | test  Acc: 68.38%\n",
      "\t best  test acc: 68.38%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.606 | Train Acc: 68.89%\n",
      "\t test  Loss: 0.599 | test  Acc: 68.38%\n",
      "\t best  test acc: 68.38%\n",
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.570 | Train Acc: 73.63%\n",
      "\t test  Loss: 0.577 | test  Acc: 72.48%\n",
      "\t best  test acc: 72.48%\n",
      "Epoch: 04 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.520 | Train Acc: 76.75%\n",
      "\t test  Loss: 0.545 | test  Acc: 73.60%\n",
      "\t best  test acc: 73.60%\n",
      "Epoch: 05 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.438 | Train Acc: 81.86%\n",
      "\t test  Loss: 0.496 | test  Acc: 78.45%\n",
      "\t best  test acc: 78.45%\n",
      "Epoch: 06 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.348 | Train Acc: 87.02%\n",
      "\t test  Loss: 0.534 | test  Acc: 77.52%\n",
      "\t best  test acc: 78.45%\n",
      "Epoch: 07 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.285 | Train Acc: 90.27%\n",
      "\t test  Loss: 0.503 | test  Acc: 80.97%\n",
      "\t best  test acc: 80.97%\n",
      "Epoch: 08 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.246 | Train Acc: 91.82%\n",
      "\t test  Loss: 0.504 | test  Acc: 81.44%\n",
      "\t best  test acc: 81.44%\n",
      "Epoch: 09 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.203 | Train Acc: 93.82%\n",
      "\t test  Loss: 0.530 | test  Acc: 81.34%\n",
      "\t best  test acc: 81.44%\n",
      "Epoch: 10 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.179 | Train Acc: 94.66%\n",
      "\t test  Loss: 0.551 | test  Acc: 81.81%\n",
      "\t best  test acc: 81.81%\n",
      "Epoch: 11 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.164 | Train Acc: 95.21%\n",
      "\t test  Loss: 0.561 | test  Acc: 81.25%\n",
      "\t best  test acc: 81.81%\n",
      "Epoch: 12 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.140 | Train Acc: 95.89%\n",
      "\t test  Loss: 0.541 | test  Acc: 82.37%\n",
      "\t best  test acc: 82.37%\n",
      "Epoch: 13 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.137 | Train Acc: 95.92%\n",
      "\t test  Loss: 0.556 | test  Acc: 81.62%\n",
      "\t best  test acc: 82.37%\n",
      "Epoch: 14 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.119 | Train Acc: 96.54%\n",
      "\t test  Loss: 0.581 | test  Acc: 82.18%\n",
      "\t best  test acc: 82.37%\n",
      "Epoch: 15 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.107 | Train Acc: 96.80%\n",
      "\t test  Loss: 0.592 | test  Acc: 82.00%\n",
      "\t best  test acc: 82.37%\n",
      "Epoch: 16 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.104 | Train Acc: 96.77%\n",
      "\t test  Loss: 0.568 | test  Acc: 82.46%\n",
      "\t best  test acc: 82.46%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.090 | Train Acc: 97.21%\n",
      "\t test  Loss: 0.618 | test  Acc: 81.90%\n",
      "\t best  test acc: 82.46%\n",
      "Epoch: 18 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.079 | Train Acc: 97.59%\n",
      "\t test  Loss: 0.638 | test  Acc: 81.53%\n",
      "\t best  test acc: 82.46%\n",
      "Epoch: 19 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.071 | Train Acc: 97.76%\n",
      "\t test  Loss: 0.661 | test  Acc: 82.56%\n",
      "\t best  test acc: 82.56%\n",
      "Epoch: 20 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.063 | Train Acc: 97.79%\n",
      "\t test  Loss: 0.714 | test  Acc: 81.81%\n",
      "\t best  test acc: 82.56%\n",
      "Epoch: 21 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.062 | Train Acc: 97.83%\n",
      "\t test  Loss: 0.710 | test  Acc: 81.06%\n",
      "\t best  test acc: 82.56%\n",
      "Epoch: 22 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.071 | Train Acc: 97.69%\n",
      "\t test  Loss: 0.706 | test  Acc: 81.81%\n",
      "\t best  test acc: 82.56%\n",
      "Epoch: 23 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.062 | Train Acc: 97.75%\n",
      "\t test  Loss: 0.743 | test  Acc: 80.60%\n",
      "\t best  test acc: 82.56%\n",
      "Epoch: 24 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.051 | Train Acc: 97.98%\n",
      "\t test  Loss: 0.755 | test  Acc: 81.90%\n",
      "\t best  test acc: 82.56%\n",
      "Epoch: 25 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.047 | Train Acc: 98.02%\n",
      "\t test  Loss: 0.728 | test  Acc: 81.16%\n",
      "\t best  test acc: 82.56%\n",
      "Epoch: 26 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.049 | Train Acc: 98.20%\n",
      "\t test  Loss: 0.806 | test  Acc: 79.94%\n",
      "\t best  test acc: 82.56%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,489,601 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.627 | Train Acc: 68.04%\n",
      "\t test  Loss: 0.622 | test  Acc: 68.38%\n",
      "\t best  test acc: 68.38%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.599 | Train Acc: 69.75%\n",
      "\t test  Loss: 0.585 | test  Acc: 68.38%\n",
      "\t best  test acc: 68.38%\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.539 | Train Acc: 75.98%\n",
      "\t test  Loss: 0.561 | test  Acc: 73.60%\n",
      "\t best  test acc: 73.60%\n",
      "Epoch: 04 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.464 | Train Acc: 80.47%\n",
      "\t test  Loss: 0.524 | test  Acc: 77.89%\n",
      "\t best  test acc: 77.89%\n",
      "Epoch: 05 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.380 | Train Acc: 85.58%\n",
      "\t test  Loss: 0.505 | test  Acc: 79.20%\n",
      "\t best  test acc: 79.20%\n",
      "Epoch: 06 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.317 | Train Acc: 88.76%\n",
      "\t test  Loss: 0.517 | test  Acc: 79.66%\n",
      "\t best  test acc: 79.66%\n",
      "Epoch: 07 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.263 | Train Acc: 91.23%\n",
      "\t test  Loss: 0.519 | test  Acc: 81.44%\n",
      "\t best  test acc: 81.44%\n",
      "Epoch: 08 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.242 | Train Acc: 92.24%\n",
      "\t test  Loss: 0.545 | test  Acc: 80.04%\n",
      "\t best  test acc: 81.44%\n",
      "Epoch: 09 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.218 | Train Acc: 93.08%\n",
      "\t test  Loss: 0.521 | test  Acc: 81.16%\n",
      "\t best  test acc: 81.44%\n",
      "Epoch: 10 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.208 | Train Acc: 93.20%\n",
      "\t test  Loss: 0.524 | test  Acc: 82.00%\n",
      "\t best  test acc: 82.00%\n",
      "Epoch: 11 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.183 | Train Acc: 94.36%\n",
      "\t test  Loss: 0.539 | test  Acc: 81.90%\n",
      "\t best  test acc: 82.00%\n",
      "Epoch: 12 | Epoch Time: 0m 6s\n",
      "\t Train Loss: 0.158 | Train Acc: 95.22%\n",
      "\t test  Loss: 0.596 | test  Acc: 81.06%\n",
      "\t best  test acc: 82.00%\n",
      "Epoch: 13 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.140 | Train Acc: 95.76%\n",
      "\t test  Loss: 0.608 | test  Acc: 80.78%\n",
      "\t best  test acc: 82.00%\n",
      "Epoch: 14 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.124 | Train Acc: 96.42%\n",
      "\t test  Loss: 0.623 | test  Acc: 80.69%\n",
      "\t best  test acc: 82.00%\n",
      "Epoch: 15 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.116 | Train Acc: 96.61%\n",
      "\t test  Loss: 0.593 | test  Acc: 82.37%\n",
      "\t best  test acc: 82.37%\n",
      "Epoch: 16 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.119 | Train Acc: 96.29%\n",
      "\t test  Loss: 0.599 | test  Acc: 82.74%\n",
      "\t best  test acc: 82.74%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.105 | Train Acc: 96.77%\n",
      "\t test  Loss: 0.631 | test  Acc: 82.74%\n",
      "\t best  test acc: 82.74%\n",
      "Epoch: 18 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.094 | Train Acc: 97.00%\n",
      "\t test  Loss: 0.620 | test  Acc: 82.65%\n",
      "\t best  test acc: 82.74%\n",
      "Epoch: 19 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.090 | Train Acc: 97.16%\n",
      "\t test  Loss: 0.662 | test  Acc: 82.93%\n",
      "\t best  test acc: 82.93%\n",
      "Epoch: 20 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.084 | Train Acc: 97.39%\n",
      "\t test  Loss: 0.665 | test  Acc: 82.56%\n",
      "\t best  test acc: 82.93%\n",
      "Epoch: 21 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.076 | Train Acc: 97.58%\n",
      "\t test  Loss: 0.595 | test  Acc: 83.21%\n",
      "\t best  test acc: 83.21%\n",
      "Epoch: 22 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.085 | Train Acc: 97.13%\n",
      "\t test  Loss: 0.630 | test  Acc: 83.02%\n",
      "\t best  test acc: 83.21%\n",
      "Epoch: 23 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.072 | Train Acc: 97.58%\n",
      "\t test  Loss: 0.647 | test  Acc: 82.56%\n",
      "\t best  test acc: 83.21%\n",
      "Epoch: 24 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.077 | Train Acc: 97.46%\n",
      "\t test  Loss: 0.629 | test  Acc: 82.56%\n",
      "\t best  test acc: 83.21%\n",
      "Epoch: 25 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.067 | Train Acc: 97.70%\n",
      "\t test  Loss: 0.632 | test  Acc: 83.49%\n",
      "\t best  test acc: 83.49%\n",
      "Epoch: 26 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.060 | Train Acc: 97.96%\n",
      "\t test  Loss: 0.660 | test  Acc: 82.74%\n",
      "\t best  test acc: 83.49%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
