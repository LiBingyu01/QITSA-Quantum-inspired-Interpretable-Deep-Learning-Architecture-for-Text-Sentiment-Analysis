{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MR'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MR\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([16143, 100])\n",
      "16143\n",
      "16143\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 3,604,401 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.667 | Train Acc: 62.31%\n",
      "\t test  Loss: 0.593 | test  Acc: 73.63%\n",
      "\t best  test acc: 73.63%\n",
      "Epoch: 02 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.506 | Train Acc: 78.83%\n",
      "\t test  Loss: 0.507 | test  Acc: 78.88%\n",
      "\t best  test acc: 78.88%\n",
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.360 | Train Acc: 87.00%\n",
      "\t test  Loss: 0.502 | test  Acc: 78.23%\n",
      "\t best  test acc: 78.88%\n",
      "Epoch: 04 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.255 | Train Acc: 91.99%\n",
      "\t test  Loss: 0.542 | test  Acc: 79.07%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 05 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.187 | Train Acc: 94.87%\n",
      "\t test  Loss: 0.625 | test  Acc: 77.68%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 06 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.151 | Train Acc: 96.18%\n",
      "\t test  Loss: 0.719 | test  Acc: 76.83%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 07 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.135 | Train Acc: 96.65%\n",
      "\t test  Loss: 0.774 | test  Acc: 75.76%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 08 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.124 | Train Acc: 96.89%\n",
      "\t test  Loss: 0.745 | test  Acc: 77.20%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 09 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.105 | Train Acc: 97.62%\n",
      "\t test  Loss: 0.755 | test  Acc: 77.11%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 10 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.090 | Train Acc: 97.93%\n",
      "\t test  Loss: 0.814 | test  Acc: 76.65%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 11 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.080 | Train Acc: 98.23%\n",
      "\t test  Loss: 0.874 | test  Acc: 76.74%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 12 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.075 | Train Acc: 98.33%\n",
      "\t test  Loss: 0.918 | test  Acc: 76.46%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 13 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.070 | Train Acc: 98.40%\n",
      "\t test  Loss: 0.883 | test  Acc: 77.02%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 14 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.063 | Train Acc: 98.57%\n",
      "\t test  Loss: 0.999 | test  Acc: 75.10%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 15 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.060 | Train Acc: 98.71%\n",
      "\t test  Loss: 0.972 | test  Acc: 76.98%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 16 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.060 | Train Acc: 98.65%\n",
      "\t test  Loss: 0.950 | test  Acc: 77.48%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 17 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.057 | Train Acc: 98.69%\n",
      "\t test  Loss: 0.935 | test  Acc: 77.11%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 18 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.050 | Train Acc: 98.99%\n",
      "\t test  Loss: 0.975 | test  Acc: 77.39%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 19 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.046 | Train Acc: 99.05%\n",
      "\t test  Loss: 1.027 | test  Acc: 76.09%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 20 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.052 | Train Acc: 98.89%\n",
      "\t test  Loss: 0.966 | test  Acc: 76.65%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 21 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.052 | Train Acc: 98.85%\n",
      "\t test  Loss: 0.999 | test  Acc: 76.46%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 22 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.048 | Train Acc: 98.99%\n",
      "\t test  Loss: 1.099 | test  Acc: 75.43%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 23 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.045 | Train Acc: 99.12%\n",
      "\t test  Loss: 1.140 | test  Acc: 75.95%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 24 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.044 | Train Acc: 99.15%\n",
      "\t test  Loss: 1.182 | test  Acc: 75.58%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 25 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.047 | Train Acc: 99.05%\n",
      "\t test  Loss: 1.210 | test  Acc: 73.99%\n",
      "\t best  test acc: 79.07%\n",
      "Epoch: 26 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.049 | Train Acc: 98.95%\n",
      "\t test  Loss: 1.112 | test  Acc: 75.30%\n",
      "\t best  test acc: 79.07%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPSElEQVR4nO3deXwT1d4G8CdJk3TfKN1oadl3WtaCiIJUCnpBwAVREXB7VeSKvNwLyI4KV1QuKihXXoXLVRZFQFREsLaIUkFZBC5YBFso0JXSfU/O+8e0oUvaJm3aSafP9/OZT5ZOZn6dppknZ86cUQkhBIiIiIgUQi13AURERES2xHBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKImu4+eGHHzBu3DgEBgZCpVJhz5499b4mNjYW/fv3h16vR+fOnbF58+Ymr5OIiIhaDlnDTX5+PsLCwrB+/XqL5k9ISMC9996LkSNH4tSpU5g9ezaeeuopfPvtt01cKREREbUUKnu5cKZKpcLu3bsxYcKEWueZN28evv76a5w9e9b03MMPP4ysrCzs37+/GaokIiIie+cgdwHWiIuLQ2RkZJXnoqKiMHv27FpfU1xcjOLiYtNjo9GIzMxMtGnTBiqVqqlKJSIiIhsSQiA3NxeBgYFQq+s+8NSiwk1KSgr8/PyqPOfn54ecnBwUFhbCycmpxmtWrVqF5cuXN1eJRERE1ISSkpIQFBRU5zwtKtw0xIIFCzBnzhzT4+zsbLRv3x5JSUlwd3eXsTKiFspgAI4cAVJSAH9/4LbbAI1G3mXt3QvMmwdcv37rucBA4PXXgfHj5VuWvda2dy8wdWrtP//PfyxfHpdl+bIMBqB376p/v+ratQPOnKn//8CWywLsc3tVk5OTg+DgYLi5udU7b4vqc3PHHXegf//+WLt2rem5TZs2Yfbs2cjOzrZoPTk5OfDw8EB2djbDDbUeBgNw+DCQnAwEBADDhzcsROzaBbz4InD16q3ngoKAt98GJk2SZ1m7dgEPPABU/yirOOy8c6fly7Plsuy1ttJSIDS07p2ijw/wwQfSfYMBMBql2+pTaSmwcCGQlVX3sv7zH8DFBXB0rH1SqYAOHaq+H6r/nkFBQEKCZTv+0NCGLctgAIqLb00FBcCwYVIAr423N/DGG9L2KCmRpuLimvcTE4Gvvqq7dgDo3x/w9JS2uxDmp5s3gfPn61/WkCHS/7yDA6DVSlPF/YpbjQb417+A3Ny6f8d33wX0+lvL0WoBna7qY7UaGD269u1lzd+xGmv23y0q3MybNw/79u3DmTNnTM898sgjyMzMtLhDMcMNtRj2FkjscUfdmJ0YIK2/tPTWTqxfP2l717YsPz8gOlr6QFerpWXWNgkB9OwJXLtW+/LatZN2UCqVNL/ReGuq/Li0FBg8uPbaAMDLC/jf/5V2UNnZtU85OXVuUtlUbIP6dOwIuLtL21+lkm4rporHOTnA6dP1L8vXV3pNRfgoLpbeU9T0YmKAESOsekmLCTd5eXm4ePEiAKBfv35Ys2YNRo4cCW9vb7Rv3x4LFizAtWvXsGXLFgDSqeC9e/fGzJkz8cQTT+D777/HX//6V3z99deIioqyaJ0MN9SklBpIGhsirF2Wry/w6afSDqeoCCgslKbq9+Pjge3b66+/fXvpW2rlb+QVOzQyr1MnKcxVhDVzYe76deDXX+tfVvv2gJPTrb9fUZE0tYTt7+AAlJXVP194uPS+1umk1g2drub969eBjz6qf1kLF0qHnFQq85NaDZw9CyxeXP+y5s6V/pZlZVJIrritfP/MGWDfvvqX1bOn1IJT8fqKlqrKj/PypKk+W7cCU6bUP18lLSbcxMbGYuTIkTWenzZtGjZv3ozp06cjMTERsbGxVV7z0ksv4dy5cwgKCsLixYsxffp0i9fJcENNxh4CSVmZ9K01OxvIzATGjgXS02tfl5sb8OSTUuCo68MvNRU4dqz+2v39pabpisMWZWU1b8vKLPuGbq+cnaUdXvVDNEZj06yv4u9uyTa7806p9cnDo/bp7Fng/vvrX5Yl36xjYwEzn+EWL8tolEJmURHw/ffS+74+q1cDffuab+GqeHzmDGDJiSTvvSf189Lrq04VoUSrBQ4datzvWFlFsL92zfzfsyFfEmyxrMb+HZtqWdW0mHAjB4YbahK2aCEpK5MCSVhY3cf3XVyk0GLu8EN+fuN+D3vi5we0bSt943d0lG4r33d0BDIypG1bnzVrgIiImjuxytORI0C1oSbMqu1DuWInWxF0YmKAe+6pf3n79gF33GH+8ErFN3Vb7jDsdQdrg2UZDAaUlpZKyxo1SgrltS3L3x/47jvL6rLVsgDgwAHpSxBQdXkVnxVvvy31WbGErZZlR9tLp9PVepo3w00dGG4UwlaHf2yxrPoOswBSH4EnnpCaa2vrC1FQ0LD6zXF0lL59WtK/4i9/kQKVuY6GFbcXL0pn5NRn/Xqpb4hGI73W3O2xY7ZrObCznWuLqa0ijAPmd4oN6T8l47KEEEhJSUFW5Y7NBQV1t1q2bSu1wlnClsuqWF5mZtX+PRqNdMjHmuXYcll2sr3UajU6dOgAnU5X42cMN3VguFEAuc/YKSgA/vxT2uFfvCg1W1tyBoQtTZ0K3HVX7YcedLrW8W0fsIuda4utrfp7PzgYWLvWNv9Hzbis5ORkZGVlwdfXF87OzrcGaM3OllpBS0tvzazVSi0HHh7W1WXLZQHS37CgQOqzotNJO/uGDixrq2XJvL2MRiOuX78OrVaL9u3b1xhol+GmDgw3MrJFa0tznrHz5ptASMitEHPxIvDHH7Wf/VKfe++VTsusqz/EyZPA3XfXv6zmDiQAd9QNWZa912ZPLaANXJbBYMCFCxfg6+uLNm3a1JxBCKnFtGLH7+rauBBhq2XZK5m3V3Z2Nq5fv47OnTtDq9VW+RnDTR0YbmRii9YWa8/YKSuT/rHy82ve5uQAzz0njRXREB4eQJcu0uTgII3jUZ+WHkgqlscdtbJqa+GKioqQkJCA0NBQs6PUU8tSWFiIxMREdOjQAY6OjlV+xnBTB4YbGTSmtaW0FEhLkzqnHTwIzJ9f//rc3Gx3mm+PHtKAWp07S0Gmc2dp8va+VX9rCiQAd9RkVyrCjbmdIbU8df09GW7qwHDTzCzpbOvlBcyZI3VAS02tOmVmNr4GBwepOdTFRZpcXaXWm/j4+l9r6VgMrSmQENkRhhtlsVW4Ufy1pUhmP/xQd7ABpENDdQ1GpdFIg7o5OwOXLtW/zs2bpc62FUHGTK97izvbBgTUPw8gBY6dO80femtIIJk0CbjvPtsFEo3G6jEliKjlCA0NxezZszF79uxGL6tiDLqbN2/C09Oz0cuTA8MN1c3ab/xCABcuSOEhJgb45hvL1nPnncDQodLYJtUnb29pzA9LD/889lj9IWD4cGne+pY1fLhl9QMMJEQtXTO3cI4YMQLh4eFVrpfYUL/88gtcXFwaX5RCMNxQ7SzpBCyEdBZRTIwUaGJj677+TW2WLat/R67RSOt+4IGa16GpOPyzdq1lH0a2XFb15TKQELU8thxiwkaEEDAYDHBwqH9X3bZt22aoqOUwPwwgUUUfkuqHlK5dk55//nng0Uelf/6uXYH/+R9g2zYp2Oj10g5++XJpSPV27Wo//U+lkvqSWNpCUnH4p127qs8HBVnfr8WWyyKilqu+z7tdu2y+yunTp+PQoUN4++23oVKpoFKpsHnzZqhUKnzzzTcYMGAA9Ho9fvzxR1y6dAn33Xcf/Pz84OrqikGDBuG7776rsrzQ0NAqLUAqlQr/93//h4kTJ8LZ2RldunTB3r17G1zv559/jl69ekGv1yM0NBRvvfVWlZ+/99576NKlCxwdHeHn54cHKl1KY+fOnejTpw+cnJzQpk0bREZGIr+pR1MXrUx2drYAILKzs+UuxX6VlQkRFCSE1J5R/6TTCXHHHUIsXSpETIwQhYVVl/f550KoVNJU+XUVz33+ecNqjIkRYutW6basrHG/r62WRUTNqrCwUJw7d04UVv7cMRqFyMuzbMrOFqJdu9o/31Qq6fMwO9uy5RmNFtWdlZUlhg4dKp5++mmRnJwskpOTxXfffScAiL59+4oDBw6Iixcvihs3bohTp06JDRs2iDNnzogLFy6IRYsWCUdHR3H58mXT8kJCQsQ///lP02MAIigoSGzdulX88ccf4q9//atwdXUVN27cqLe2mJgYAUDcvHlTCCHEr7/+KtRqtVixYoWIj48XmzZtEk5OTmLTpk1CCCF++eUXodFoxNatW0ViYqI4ceKEePvtt4UQQly/fl04ODiINWvWiISEBHH69Gmxfv16kZuba/nfs5w1+2+GG6opJsayUDN1qhDffy9EQUH9y/z885qBKTi4YcGGiKic2Z1hXp7lX85sPeXlWVz7nXfeKV588UXT44pQsWfPnnpf26tXL/Huu++aHpsLN4sWLaq0SfIEAPHNN9/Uu+zq4eaRRx4Rd999d5V5/va3v4mePXsKIYT4/PPPhbu7u8jJyamxrOPHjwsAIjExsd71CmG7cMPDUlTTn39aNt/YsdIZR5YMnDVpEpCYKPXN2bpVuk1I4KEfIqJqBg4cWOVxXl4e5s6dix49esDT0xOurq44f/48rly5Uudy+vbta7rv4uICd3d3pKWlWV3P+fPnMWzYsCrPDRs2DH/88QcMBgPuvvtuhISEoGPHjpg6dSo++eQTFJRfKy8sLAyjRo1Cnz598OCDD2Ljxo242dDBU63AcEO3lJYC770njTljCUtPk65Q0dl2yhTpluOsEFFTcHaWRiO3ZNq3z7Jl7ttn2fKsvfClGdXPepo7dy52796NlStX4vDhwzh16hT69OmDknoGKq1++QKVSgWj0djo+qpzc3PDiRMnsG3bNgQEBGDJkiUICwtDVlYWNBoNDh48iG+++QY9e/bEu+++i27duiEhIcHmdVTGcENSY+oXXwC9ewMzZ0oXPKurd761nYCJiJqTSnVr0M76ptGjpZMI6jvpYfRoy5ZnxXWYdDodDJWv5l2Ln376CdOnT8fEiRPRp08f+Pv7IzEx0eL1NFaPHj3w008/1aipa9eu0JR/SXVwcEBkZCRWr16N06dPIzExEd9//z0AKVQNGzYMy5cvx8mTJ6HT6bB79+4mrZmngrd2x44Bc+dKYzsAgI+PdFp227bAww9Lz9nqNGkiInvTVMNCWCA0NBRHjx5FYmIiXF1da21V6dKlC3bt2oVx48ZBpVJh8eLFTdICU5v//d//xaBBg/DKK69g8uTJiIuLw7p16/Dee+8BAL766iv8+eefuOOOO+Dl5YV9+/bBaDSiW7duOHr0KKKjozF69Gj4+vri6NGjSE9PR48ePZq0ZrbctFYJCdLhoYgIKdg4OgILFkhj1sycCTz0EE+TJqLWQaZhIebOnQuNRoOePXuibdu2tfahWbNmDby8vHDbbbdh3LhxiIqKQv/+/ZukJnP69++PTz/9FNu3b0fv3r2xZMkSrFixAtOnTwcAeHp6YteuXbjrrrvQo0cPbNiwAdu2bUOvXr3g7u6OH374Affccw+6du2KRYsW4a233sLYsWObtGZeW0qJ6hpl8+ZN4LXXgHfflS4sqVIBU6cCr74qNb1asywiIpnZ9NpS/LyTHa8tRebVNsrmm28C168Dr7wiBRwAGDUKeOMNoF+/2pfHEXeJqLXg551i8LCUktQ2yubVq1L/mTlzpGDTq5fU8//gwbqDDRERKc6zzz4LV1dXs9Ozzz4rd3k2wZYbpTAYpBabuo4yqtXA++8DTzxR99lQRESkWCtWrMDcuXPN/kwp3TW4h1OKw4drtthUZzRK14FisCEiarV8fX3h6+srdxlNioellMLSK3E35IrdRERELQjDjVJYOlqwtaMKExERtTAMN0rRrl3dpyxyVGEiImolGG6U4PffpQtYVgzjXX34b44qTERErQjDTUt3+jRw553AtWtAz57A//0fRxUmIqJWjafNtGS//ipdzO3mTWm8mgMHpGtDTZ/OUTaJiKhOiYmJ6NChA06ePInw8HC5y7EphpuW6qefgHvuAXJygCFDgG++ATw9pZ9xlE0iIrs3YsQIhIeHY+3atTZZ3vTp05GVlYU9e/bYZHktGQ9LtUTR0VKLTU6OFGIOHLgVbIiIqMF+zcnBXadO4decHLlLoUZguGlpvv4auPdeoKAAiIqSHru5yV0VEZEibElNRUxWFv6Tmtqk65k+fToOHTqEt99+GyqVCiqVComJiTh79izGjh0LV1dX+Pn5YerUqcjIyDC9bufOnejTpw+cnJzQpk0bREZGIj8/H8uWLcO///1vfPHFF6blxcbGWl3XoUOHMHjwYOj1egQEBGD+/PkoKyurd/0AEBsbi8GDB8PFxQWenp4YNmwYLl++3Oht1RA8LNWSfP45MGUKUFoKTJgAbN8O6PVyV0VEZFeEECgwGi2e/0pREW6UlkKlUmF7WhoAYFtaGh7y9YUQAm20WrS38Irjzmo1VNXPWDXj7bffxoULF9C7d2+sWLECAKDVajF48GA89dRT+Oc//4nCwkLMmzcPDz30EL7//nskJydjypQpWL16NSZOnIjc3FwcPnwYQgjMnTsX58+fR05ODjZt2gQA8Pb2tngbAMC1a9dwzz33YPr06diyZQt+//13PP3003B0dMSyZcvqXH9ZWRkmTJiAp59+Gtu2bUNJSQmOHTtm0bZoCgw3LcXHHwPTpkmXUHj4YWDLFkCrlbsqIiK7U2A0wvXw4UYtI720FLefPGn16/KGD4eLBSdweHh4QKfTwdnZGf7+/gCAV199Ff369cPKlStN83300UcIDg7GhQsXkJeXh7KyMkyaNAkhISEAgD59+pjmdXJyQnFxsWl51nrvvfcQHByMdevWQaVSoXv37rh+/TrmzZuHJUuWIDk5udb1Z2ZmIjs7G3/5y1/QqVMnAECPHj0aVIct8LBUS/DBB8Djj0vBZsYMKegw2BARKcpvv/2GmJiYKlfp7t69OwDg0qVLCAsLw6hRo9CnTx88+OCD2LhxI27evGmz9Z8/fx5Dhw6t0toybNgw5OXl4erVq3Wu39vbG9OnT0dUVBTGjRuHt99+G8kyXu6HLTf27u23gdmzpfszZwLvvCNd3ZuIiMxyVquRZ+Vo7Kfy8sy21PzYrx/CXV2tWndD5eXlYdy4cXj99ddr/CwgIAAajQYHDx7EkSNHcODAAbz77rtYuHAhjh49ig4dOjR4vZaqb/2bNm3CX//6V+zfvx87duzAokWLcPDgQQwZMqTJa6uOe0l7tnLlrWDzt78B777LYENEVA+VSgUXjcaqyan8s7XiE7bi1kmttmo51vQx0el0MFSMLA+gf//++O9//4vQ0FB07ty5yuTi4mL63YYNG4bly5fj5MmT0Ol02L17t9nlWatHjx6Ii4uDEML03E8//QQ3NzcEBQXVu34A6NevHxYsWIAjR46gd+/e2Lp1a4PraQzuKe2FwQDExgLbtgExMcDLLwMLF0o/W7YMeP31mpdVICIim/DVauGv1WKAmxs2dO2KAW5u8Ndq4duEXQBCQ0Nx9OhRJCYmIiMjAzNnzkRmZiamTJmCX375BZcuXcK3336LGTNmwGAw4OjRo1i5ciV+/fVXXLlyBbt27UJ6erqpb0toaChOnz6N+Ph4ZGRkoLS01Kp6nn/+eSQlJWHWrFn4/fff8cUXX2Dp0qWYM2cO1Gp1netPSEjAggULEBcXh8uXL+PAgQP4448/5Ot3I1qZ7OxsAUBkZ2fLXcotn38uRFCQEEDNafVquasjIrJbhYWF4ty5c6KwsLDRyyoyGITRaBRCCGE0GkWRwdDoZdYlPj5eDBkyRDg5OQkAIiEhQVy4cEFMnDhReHp6CicnJ9G9e3cxe/ZsYTQaxblz50RUVJRo27at0Ov1omvXruLdd981LS8tLU3cfffdwtXVVQAQMTExda4/ISFBABAnT540PRcbGysGDRokdDqd8Pf3F/PmzROlpaVCCFHn+lNSUsSECRNEQECA0Ol0IiQkRCxZskQYrNyGdf09rdl/q4So1P7UCuTk5MDDwwPZ2dlwd3eXuxxg1y7ggQekKGPO55/zmlBERLUoKipCQkICOnToAEcLT9cm+1XX39Oa/TcPS8nJYABefLH2YKNSSX1uGnEMlYiIqLVhuJHT4cPA1au1/1wIIClJmo+IiMgKK1eurHJaeeVp7NixcpfXpHgquJwsHQNAxrECiIioZXr22Wfx0EMPmf2Zk5NTM1fTvBhu5BQQYNv5iIiIynl7e1t9CQal4GEpOQ0fXvfVvFUqIDhYmo+IiIgswnAjp+RkoKjI/M8qxrRZuxaw4DolREStmdGKC2WS/bLVCdw8LCUXIaTLKRQVAV27AgUFVTsXBwVJwYangRMR1Uqn00GtVuP69eto27YtdDqdbFeipsYRQiA9PR0qlQraRg6eyHAjl88/B/bulS6AuWsX0L27dFZUcrLUx2b4cLbYEBHVQ61Wo0OHDkhOTsb169flLocaSaVSISgoCJpG7v8YbuRw8yYwa5Z0f/58oFcv6f6IEbKVRETUUul0OrRv3x5lZWWNurYSyU+r1TY62AAMN/KYNw9ISQG6dZOuIUVERI1ScSijsYczSBnYobi5HToEbNwo3d+4EeBw4URERDbFcNOcioqAZ56R7v/P//AUbyIioibAcNOcXn0VuHBB6jD8+utyV0NERKRIDDfN5cyZW4Fm3TrAw0PeeoiIiBSK4aY5GAzAU08BZWXAxIkcu4aIiKgJMdw0h/XrgWPHAHd3qdWGiIiImgzDTVO7cuXW6d6vvw4EBspbDxERkcIx3DQlIYDnngPy84Hbb791phQRERE1GYabprRjB7BvH6DTSWPaqLm5iYiImhr3tk0lMxN48UXp/sKF0rWjiIiIqMkx3DSVuXOBtDTpulHz58tdDRERUavBcNMUoqOBTZsAlUo6HKXTyV0RERFRq8FwY2uFhdKlFQDg+eeBoUPlrYeIiKiVkT3crF+/HqGhoXB0dERERASOHTtW5/xr165Ft27d4OTkhODgYLz00ksoKipqpmotsHw5cOkS0K4dsHKl3NUQERG1OrKGmx07dmDOnDlYunQpTpw4gbCwMERFRSEtLc3s/Fu3bsX8+fOxdOlSnD9/Hh9++CF27NiBlyvGkZHbqVPAm29K9997Txq0j4iIiJqVrOFmzZo1ePrppzFjxgz07NkTGzZsgLOzMz766COz8x85cgTDhg3DI488gtDQUIwePRpTpkypt7WnWZSVSZdYMBiABx8Exo+XuyIiIqJWSbZwU1JSguPHjyMyMvJWMWo1IiMjERcXZ/Y1t912G44fP24KM3/++Sf27duHe+65p9b1FBcXIycnp8rUJN55Bzh+HPD0lO4TERGRLGQLNxkZGTAYDPDz86vyvJ+fH1JSUsy+5pFHHsGKFStw++23Q6vVolOnThgxYkSdh6VWrVoFDw8P0xQcHGy7X8JgwK+xsbjryy/x66ZN0nNvvgn4+9tuHQ30a04O7jp1Cr82VZgjIiKyU7J3KLZGbGwsVq5ciffeew8nTpzArl278PXXX+OVV16p9TULFixAdna2aUpKSrJNMbt2AaGh2LJrF2Lc3PCfESMAvV5qubEDW1JTEZOVhf+kpspdChERUbNykGvFPj4+0Gg0SK22801NTYV/LS0fixcvxtSpU/HUU08BAPr06YP8/Hw888wzWLhwIdRmLm+g1+uh1+ttWvvlPXuQsWABVE5O2DFyJABg+113YdqBAxAvvwwfjQYhEybYdJ0W1VVUhJTiYlwtLsaW8tav7WlpmObvDwHAR6tFiKNjs9dFRETUnGQLNzqdDgMGDEB0dDQmlAcBo9GI6OhovPDCC2ZfU1BQUCPAaDQaAIAQoknrNTEYEOrpCfzrXyhfMQAgzdMTAyqeAyAMBqC8Nkv9mpODv//5J1Z37IiB9ZxpVWAwIL6gAOfLp3P5+diVkVFjvrTSUgw4fvxWXSNGWFUTERFRSyNbuAGAOXPmYNq0aRg4cCAGDx6MtWvXIj8/HzNmzAAAPP7442jXrh1WrVoFABg3bhzWrFmDfv36ISIiAhcvXsTixYsxbtw4U8hpcocP4+PXXsO0+fNh0GikUYiBW7fl/A4fRqibG0IdHWtMIY6OcDZTb+VDSRXh5mZpqSnAnM/PN91PLCpCQ+Jc+C+/INLLC5FeXrjD09NsHURERC2ZrOFm8uTJSE9Px5IlS5CSkoLw8HDs37/f1Mn4ypUrVVpqFi1aBJVKhUWLFuHatWto27Ytxo0bh9dee635ik5ORsS5c/DOyUG6l1eNH7sUFCDf2RlpANJyc3EsN9fsYny1WoQ6OqKtVos2Wi3a6XSmQ0kbk5NxJDsbCUVFuFFWVmspbRwc0MPFBT2dndHD2Rk9XFxQJgT+cuZMjXm7OjnhQmEhfsvPx2/5+Xjr6lXoVCrc5uGBSC8v3O3lhQFubtBUC2mAdS1KREREclOJZjueYx9ycnLg4eGB7OxsuDdgR30pNhYj0tJw1dcXAKAyGiHUaqiNRhjVahx/5hl0vH4dCV99hcRevZBYVFRlSigqQq7BYNU6g/R6KbyUTz1dXNDD2RltzVyz6kRuLgYcPw41ACNguj0+YACC9Xp8n5WFg5mZOHjzJq4UF1d5raeDA0Z6euLu8padzk5OUKlU+Osff+Dda9fw13bt8HaXLlZvMyKy3y8J9loXUXXW7L9lbblpaf4sLMRIvR5XfX3ROSkJ2a6uCE1NxZP79uHDe+5BUtu28M3Kgqe3N/oNH45+Zg75CCGQVVZmCjufp6djW1oajGbWpwGwoWtXPBUYaHGNvlot/LVaBDs64smAAHyYnIykoiL4arVoq9Nhsq8vJvv6QgiBi4WF+O7mTXx38ya+z8pCVlkZdmdkYHd53x1/rRaD3d0Rm5UFQNmdk235Ac+dhXXsdXvZui5zh53toTZb1kVkLxhuLJRYWIiRp04hqbgY3QwGxL74Irzy8qArLYUKwDNffokSnQ760lJg585aOxOrVCp4abXw0mrRz80NE9u2xZzg4CqdfiscGzAA/d3crKozyNERiUOHQqdSQaVS4ZmAAJQIAX21jtgqlQpdnJ3RxdkZz7VrB4MQOJ6bi4PlYSc2KwsppaXYe+OG6TXVOyd/3qsXejo7o5OTE7RmzlQzx153ZLb8gLfXnUVr2Pa21Ji68srKkFxSgpN5ebhUWIiM0lJ8mJwMANiUkoJgvR7uDg4I0evRx9UV3g4OcLSi/1tjt9nFggJcLi5GgcGAT8rPWFXylxdqfRhuLHC5qAgjTp3CleJidHVyQoyfH/xv3qwyjwqA3s8PWLsWmDSpQeupfiipoSoHGZVKBb2ZfjTVaVQqDHZ3x2B3dywMCcFHycl4Jj4edR1Au/+//wUAaFUqdHFyMh0u61ne/6ebk1OND2x72pFdLipCekkJrhUXY3N5f6eKHZBapYKnRgM/nQ4OKhW0arV0Wz45VL5Vq3GjtBS5BgO0KpVpZ7HNBjsLe/2G3ti6LhcVIaP8i8GO8mvJ2cPOta66jEJIf3O1GsnFxUguKbk1VXucV8eh51yDAX/7888azzup1Wij1cLbwQHeWi3alN9WPAakzwYPBwfTe2xLSgqC9Hrkl6/PQaVCjsGAXIMBOWVlyCm/rfw412BAkbHmJ4y9nVnJ1lRqDIabelwpDzaXi4vRxckJMeHhCNi4UfrhbbcBr70GJCcDAQHA8OFWn/4N1H0oSS5PBAQg3NXVbIvSrHbtkF1WhnPlZ3DlG404V1CAcwUFVeZTA+jo5IQQvR5Bej06OjnhYzv4lphTVobvb97ExPJwVlm+0Yh3rl2zyXrSq+0sJvr4wE+ng59WK92WT77lj900GqiqBdHGBpKmChHW1mUQAmnlQfJqcbHZbW8PO9fQn3+u8Vz1uizlolbDVaNBWmlprWc2umk0KDAYYABQaDTiavn2sVSWwYC/mwlKjaUBcOfJkxjh6YkRnp4Y4u4Op2Y+s7I1tKZS02GH4joklQebP4uK0NnJCbHh4Win1wORkUB0NPDGG8DcuTapq9hoNB1KEkKYPZTU3OrqnFxxuMwoBK4WF+Nc+Wnq58rH3DlXUICsOs70qq74jjuga6Lf11h+yO3bzEwcuHkTcTk5KKvnba8CMNjNDYF6PcqEQKkQKDUaTfdNz5XfzywtRVppaaPqdFSr4afVwtPBAe4ODmij1eJAZiYKjEa4qNV4xNcXZZBaylw0mlt1GI1Vaqp8uz8zs971LgoJgZtGA3eNBu4ODqZbt2qPU0pKTEFp7OnTSCstha9Wiy9690ZaaSmKjUYYyt8P10pKpNvynXVySUm927zytn8uMBBvdOrUrEMVFBuNmH/pEt6+dq3OYRa8HBwQoNNJk15/6361x24O0nfHiv+j6ir+j4QQyDEYkFlaisyyMtwoLa16v6wMmaWlOJ2Xh9/y883WVvF+7ePqCneNpsbfztzjiwUFiDh5ssayfBwckFHtf1enUmGIu7sp7Ax1dzd7GK0xLSRlRiN+zc3F7wUFSC8txYrLl5FnMMBNo8Hfg4OhU6vhWx7GndRqOGk0cFarTfed1Go4qtVQl39BqBzsK79fv+nb124OvbFFyTrW7L8ZbmpxtTzYXCoqQkdHRxwKD0eQoyOQmQn4+kpX/754EejUqRmrb15Xi4ow6PjxGi1KvwwYIG2LOgghkFpSgnMFBdiSkoItqal17jB0KhX6urpikJsbBrq5YZCbG3o4O8OhjsBT1wfD9eJiU5g5mJlZ45T6Lk5OiPL2RidHR7x06VKNZR9vQH+n2nZiG7t2haeDA1JLS5FaUoLUkhKkVbqfWlKCfDOHCZRGDSBAp0M7vR7t9HroVCrsSE+vdX43jQYPtm2Lx/39MdzDw7TTsiWjEDiSnY2PU1PxaXo6btYRyL/s3RuRXl5W9Y0BLPuSYO2yqmvMsqrX9Wv//nB3cEBsVhZis7IQk5WF5JKSKq/VVws7Q8rDTm1nVhYYDKaga7qtFICvFRcjpaSkUYfjKziWB566/pYV5D70ZsszUVtDUOLZUo10rbgYI3/7DZeKitDB0RExFcEGAL76Sgo2ffooOtgAlndONkelUsFfr4e/Xo+7vLzw16Agsx/KQ9zccKGwEJllZfg1Nxe/VhoXyFmtRj9XVwysCDzu7uji5GTayVVuau7t4oLD2dn4NjMT3968ibP5+VXW46bRYJSXF6K8vBDl7Y0OTk4ApA94wHb9ncwtq7+bW707nnyDwRR0Pk1LwzvXrpmtQw0gytsbfV1cTP19avQBqtQXSKtS4UpRERYkJNRY1guBgXB3cDDbL8P02GCos/9IZb5aLXo4O6Nd+WHI6rd+Wm2VsHoiNxc70tNrbK+n/P3xXVYWEouK8FFKCj5KSUGooyOm+vlhqp8fujg7W1RPXX7Pz8fHqan4JC0NiUVFpucDdTpEenlhS2pqjboC9Xqrgw3QNIedbfF+ra0uP50OQY6O6OLsjKcDA01nVsaUh53Y8rBzKDsbh7KzsfzyZWgB9HV1xfnyQ9MfJCfjl9xcpJWUIL20FDkWvofq+n1UAEL0ejhrNCg0GlFoNKLAYEBhectlhSKj0Wyfouq8HRww8exZ9Hd1RX83NwxwdYW/BZfqsdf+Zjz0VhVbbqq5XlyMEadO4Y/CQoQ6OiI2PLzqG23iRGDPHmDJEmD58uYrvIWr69trP1dXJBQV4ZfycPNLTg6O5+WZ3am6qtXoXj7Wz56MDOQYDNCVh52SSm9lFYCBbm6I8vZGlJcXItzdzZ7R1ZjWqaZcVnN8Q7d0WQYhkF8eeH7OycGD587VmOfX/v0xwMoP1Lq2V6Bejx+zs7ElJQWfpqdXGRtqqLs7Hvfzw0O+vqaOtqY66tjxpBQXY3taGj5OTcXxvDzT824aDR5o2xaP+fnhTk9PJBcX2+zvWMFWh51t+R5raF1CCPxRWGgKOtvKd9D1cVarEVQt8FYJwTodfHU6nMrLs/q9bxAChQYDCspDT2F56DmVl4cn4uMtqg+QWhYHuLmhv6ur6badXl+lL5ylrS1CCGSWleF6+WHZituXzXzRqO7l9u1NnckrdzKvuK04hN/aDr3xsFQd6to4ycXFGHnqFOILC9Fer8eh8HCEln/DBwAUFAA+PkBhIXDiBNCvXzNX33JZ+6FsFALxBQVS2CkPPSfz8iz6RratRw9EennBx8wgh+bYsr+TrZZly0MZTRG6bFEXYNn2KjAY8EVGBrakpuJAZqbpm71OpcK4Nm0wzd8fY7y9oVWra+x48srKsCcjAx+npuLgzZum1zqoVBjj7Y3H/Pwwvk2bGp1l7bEPXAV7q+3jlBRM//13s2dWagC81rEj/icgAB4ODjU6zJvTFIfxqi/rUHg4RPnPj+fm4kReHn4vKDB76LyiRbKjkxN6OjvjH1eu4EZZGbwdHLA8NBTppaXILz8D7Xq1s+dKmmj36qrRwNvBocZArOYo6dAbw00dats4KeWHon4vKEBwebDpUDnYAFKLzcSJQEgIkJBQ43pSVLfGfiiXGo14IykJixMSzDZdO6hU2Ny9Ox4tv3xHS2YP39Cboy5rJRcXY2taGv6dkoIzlQ49ejo4YIyXF769eRM3y8rgodHgNnd3xGRloajSR9wQd3c85ueHh9q2NTvCNzWMLVsa5WpNzSsrw2/5+ThRHnaO5+biXH5+ncNhWKKNgwMCK3U0D9TrUWY04o2rV2vM+7egILg4OCCztLRKZ/Ib5bc3y8osvqagGsCC9u2xLDS0zr6LTaGiRel6cTEePX8euQYD2mq12N/IFiWGmzqY2zipJSUYeeoUzhcUIKg82HSsHmwAYNo0YMsWYPZs4J//bN7CycSWH6T2zN6+odtbXb/l5WFLSgrWmNlJVLcsNBSP+vqisw3661BNcrToNceyCg0GnM7Px4Zr1/DvWk6KUAEY7uGB2z08TCEmsPzMOX+dzuy6Grq9jOUj3Fc+m+54bi4WJybW+hovBwfc26YNxrdpgyhvb7g7NF1X28Tyw5UzLDgU2JAWJXYotkJaSQlGlQebdjodYmsLNqWlwJdfSvcnTmzeIsksW3YCtkcNGYyxOdhLXWGurnirc2eEubjgiVoGnNQA2Ny9Ox7z92/u8loVW3eatuV7rDHLctJoEOHujgh3d8yq5aSIXxsQ4Bq6vdQqldT3ptJ8fjodFicm1vg8vNfbGz/n5OBGWRk+Tk3Fx6mp0KpUGOnpifE+PhjXpg3a19J6Ymk/mctFRYgpH9E+NisLly04TFbRwt7UWnW4SS8pwajffsN/CwoQWB5sOpkLNgDwww/AzZtSn5thw5q3UKrCHgc9JPk8HhCA3rUMONmQS5iQ9RpzZmVLY4svVbbcXrV9Hm7o2hX+Oh3icnKw98YN7M3IwIXCQhy4eRMHbt7EC3/8gTAXF4z38cH4Nm3Q383N7JmolcPN5aIiU5CJLT+jsTIHlQqD3NwwwtMT7XQ6vHDxYo16j/bv3yz/k6023MRkZmJxejrO5ucjQKdDTHh43U3We/ZIt+PHN2gUYrKd1vRBStZRemuePbOXFr2mYq+tU/V9Hg739MRwT0+80akT4gsK8GVGBvbeuIGfsrPxW34+fsvPxyuXL8NXq8XtHh6409MT28vPgPskNRVttFr8kpuLU3l5NUbP1gAY5O6OkeXjHd3m7g7XSoNXAvL9T7baPjfe+/cjs/yYaGx4OLrVFWyEANq3B65elQ5N/eUvzVcwEdVL7o7O1DrYS38zW8goKcG+zEzszcjA/sxMiwYSrQgzFYM3DqsUZqpriv9JdiiuQ8XGwVdfwdvDAx907YqB7u5199z+5Rdg8GDA1RVITwf4YUlkd5S04yFqTkUGA5YkJODNq1fNdppWA/jfoCAsDg01XVbEErb+n2SHYgtllpXhgfIByersub17t3Q7diyDDZGdUvphEaKm4qjRYHXnznjYz89s37VfGth3Tc7/yVb/tcZBpcLHPXrUPVNFf5sJE5q6HCIiIlmpq922RK265QawoOd2fDxw/jyg1QL33tt8hRERETUjJZ2J2mrDjQqwbKTHikNSd90FeHg0YUVERETyUdKZqK023PRzdcV1B4f6E2lFuOHAfUREpHBK6bvWasPN9+HhcHRzqzuRXrsGHDsmXUNq/PjmK46IiIgarOW1NdmISqWqv6ntiy+k2yFDgICApi+KiIiIGq3VhhuL8JAUERFRi8NwU5ubN4HYWOk+ww0REVGLwXBTm6++AsrKgN69gc6d5a6GiIiILMRwUxsO3EdERNQiMdyYU1gI7N8v3echKSIiohaF4cacAweAggIgJATo10/uaoiIiMgKDDfmVJwlNWGCNMYNERERtRgMN9WVlQFffindZ38bIiKiFofhprrDh4HMTKBNG+D22+WuhoiIiKzEcFNdxSGp8eMBh1Z7dQoiIqIWi+GmMiFunQLOs6SIiIhaJIabyo4fB5KSABcXIDJS7mqIiIioARhuKqtotRkzBnBykrUUIiIiahiGm8p4oUwiIqIWj+GmwoULwLlzUifie++VuxoiIiJqIIabChWtNnfdBXh6yloKERERNRzDTQVeKJOIiEgRGG4A4Pp14Oefpfv33SdvLURERNQoDDcA8MUX0u2QIUBgoLy1EBERUaMw3AA8S4qIiEhBGG6ysoCYGOk++9sQERG1eAw3X38tXQm8Z0+ga1e5qyEiIqJGYrjhISkiIiJFad3hprAQ+OYb6T7DDRERkSK07nBz8CBQUAAEBwP9+8tdDREREdlA6w43lQfuU6nkrISIiIhspPWGm7IyYO9e6T4PSRERESlG6w03cXHAjRtAmzbA8OFyV0NEREQ20nrDzZdfSrfjxklXAiciIiJFaL3h5uuvpVsO3EdERKQorTfcXL0KODkBo0fLXQkRERHZUOsNNxUqxrkhIiIiRWjd4aawEHjgAWDXLrkrISIiIhtp3eGmwuzZgMEgdxVERERkAww3QgBJScDhw3JXQkRERDbAcFMhOVnuCoiIiMgGGG4qBATIXQERERHZAEevU6mAoCCOUkxERKQQrbvlpuJimWvXAhqNrKUQERGRbcgebtavX4/Q0FA4OjoiIiICx44dq3P+rKwszJw5EwEBAdDr9ejatSv27dvXsJUHBQE7dwKTJjXs9URERGR3ZD0stWPHDsyZMwcbNmxAREQE1q5di6ioKMTHx8PX17fG/CUlJbj77rvh6+uLnTt3ol27drh8+TI8PT2tX/lXXwFjxrDFhoiISGFUQggh18ojIiIwaNAgrFu3DgBgNBoRHByMWbNmYf78+TXm37BhA9544w38/vvv0Gq1DVpnTk4OPDw8kJ2dDXd390bVT0RERM3Dmv23bIelSkpKcPz4cURGRt4qRq1GZGQk4uLizL5m7969GDp0KGbOnAk/Pz/07t0bK1euhKGOAfiKi4uRk5NTZSIiIiLlki3cZGRkwGAwwM/Pr8rzfn5+SElJMfuaP//8Ezt37oTBYMC+ffuwePFivPXWW3j11VdrXc+qVavg4eFhmoKDg236exAREZF9kb1DsTWMRiN8fX3xwQcfYMCAAZg8eTIWLlyIDRs21PqaBQsWIDs72zQlJSU1Y8VERETU3GTrUOzj4wONRoPU1NQqz6empsLf39/sawICAqDVaqGp1Am4R48eSElJQUlJCXQ6XY3X6PV66PV62xZPREREdku2lhudTocBAwYgOjra9JzRaER0dDSGDh1q9jXDhg3DxYsXYTQaTc9duHABAQEBZoMNERERtT6yHpaaM2cONm7ciH//+984f/48nnvuOeTn52PGjBkAgMcffxwLFiwwzf/cc88hMzMTL774Ii5cuICvv/4aK1euxMyZM+X6FYiIiMjOyDrOzeTJk5Geno4lS5YgJSUF4eHh2L9/v6mT8ZUrV6BW38pfwcHB+Pbbb/HSSy+hb9++aNeuHV588UXMmzdPrl+BiIiI7Iys49zIgePcEBERtTwtYpwbIiIioqbAcENERESKwnBDREREisJwQ0RERIrCcENERESKYnW4SUpKwtWrV02Pjx07htmzZ+ODDz6waWFEREREDWF1uHnkkUcQExMDAEhJScHdd9+NY8eOYeHChVixYoXNCyQiIiKyhtXh5uzZsxg8eDAA4NNPP0Xv3r1x5MgRfPLJJ9i8ebOt6yMiIiKyitXhprS01HQhyu+++w7jx48HAHTv3h3Jycm2rY6IiIjISlaHm169emHDhg04fPgwDh48iDFjxgAArl+/jjZt2ti8QCIiIiJrWB1uXn/9dfzrX//CiBEjMGXKFISFhQEA9u7dazpcRURERCSXBl1bymAwICcnB15eXqbnEhMT4ezsDF9fX5sWaGu8thQREVHL06TXliosLERxcbEp2Fy+fBlr165FfHy83QcbIiIiUj6rw819992HLVu2AACysrIQERGBt956CxMmTMD7779v8wKJiIiIrGF1uDlx4gSGDx8OANi5cyf8/Pxw+fJlbNmyBe+8847NCyQiIiKyhtXhpqCgAG5ubgCAAwcOYNKkSVCr1RgyZAguX75s8wKJiIiIrGF1uOncuTP27NmDpKQkfPvttxg9ejQAIC0tjR10iYiISHZWh5slS5Zg7ty5CA0NxeDBgzF06FAAUitOv379bF4gERERkTUadCp4SkoKkpOTERYWBrVaykfHjh2Du7s7unfvbvMibYmnghMREbU81uy/HRqyAn9/f/j7+5uuDh4UFMQB/IiIiMguWH1Yymg0YsWKFfDw8EBISAhCQkLg6emJV155BUajsSlqJCIiIrKY1S03CxcuxIcffoh//OMfGDZsGADgxx9/xLJly1BUVITXXnvN5kUSERERWcrqPjeBgYHYsGGD6WrgFb744gs8//zzuHbtmk0LtDX2uSEiImp5mvTyC5mZmWY7DXfv3h2ZmZnWLo6IiIjIpqwON2FhYVi3bl2N59etW2e6QjgRERGRXKzuc7N69Wrce++9+O6770xj3MTFxSEpKQn79u2zeYFERERE1rC65ebOO+/EhQsXMHHiRGRlZSErKwuTJk1CfHy86ZpTRERERHJp0CB+5ly9ehUrVqzABx98YIvFNRl2KCYiImp5mrRDcW1u3LiBDz/80FaLIyIiImoQm4UbIiIiInvAcENERESKwnBDREREimLxqeCTJk2q8+dZWVmNrYWIiIio0SwONx4eHvX+/PHHH290QURERESNYXG42bRpU1PWQURERGQT7HNDREREisJwQ0RERIrCcENERESKwnBDREREimLTcFNYWGjLxRERERFZzSbhpri4GG+99RY6dOhgi8URERERNZjF4aa4uBgLFizAwIEDcdttt2HPnj0ApFPEO3TogLVr1+Kll15qqjqJiIiILGLxODdLlizBv/71L0RGRuLIkSN48MEHMWPGDPz8889Ys2YNHnzwQWg0mqaslYiIiKheFoebzz77DFu2bMH48eNx9uxZ9O3bF2VlZfjtt9+gUqmaskYiIiIii1l8WOrq1asYMGAAAKB3797Q6/V46aWXGGyIiIjIrlgcbgwGA3Q6nemxg4MDXF1dm6QoIiIiooay+LCUEALTp0+HXq8HABQVFeHZZ5+Fi4tLlfl27dpl2wqJiIiIrGBxuJk2bVqVx4899pjNiyEiIiJqLF4VnIiIiBSFl18gIiIiRbG45eaJJ56waL6PPvqowcUQERERNZbF4Wbz5s0ICQlBv379IIRoypqIiIiIGszicPPcc89h27ZtSEhIwIwZM/DYY4/B29u7KWsjIiIisprFfW7Wr1+P5ORk/P3vf8eXX36J4OBgPPTQQ/j222/ZkkNERER2QyUamEwuX76MzZs3Y8uWLSgrK8N///vfFjGoX05ODjw8PJCdnQ13d3e5yyEiIiILWLP/bvDZUmq1GiqVCkIIGAyGhi6GiIiIyKasCjfFxcXYtm0b7r77bnTt2hVnzpzBunXrcOXKlRbRakNERETKZ3GH4ueffx7bt29HcHAwnnjiCWzbtg0+Pj5NWRsRERGR1Szuc6NWq9G+fXv069evziuB2/u1pdjnhoiIqOWxZv9tccvN448/XmeoISIiIrIHVg3iR0RERGTveG0pIiIiUhSGGyIiIlIUuwg369evR2hoKBwdHREREYFjx45Z9Lrt27dDpVJhwoQJTVsgERERtRiyh5sdO3Zgzpw5WLp0KU6cOIGwsDBERUUhLS2tztclJiZi7ty5GD58eDNVSkRERC2B7OFmzZo1ePrppzFjxgz07NkTGzZsgLOzMz766KNaX2MwGPDoo49i+fLl6NixYzNWS0RERPZO1nBTUlKC48ePIzIy0vScWq1GZGQk4uLian3dihUr4OvriyeffLLedRQXFyMnJ6fKRERERMola7jJyMiAwWCAn59flef9/PyQkpJi9jU//vgjPvzwQ2zcuNGidaxatQoeHh6mKTg4uNF1ExERkf2S/bCUNXJzczF16lRs3LjR4ks/LFiwANnZ2aYpKSmpiaskIiIiOVk8iF9T8PHxgUajQWpqapXnU1NT4e/vX2P+S5cuITExEePGjTM9ZzQaAQAODg6Ij49Hp06dqrxGr9dDr9c3QfVERERkj2RtudHpdBgwYACio6NNzxmNRkRHR2Po0KE15u/evTvOnDmDU6dOmabx48dj5MiROHXqFA85ERERkbwtNwAwZ84cTJs2DQMHDsTgwYOxdu1a5OfnY8aMGQCka1q1a9cOq1atgqOjI3r37l3l9Z6engBQ43kiIiJqnWQPN5MnT0Z6ejqWLFmClJQUhIeHY//+/aZOxleuXIFa3aK6BhEREZGMVEIIIXcRzcmaS6YTERGRfbBm/80mESIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFLsIN+vXr0doaCgcHR0RERGBY8eO1Trvxo0bMXz4cHh5ecHLywuRkZF1zk9ERESti+zhZseOHZgzZw6WLl2KEydOICwsDFFRUUhLSzM7f2xsLKZMmYKYmBjExcUhODgYo0ePxrVr15q5ciIiIrJHKiGEkLOAiIgIDBo0COvWrQMAGI1GBAcHY9asWZg/f369rzcYDPDy8sK6devw+OOP1zt/Tk4OPDw8kJ2dDXd390bXT0RERE3Pmv23rC03JSUlOH78OCIjI03PqdVqREZGIi4uzqJlFBQUoLS0FN7e3mZ/XlxcjJycnCoTERERKZes4SYjIwMGgwF+fn5Vnvfz80NKSopFy5g3bx4CAwOrBKTKVq1aBQ8PD9MUHBzc6LqJiIjIfsne56Yx/vGPf2D79u3YvXs3HB0dzc6zYMECZGdnm6akpKRmrpKIiIiak4OcK/fx8YFGo0FqamqV51NTU+Hv71/na99880384x//wHfffYe+ffvWOp9er4der7dJvURERGT/ZG250el0GDBgAKKjo03PGY1GREdHY+jQobW+bvXq1XjllVewf/9+DBw4sDlKJSIiohZC1pYbAJgzZw6mTZuGgQMHYvDgwVi7di3y8/MxY8YMAMDjjz+Odu3aYdWqVQCA119/HUuWLMHWrVsRGhpq6pvj6uoKV1dX2X4PIiIisg+yh5vJkycjPT0dS5YsQUpKCsLDw7F//35TJ+MrV65Arb7VwPT++++jpKQEDzzwQJXlLF26FMuWLWvO0omIiMgOyT7OTXPjODdEREQtT4sZ54aIiIjI1hhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFHsItysX78eoaGhcHR0REREBI4dO1bn/J999hm6d+8OR0dH9OnTB/v27WumSomIiMjeyR5uduzYgTlz5mDp0qU4ceIEwsLCEBUVhbS0NLPzHzlyBFOmTMGTTz6JkydPYsKECZgwYQLOnj3bzJUTERGRPVIJIYScBURERGDQoEFYt24dAMBoNCI4OBizZs3C/Pnza8w/efJk5Ofn46uvvjI9N2TIEISHh2PDhg31ri8nJwceHh7Izs6Gu7u77X4RIiIiajLW7L9lbbkpKSnB8ePHERkZaXpOrVYjMjIScXFxZl8TFxdXZX4AiIqKqnX+4uJi5OTkVJmIiIhIuWQNNxkZGTAYDPDz86vyvJ+fH1JSUsy+JiUlxar5V61aBQ8PD9MUHBxsm+KJiIjILsne56apLViwANnZ2aYpKSlJ7pKIiIioCTnIuXIfHx9oNBqkpqZWeT41NRX+/v5mX+Pv72/V/Hq9Hnq93jYFExERkd2TNdzodDoMGDAA0dHRmDBhAgCpQ3F0dDReeOEFs68ZOnQooqOjMXv2bNNzBw8exNChQy1aZ0X/afa9ISIiajkq9tsWnQclZLZ9+3ah1+vF5s2bxblz58QzzzwjPD09RUpKihBCiKlTp4r58+eb5v/pp5+Eg4ODePPNN8X58+fF0qVLhVarFWfOnLFofZcuXRIAOHHixIkTJ04tcEpKSqp3Xy9ryw0gndqdnp6OJUuWICUlBeHh4di/f7+p0/CVK1egVt/qGnTbbbdh69atWLRoEV5++WV06dIFe/bsQe/evS1an7e3t2m5Hh4etv+FqE45OTkIDg5GUlIST8VvZtz28uL2lw+3vXxsue2FEMjNzUVgYGC988o+zk1z4zg38uL2lw+3vby4/eXDbS8fuba94s+WIiIiotaF4YaIiIgUpdWFG71ej6VLl/L0cJlw+8uH215e3P7y4baXj1zbvtX1uSEiIiJla3UtN0RERKRsDDdERESkKAw3REREpCgMN0RERKQorS7crF+/HqGhoXB0dERERASOHTsmd0mtwrJly6BSqapM3bt3l7ssRfrhhx8wbtw4BAYGQqVSYc+ePVV+LoTAkiVLEBAQACcnJ0RGRuKPP/6Qp1iFqW/bT58+vcb/wZgxY+QpVmFWrVqFQYMGwc3NDb6+vpgwYQLi4+OrzFNUVISZM2eiTZs2cHV1xf3331/jQsxkPUu2/YgRI2q895999tkmq6lVhZsdO3Zgzpw5WLp0KU6cOIGwsDBERUUhLS1N7tJahV69eiE5Odk0/fjjj3KXpEj5+fkICwvD+vXrzf589erVeOedd7BhwwYcPXoULi4uiIqKQlFRUTNXqjz1bXsAGDNmTJX/g23btjVjhcp16NAhzJw5Ez///DMOHjyI0tJSjB49Gvn5+aZ5XnrpJXz55Zf47LPPcOjQIVy/fh2TJk2SsWplsGTbA8DTTz9d5b2/evXqpivK2gtdtmSDBw8WM2fOND02GAwiMDBQrFq1SsaqWoelS5eKsLAwuctodQCI3bt3mx4bjUbh7+8v3njjDdNzWVlZQq/Xi23btslQoXJV3/ZCCDFt2jRx3333yVJPa5OWliYAiEOHDgkhpPe5VqsVn332mWme8+fPCwAiLi5OrjIVqfq2F0KIO++8U7z44ovNVkOrabkpKSnB8ePHERkZaXpOrVYjMjIScXFxMlbWevzxxx8IDAxEx44d8eijj+LKlStyl9TqJCQkICUlpcr/gYeHByIiIvh/0ExiY2Ph6+uLbt264bnnnsONGzfkLkmRsrOzAdy6WPLx48dRWlpa5b3fvXt3tG/fnu99G6u+7St88skn8PHxQe/evbFgwQIUFBQ0WQ2yXxW8uWRkZMBgMJiuNl7Bz88Pv//+u0xVtR4RERHYvHkzunXrhuTkZCxfvhzDhw/H2bNn4ebmJnd5rUZKSgoAmP0/qPgZNZ0xY8Zg0qRJ6NChAy5duoSXX34ZY8eORVxcHDQajdzlKYbRaMTs2bMxbNgw9O7dG4D03tfpdPD09KwyL9/7tmVu2wPAI488gpCQEAQGBuL06dOYN28e4uPjsWvXriapo9WEG5LX2LFjTff79u2LiIgIhISE4NNPP8WTTz4pY2VEzefhhx823e/Tpw/69u2LTp06ITY2FqNGjZKxMmWZOXMmzp49y359Mqht2z/zzDOm+3369EFAQABGjRqFS5cuoVOnTjavo9UclvLx8YFGo6nRMz41NRX+/v4yVdV6eXp6omvXrrh48aLcpbQqFe91/h/Yh44dO8LHx4f/Bzb0wgsv4KuvvkJMTAyCgoJMz/v7+6OkpARZWVlV5ud733Zq2/bmREREAECTvfdbTbjR6XQYMGAAoqOjTc8ZjUZER0dj6NChMlbWOuXl5eHSpUsICAiQu5RWpUOHDvD396/yf5CTk4OjR4/y/0AGV69exY0bN/h/YANCCLzwwgvYvXs3vv/+e3To0KHKzwcMGACtVlvlvR8fH48rV67wvd9I9W17c06dOgUATfbeb1WHpebMmYNp06Zh4MCBGDx4MNauXYv8/HzMmDFD7tIUb+7cuRg3bhxCQkJw/fp1LF26FBqNBlOmTJG7NMXJy8ur8m0oISEBp06dgre3N9q3b4/Zs2fj1VdfRZcuXdChQwcsXrwYgYGBmDBhgnxFK0Rd297b2xvLly/H/fffD39/f1y6dAl///vf0blzZ0RFRclYtTLMnDkTW7duxRdffAE3NzdTPxoPDw84OTnBw8MDTz75JObMmQNvb2+4u7tj1qxZGDp0KIYMGSJz9S1bfdv+0qVL2Lp1K+655x60adMGp0+fxksvvYQ77rgDffv2bZqimu28LDvx7rvvivbt2wudTicGDx4sfv75Z7lLahUmT54sAgIChE6nE+3atROTJ08WFy9elLssRYqJiREAakzTpk0TQkingy9evFj4+fkJvV4vRo0aJeLj4+UtWiHq2vYFBQVi9OjRom3btkKr1YqQkBDx9NNPi5SUFLnLVgRz2x2A2LRpk2mewsJC8fzzzwsvLy/h7OwsJk6cKJKTk+UrWiHq2/ZXrlwRd9xxh/D29hZ6vV507txZ/O1vfxPZ2dlNVpOqvDAiIiIiRWg1fW6IiIiodWC4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4IaJWT6VSYc+ePXKXQUQ2wnBDRLKaPn06VCpVjWnMmDFyl0ZELVSrurYUEdmnMWPGYNOmTVWe0+v1MlVDRC0dW26ISHZ6vR7+/v5VJi8vLwDSIaP3338fY8eOhZOTEzp27IidO3dWef2ZM2dw1113wcnJCW3atMEzzzyDvLy8KvN89NFH6NWrF/R6PQICAvDCCy9U+XlGRgYmTpwIZ2dndOnSBXv37m3aX5qImgzDDRHZvcWLF+P+++/Hb7/9hkcffRQPP/wwzp8/DwDIz89HVFQUvLy88Msvv+Czzz7Dd999VyW8vP/++5g5cyaeeeYZnDlzBnv37kXnzp2rrGP58uV46KGHcPr0adxzzz149NFHkZmZ2ay/JxHZSJNdkpOIyALTpk0TGo1GuLi4VJlee+01IYR0xeFnn322ymsiIiLEc889J4QQ4oMPPhBeXl4iLy/P9POvv/5aqNVq0xW3AwMDxcKFC2utAYBYtGiR6XFeXp4AIL755hub/Z5E1HzY54aIZDdy5Ei8//77VZ7z9vY23R86dGiVnw0dOhSnTp0CAJw/fx5hYWFwcXEx/XzYsGEwGo2Ij4+HSqXC9evXMWrUqDpr6Nu3r+m+i4sL3N3dkZaW1tBfiYhkxHBDRLJzcXGpcZjIVpycnCyaT6vVVnmsUqlgNBqboiQiamLsc0NEdu/nn3+u8bhHjx4AgB49euC3335Dfn6+6ec//fQT1Go1unXrBjc3N4SGhiI6OrpZayYi+bDlhohkV1xcjJSUlCrPOTg4wMfHBwDw2WefYeDAgbj99tvxySef4NixY/jwww8BAI8++iiWLl2KadOmYdmyZUhPT8esWbMwdepU+Pn5AQCWLVuGZ599Fr6+vhg7dixyc3Px008/YdasWc37ixJRs2C4ISLZ7d+/HwEBAVWe69atG37//XcA0plM27dvx/PPP4+AgABs27YNPXv2BAA4Ozvj22+/xYsvvohBgwbB2dkZ999/P9asWWNa1rRp01BUVIR//vOfmDt3Lnx8fPDAAw803y9IRM1KJYQQchdBRFQblUqF3bt3Y8KECXKXQkQtBPvcEBERkaIw3BAREZGisM8NEdk1HjknImux5YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBTl/wEo0ASWESJ8YwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,489,401 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.539 | Train Acc: 73.56%\n",
      "\t test  Loss: 0.437 | test  Acc: 80.69%\n",
      "\t best  test acc: 80.69%\n",
      "Epoch: 02 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.353 | Train Acc: 87.41%\n",
      "\t test  Loss: 0.346 | test  Acc: 85.35%\n",
      "\t best  test acc: 85.35%\n",
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.269 | Train Acc: 91.10%\n",
      "\t test  Loss: 0.379 | test  Acc: 84.51%\n",
      "\t best  test acc: 85.35%\n",
      "Epoch: 04 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.233 | Train Acc: 92.42%\n",
      "\t test  Loss: 0.366 | test  Acc: 83.40%\n",
      "\t best  test acc: 85.35%\n",
      "Epoch: 05 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.186 | Train Acc: 94.36%\n",
      "\t test  Loss: 0.411 | test  Acc: 85.45%\n",
      "\t best  test acc: 85.45%\n",
      "Epoch: 06 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.156 | Train Acc: 95.50%\n",
      "\t test  Loss: 0.386 | test  Acc: 86.01%\n",
      "\t best  test acc: 86.01%\n",
      "Epoch: 07 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.141 | Train Acc: 95.85%\n",
      "\t test  Loss: 0.429 | test  Acc: 85.73%\n",
      "\t best  test acc: 86.01%\n",
      "Epoch: 08 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.124 | Train Acc: 96.27%\n",
      "\t test  Loss: 0.424 | test  Acc: 86.75%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 09 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.103 | Train Acc: 96.70%\n",
      "\t test  Loss: 0.420 | test  Acc: 85.91%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 10 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.104 | Train Acc: 96.65%\n",
      "\t test  Loss: 0.459 | test  Acc: 85.91%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 11 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.112 | Train Acc: 96.08%\n",
      "\t test  Loss: 0.450 | test  Acc: 85.63%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 12 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.087 | Train Acc: 97.18%\n",
      "\t test  Loss: 0.439 | test  Acc: 84.33%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 13 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.079 | Train Acc: 97.39%\n",
      "\t test  Loss: 0.496 | test  Acc: 85.17%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 14 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.071 | Train Acc: 97.76%\n",
      "\t test  Loss: 0.474 | test  Acc: 85.07%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 15 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.060 | Train Acc: 97.96%\n",
      "\t test  Loss: 0.518 | test  Acc: 84.89%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 16 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.055 | Train Acc: 98.20%\n",
      "\t test  Loss: 0.510 | test  Acc: 85.91%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 17 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.049 | Train Acc: 98.13%\n",
      "\t test  Loss: 0.516 | test  Acc: 84.51%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 18 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.046 | Train Acc: 98.41%\n",
      "\t test  Loss: 0.517 | test  Acc: 82.74%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 19 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.039 | Train Acc: 98.59%\n",
      "\t test  Loss: 0.538 | test  Acc: 81.25%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 20 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.046 | Train Acc: 98.32%\n",
      "\t test  Loss: 0.530 | test  Acc: 83.96%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 21 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.046 | Train Acc: 98.27%\n",
      "\t test  Loss: 0.581 | test  Acc: 80.60%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 22 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.044 | Train Acc: 98.31%\n",
      "\t test  Loss: 0.583 | test  Acc: 80.60%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 23 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.036 | Train Acc: 98.54%\n",
      "\t test  Loss: 0.539 | test  Acc: 79.76%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 24 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.038 | Train Acc: 98.47%\n",
      "\t test  Loss: 0.603 | test  Acc: 79.94%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 25 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.035 | Train Acc: 98.47%\n",
      "\t test  Loss: 0.574 | test  Acc: 80.32%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 26 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.033 | Train Acc: 98.73%\n",
      "\t test  Loss: 0.621 | test  Acc: 80.32%\n",
      "\t best  test acc: 86.75%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQu0lEQVR4nO3deXhTVeI+8DdJk3TfKF1oCy2Upex7rQijQ6HAiKIwIKIWVBy0KNhhBGTHBbdB+AqK44ygDpsw4AYiWAEVELSIwI8dWlpoS1ug+56c3x+3DU2btkmbNunt+3me+yS5uTn35HbJm3POvUchhBAgIiIikgmlrStAREREZE0MN0RERCQrDDdEREQkKww3REREJCsMN0RERCQrDDdEREQkKww3REREJCsMN0RERCQrDDdEREQkKww3REREJCs2DTc//vgjxo4di3bt2kGhUOCLL76o9zUHDhxA//79odVqERYWhg0bNjR5PYmIiKjlsGm4KSgoQJ8+fbB27Vqztk9MTMRf/vIX3HfffThx4gRmz56Np59+Gt99910T15SIiIhaCoW9TJypUCiwc+dOjBs3rtZt5s6di127duH06dOGdY888giys7OxZ8+eZqglERER2TsHW1fAEkeOHEFUVJTRuujoaMyePbvW15SUlKCkpMTwWK/X49atW2jTpg0UCkVTVZWIiIisSAiBvLw8tGvXDkpl3R1PLSrcpKenw8/Pz2idn58fcnNzUVRUBCcnpxqvWbFiBZYtW9ZcVSQiIqImlJKSgqCgoDq3aVHhpiHmz5+PuLg4w+OcnBy0b98eKSkpcHd3t2HNiIhsTKcDDh8G0tMBf3/g7rsBlcrycr76Cpg7F0hNvbOuXTvgzTeBBx6wXb3stazWcLys/R4B5ObmIjg4GG5ubvVvLOwEALFz5846txk6dKiYNWuW0bqPP/5YuLu7m72fnJwcAUDk5OQ0oJZERA1QXi7E/v1CbNok3ZaX276s//1PiKAgIYA7S1CQtN7SchQK43IAaZ1C0bDyrFEvey2rNRwva7/HCpZ8freocPPSSy+Jnj17Gq2bPHmyiI6ONns/DDdEMmWPAUIIeX/4lJfXrE/18oKDzT9+1vxQtMey5H689HohcnOFCAiw3nuswpLPb5ueLZWfn49Lly4BAPr164eVK1fivvvug7e3N9q3b4/58+fj+vXr+PTTTwFIp4L37NkTsbGxePLJJ/HDDz/ghRdewK5duxAdHW3WPnNzc+Hh4YGcnBx2SxHJxY4dwKxZwLVrd9YFBQGrVwMPP2zbsiZMkP6tV1V5MsP27eaXaa2ydDogJMT4/VXXti2wbh1QVgYUFUlLcbHxbVERkJgI7N5d/z5nzAD69gXc3KTF3f3O/crHGg0QGlp7vRQK6eeQmFh/N0l977GpytLrgYICID+/5m1+PpCQALz1Vt37A4DHHwfCwqS6OTgY31beVyikbp/bt2svp00b4IMPzHuPzz4L3LxZ+zZubsDkydL7ycuT3k9envH9/HypLHPs3w/ce69521aw5PPbpuHmwIEDuO+++2qsj4mJwYYNGzB16lQkJSXhwIEDRq958cUXcebMGQQFBWHRokWYOnWq2ftkuCFqJJ0O+OknIC0NCAgAhg5tXP9+Y8uypwBRXn7nAy0nB7jvPiAjo/bt27YFNm+WPtirf4hVvQWAYcOk41SbNm2A116T9p+bW/uSmSkt9kahqHncTRk8WDpuSqV0fKreVt7PyAD27q2/rJEjAT8/KZRUXYS4cz8jQxqDUh8HB+nnT+bZtEkKSxZoMeHGFhhuiBrB3lpILP2GXl4utTgUFhovRUXSN8+YmLq/vTo5SYGlsND0t/PSUrPfvt0LC5OOnZOTtDg61ryflgb8+9/1lzViBODiIoWrym/7lffz880LNWbQOTujzMfnThi1FQcHwNlZWpyc7twvLQX++KP+10dFAT4+0u+3qUWvlwbqnjlTf1mhoYC3d93b3Lol/Y3UZ+RIoF8/6b24uBgvlevOngX+9rf6y/r0UymoVqPRaGo9zZvhpg4MN9Sk7K1Vw5ps3UJSUiIFj1u37twePgy88079+3NxkT5YysrMq19jOThIrTGFhfVvGxgo1U+nk8KXqdviYvOCU//+QPfuUjdP9aWy++fiRambqD7mdBtUhsvr100HFHO6fyq7cr77DvjrX+uv19y5QJcu0usqPuiFXo/0gABk+/tLrTeVLWj1cXUF1Oqada6qvFwKYvXx8ZGCjEJRe7gSQjpWdXXdqFTS70R9Aa24GLhxo/56+flJYbS5ymrke1QqlQgNDYVGo6nxHMNNHRhuqMnYW6uGNTVmDINeL7WMFBRIH/Z5edI307q6a5ycgLvukgJMZZgxJyhYovLbdOW36+Ji4OrV+l83fTowfLgUSFxd79xWva/RAAcOSK089TEnRFizLGsEkqoqgypgXF5DxwI1oF5paWnIzs6Gr68vnJ2doQCACxfqDrNqtRSS6gsRQlivLEDqrkxJqf354GDAw6P+cqxZLzt5j3q9HqmpqVCr1Wjfvn2NC+0y3NSB4YZqkNu4D1Ma+x7N/XDt3FkqtzLIVHb5WItSKTWxe3tLY0yEAH75pf7XffKJVP/KMOPoWPOftDUDBGDdEGGvgaRqedXDeHAwsGqV5eVYWC+dTocLFy7A19cXbdq0ufPE7dvA5cu176tTJ8DLy7x6WbOsyvJSUoxb4zQa6ZhZWo7M3mNOTg5SU1MRFhYGdbVWNYabOjDcyIS1umxsMe6jucqq1ND3WFYGnD4NHDsmDXo9eNC8/dXFyUnqssnLq3/b2Fhg7Ng7QcbbW+pWqdofb88BArBuiLDXQFKpKf8m66hXcXExEhMTERISUvMq9dYKEdYuC5B+hpXjtDQaqcWvIWOFZPYei4qKkJSUhNDQUDhW6wJjuKkDw40MWKvLxtIWEr0eyM6WzjTJyLhz1snRo8D69fXvr3NnwNPT+AyP6svt2+a1RHz1FXD//fX/MzT3PQoBXLoE/PqrFGaOHQN+/13qqrHEG29I3UlVBxhW7fpRKq3fQmLPAaKyTGuFCHsNJNZmQb0qw42pD0MA1gsR1i7LmmT0Huv6eTLc1IHhxobsqfvHnGt9ODtLH9SVISYry75O9XR2lkJdYKB0W/1+QAAQEVH3e3R3l7b57TfT18vw9AQGDQIGDgT+9S9p/Iu9tpDYa4AA5D3Q3MbqDTfUojDcNBDDjY00V/dPQACwa5f0IVwZSqqGk8r7169LrTAN4eEhXWfD11e6LS+X9lmfN94AevS4cyqnqVM8/9//M+/sn6ag1UqneQ4efGfp1OlON5C9t5AwQLRKDDeSkJAQzJ49G7Nnz250WZXXoLt9+zY8PT0bXZ4lrBVuZD9xJtmB2lpbrl+X1lf9IBNCGoB6+/adJTtbuj12rO5WCCGkaz/062e9uj/3HPDgg3eCjI+PFAKqMrclYs4c81o1tmypv6wzZ6RTN69du7Ncv278uK4LvlX15JPS+JaePaVm6No8/LD0szIVUi1t1bBmWZVUKouveNosZVHL0cyh9t5770Xfvn2xatWqRpf166+/wsXFpfGVkgmGG2paOp30AWbqg7py3eTJUjjIzpaWxl4Izc1N6kbw8ZECiaklMVE6pbc+f/1r/R9yKpXUAjVhQs2rrFa2RKxaZd4/SXPLqjz1uFOn2sv6/nvp4mn1efxx6foo5nj4YSnsWeMDwJplETWWvV1+AYAQAjqdDg4O9X9Ut23bthlq1IJYPHNVC8eJMy3U0AkEU1KE2LZNiIkTa59Ara5FpRLCx0eIsDAhBg0SYuRIIe6917zX7t9v3vsKCjI9UVxDJ3czNalhcLD1Jki0tKymeI9EdqaoqEicOXNGFBUVNbyQJprFui4xMTECgNGyfv16AUDs3r1b9O/fX6jVarF//35x6dIl8cADDwhfX1/h4uIiBg4cKPbt22dUXocOHcS7775reAxAfPTRR2LcuHHCyclJhIWFiS+//NKsuu3fv18AELdv3zas2759u+jevbvQaDSiQ4cO4p133jF6zdq1a0VYWJjQarXC19dXjB8/3vDctm3bRM+ePYWjo6Pw9vYWw4cPF/n5+Sb3XdfPs0XOCt5cGG4sYO4MxIWFQvz0kxBvvy3E+PFCBAZaHmYWLRLijz+EuHpVmlVWr69ZH2t/WFf+Q6teXmP+odnbzNRN8R6J7IjJD0O9Xoj8fPOWnJy6/2cpFNL/nZwc88oz9b/LhOzsbBEZGSmmT58u0tLSRFpamvj+++8FANG7d2+xd+9ecenSJXHz5k1x4sQJsW7dOnHq1Clx4cIFsXDhQuHo6CiuXr1qKM9UuAkKChKbNm0SFy9eFC+88IJwdXUVN2/erLdu1cPNb7/9JpRKpVi+fLk4f/68WL9+vXBychLr168XQgjx66+/CpVKJTZt2iSSkpLE8ePHxerVq4UQQqSmpgoHBwexcuVKkZiYKE6ePCnWrl0r8vLyzP95VmC4qQPDjZnq+ybzwgtCxMYKMWCAEA4Oplte+vUT4oEHrNfaUrVe1vqwtmZri71qDe+RWi2TH4b5+Q1rMbbGUkuLhCl/+tOfxKxZswyPK0PFF198Ue9re/ToId577z3DY1PhZuHChVUOSb4AIL799tt6y64ebh599FExYsQIo23+8Y9/iO7duwshhPjf//4n3N3dRW5ubo2yEhISBACRlJRU736FsF644ZgbqsmccTL/93/G6/39gchI6dTpu+4CBgy4M1+OOYNthw41r27WHojaGsZ9tIb3SCQjAwcONHqcn5+PpUuXYteuXUhLS0N5eTmKioqQnJxcZzm9e/c23HdxcYG7uzsy6pr2pBZnz57Fgw8+aLRuyJAhWLVqFXQ6HUaMGIEOHTqgY8eOGDVqFEaNGoWHHnoIzs7O6NOnD4YPH45evXohOjoaI0eOxIQJE+DVkIsCWoDhhmr66ae6z0qqNGGCNOD2rrukAbymLvRkzcG2laz9Yd0azoxpDe+RqJKzs3kTZwLAjz8CY8bUv93u3cCwYebtu5Gqn/U0Z84c7Nu3D++88w7CwsLg5OSECRMmoLSeky+qT1+gUCig1+sbXb/q3NzccPz4cRw4cAB79+7F4sWLsXTpUvz666/w9PTEvn37cPjwYezduxfvvfceFixYgKNHjyI0NNTqdalkel5xap1u3wbWrTPvLCJAChkTJwLt29d9BcvK1pbAQOP1QUENu54JcOfDevJk6ZatEERUSaGQWo7NWUaOlP4X1fY/TKGQvryNHGleeRZczVej0UBX1+zZFQ4dOoSpU6fioYceQq9eveDv74+kpCSz99NY4eHhOHToUI06denSBaqK/70ODg6IiorCW2+9hZMnTyIpKQk//PADAClUDRkyBMuWLcPvv/8OjUaDnTt3Nmmd2XLT2pWXA3v3ShMLfvklUFJi/msDAszfll0jRGSPmqJ12UwhISE4evQokpKS4OrqWmurSufOnbFjxw6MHTsWCoUCixYtapIWmNr8/e9/x6BBg/DKK69g0qRJOHLkCNasWYP3338fAPDNN9/gypUrGDZsGLy8vLB7927o9Xp07doVR48eRXx8PEaOHAlfX18cPXoUmZmZCA8Pb9I6s+VGjnQ6af6ezZulW1PfDE6fBv7xD+kbyV/+Anz+uRRsevUC3n5bCh/1fZMxd5xMJba2EJE9aorWZTPMmTMHKpUK3bt3R9u2bWsdQ7Ny5Up4eXnh7rvvxtixYxEdHY3+5l6bygr69++Pzz//HFu2bEHPnj2xePFiLF++HFOnTgUAeHp6YseOHfjzn/+M8PBwrFu3Dps3b0aPHj3g7u6OH3/8EWPGjEGXLl2wcOFC/POf/8To0aObtM6cfkFu6roQ1bBhUuD55BMgIeHO8z4+wJQpQEwM0LevFF6a4vL4RERWZtXpFzjths1x+gWqqbZpDq5dA8aPl/5IK1txHBykWaWnTgVGj6552f2muDw+EZE948B72WC4kYu6Tt+uuk2/fsC0aVLXkI9P3WVynAwRkezMmDED//3vf00+99hjj2HdunXNXCPrY7iRAyGA//7XvNO3V6607JsJv8kQEcnK8uXLMWfOHJPPyWW4BsONvbCkr1cI4OJFYP9+aTlwQJoh2hzmzhRNRESy5OvrC19fX1tXo0kx3NiD+majFQK4csU4zKSmGpehVgNlZfXvy5LTt4mIiFoghhtbq20Q8PXr0iDgP/1JCjYpKcbPazTSdAf33Sd1Gw0cCHTrZr1pDoiIiFoohhtbMmcOp4MHpVu1GoiIuBNmIiMBJyfj19joQlRERET2hOHGlsydw+ntt4Fnn5Uu7V0Xnr5NRETEcGNT1cfN1CYwsP5gU4mnbxMRUSvHcGMrWVlAxbwc9bJ0EDBP3yYionokJSUhNDQUv//+O/r27Wvr6lgV55ayhb17gd69gWqzrNbQ0DmciIjI7t17772YPXu21cqbOnUqxo0bZ7XyWjKGm+ZUXAy8+CIQHS11GXXrJo2nUShqTlLJQcBERM3ut9xc/PnECfyWm2vrqlAjMNw0l9OngcGDpbACAM89J01eOWeOTWajJSKimj69cQP7s7PxmbkXRm2gqVOn4uDBg1i9ejUUCgUUCgWSkpJw+vRpjB49Gq6urvDz88Pjjz+OrKwsw+u2b9+OXr16wcnJCW3atEFUVBQKCgqwdOlSfPLJJ/jyyy8N5R04cMDieh08eBCDBw+GVqtFQEAA5s2bh/Ly8nr3DwAHDhzA4MGD4eLiAk9PTwwZMgRXr15t9LFqCI65aWpCAO+9B7z0ElBSArRtC3z8sTRpZSUOAiYishohBAr1erO3Ty4uxs2yMigUCmzJyAAAbM7IwERfXwgh0EatRnszZxx3ViqhqN4Sb8Lq1atx4cIF9OzZE8uXLwcAqNVqDB48GE8//TTeffddFBUVYe7cuZg4cSJ++OEHpKWlYfLkyXjrrbfw0EMPIS8vDz/99BOEEJgzZw7Onj2L3NxcrF+/HgDg7e1t9jEAgOvXr2PMmDGYOnUqPv30U5w7dw7Tp0+Ho6Mjli5dWuf+y8vLMW7cOEyfPh2bN29GaWkpjh07ZtaxaAoMN00pPV2apHLPHunx6NHA+vWAn1/NbTkImIjIKgr1erj+9FOjysgsK8M9v/9u8evyhw6FixlfTD08PKDRaODs7Ax/f38AwKuvvop+/frh9ddfN2z38ccfIzg4GBcuXEB+fj7Ky8vx8MMPo0OHDgCAXr16GbZ1cnJCSUmJoTxLvf/++wgODsaaNWugUCjQrVs3pKamYu7cuVi8eDHS0tJq3f+tW7eQk5OD+++/H506dQIAhIeHN6ge1sBuqaby1VdAr15SsHF0lFpvdu0yHWyIiKjV++OPP7B//364uroalm7dugEALl++jD59+mD48OHo1asX/vrXv+Kjjz7C7du3rbb/s2fPIjIy0qi1ZciQIcjPz8e1a9fq3L+3tzemTp2K6OhojB07FqtXr0aaDecyZMtNY5ia7LK4GPj734EPP5S26d0b2LQJ6NHDtnUlImolnJVK5Ft4lumJ/HyTLTU/9+uHvq6uFu27ofLz8zF27Fi8+eabNZ4LCAiASqXCvn37cPjwYezduxfvvfceFixYgKNHjyI0NLTB+zVXfftfv349XnjhBezZswdbt27FwoULsW/fPtx1111NXrfq2HLTUDt2ACEh0nQIjz4q3bZrB3TpcifY/P3vwLFjDDZERM1IoVDARaWyaHGqCCWVH4qVt05KpUXlWDLGRKPRQKfTGR73798f/+///T+EhIQgLCzMaHGpuJCrQqHAkCFDsGzZMvz+++/QaDTYuXOnyfIsFR4ejiNHjkBUmb7n0KFDcHNzQ1BQUL37B4B+/fph/vz5OHz4MHr27IlNmzY1uD6NwXDTEJWTXVafOiEjQ7rqsJcXsG8f8M47gFZrmzoSEZHZfNVq+KvVGODmhnVdumCAmxv81Wr4qtVNts+QkBAcPXoUSUlJyMrKQmxsLG7duoXJkyfj119/xeXLl/Hdd99h2rRp0Ol0OHr0KF5//XX89ttvSE5Oxo4dO5CZmWkY2xISEoKTJ0/i/PnzyMrKQllZmUX1ee6555CSkoLnn38e586dw5dffoklS5YgLi4OSqWyzv0nJiZi/vz5OHLkCK5evYq9e/fi4sWLtht3I1qZnJwcAUDk5OQ0rIDyciGCgoSQzoMyvQQGStsREVGTKioqEmfOnBFFRUWNLqtYpxN6vV4IIYRerxfFOl2jy6zL+fPnxV133SWcnJwEAJGYmCguXLggHnroIeHp6SmcnJxEt27dxOzZs4VerxdnzpwR0dHRom3btkKr1YouXbqI9957z1BeRkaGGDFihHB1dRUAxP79++vcf2JiogAgfv/9d8O6AwcOiEGDBgmNRiP8/f3F3LlzRVlZmRBC1Ln/9PR0MW7cOBEQECA0Go3o0KGDWLx4sdBZeAzr+nla8vmtEMLUlNTylZubCw8PD+Tk5MDd3d3yAg4ckLqg6rN/P89+akF+y83FS1eu4K2OHTGwIb8XRGQTxcXFSExMRGhoKBzNPF2b7FddP09LPr/ZLWUpc0d/23CUOFmuuS7cRURETY/hxlLmTmJp6WSXrYQ9Xdr8anExjubkYMuNG9iQng4A+OzGDfyYnY2EvDxcLS62cQ2JiBru9ddfNzqtvOoyevRoW1evSfFUcEsNHSpNjVB9MHElhUJ6npNdmlS1haSx3T+WdiWV6PU4XVCA43l5OJ6fj3WpqTW2uV1ejj+dOGF4/HxgIMKdnRHu7IzuLi5oq1bXezaENbu42F0mH/xZUnObMWMGJk6caPI5JyenZq5N82K4sZRKJc0PNWFCzedkOtllY/8pXy0uRlZZGRQAtlZc2nxLRgZi/P0hAPio1ejQgL7yuoJSkU6HUwUFSKgIMgl5eThdUIAyC4eYvXf9utFjbwcHKey4uKB7RegJd3FBsFYLZcXP35oBzpZhkKzLmj9LInN4e3tbPAWDXDDcNETHjoa7v3Xpgpf+9je89eGHGFhUJAUbmU122ZB/yvnl5bheWoprJSWI+uOPGs9nlJVhQEKC4fHazp3hrlLB3cEBbhW3VR87VczXYioobc7IQF9XV5wpKEBSSQnOFxbiTEEBTF3twdvBAQPc3NDf1RX93dygVSox7vTpGttt6NoVOgBnCwtxtqAAZwsLkVhcjFvl5TiUm4tD1brVHBUKhDg6ItTJCT9mZwMA1qenw8tB+hNzVangY+YppVllZcivuFZFZXfZJ+np6OHsDBeVCkFaLbq5uMBdpYKjmfPYAPb74Srn0HW1uBipJSW4UlyMTyp+ltYI9kRUN4abhqiYlAwTJuDT2FjsB/DZhx9ioIwmu6ytteUJPz9kl5ejRK+HUChwraQE10tKatzmWHghqdiLF+t8XgXA3cEBt6vMTlsps6wMT54/X2O9b8U1KyqDzAA3N7TXao3CwPG8PADS4DN9ldteFa+pqkinw/nCQinwVASos4WFuFhUhGIhcK6oCOeKigzb5+l0WGalGXFzdDr8zcQxclAojENhlWDo5uAACAGlQgFXlcoQlDbZ2YervbZONaSsIp0OJ6t0ff7bxIkF1YO94FmVVqG3YKJMsl/WOoGb4cZSJSW4uncvsrp0ge6pp/BfBwegvByb1WrEFBbazQdGY4X88kuNdRllZRh4/LjZZbhVtDIEarVwUirx9c2bNbZ5pG1bOKpUyCsvR65Oh9yK27yK+3k6HQQAHWAy2FSlADCuTRtMDQjAADc3tNNo6m3VqLxwV7CjI54KCMB/0tKQUlxs8sJdTioV+rq5oW+10FOm12P1tWuYd+WKydYiBYBeLi4INPOCjtdLSnCqoAC1/Yk7KhQorvgHUC4EbpWX41Y9x6aqrGofrtn33AMPh+b9V2CLrkprl1Wg0+GPii7Pyq7P2loM69L/t98Q5eWFEV5euMfDA04y+YLUXDQaDZRKJVJTU9G2bVtozPi7J/skhEBmZiYUCgXUjbx4Iq9zY6n//Q+KNm3q3ew/XbtKYzJcXMz+4LCX5vn0khLMunQJn2dm1rqNu0qFMCcnBGq1hgATqNHcua/Vwr3K+z6el4cBCQk1WkgSBgyo0UJSlV4IFFQJO7k6HRJyc/HcpUs1tq2vrNqU6PXQKBRQKBQQQqBUCGgbMD9M5Xu0Rr3qK0svBPKrBECjYFglKP6Sm4vdt27VGpQA6WfRz9UV93p64l5PTwz19Kz3d7axv6uKAwfq3ebFoCCoFQo4KBRQKxRQK5WG+4Z1CgWyy8tRrNfDQaHAG8nJyNHp4KlS4Z9hYdAqFPDXaBDm7AwnpdKwONTy860aukafPImMsjL4qtXY1qMHzhcWIrm4GEklJUjIy8P5wkKYaitoW63FUKtQYKyJrs8wR0dcqnZGnlahwFBPT0PY6evqahjLVZW9/K+wF6WlpUhLS0NhYaGtq0KNpFAoEBQUBFcT83lZ8vnNlhtLbdiANSoVZs6adWcAsQlPVekmCdBoDGfbVD3zxrfamTe2HBOhEwLf3bqFj9LS8HVWVp3fPo/064e7PDwsKt+SFpKqlAoF3Bwc4ObggHYVLR8OFceselBqqKpBRqFQQNvIb33WqlddZSkVCqn7yYzgXFtQesjHB6cLCnCxqAgJ+flIyM/HP69dgxJAfzc3Q9i5x8OjRtgx93c1q7QUZyq78iq68c6Y+QH0bm1nJJohW6cz+husTq1Q3Ak7FWO6nJRKHM/Pr7FtRlmZ0Rl0VQVoNMZdn66uCDSz63Nrjx5op9EgPjsb+27dwr7bt5FaWorvb9/G97dvYx6kFqzhnp4Y4e2NKC8vQ2uWvY6fshWNRoP27dujvLy8UXMrke2p1WqorNB6yXBjifR0XDh5Eu+88UatwWZecDAK9HrDmIzU0lKkVSw/VAw0reTl4IBQR0cEa7UIdXLCpzYYcJhcXIyP09LwcXo6UkpKDOvvdnfHCC8vLLt6tcY/ZU0DWjWCHB2RFBlpaCF5JiCgwS0kDQ1KTc2a9WqK91j957iwQwf0d3PD9ZISHMzOxoGK5WJREX7Ly8NveXl4JyUFSgAD3NzQz9UV3V1c0M/VtcY4rPTSUkP3WOVYpLOFhciqY24bbwcHk91pzwQEoK1ajXIhUCaE4dZwX683Wne1uLjObjxnpRJ6AMVVxmSUCYGyihYvWDD/zgBXVzzo44P+FYEmwIyuxrp+lv5aLab4+WGKnx+EEDhXWIh9t29j3+3bOJCdjayyMmzNzMTWilbUYK0Wd7m5Ye/t2wDkPTjZ0tapyq6MxnZnkDywW8oCv3zwAe5v1w43PTwQpNXiWklJvd0sOeXlOFfxrbXqN9grxcV1dhVUVTh0qFX74cv0enx98yb+nZaGPVW6LLwdHPCEvz+eDghADxcXXCsuxqCEhBr/lH8dMABBNv4naq2uJHuul7XKsvTneK24GAdzcgxh51KVQdINEeLoaNRiWXk/sbi4QV2VppjTJagXAsV6PYr0ehTpdNKtXo/CKveL9HqcLSjAoqSkOsuyVEN+lmV6PY7m5mJfRUvOYTMufCmnwckvXLyI965fxwuBgVjdubOtq0N2wJLPb4YbM32TlYWJx4+jSKPBoKIi/OueezD65MkGf/AX6XS4UFSEj1JT8UFqap3dFw4KBXq7uCDC3V1a3NzQxdnZZF98JVPfei4VFuLfaWnYkJ6OG1W+rd7n6YnpAQF4yMcHjtVClL2GCLJMY36OlWHn32lpOFCt9bGqAI0Gke7uhmv/hDs7o2vF6eu1lWut8NzQMV1NXZY1fZSaimcvXKi1y/hud3fMa98eI729W+zfaNUxTyP/+AM3y8vhq1bj2969Zdk6RZZhuKlDQ8LNv1NT8bcLF6AHMPrXX/H5k0/CtU2bJh+IOszDA+cLC42CSCVPBwcMcnMzhJ0Id3e01WgMz1d+63muXTsM8fDAv9PSsL/KB5OfWo1pAQF4yt8fYc7OFteZWqfafleP9uuHwRaOwwJs1zrVXGVZW23HvyoPlQoPtW2LSW3bYriXF9QtKOiYM9BcTq1TZBkOKLYSIQReuXoVSyqaqKd++y3+de0a1BVnSzX1QNR3w8LQz9UVySUlOJqba1gS8vORXV5u6JuvFKTVoruzM3q6uOCzivE7H6Sm4v0q0wyM9vbG9IAA3N+mTYv6p0f2pfrvam1nH9XHWn9D1hzTZc2ymkr147++a1ecyM/HtsxMpJaWYkN6Ojakp6ONgwMebtsWk3x9ca+nJ1R2fObV5aIiDHF3r3GBzEoOCgU2dOvWzLWilorhphblej1iL17EvyouwrVg2za88v77UHz3ndX3VdeAQ4VCgQ6Ojujg6IiJvr4ApL74UwUFdwJPXh7OFRbiWsVF9PZWCTzVm+V29+5t9fpT62Gvg7kB637ZsPYXF2up7fhHeXlhakAAVoaF4eecHGzNyMD2zExklJXho7Q0fJSWBj+1GhMqgs4QD48mmS6kIa4VF+OVq1fxcXo6yuvoSHBSKlEuBIQQvI4N1YvdUiYU6nSYfOYMvrp5EwoAa/Ly8NwDD0gTYiYlNclViBvbPJ9dVoY3k5PxVkqKyfE7ld96pvj5Wa/S1CpxHJZtmXv8y/V6HKwIOv/LzDQ6M81PrcafvbwQ7eWFl65cMVzPpznHtmSUlmJFcjI+uH4dJRUfQ6O8vTHF1xePnztnaJVSwPhL2kgvL3zYpQtCZD7xI9XEMTd1qO/g3Cwrw9hTp3AkNxdahQKbunfHwzExwLffAi+/DLz2mg1qbT5rXkiOiOShTK9H/O3b2JKRgS+yssyaHqWpxrbcLivDOykpWH3tGgoqTs8f5uGBV0NDMdTT0+SYp+TiYjwZEIB3r11DsV4PZ6USr4WG4vmgIJNdbSRPDDd1qOvgXC0uxqiTJ3GusBCeDg74qmdPDC0sBIKDAb0euHABsPNTEu31TA8isg8lej3mX7mCVdeumbwchQLA435+WBwSgk5WbB3JLy/H6uvX8U5KCrIrWpEGurnhtdBQjPDyMupqqq116mJhIaafP4+DOTkAgAg3N/y7a1f0NHE1W5IfS8IN25Ir/JGfj8jjx3GusBBBWi1+7tcPQz09gc8+k4LNkCF2H2yAO33yA9zcsK5LFwxwc4O/Wm0XYyKIyPa0SiVWhoXhtwEDTD4vII3DCTt6FF2PHsXsixfx3a1bKG7glX+LdTq8m5KCjkePYmFiIrLLy9HTxQU7e/TAsf79MdLbu8YYGm2V2e4VCoWh262zszN+6NsXH3bpAneVCkfz8tA/IQFLEhNRwokzqQq23ADYf/s2xp0+jVydDj1dXPBtr17SKZ9CAN27A+fOAR99BDz9tI1rbx6OiSCi+tTWyvtCYCBOFhTg55wcowG+Tkol/uzpidFt2mC0tzc6mmjVqXrmVR9XV3ycno5XkpJwvbQUABDm5IRlISGY5Ovb6O6k6yUliL1wAV9WTMgb7uyMf3ftirsbcEkCahnYLVWH6gdna0YGnjh7FqVCYJiHB77s2ROela0cv/wCREYCTk5AejrAOVyISCbqu55Pbnk5vr99G9/euoXdN28itSKgVOrq5GQIOsM8POCoUhmurzXSywuXiopwpWJi0GCtFktCQvCEn59VL0EhhMD2zEzMvHgRGRUX/4sNDMTroaFwa+aZ7qnpMdzUofLg7E9JwQkh8OLlywCACW3b4rNu3Yyv0DtjBvDhh8Bjj0ndU0REMmJuK68QAqcKCgxB51BOjtGVkh0VCgxyd8fxvDzDIGFAmtLlhcBAzOvQoUlbj2+VleHvly9jQ8X1vdprtVjXpQtGV1yTzJrX8rGX6wK1RhxzY4bZly4Zgs3zgYHY0r27cbApKgK2bJHuT5tmgxoSETWt2sa2VKdQKNDb1RVz27fHwX79cPOee7C9Rw885e8PACgWAj/l5BgFGwC4VV6OpVevNnm3uLdajfXdumFv794IcXREckkJxpw6hcfOnEFWaanRtXway5pl2avfcnPx5xMn8JsZ85k1Z1mWsHm4Wbt2LUJCQuDo6IiIiAgcO3aszu1XrVqFrl27wsnJCcHBwXjxxRdRXNH0aYk/CgoAADMDAxFn6nTCL74AcnKA9u0BXu6biMjAw8EB49u2xb+7dcNn3bqhtit/OSgU+G94eLPVa4S3N04PGoQXg4KgALAxIwOdjx3DJxUtOlsyMnA8Lw8JeXm4asHnxtXiYiTk5eF4Xh62ZmQ0qqyWQA5h0KbdUlu3bsUTTzyBdevWISIiAqtWrcK2bdtw/vx5+FZcjbeqTZs24cknn8THH3+Mu+++GxcuXMDUqVPxyCOPYOXKlWbts7JZC998A7i4GNbXuKZDdDSwdy+waBGwfHlj3iYRkazZ4/W1zJmnysfMs0izTMzvV13+0KG1ThJbG3vqLqs6aenokycbdWFHa5ZVVYuZW2rlypWYPn06plV0+6xbtw67du3Cxx9/jHnz5tXY/vDhwxgyZAgeffRRAEBISAgmT56Mo0ePNrgOJucruXYN2LdPuh8T0+CyiYhak+pnXtnSf8PDMfXcuTqndDAntJjL9aef0EGrRbiLC7o7OyPc2RnhLi4Id3aGdy0hyppTX9RVll4I5JaX41Z5OW6WleFWeTlulZUZ3V99/XqNMjPKyoxCa2CVyZnrcr3a4HNTZTX1BKg2CzelpaVISEjA/PnzDeuUSiWioqJw5MgRk6+5++678d///hfHjh3D4MGDceXKFezevRuPP/54rfspKSlBSUmJ4XFutX6/o/371/xm8emn0mngw4YBnTo14N0REbUe9jjn2BQ/P4Q7O5tsUfq8e3d0r9Jyb44zBQWYeOZMjfX9XF2RUlKCrLIyXC0pwdWSEuy5dctoGz+12hB0/NRq+Go06OjoaNTFFePvDwHAy8EBvmo1ivT6O4tOZ/S4sOLxtZIS3CwrQ4lej/UVXW//Sk3F8bw8ZOt0KCgvR55ej1tlZVYJm6ZCi6WaawJUm4WbrKws6HQ6+FWb68jPzw/nzp0z+ZpHH30UWVlZuOeeeyCEQHl5OWbMmIGXX3651v2sWLECy5Ytq7G++nwlBkIAGzZI96dONeu9EBG1ZvY+k3r1FqVOTk7oYWG4qbxIYPWy/t21K/q7uSGrtBRnCwtxprAQZwsKcLawEGcLC5FSUoIbZWW4kZ2NA9nZJsuu3qrRGMVC4OdaBu+6KJXwVqvh7eCANmq18X0HB+TpdFh+9WqN120MD0e4s7NF9ThbWIgpZ8/WWG+yQaEJtKgLARw4cACvv/463n//fURERODSpUuYNWsWXnnlFSxatMjka+bPn4+4uDjD49zcXAQHB6OfqytSKxKykcOHgYsXpfE4f/1rU74dIiLZsMeZ1K3ZolRfWT4aDYZqNNKV7avIKy/HuYqgc7awEHtv3cLx/Hyz9qlVKOCkUsFJqbyzqFRwrrifVVaG4/n5Jr+oqwDMb98ej/j5wdvBAd5qdb1h83heHpZfvVojwHVzdkY/CwNJZZ1s1VVps3Dj4+MDlUqFG9VGUN+4cQP+FacXVrdo0SI8/vjjeLriSsG9evVCQUEBnnnmGSxYsABKEz84rVYLrVZbY/0PffvC0c2t5g+7stVmwgSA85UQEbVY1mxRamhZbg4OGOTujkEV42BWdOxY6wDsXb16YbCbG5xUKjgqlWZdxbm2so41YDB3c4bBpmazcKPRaDBgwADEx8dj3LhxAAC9Xo/4+HjMnDnT5GsKCwtrBBhVxeh0S0/6MnlNh8JCYOtW6T6vbUNE1OJZs0XJ2q1T1Vs1/DUa+Jg5aLe+shrCHsKgtdi0WyouLg4xMTEYOHAgBg8ejFWrVqGgoMBw9tQTTzyBwMBArFixAgAwduxYrFy5Ev369TN0Sy1atAhjx441hJxG2bEDyMsDQkOBoUMbXx4REVE19txCYs9h0BI2DTeTJk1CZmYmFi9ejPT0dPTt2xd79uwxDDJOTk42aqlZuHAhFAoFFi5ciOvXr6Nt27YYO3YsXnvtNetUqLJLKiYGsJOBcEREJC9yaiGxV612bqkaFwG6elVqsRECSEwEQkJsVkciIiIyxrmlGqLy2jb33cdgQ0RE1IIx3AC8tg0REZGMMNwAwE8/AVeuSKd+jx9v69oQERFRIzDcAHdabSZONJpMk4iIiFoehpv8fODzz6X7vLYNERFRi8dw87//AQUF0gSZQ4bYujZERETUSAw3VQcS28FcKERERNQ4rTvcXLkCHDgghZonnrB1bYiIiMgKWne4+fRT6Xb4cKB9e9vWhYiIiKyi9YYbvR745BPpPgcSExERyUbrDTc//wwkJQHu7kDFrORERETU8rXecLNxo3Q7aRLg7GzbuhAREZHVtN5ws2OHdMsuKSIiIllpveGmtBRwcABSU21dEyIiIrKi1htuAKC8HPjrX++04hAREVGL17rDTaXZswGdzta1ICIiIitguBECSEmRZgYnIiKiFo/hplJamq1rQERERFbAcFMpIMDWNSAiIiIrcLB1BWxOoQCCgoChQ21dEyIiIrKC1t1yUzkL+KpVgEpl06oQERGRdbTucBMUBGzfDjz8sK1rQkRERFbSerulvvkGGDWKLTZEREQy03pbboYOZbAhIiKSodYbboiIiEiWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVmwebtauXYuQkBA4OjoiIiICx44dq3P77OxsxMbGIiAgAFqtFl26dMHu3bubqbZERERk7xxsufOtW7ciLi4O69atQ0REBFatWoXo6GicP38evr6+NbYvLS3FiBEj4Ovri+3btyMwMBBXr16Fp6dn81eeiIiI7JJCCCFstfOIiAgMGjQIa9asAQDo9XoEBwfj+eefx7x582psv27dOrz99ts4d+4c1Gp1g/aZm5sLDw8P5OTkwN3dvVH1JyIiouZhyee3zbqlSktLkZCQgKioqDuVUSoRFRWFI0eOmHzNV199hcjISMTGxsLPzw89e/bE66+/Dp1OV+t+SkpKkJuba7QQERGRfNks3GRlZUGn08HPz89ovZ+fH9LT002+5sqVK9i+fTt0Oh12796NRYsW4Z///CdeffXVWvezYsUKeHh4GJbg4GCrvg8iIiKyLzYfUGwJvV4PX19f/Otf/8KAAQMwadIkLFiwAOvWrav1NfPnz0dOTo5hSUlJacYaExERUXOz2YBiHx8fqFQq3Lhxw2j9jRs34O/vb/I1AQEBUKvVUKlUhnXh4eFIT09HaWkpNBpNjddotVpotVrrVp6IiIjsVoNabo4fP45Tp04ZHn/55ZcYN24cXn75ZZSWlppVhkajwYABAxAfH29Yp9frER8fj8jISJOvGTJkCC5dugS9Xm9Yd+HCBQQEBJgMNkRERNT6NCjc/O1vf8OFCxcASONgHnnkETg7O2Pbtm146aWXzC4nLi4OH330ET755BOcPXsWzz77LAoKCjBt2jQAwBNPPIH58+cbtn/22Wdx69YtzJo1CxcuXMCuXbvw+uuvIzY2tiFvg4iIiGSoQd1SFy5cQN++fQEA27Ztw7Bhw7Bp0yYcOnQIjzzyCFatWmVWOZMmTUJmZiYWL16M9PR09O3bF3v27DEMMk5OToZSeSd/BQcH47vvvsOLL76I3r17IzAwELNmzcLcuXMb8jaIiIhIhhp0nRt3d3ckJCSgc+fOGDFiBO6//37MmjULycnJ6Nq1K4qKipqirlbB69wQERG1PE1+nZuBAwfi1VdfxWeffYaDBw/iL3/5CwAgMTGxxqndRERERM2pQeFm1apVOH78OGbOnIkFCxYgLCwMALB9+3bcfffdVq0gERERkSWsOv1CcXExVCpVg6dGaA7sliIiImp5mrxbKiUlBdeuXTM8PnbsGGbPno1PP/3UroMNERERyV+Dws2jjz6K/fv3AwDS09MxYsQIHDt2DAsWLMDy5cutWkEiIiIiSzQo3Jw+fRqDBw8GAHz++efo2bMnDh8+jI0bN2LDhg3WrB8RERGRRRoUbsrKygxTGnz//fd44IEHAADdunVDWlqa9WpHREREZKEGhZsePXpg3bp1+Omnn7Bv3z6MGjUKAJCamoo2bdpYtYJERERElmhQuHnzzTfx4Ycf4t5778XkyZPRp08fAMBXX31l6K4iIiIisoUGnwqu0+mQm5sLLy8vw7qkpCQ4OzvD19fXahW0Np4KTkRE1PJY8vndoLmlAEClUqG8vBw///wzAKBr164ICQlpaHFEREREVtGgbqmCggI8+eSTCAgIwLBhwzBs2DC0a9cOTz31FAoLC61dRyIiIiKzNSjcxMXF4eDBg/j666+RnZ2N7OxsfPnllzh48CD+/ve/W7uORERERGZr0JgbHx8fbN++Hffee6/R+v3792PixInIzMy0Vv2sjmNuiIiIWp4mn36hsLDQ5Ozfvr6+7JYiIiIim2pQuImMjMSSJUtQXFxsWFdUVIRly5YhMjLSapUjIiIislSDzpZavXo1oqOjERQUZLjGzR9//AGtVou9e/datYJERERElmjwdW4KCwuxceNGnDt3DgAQHh6OKVOmwMnJyaoVtDaOuSEiImp5muU6N87Ozpg+fbrRuitXrmDGjBlsvSEiIiKbadCYm9rk5eUhPj7emkUSERERWcSq4YaIiIjI1hhuiIiISFYYboiIiEhWLBpQ3K9fPygUilqf5wX8iIiIyNYsCjfjxo1romoQERERWUeDr3PTUvE6N0RERC1Pk88tRURERGSvGG6IiIhIVhhuiIiISFYYboiIiEhWrBpusrOzsWbNGmsWSURERGQRq4Sb+Ph4PProowgICMCSJUusUSQRERFRgzQ43KSkpGD58uUIDQ3FyJEjoVAosHPnTqSnp1uzfkREREQWsSjclJWVYdu2bYiOjkbXrl1x4sQJvP3221AqlViwYAFGjRoFtVrdVHUlIiIiqpdFVygODAxEt27d8Nhjj2HLli3w8vICAEyePLlJKkdERERkKYtabsrLy6FQKKBQKKBSqZqqTkREREQNZlG4SU1NxTPPPIPNmzfD398f48ePx86dO+ucTJOIiIioOVkUbhwdHTFlyhT88MMPOHXqFMLDw/HCCy+gvLwcr732Gvbt2wedTtdUdSUiIiKqV4PPlurUqRNeffVVXL16Fd988w1KSkpw//33w8/Pz5r1IyIiIrKIRQOKTVEqlRgzZgzGjBmDzMxMfPbZZ9aoFxEREVGDKIQQwtIXFRUVYd++fbhw4QI0Gg26dOmCESNGtIhBxpZMmU5ERET2wZLPb4tbbr766is8/fTTyMrKMlofGBiIjRs3YtiwYQCAxMREhIaGWlo8ERERUaNYNObm8OHDmDBhAoYNG4ZDhw7h1q1buHXrFn7++WcMHjwY0dHROHfuHObOncvuKSIiIrIJi7qlxowZg+DgYHz44Ycmn//b3/6GHTt2QAiB+Ph49OnTx2oVtRZ2SxEREbU8lnx+W9Ry88svv2DmzJm1Ph8bG4ubN2/i+++/t8tgQ0RERPJnUbgpKiqqMy15eHhAq9Wib9++ja0XERERUYNYFG46d+6MH374odbn4+Pj0blz50ZXioiIiKihLAo306ZNw5w5c7B79+4az+3atQsvvfQSpk6daq26EREREVnMolPBZ82ahcOHD+P+++9H165dER4eDiEEzp49i4sXL+LBBx/E7Nmzm6iqRERERPWzqOVGqVRi27Zt2Lx5M7p06YJz587h/Pnz6Nq1KzZu3IgdO3ZAqWzwjA5EREREjdagKxS3ZDwVnIiIqOVpslPB9Xo93nzzTQwZMgSDBg3CvHnzUFRU1KjKEhEREVmTReHmtddew8svvwxXV1cEBgZi9erViI2Nbaq6EREREVnMonDz6aef4v3338d3332HL774Al9//TU2btwIvV7fVPUjIiIisohF4SY5ORljxowxPI6KioJCoUBqaqrVK0ZERETUEBaFm/Lycjg6OhqtU6vVKCsrs2qliIiIiBrKouvcCCEwdepUaLVaw7ri4mLMmDEDLi4uhnU7duywXg2JiIiILGBRuImJiamx7rHHHrNaZYiIiIgay6Jws379+qaqBxEREZFV8HLCREREJCsWtdw8+eSTZm338ccfN6gyRERERI1lUbjZsGEDOnTogH79+qGVzdpARERELYRF4ebZZ5/F5s2bkZiYiGnTpuGxxx6Dt7d3U9WNiIiIyGIWjblZu3Yt0tLS8NJLL+Hrr79GcHAwJk6ciO+++65RLTlr165FSEgIHB0dERERgWPHjpn1ui1btkChUGDcuHEN3jcRERHJi8UDirVaLSZPnox9+/bhzJkz6NGjB5577jmEhIQgPz/f4gps3boVcXFxWLJkCY4fP44+ffogOjoaGRkZdb4uKSkJc+bMwdChQy3eJxEREclXo86WUiqVUCgUEEJAp9M1qIyVK1di+vTpmDZtGrp3745169bB2dm5zkHJOp0OU6ZMwbJly9CxY8eGVp+IiIhkyOJwU1JSgs2bN2PEiBHo0qULTp06hTVr1iA5ORmurq4WlVVaWoqEhARERUXdqZBSiaioKBw5cqTW1y1fvhy+vr546qmnzKpvbm6u0UJERETyZdGA4ueeew5btmxBcHAwnnzySWzevBk+Pj4N3nlWVhZ0Oh38/PyM1vv5+eHcuXMmX/Pzzz/jP//5D06cOGHWPlasWIFly5Y1uI5ERETUslgUbtatW4f27dujY8eOOHjwIA4ePGhyu6aaWyovLw+PP/44PvroI7ND1fz58xEXF2d4nJubi+Dg4CapHxEREdmeReHmiSeegEKhsNrOfXx8oFKpcOPGDaP1N27cgL+/f43tL1++jKSkJIwdO9awTq/XAwAcHBxw/vx5dOrUyeg1Wq3WaKJPIiIikjeLL+JnTRqNBgMGDEB8fLzhdG69Xo/4+HjMnDmzxvbdunXDqVOnjNYtXLgQeXl5WL16NVtkiIiIyLJw0xTi4uIQExODgQMHYvDgwVi1ahUKCgowbdo0AFJrUWBgIFasWAFHR0f07NnT6PWenp4AUGM9ERERtU42DzeTJk1CZmYmFi9ejPT0dPTt2xd79uwxDDJOTk6GUsn5PYmIiMg8CtHKJonKzc2Fh4cHcnJy4O7ubuvqEBERkRks+fxmkwgRERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyYpdhJu1a9ciJCQEjo6OiIiIwLFjx2rd9qOPPsLQoUPh5eUFLy8vREVF1bk9ERERtS42Dzdbt25FXFwclixZguPHj6NPnz6Ijo5GRkaGye0PHDiAyZMnY//+/Thy5AiCg4MxcuRIXL9+vZlrTkRERPZIIYQQtqxAREQEBg0ahDVr1gAA9Ho9goOD8fzzz2PevHn1vl6n08HLywtr1qzBE088Ue/2ubm58PDwQE5ODtzd3RtdfyIiImp6lnx+27TlprS0FAkJCYiKijKsUyqViIqKwpEjR8wqo7CwEGVlZfD29jb5fElJCXJzc40WIiIiki+bhpusrCzodDr4+fkZrffz80N6erpZZcydOxft2rUzCkhVrVixAh4eHoYlODi40fUmIiIi+2XzMTeN8cYbb2DLli3YuXMnHB0dTW4zf/585OTkGJaUlJRmriURERE1Jwdb7tzHxwcqlQo3btwwWn/jxg34+/vX+dp33nkHb7zxBr7//nv07t271u20Wi20Wq1V6ktERET2z6YtNxqNBgMGDEB8fLxhnV6vR3x8PCIjI2t93VtvvYVXXnkFe/bswcCBA5ujqkRERNRC2LTlBgDi4uIQExODgQMHYvDgwVi1ahUKCgowbdo0AMATTzyBwMBArFixAgDw5ptvYvHixdi0aRNCQkIMY3NcXV3h6upqs/dBRERE9sHm4WbSpEnIzMzE4sWLkZ6ejr59+2LPnj2GQcbJyclQKu80MH3wwQcoLS3FhAkTjMpZsmQJli5d2pxVJyIiIjtk8+vcNDde54aIiKjlaTHXuSEiIiKyNoYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhW7CDdr165FSEgIHB0dERERgWPHjtW5/bZt29CtWzc4OjqiV69e2L17dzPVlIiIiOydzcPN1q1bERcXhyVLluD48ePo06cPoqOjkZGRYXL7w4cPY/LkyXjqqafw+++/Y9y4cRg3bhxOnz7dzDUnIiIie6QQQghbViAiIgKDBg3CmjVrAAB6vR7BwcF4/vnnMW/evBrbT5o0CQUFBfjmm28M6+666y707dsX69atq3d/ubm58PDwQE5ODtzd3a33RoiIiKjJWPL5bdOWm9LSUiQkJCAqKsqwTqlUIioqCkeOHDH5miNHjhhtDwDR0dG1bl9SUoLc3FyjhYiIiOTLpuEmKysLOp0Ofn5+Ruv9/PyQnp5u8jXp6ekWbb9ixQp4eHgYluDgYOtUnoiIiOySzcfcNLX58+cjJyfHsKSkpNi6SkRERNSEHGy5cx8fH6hUKty4ccNo/Y0bN+Dv72/yNf7+/hZtr9VqodVqrVNhIiIisns2DTcajQYDBgxAfHw8xo0bB0AaUBwfH4+ZM2eafE1kZCTi4+Mxe/Zsw7p9+/YhMjLSrH1Wjp/m2BsiIqKWo/Jz26zzoISNbdmyRWi1WrFhwwZx5swZ8cwzzwhPT0+Rnp4uhBDi8ccfF/PmzTNsf+jQIeHg4CDeeecdcfbsWbFkyRKhVqvFqVOnzNrf5cuXBQAuXLhw4cKFSwtcUlJS6v2st2nLDSCd2p2ZmYnFixcjPT0dffv2xZ49ewyDhpOTk6FU3hkadPfdd2PTpk1YuHAhXn75ZXTu3BlffPEFevbsadb+vL29DeV6eHhY/w1RnXJzcxEcHIyUlBSeit/MeOxti8ffdnjsbceax14Igby8PLRr167ebW1+nZvmxuvc2BaPv+3w2NsWj7/t8Njbjq2OvezPliIiIqLWheGGiIiIZKXVhRutVoslS5bw9HAb4fG3HR572+Lxtx0ee9ux1bFvdWNuiIiISN5aXcsNERERyRvDDREREckKww0RERHJCsMNERERyUqrCzdr165FSEgIHB0dERERgWPHjtm6Sq3C0qVLoVAojJZu3brZulqy9OOPP2Ls2LFo164dFAoFvvjiC6PnhRBYvHgxAgIC4OTkhKioKFy8eNE2lZWZ+o791KlTa/wdjBo1yjaVlZkVK1Zg0KBBcHNzg6+vL8aNG4fz588bbVNcXIzY2Fi0adMGrq6uGD9+fI2JmMly5hz7e++9t8bv/owZM5qsTq0q3GzduhVxcXFYsmQJjh8/jj59+iA6OhoZGRm2rlqr0KNHD6SlpRmWn3/+2dZVkqWCggL06dMHa9euNfn8W2+9hf/7v//DunXrcPToUbi4uCA6OhrFxcXNXFP5qe/YA8CoUaOM/g42b97cjDWUr4MHDyI2Nha//PIL9u3bh7KyMowcORIFBQWGbV588UV8/fXX2LZtGw4ePIjU1FQ8/PDDNqy1PJhz7AFg+vTpRr/7b731VtNVytKJLluywYMHi9jYWMNjnU4n2rVrJ1asWGHDWrUOS5YsEX369LF1NVodAGLnzp2Gx3q9Xvj7+4u3337bsC47O1totVqxefNmG9RQvqofeyGEiImJEQ8++KBN6tPaZGRkCADi4MGDQgjp91ytVott27YZtjl79qwAII4cOWKraspS9WMvhBB/+tOfxKxZs5qtDq2m5aa0tBQJCQmIiooyrFMqlYiKisKRI0dsWLPW4+LFi2jXrh06duyIKVOmIDk52dZVanUSExORnp5u9Hfg4eGBiIgI/h00kwMHDsDX1xddu3bFs88+i5s3b9q6SrKUk5MD4M5kyQkJCSgrKzP63e/WrRvat2/P330rq37sK23cuBE+Pj7o2bMn5s+fj8LCwiarg81nBW8uWVlZ0Ol0htnGK/n5+eHcuXM2qlXrERERgQ0bNqBr165IS0vDsmXLMHToUJw+fRpubm62rl6rkZ6eDgAm/w4qn6OmM2rUKDz88MMIDQ3F5cuX8fLLL2P06NE4cuQIVCqVrasnG3q9HrNnz8aQIUPQs2dPANLvvkajgaenp9G2/N23LlPHHgAeffRRdOjQAe3atcPJkycxd+5cnD9/Hjt27GiSerSacEO2NXr0aMP93r17IyIiAh06dMDnn3+Op556yoY1I2o+jzzyiOF+r1690Lt3b3Tq1AkHDhzA8OHDbVgzeYmNjcXp06c5rs8Gajv2zzzzjOF+r169EBAQgOHDh+Py5cvo1KmT1evRarqlfHx8oFKpaoyMv3HjBvz9/W1Uq9bL09MTXbp0waVLl2xdlVal8nedfwf2oWPHjvDx8eHfgRXNnDkT33zzDfbv34+goCDDen9/f5SWliI7O9toe/7uW09tx96UiIgIAGiy3/1WE240Gg0GDBiA+Ph4wzq9Xo/4+HhERkbasGatU35+Pi5fvoyAgABbV6VVCQ0Nhb+/v9HfQW5uLo4ePcq/Axu4du0abt68yb8DKxBCYObMmdi5cyd++OEHhIaGGj0/YMAAqNVqo9/98+fPIzk5mb/7jVTfsTflxIkTANBkv/utqlsqLi4OMTExGDhwIAYPHoxVq1ahoKAA06ZNs3XVZG/OnDkYO3YsOnTogNTUVCxZsgQqlQqTJ0+2ddVkJz8/3+jbUGJiIk6cOAFvb2+0b98es2fPxquvvorOnTsjNDQUixYtQrt27TBu3DjbVVom6jr23t7eWLZsGcaPHw9/f39cvnwZL730EsLCwhAdHW3DWstDbGwsNm3ahC+//BJubm6GcTQeHh5wcnKCh4cHnnrqKcTFxcHb2xvu7u54/vnnERkZibvuusvGtW/Z6jv2ly9fxqZNmzBmzBi0adMGJ0+exIsvvohhw4ahd+/eTVOpZjsvy0689957on379kKj0YjBgweLX375xdZVahUmTZokAgIChEajEYGBgWLSpEni0qVLtq6WLO3fv18AqLHExMQIIaTTwRctWiT8/PyEVqsVw4cPF+fPn7dtpWWirmNfWFgoRo4cKdq2bSvUarXo0KGDmD59ukhPT7d1tWXB1HEHINavX2/YpqioSDz33HPCy8tLODs7i4ceekikpaXZrtIyUd+xT05OFsOGDRPe3t5Cq9WKsLAw8Y9//EPk5OQ0WZ0UFRUjIiIikoVWM+aGiIiIWgeGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyJq9RQKBb744gtbV4OIrIThhohsaurUqVAoFDWWUaNG2bpqRNRCtaq5pYjIPo0aNQrr1683WqfVam1UGyJq6dhyQ0Q2p9Vq4e/vb7R4eXkBkLqMPvjgA4wePRpOTk7o2LEjtm/fbvT6U6dO4c9//jOcnJzQpk0bPPPMM8jPzzfa5uOPP0aPHj2g1WoREBCAmTNnGj2flZWFhx56CM7OzujcuTO++uqrpn3TRNRkGG6IyO4tWrQI48ePxx9//IEpU6bgkUcewdmzZwEABQUFiI6OhpeXF3799Vds27YN33//vVF4+eCDDxAbG4tnnnkGp06dwldffYWwsDCjfSxbtgwTJ07EyZMnMWbMGEyZMgW3bt1q1vdJRFbSZFNyEhGZISYmRqhUKuHi4mK0vPbaa0IIacbhGTNmGL0mIiJCPPvss0IIIf71r38JLy8vkZ+fb3h+165dQqlUGmbcbteunViwYEGtdQAgFi5caHicn58vAIhvv/3Wau+TiJoPx9wQkc3dd999+OCDD4zWeXt7G+5HRkYaPRcZGYkTJ04AAM6ePYs+ffrAxcXF8PyQIUOg1+tx/vx5KBQKpKamYvjw4XXWoXfv3ob7Li4ucHd3R0ZGRkPfEhHZEMMNEdmci4tLjW4ia3FycjJrO7VabfRYoVBAr9c3RZWIqIlxzA0R2b1ffvmlxuPw8HAAQHh4OP744w8UFBQYnj906BCUSiW6du0KNzc3hISEID4+vlnrTES2w5YbIrK5kpISpKenG61zcHCAj48PAGDbtm0YOHAg7rnnHmzcuBHHjh3Df/7zHwDAlClTsGTJEsTExGDp0qXIzMzE888/j8cffxx+fn4AgKVLl2LGjBnw9fXF6NGjkZeXh0OHDuH5559v3jdKRM2C4YaIbG7Pnj0ICAgwWte1a1ecO3cOgHQm05YtW/Dcc88hICAAmzdvRvfu3QEAzs7O+O677zBr1iwMGjQIzs7OGD9+PFauXGkoKyYmBsXFxXj33XcxZ84c+Pj4YMKECc33BomoWSmEEMLWlSAiqo1CocDOnTsxbtw4W1eFiFoIjrkhIiIiWWG4ISIiIlnhmBsismvsOSciS7HlhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZOX/A3Oom01nHqSfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'SUBJ'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: SUBJ\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([18512, 100])\n",
      "18512\n",
      "18512\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 4,078,201 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.553 | Train Acc: 75.69%\n",
      "\t test  Loss: 0.410 | test  Acc: 85.32%\n",
      "\t best  test acc: 85.32%\n",
      "Epoch: 02 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.278 | Train Acc: 91.67%\n",
      "\t test  Loss: 0.265 | test  Acc: 90.77%\n",
      "\t best  test acc: 90.77%\n",
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.160 | Train Acc: 95.64%\n",
      "\t test  Loss: 0.253 | test  Acc: 91.77%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 04 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.096 | Train Acc: 97.76%\n",
      "\t test  Loss: 0.284 | test  Acc: 91.47%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 05 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.065 | Train Acc: 98.49%\n",
      "\t test  Loss: 0.269 | test  Acc: 92.56%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 06 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.045 | Train Acc: 99.04%\n",
      "\t test  Loss: 0.295 | test  Acc: 92.36%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 07 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.033 | Train Acc: 99.45%\n",
      "\t test  Loss: 0.369 | test  Acc: 91.37%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 08 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.042 | Train Acc: 99.09%\n",
      "\t test  Loss: 0.312 | test  Acc: 92.16%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 09 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.023 | Train Acc: 99.65%\n",
      "\t test  Loss: 0.399 | test  Acc: 90.67%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 10 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.024 | Train Acc: 99.48%\n",
      "\t test  Loss: 0.425 | test  Acc: 90.08%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 11 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.019 | Train Acc: 99.67%\n",
      "\t test  Loss: 0.503 | test  Acc: 89.78%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 12 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.015 | Train Acc: 99.79%\n",
      "\t test  Loss: 0.461 | test  Acc: 90.48%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 13 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.014 | Train Acc: 99.80%\n",
      "\t test  Loss: 0.514 | test  Acc: 89.88%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 14 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.012 | Train Acc: 99.84%\n",
      "\t test  Loss: 0.506 | test  Acc: 90.38%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 15 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.012 | Train Acc: 99.81%\n",
      "\t test  Loss: 0.468 | test  Acc: 90.97%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 16 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.020 | Train Acc: 99.64%\n",
      "\t test  Loss: 0.587 | test  Acc: 88.79%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 17 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.027 | Train Acc: 99.49%\n",
      "\t test  Loss: 0.675 | test  Acc: 87.10%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 18 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.019 | Train Acc: 99.54%\n",
      "\t test  Loss: 0.413 | test  Acc: 89.78%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 19 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.014 | Train Acc: 99.69%\n",
      "\t test  Loss: 0.594 | test  Acc: 88.89%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 20 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.012 | Train Acc: 99.76%\n",
      "\t test  Loss: 0.452 | test  Acc: 91.07%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 21 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.010 | Train Acc: 99.84%\n",
      "\t test  Loss: 0.448 | test  Acc: 90.97%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 22 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.010 | Train Acc: 99.85%\n",
      "\t test  Loss: 0.447 | test  Acc: 91.77%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 23 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.010 | Train Acc: 99.85%\n",
      "\t test  Loss: 0.443 | test  Acc: 92.16%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 24 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.007 | Train Acc: 99.89%\n",
      "\t test  Loss: 0.474 | test  Acc: 90.77%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 25 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.013 | Train Acc: 99.74%\n",
      "\t test  Loss: 0.422 | test  Acc: 91.27%\n",
      "\t best  test acc: 92.56%\n",
      "Epoch: 26 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.009 | Train Acc: 99.83%\n",
      "\t test  Loss: 0.460 | test  Acc: 91.07%\n",
      "\t best  test acc: 92.56%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}