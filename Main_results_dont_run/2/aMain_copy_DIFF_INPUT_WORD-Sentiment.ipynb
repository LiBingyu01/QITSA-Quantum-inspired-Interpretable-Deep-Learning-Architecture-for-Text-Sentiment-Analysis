{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'SUBJ'\n",
    "N_EPOCHS = 21\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: SUBJ\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([18512, 100])\n",
      "18512\n",
      "18512\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding2(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 2,227,001 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.631 | Train Acc: 67.45%\n",
      "\t test  Loss: 0.513 | test  Acc: 80.56%\n",
      "\t best  test acc: 80.56%\n",
      "Epoch: 02 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.433 | Train Acc: 83.10%\n",
      "\t test  Loss: 0.371 | test  Acc: 85.32%\n",
      "\t best  test acc: 85.32%\n",
      "Epoch: 03 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.272 | Train Acc: 90.65%\n",
      "\t test  Loss: 0.341 | test  Acc: 86.61%\n",
      "\t best  test acc: 86.61%\n",
      "Epoch: 04 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.184 | Train Acc: 94.49%\n",
      "\t test  Loss: 0.322 | test  Acc: 88.39%\n",
      "\t best  test acc: 88.39%\n",
      "Epoch: 05 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.132 | Train Acc: 96.33%\n",
      "\t test  Loss: 0.311 | test  Acc: 89.38%\n",
      "\t best  test acc: 89.38%\n",
      "Epoch: 06 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.099 | Train Acc: 97.55%\n",
      "\t test  Loss: 0.336 | test  Acc: 89.09%\n",
      "\t best  test acc: 89.38%\n",
      "Epoch: 07 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.076 | Train Acc: 98.21%\n",
      "\t test  Loss: 0.379 | test  Acc: 88.59%\n",
      "\t best  test acc: 89.38%\n",
      "Epoch: 08 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.065 | Train Acc: 98.42%\n",
      "\t test  Loss: 0.348 | test  Acc: 89.48%\n",
      "\t best  test acc: 89.48%\n",
      "Epoch: 09 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.056 | Train Acc: 98.75%\n",
      "\t test  Loss: 0.348 | test  Acc: 90.18%\n",
      "\t best  test acc: 90.18%\n",
      "Epoch: 10 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.046 | Train Acc: 99.06%\n",
      "\t test  Loss: 0.414 | test  Acc: 88.79%\n",
      "\t best  test acc: 90.18%\n",
      "Epoch: 11 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.035 | Train Acc: 99.39%\n",
      "\t test  Loss: 0.390 | test  Acc: 89.78%\n",
      "\t best  test acc: 90.18%\n",
      "Epoch: 12 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.033 | Train Acc: 99.39%\n",
      "\t test  Loss: 0.362 | test  Acc: 91.57%\n",
      "\t best  test acc: 91.57%\n",
      "Epoch: 13 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.035 | Train Acc: 99.29%\n",
      "\t test  Loss: 0.400 | test  Acc: 90.77%\n",
      "\t best  test acc: 91.57%\n",
      "Epoch: 14 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.029 | Train Acc: 99.46%\n",
      "\t test  Loss: 0.447 | test  Acc: 90.28%\n",
      "\t best  test acc: 91.57%\n",
      "Epoch: 15 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.033 | Train Acc: 99.28%\n",
      "\t test  Loss: 0.466 | test  Acc: 89.58%\n",
      "\t best  test acc: 91.57%\n",
      "Epoch: 16 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.029 | Train Acc: 99.44%\n",
      "\t test  Loss: 0.439 | test  Acc: 89.88%\n",
      "\t best  test acc: 91.57%\n",
      "Epoch: 17 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.025 | Train Acc: 99.50%\n",
      "\t test  Loss: 0.455 | test  Acc: 89.48%\n",
      "\t best  test acc: 91.57%\n",
      "Epoch: 18 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.020 | Train Acc: 99.65%\n",
      "\t test  Loss: 0.530 | test  Acc: 88.99%\n",
      "\t best  test acc: 91.57%\n",
      "Epoch: 19 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.021 | Train Acc: 99.60%\n",
      "\t test  Loss: 0.465 | test  Acc: 89.88%\n",
      "\t best  test acc: 91.57%\n",
      "Epoch: 20 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.015 | Train Acc: 99.76%\n",
      "\t test  Loss: 0.504 | test  Acc: 89.48%\n",
      "\t best  test acc: 91.57%\n",
      "Epoch: 21 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.013 | Train Acc: 99.80%\n",
      "\t test  Loss: 0.530 | test  Acc: 89.68%\n",
      "\t best  test acc: 91.57%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding2(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 932,601 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.591 | Train Acc: 68.87%\n",
      "\t test  Loss: 0.571 | test  Acc: 68.38%\n",
      "\t best  test acc: 68.38%\n",
      "Epoch: 02 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.530 | Train Acc: 72.20%\n",
      "\t test  Loss: 0.552 | test  Acc: 68.38%\n",
      "\t best  test acc: 68.38%\n",
      "Epoch: 03 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.514 | Train Acc: 74.26%\n",
      "\t test  Loss: 0.545 | test  Acc: 69.59%\n",
      "\t best  test acc: 69.59%\n",
      "Epoch: 04 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.502 | Train Acc: 75.25%\n",
      "\t test  Loss: 0.559 | test  Acc: 70.99%\n",
      "\t best  test acc: 70.99%\n",
      "Epoch: 05 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.492 | Train Acc: 76.27%\n",
      "\t test  Loss: 0.535 | test  Acc: 73.51%\n",
      "\t best  test acc: 73.51%\n",
      "Epoch: 06 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.478 | Train Acc: 77.86%\n",
      "\t test  Loss: 0.504 | test  Acc: 75.93%\n",
      "\t best  test acc: 75.93%\n",
      "Epoch: 07 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.448 | Train Acc: 79.93%\n",
      "\t test  Loss: 0.474 | test  Acc: 78.08%\n",
      "\t best  test acc: 78.08%\n",
      "Epoch: 08 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.419 | Train Acc: 81.96%\n",
      "\t test  Loss: 0.486 | test  Acc: 77.89%\n",
      "\t best  test acc: 78.08%\n",
      "Epoch: 09 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.368 | Train Acc: 85.19%\n",
      "\t test  Loss: 0.463 | test  Acc: 80.41%\n",
      "\t best  test acc: 80.41%\n",
      "Epoch: 10 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.321 | Train Acc: 88.16%\n",
      "\t test  Loss: 0.469 | test  Acc: 80.69%\n",
      "\t best  test acc: 80.69%\n",
      "Epoch: 11 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.285 | Train Acc: 89.90%\n",
      "\t test  Loss: 0.479 | test  Acc: 82.28%\n",
      "\t best  test acc: 82.28%\n",
      "Epoch: 12 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.250 | Train Acc: 91.61%\n",
      "\t test  Loss: 0.503 | test  Acc: 82.37%\n",
      "\t best  test acc: 82.37%\n",
      "Epoch: 13 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.239 | Train Acc: 91.81%\n",
      "\t test  Loss: 0.545 | test  Acc: 81.16%\n",
      "\t best  test acc: 82.37%\n",
      "Epoch: 14 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.222 | Train Acc: 92.54%\n",
      "\t test  Loss: 0.491 | test  Acc: 82.84%\n",
      "\t best  test acc: 82.84%\n",
      "Epoch: 15 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.196 | Train Acc: 93.73%\n",
      "\t test  Loss: 0.490 | test  Acc: 82.37%\n",
      "\t best  test acc: 82.84%\n",
      "Epoch: 16 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.167 | Train Acc: 94.64%\n",
      "\t test  Loss: 0.502 | test  Acc: 82.56%\n",
      "\t best  test acc: 82.84%\n",
      "Epoch: 17 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.154 | Train Acc: 95.12%\n",
      "\t test  Loss: 0.519 | test  Acc: 83.02%\n",
      "\t best  test acc: 83.02%\n",
      "Epoch: 18 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.146 | Train Acc: 95.57%\n",
      "\t test  Loss: 0.514 | test  Acc: 83.49%\n",
      "\t best  test acc: 83.49%\n",
      "Epoch: 19 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.128 | Train Acc: 96.08%\n",
      "\t test  Loss: 0.554 | test  Acc: 83.49%\n",
      "\t best  test acc: 83.49%\n",
      "Epoch: 20 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.117 | Train Acc: 96.42%\n",
      "\t test  Loss: 0.586 | test  Acc: 83.68%\n",
      "\t best  test acc: 83.68%\n",
      "Epoch: 21 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.122 | Train Acc: 96.30%\n",
      "\t test  Loss: 0.506 | test  Acc: 83.86%\n",
      "\t best  test acc: 83.86%\n",
      "Epoch: 22 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.113 | Train Acc: 96.42%\n",
      "\t test  Loss: 0.544 | test  Acc: 83.86%\n",
      "\t best  test acc: 83.86%\n",
      "Epoch: 23 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.101 | Train Acc: 96.88%\n",
      "\t test  Loss: 0.574 | test  Acc: 83.30%\n",
      "\t best  test acc: 83.86%\n",
      "Epoch: 24 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.088 | Train Acc: 97.46%\n",
      "\t test  Loss: 0.585 | test  Acc: 83.49%\n",
      "\t best  test acc: 83.86%\n",
      "Epoch: 25 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.086 | Train Acc: 97.28%\n",
      "\t test  Loss: 0.597 | test  Acc: 84.14%\n",
      "\t best  test acc: 84.14%\n",
      "Epoch: 26 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.074 | Train Acc: 97.78%\n",
      "\t test  Loss: 0.633 | test  Acc: 82.65%\n",
      "\t best  test acc: 84.14%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'SST'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: SST\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([13772, 100])\n",
      "13772\n",
      "13772\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding2(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,753,001 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 1m 8s\n",
      "\t Train Loss: 0.515 | Train Acc: 74.61%\n",
      "\t test  Loss: 0.452 | test  Acc: 79.68%\n",
      "\t best  test acc: 79.68%\n",
      "Epoch: 02 | Epoch Time: 1m 6s\n",
      "\t Train Loss: 0.283 | Train Acc: 88.85%\n",
      "\t test  Loss: 0.421 | test  Acc: 83.45%\n",
      "\t best  test acc: 83.45%\n",
      "Epoch: 03 | Epoch Time: 1m 10s\n",
      "\t Train Loss: 0.196 | Train Acc: 92.75%\n",
      "\t test  Loss: 0.488 | test  Acc: 82.53%\n",
      "\t best  test acc: 83.45%\n",
      "Epoch: 04 | Epoch Time: 1m 9s\n",
      "\t Train Loss: 0.148 | Train Acc: 94.64%\n",
      "\t test  Loss: 0.598 | test  Acc: 81.03%\n",
      "\t best  test acc: 83.45%\n",
      "Epoch: 05 | Epoch Time: 1m 6s\n",
      "\t Train Loss: 0.120 | Train Acc: 95.73%\n",
      "\t test  Loss: 0.579 | test  Acc: 82.20%\n",
      "\t best  test acc: 83.45%\n",
      "Epoch: 06 | Epoch Time: 1m 5s\n",
      "\t Train Loss: 0.097 | Train Acc: 96.62%\n",
      "\t test  Loss: 0.593 | test  Acc: 81.97%\n",
      "\t best  test acc: 83.45%\n",
      "Epoch: 07 | Epoch Time: 1m 6s\n",
      "\t Train Loss: 0.083 | Train Acc: 97.14%\n",
      "\t test  Loss: 0.611 | test  Acc: 82.73%\n",
      "\t best  test acc: 83.45%\n",
      "Epoch: 08 | Epoch Time: 1m 4s\n",
      "\t Train Loss: 0.072 | Train Acc: 97.53%\n",
      "\t test  Loss: 0.604 | test  Acc: 82.75%\n",
      "\t best  test acc: 83.45%\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m/root/autodl-tmp/sentiment_analysis/aMain_copy_DIFF_INPUT.py:48\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N_EPOCHS):\n\u001b[1;32m     45\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     47\u001b[0m     train_loss, train_acc, train_f1_score, train_recall \\\n\u001b[0;32m---> 48\u001b[0m         \u001b[39m=\u001b[39m train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n\u001b[1;32m     50\u001b[0m     test_loss, test_acc, test_f1_score, test_recall \\\n\u001b[1;32m     51\u001b[0m         \u001b[39m=\u001b[39m evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n\u001b[1;32m     53\u001b[0m     acc_train\u001b[39m.\u001b[39mappend(train_acc)\n",
      "File \u001b[1;32m/root/autodl-tmp/sentiment_analysis/aMain_copy_DIFF_INPUT.py:44\u001b[0m\n\u001b[1;32m     40\u001b[0m sentiment \u001b[39m=\u001b[39m batch[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mcuda(CUDA_NUMBER)\n\u001b[1;32m     42\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 44\u001b[0m predictions \u001b[39m=\u001b[39m model(text, sentiment)\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[39m# print(predictions)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m loss \u001b[39m=\u001b[39m criterion(predictions\u001b[39m.\u001b[39mreshape(\u001b[39mlen\u001b[39m(label)), label)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m/root/autodl-tmp/sentiment_analysis/aMain_copy_DIFF_INPUT.py:54\u001b[0m\n\u001b[1;32m     51\u001b[0m phase_is_sentiment \u001b[39m=\u001b[39m sentiment_unsqueeze\n\u001b[1;32m     53\u001b[0m \u001b[39m# ================ 2、实部进行GRU处理 ================\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m amplitude_plus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgru1(amplitude_is_WordEmbedding)\n\u001b[1;32m     55\u001b[0m amplitude_plus2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attention1(amplitude_plus)\n\u001b[1;32m     56\u001b[0m amplitude_plus2 \u001b[39m=\u001b[39m amplitude_plus2\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m/root/autodl-tmp/sentiment_analysis/aMain_copy_DIFF_INPUT.py:16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     15\u001b[0m     \u001b[39m# Forward pass through GRU layer\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     output, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn(x)\n\u001b[1;32m     18\u001b[0m     \u001b[39m# Skip connection: Add output of middle layer to GRU layer output\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     output \u001b[39m=\u001b[39m output \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmiddle_layer(x)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:998\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    997\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 998\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mgru(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    999\u001b[0m                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m   1000\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1001\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m   1002\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}