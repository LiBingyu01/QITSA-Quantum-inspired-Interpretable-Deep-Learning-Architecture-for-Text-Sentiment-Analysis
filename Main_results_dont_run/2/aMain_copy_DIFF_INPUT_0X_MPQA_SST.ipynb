{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'CR'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: CR\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([4749, 100])\n",
      "4749\n",
      "4749\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,325,601 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.657 | Train Acc: 63.62%\n",
      "\t test  Loss: 0.656 | test  Acc: 64.06%\n",
      "\t best  test acc: 64.06%\n",
      "Epoch: 02 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.647 | Train Acc: 63.62%\n",
      "\t test  Loss: 0.622 | test  Acc: 64.06%\n",
      "\t best  test acc: 64.06%\n",
      "Epoch: 03 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.612 | Train Acc: 63.62%\n",
      "\t test  Loss: 0.605 | test  Acc: 64.06%\n",
      "\t best  test acc: 64.06%\n",
      "Epoch: 04 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.509 | Train Acc: 77.51%\n",
      "\t test  Loss: 0.538 | test  Acc: 71.88%\n",
      "\t best  test acc: 71.88%\n",
      "Epoch: 05 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.393 | Train Acc: 85.32%\n",
      "\t test  Loss: 0.487 | test  Acc: 77.86%\n",
      "\t best  test acc: 77.86%\n",
      "Epoch: 06 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.293 | Train Acc: 89.85%\n",
      "\t test  Loss: 0.400 | test  Acc: 83.85%\n",
      "\t best  test acc: 83.85%\n",
      "Epoch: 07 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.230 | Train Acc: 92.72%\n",
      "\t test  Loss: 0.476 | test  Acc: 83.33%\n",
      "\t best  test acc: 83.85%\n",
      "Epoch: 08 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.215 | Train Acc: 93.15%\n",
      "\t test  Loss: 0.489 | test  Acc: 83.07%\n",
      "\t best  test acc: 83.85%\n",
      "Epoch: 09 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.167 | Train Acc: 95.27%\n",
      "\t test  Loss: 0.473 | test  Acc: 84.38%\n",
      "\t best  test acc: 84.38%\n",
      "Epoch: 10 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.132 | Train Acc: 96.66%\n",
      "\t test  Loss: 0.501 | test  Acc: 83.33%\n",
      "\t best  test acc: 84.38%\n",
      "Epoch: 11 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.115 | Train Acc: 97.19%\n",
      "\t test  Loss: 0.542 | test  Acc: 83.33%\n",
      "\t best  test acc: 84.38%\n",
      "Epoch: 12 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.099 | Train Acc: 97.78%\n",
      "\t test  Loss: 0.565 | test  Acc: 81.25%\n",
      "\t best  test acc: 84.38%\n",
      "Epoch: 13 | Epoch Time: 0m 4s\n",
      "\t Train Loss: 0.089 | Train Acc: 98.02%\n",
      "\t test  Loss: 0.571 | test  Acc: 83.33%\n",
      "\t best  test acc: 84.38%\n",
      "Epoch: 14 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.106 | Train Acc: 97.29%\n",
      "\t test  Loss: 0.583 | test  Acc: 82.03%\n",
      "\t best  test acc: 84.38%\n",
      "Epoch: 15 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.098 | Train Acc: 97.52%\n",
      "\t test  Loss: 0.648 | test  Acc: 79.95%\n",
      "\t best  test acc: 84.38%\n",
      "Epoch: 16 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.091 | Train Acc: 97.75%\n",
      "\t test  Loss: 0.606 | test  Acc: 82.03%\n",
      "\t best  test acc: 84.38%\n",
      "Epoch: 17 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.070 | Train Acc: 98.54%\n",
      "\t test  Loss: 0.641 | test  Acc: 81.51%\n",
      "\t best  test acc: 84.38%\n",
      "Epoch: 18 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.062 | Train Acc: 98.84%\n",
      "\t test  Loss: 0.653 | test  Acc: 81.25%\n",
      "\t best  test acc: 84.38%\n",
      "Epoch: 19 | Epoch Time: 0m 4s\n",
      "\t Train Loss: 0.059 | Train Acc: 98.91%\n",
      "\t test  Loss: 0.698 | test  Acc: 80.99%\n",
      "\t best  test acc: 84.38%\n",
      "Epoch: 20 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.057 | Train Acc: 98.94%\n",
      "\t test  Loss: 0.650 | test  Acc: 81.51%\n",
      "\t best  test acc: 84.38%\n",
      "Epoch: 21 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.055 | Train Acc: 98.94%\n",
      "\t test  Loss: 0.694 | test  Acc: 81.51%\n",
      "\t best  test acc: 84.38%\n",
      "Epoch: 22 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.056 | Train Acc: 98.88%\n",
      "\t test  Loss: 0.774 | test  Acc: 80.21%\n",
      "\t best  test acc: 84.38%\n",
      "Epoch: 23 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.122 | Train Acc: 96.59%\n",
      "\t test  Loss: 0.645 | test  Acc: 80.21%\n",
      "\t best  test acc: 84.38%\n",
      "Epoch: 24 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.076 | Train Acc: 97.95%\n",
      "\t test  Loss: 0.654 | test  Acc: 81.77%\n",
      "\t best  test acc: 84.38%\n",
      "Epoch: 25 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.058 | Train Acc: 98.74%\n",
      "\t test  Loss: 0.705 | test  Acc: 81.25%\n",
      "\t best  test acc: 84.38%\n",
      "Epoch: 26 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.053 | Train Acc: 98.97%\n",
      "\t test  Loss: 0.707 | test  Acc: 81.51%\n",
      "\t best  test acc: 84.38%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,489,401 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.530 | Train Acc: 73.99%\n",
      "\t test  Loss: 0.414 | test  Acc: 84.14%\n",
      "\t best  test acc: 84.14%\n",
      "Epoch: 02 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.324 | Train Acc: 88.88%\n",
      "\t test  Loss: 0.356 | test  Acc: 84.51%\n",
      "\t best  test acc: 84.51%\n",
      "Epoch: 03 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.247 | Train Acc: 91.68%\n",
      "\t test  Loss: 0.343 | test  Acc: 86.38%\n",
      "\t best  test acc: 86.38%\n",
      "Epoch: 04 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.196 | Train Acc: 93.51%\n",
      "\t test  Loss: 0.351 | test  Acc: 86.47%\n",
      "\t best  test acc: 86.47%\n",
      "Epoch: 05 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.160 | Train Acc: 94.99%\n",
      "\t test  Loss: 0.383 | test  Acc: 86.94%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 06 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.135 | Train Acc: 95.82%\n",
      "\t test  Loss: 0.393 | test  Acc: 86.47%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 07 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.115 | Train Acc: 96.45%\n",
      "\t test  Loss: 0.409 | test  Acc: 85.63%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 08 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.101 | Train Acc: 96.82%\n",
      "\t test  Loss: 0.420 | test  Acc: 85.17%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 09 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.096 | Train Acc: 96.80%\n",
      "\t test  Loss: 0.437 | test  Acc: 86.19%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 10 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.088 | Train Acc: 97.16%\n",
      "\t test  Loss: 0.447 | test  Acc: 86.47%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 11 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.077 | Train Acc: 97.54%\n",
      "\t test  Loss: 0.463 | test  Acc: 85.63%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 12 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.069 | Train Acc: 97.60%\n",
      "\t test  Loss: 0.477 | test  Acc: 85.45%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 13 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.062 | Train Acc: 97.79%\n",
      "\t test  Loss: 0.475 | test  Acc: 85.35%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 14 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.058 | Train Acc: 97.82%\n",
      "\t test  Loss: 0.475 | test  Acc: 86.10%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 15 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.053 | Train Acc: 98.06%\n",
      "\t test  Loss: 0.516 | test  Acc: 84.05%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 16 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.051 | Train Acc: 98.05%\n",
      "\t test  Loss: 0.518 | test  Acc: 84.61%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 17 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.045 | Train Acc: 98.33%\n",
      "\t test  Loss: 0.539 | test  Acc: 82.37%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 18 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.042 | Train Acc: 98.53%\n",
      "\t test  Loss: 0.524 | test  Acc: 84.24%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 19 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.043 | Train Acc: 98.49%\n",
      "\t test  Loss: 0.563 | test  Acc: 82.37%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 20 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.035 | Train Acc: 98.67%\n",
      "\t test  Loss: 0.556 | test  Acc: 85.07%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 21 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.034 | Train Acc: 98.68%\n",
      "\t test  Loss: 0.610 | test  Acc: 80.13%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 22 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.038 | Train Acc: 98.65%\n",
      "\t test  Loss: 0.608 | test  Acc: 82.56%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 23 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.034 | Train Acc: 98.71%\n",
      "\t test  Loss: 0.604 | test  Acc: 82.84%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 24 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.033 | Train Acc: 98.69%\n",
      "\t test  Loss: 0.619 | test  Acc: 80.60%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 25 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.030 | Train Acc: 98.82%\n",
      "\t test  Loss: 0.680 | test  Acc: 79.20%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 26 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.031 | Train Acc: 98.79%\n",
      "\t test  Loss: 0.607 | test  Acc: 81.06%\n",
      "\t best  test acc: 86.94%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,489,401 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.553 | Train Acc: 72.75%\n",
      "\t test  Loss: 0.489 | test  Acc: 73.88%\n",
      "\t best  test acc: 73.88%\n",
      "Epoch: 02 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.390 | Train Acc: 83.96%\n",
      "\t test  Loss: 0.448 | test  Acc: 80.50%\n",
      "\t best  test acc: 80.50%\n",
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.338 | Train Acc: 87.78%\n",
      "\t test  Loss: 0.425 | test  Acc: 80.60%\n",
      "\t best  test acc: 80.60%\n",
      "Epoch: 04 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.299 | Train Acc: 89.81%\n",
      "\t test  Loss: 0.385 | test  Acc: 83.77%\n",
      "\t best  test acc: 83.77%\n",
      "Epoch: 05 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.254 | Train Acc: 91.73%\n",
      "\t test  Loss: 0.352 | test  Acc: 87.13%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 06 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.220 | Train Acc: 92.88%\n",
      "\t test  Loss: 0.354 | test  Acc: 87.03%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 07 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.192 | Train Acc: 94.00%\n",
      "\t test  Loss: 0.356 | test  Acc: 83.86%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 08 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.168 | Train Acc: 94.94%\n",
      "\t test  Loss: 0.364 | test  Acc: 86.38%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 09 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.158 | Train Acc: 95.27%\n",
      "\t test  Loss: 0.370 | test  Acc: 82.46%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 10 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.152 | Train Acc: 95.17%\n",
      "\t test  Loss: 0.364 | test  Acc: 86.10%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 11 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.133 | Train Acc: 95.93%\n",
      "\t test  Loss: 0.392 | test  Acc: 85.54%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 12 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.129 | Train Acc: 95.68%\n",
      "\t test  Loss: 0.393 | test  Acc: 85.17%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 13 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.110 | Train Acc: 96.37%\n",
      "\t test  Loss: 0.406 | test  Acc: 85.82%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 14 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.098 | Train Acc: 96.66%\n",
      "\t test  Loss: 0.461 | test  Acc: 84.89%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 15 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.093 | Train Acc: 96.55%\n",
      "\t test  Loss: 0.483 | test  Acc: 84.42%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 16 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.084 | Train Acc: 96.90%\n",
      "\t test  Loss: 0.469 | test  Acc: 84.61%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 17 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.074 | Train Acc: 97.46%\n",
      "\t test  Loss: 0.515 | test  Acc: 84.51%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 18 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.075 | Train Acc: 97.26%\n",
      "\t test  Loss: 0.479 | test  Acc: 85.07%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 19 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.068 | Train Acc: 97.49%\n",
      "\t test  Loss: 0.485 | test  Acc: 84.70%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 20 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.067 | Train Acc: 97.63%\n",
      "\t test  Loss: 0.481 | test  Acc: 84.98%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 21 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.060 | Train Acc: 97.56%\n",
      "\t test  Loss: 0.507 | test  Acc: 85.17%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 22 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.059 | Train Acc: 97.72%\n",
      "\t test  Loss: 0.569 | test  Acc: 83.58%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 23 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.055 | Train Acc: 97.72%\n",
      "\t test  Loss: 0.540 | test  Acc: 84.24%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 24 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.048 | Train Acc: 98.03%\n",
      "\t test  Loss: 0.599 | test  Acc: 83.96%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 25 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.040 | Train Acc: 98.36%\n",
      "\t test  Loss: 0.658 | test  Acc: 83.40%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 26 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.037 | Train Acc: 98.42%\n",
      "\t test  Loss: 0.655 | test  Acc: 83.12%\n",
      "\t best  test acc: 87.13%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        # self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "\n",
    "        self.amplitude_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        phase_is_sentiment = self.phase_embedding(text)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,489,401 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.531 | Train Acc: 74.41%\n",
      "\t test  Loss: 0.460 | test  Acc: 81.25%\n",
      "\t best  test acc: 81.25%\n",
      "Epoch: 02 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.348 | Train Acc: 87.75%\n",
      "\t test  Loss: 0.380 | test  Acc: 85.63%\n",
      "\t best  test acc: 85.63%\n",
      "Epoch: 03 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.261 | Train Acc: 91.28%\n",
      "\t test  Loss: 0.356 | test  Acc: 86.94%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 04 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.215 | Train Acc: 93.34%\n",
      "\t test  Loss: 0.384 | test  Acc: 85.45%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 05 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.190 | Train Acc: 94.11%\n",
      "\t test  Loss: 0.396 | test  Acc: 83.21%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 06 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.178 | Train Acc: 94.64%\n",
      "\t test  Loss: 0.401 | test  Acc: 85.17%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 07 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.157 | Train Acc: 95.16%\n",
      "\t test  Loss: 0.401 | test  Acc: 84.51%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 08 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.145 | Train Acc: 95.39%\n",
      "\t test  Loss: 0.412 | test  Acc: 84.33%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 09 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.129 | Train Acc: 95.90%\n",
      "\t test  Loss: 0.444 | test  Acc: 81.16%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 10 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.122 | Train Acc: 95.95%\n",
      "\t test  Loss: 0.427 | test  Acc: 85.07%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 11 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.113 | Train Acc: 96.16%\n",
      "\t test  Loss: 0.434 | test  Acc: 83.58%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 12 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.099 | Train Acc: 96.52%\n",
      "\t test  Loss: 0.459 | test  Acc: 83.77%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 13 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.089 | Train Acc: 96.90%\n",
      "\t test  Loss: 0.458 | test  Acc: 85.07%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 14 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.093 | Train Acc: 96.74%\n",
      "\t test  Loss: 0.500 | test  Acc: 84.61%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 15 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.085 | Train Acc: 96.98%\n",
      "\t test  Loss: 0.483 | test  Acc: 84.98%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 16 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.076 | Train Acc: 97.29%\n",
      "\t test  Loss: 0.531 | test  Acc: 82.09%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 17 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.066 | Train Acc: 97.63%\n",
      "\t test  Loss: 0.526 | test  Acc: 84.79%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 18 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.068 | Train Acc: 97.52%\n",
      "\t test  Loss: 0.523 | test  Acc: 85.07%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 19 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.066 | Train Acc: 97.56%\n",
      "\t test  Loss: 0.559 | test  Acc: 84.24%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 20 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.056 | Train Acc: 97.94%\n",
      "\t test  Loss: 0.557 | test  Acc: 85.26%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 21 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.060 | Train Acc: 97.73%\n",
      "\t test  Loss: 0.634 | test  Acc: 84.51%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 22 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.059 | Train Acc: 97.63%\n",
      "\t test  Loss: 0.616 | test  Acc: 84.89%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 23 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.057 | Train Acc: 97.76%\n",
      "\t test  Loss: 0.642 | test  Acc: 84.42%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 24 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.058 | Train Acc: 97.67%\n",
      "\t test  Loss: 0.618 | test  Acc: 84.24%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 25 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.050 | Train Acc: 97.99%\n",
      "\t test  Loss: 0.630 | test  Acc: 84.14%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 26 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.052 | Train Acc: 97.88%\n",
      "\t test  Loss: 0.656 | test  Acc: 81.53%\n",
      "\t best  test acc: 86.94%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}