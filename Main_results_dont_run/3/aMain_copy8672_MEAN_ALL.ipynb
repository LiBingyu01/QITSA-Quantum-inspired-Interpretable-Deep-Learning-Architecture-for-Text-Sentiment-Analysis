{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 393,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'CR'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: CR\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([4749, 100])\n",
      "4749\n",
      "4749\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # sentiment_weight = inputs[2]\n",
    "        # sentiment_weight = sentiment_weight.permute(1, 0)\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrix(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(projection_CalculateMatrix, self).__init__()  # projection是子类名\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        real_part = inputs[0]\n",
    "        imag_part = inputs[1]\n",
    "\n",
    "        # --- 求欧拉展开式之后的虚数乘法，一个句子一个句子的乘得到【每个单词的密度矩阵】\n",
    "        real_part_expand = torch.unsqueeze(real_part, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(imag_part, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # ================ 分开实数和虚数密度矩阵 ================\n",
    "        v_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                           imag_part_expand_transpose)\n",
    "        v_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                           imag_part_expand_transpose)\n",
    "        # --- 将单词的密度矩阵直接求平均值，得到句子的密度矩阵\n",
    "\n",
    "        v_real_avg = torch.mean(v_real, dim=1)\n",
    "        v_imag_avg = torch.mean(v_imag, dim=1)\n",
    "\n",
    "        return [v_real_avg, v_imag_avg]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "source": [
    "# -------------------- 01 Model_best_copy_mean ------------------------\n",
    "print(\"Model_best_copy_mean\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.layer_norm1 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.layer_norm2 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "        # ================ 3、自注意力机制 ================\n",
    "        self.attention = self_attention(embedding_dim)\n",
    "\n",
    "        # ================ 4、计算密度矩阵 ================\n",
    "        self.projection_Euler = projection_Euler()\n",
    "        self.projection_CalculateMatrix = projection_CalculateMatrix()\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 5、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 6、池化 ================\n",
    "        #         self.avgPool1 = nn.AvgPool2d((embedding_dim-2, 1), 1)\n",
    "        #         self.avgPool2 = nn.AvgPool2d((embedding_dim-2, 1), 1)\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 7、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        # phase_is_sentiment = sentiment_unsqueeze\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_sentiment = self.phase_embedding_sentiment(sentiment)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.attention(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1,0,2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.attention(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 4、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrix(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 5、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 6、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 7、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy_mean\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 769,701 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 2s\n",
      "\t Train Loss: 0.658 | Train Acc: 63.62%\n",
      "\t test  Loss: 0.653 | test  Acc: 64.06%\n",
      "\t best  test acc: 64.06%\n",
      "Epoch: 02 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.656 | Train Acc: 63.62%\n",
      "\t test  Loss: 0.652 | test  Acc: 64.06%\n",
      "\t best  test acc: 64.06%\n",
      "Epoch: 03 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.654 | Train Acc: 63.62%\n",
      "\t test  Loss: 0.648 | test  Acc: 64.06%\n",
      "\t best  test acc: 64.06%\n",
      "Epoch: 04 | Epoch Time: 0m 2s\n",
      "\t Train Loss: 0.643 | Train Acc: 63.62%\n",
      "\t test  Loss: 0.627 | test  Acc: 64.06%\n",
      "\t best  test acc: 64.06%\n",
      "Epoch: 05 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.579 | Train Acc: 70.07%\n",
      "\t test  Loss: 0.530 | test  Acc: 82.81%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 06 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.446 | Train Acc: 85.95%\n",
      "\t test  Loss: 0.454 | test  Acc: 82.29%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 07 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.331 | Train Acc: 89.85%\n",
      "\t test  Loss: 0.446 | test  Acc: 81.77%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 08 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.266 | Train Acc: 92.10%\n",
      "\t test  Loss: 0.426 | test  Acc: 83.59%\n",
      "\t best  test acc: 83.59%\n",
      "Epoch: 09 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.221 | Train Acc: 93.52%\n",
      "\t test  Loss: 0.437 | test  Acc: 81.51%\n",
      "\t best  test acc: 83.59%\n",
      "Epoch: 10 | Epoch Time: 0m 2s\n",
      "\t Train Loss: 0.181 | Train Acc: 95.34%\n",
      "\t test  Loss: 0.441 | test  Acc: 83.33%\n",
      "\t best  test acc: 83.59%\n",
      "Epoch: 11 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.152 | Train Acc: 96.36%\n",
      "\t test  Loss: 0.452 | test  Acc: 83.59%\n",
      "\t best  test acc: 83.59%\n",
      "Epoch: 12 | Epoch Time: 0m 2s\n",
      "\t Train Loss: 0.129 | Train Acc: 96.92%\n",
      "\t test  Loss: 0.451 | test  Acc: 83.85%\n",
      "\t best  test acc: 83.85%\n",
      "Epoch: 13 | Epoch Time: 0m 2s\n",
      "\t Train Loss: 0.107 | Train Acc: 97.62%\n",
      "\t test  Loss: 0.481 | test  Acc: 83.85%\n",
      "\t best  test acc: 83.85%\n",
      "Epoch: 14 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.095 | Train Acc: 98.02%\n",
      "\t test  Loss: 0.522 | test  Acc: 83.59%\n",
      "\t best  test acc: 83.85%\n",
      "Epoch: 15 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.092 | Train Acc: 97.98%\n",
      "\t test  Loss: 0.495 | test  Acc: 84.64%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 16 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.079 | Train Acc: 98.38%\n",
      "\t test  Loss: 0.496 | test  Acc: 84.11%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 17 | Epoch Time: 0m 2s\n",
      "\t Train Loss: 0.072 | Train Acc: 98.58%\n",
      "\t test  Loss: 0.542 | test  Acc: 82.81%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 18 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.065 | Train Acc: 98.64%\n",
      "\t test  Loss: 0.620 | test  Acc: 81.77%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 19 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.064 | Train Acc: 98.64%\n",
      "\t test  Loss: 0.576 | test  Acc: 82.81%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 20 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.072 | Train Acc: 98.35%\n",
      "\t test  Loss: 0.613 | test  Acc: 82.29%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 21 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.061 | Train Acc: 98.64%\n",
      "\t test  Loss: 0.590 | test  Acc: 82.55%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 22 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.051 | Train Acc: 99.04%\n",
      "\t test  Loss: 0.621 | test  Acc: 83.33%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 23 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.043 | Train Acc: 99.17%\n",
      "\t test  Loss: 0.650 | test  Acc: 83.33%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 24 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.040 | Train Acc: 99.31%\n",
      "\t test  Loss: 0.669 | test  Acc: 82.55%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 25 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.036 | Train Acc: 99.37%\n",
      "\t test  Loss: 0.681 | test  Acc: 82.03%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 26 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.040 | Train Acc: 99.17%\n",
      "\t test  Loss: 0.642 | test  Acc: 84.11%\n",
      "\t best  test acc: 84.64%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MR'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MR\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([16143, 100])\n",
      "16143\n",
      "16143\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # sentiment_weight = inputs[2]\n",
    "        # sentiment_weight = sentiment_weight.permute(1, 0)\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrix(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(projection_CalculateMatrix, self).__init__()  # projection是子类名\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        real_part = inputs[0]\n",
    "        imag_part = inputs[1]\n",
    "\n",
    "        # --- 求欧拉展开式之后的虚数乘法，一个句子一个句子的乘得到【每个单词的密度矩阵】\n",
    "        real_part_expand = torch.unsqueeze(real_part, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(imag_part, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # ================ 分开实数和虚数密度矩阵 ================\n",
    "        v_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                           imag_part_expand_transpose)\n",
    "        v_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                           imag_part_expand_transpose)\n",
    "        # --- 将单词的密度矩阵直接求平均值，得到句子的密度矩阵\n",
    "\n",
    "        v_real_avg = torch.mean(v_real, dim=1)\n",
    "        v_imag_avg = torch.mean(v_imag, dim=1)\n",
    "\n",
    "        return [v_real_avg, v_imag_avg]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "source": [
    "# -------------------- 01 Model_best_copy_mean ------------------------\n",
    "print(\"Model_best_copy_mean\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.layer_norm1 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.layer_norm2 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "        # ================ 3、自注意力机制 ================\n",
    "        self.attention = self_attention(embedding_dim)\n",
    "\n",
    "        # ================ 4、计算密度矩阵 ================\n",
    "        self.projection_Euler = projection_Euler()\n",
    "        self.projection_CalculateMatrix = projection_CalculateMatrix()\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 5、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 6、池化 ================\n",
    "        #         self.avgPool1 = nn.AvgPool2d((embedding_dim-2, 1), 1)\n",
    "        #         self.avgPool2 = nn.AvgPool2d((embedding_dim-2, 1), 1)\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 7、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        # phase_is_sentiment = sentiment_unsqueeze\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_sentiment = self.phase_embedding_sentiment(sentiment)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.attention(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1,0,2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.attention(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 4、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrix(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 5、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 6、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 7、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy_mean\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,909,101 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.694 | Train Acc: 49.94%\n",
      "\t test  Loss: 0.692 | test  Acc: 52.44%\n",
      "\t best  test acc: 52.44%\n",
      "Epoch: 02 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.694 | Train Acc: 50.44%\n",
      "\t test  Loss: 0.693 | test  Acc: 53.38%\n",
      "\t best  test acc: 53.38%\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.690 | Train Acc: 52.18%\n",
      "\t test  Loss: 0.680 | test  Acc: 59.85%\n",
      "\t best  test acc: 59.85%\n",
      "Epoch: 04 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.565 | Train Acc: 76.51%\n",
      "\t test  Loss: 0.524 | test  Acc: 75.20%\n",
      "\t best  test acc: 75.20%\n",
      "Epoch: 05 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.351 | Train Acc: 87.57%\n",
      "\t test  Loss: 0.530 | test  Acc: 77.07%\n",
      "\t best  test acc: 77.07%\n",
      "Epoch: 06 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.234 | Train Acc: 92.99%\n",
      "\t test  Loss: 0.580 | test  Acc: 78.56%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 07 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.179 | Train Acc: 95.20%\n",
      "\t test  Loss: 0.671 | test  Acc: 77.39%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 08 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.148 | Train Acc: 96.23%\n",
      "\t test  Loss: 0.736 | test  Acc: 75.99%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 09 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.143 | Train Acc: 96.34%\n",
      "\t test  Loss: 0.752 | test  Acc: 76.55%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 10 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.131 | Train Acc: 96.58%\n",
      "\t test  Loss: 0.746 | test  Acc: 77.02%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 11 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.109 | Train Acc: 97.23%\n",
      "\t test  Loss: 0.783 | test  Acc: 76.05%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 12 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.100 | Train Acc: 97.48%\n",
      "\t test  Loss: 0.897 | test  Acc: 74.60%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 13 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.084 | Train Acc: 98.05%\n",
      "\t test  Loss: 0.838 | test  Acc: 76.79%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 14 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.071 | Train Acc: 98.42%\n",
      "\t test  Loss: 0.858 | test  Acc: 76.93%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 15 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.064 | Train Acc: 98.67%\n",
      "\t test  Loss: 0.916 | test  Acc: 76.23%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 16 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.058 | Train Acc: 98.71%\n",
      "\t test  Loss: 0.969 | test  Acc: 75.12%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 17 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.045 | Train Acc: 98.89%\n",
      "\t test  Loss: 1.064 | test  Acc: 74.37%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 18 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.037 | Train Acc: 98.88%\n",
      "\t test  Loss: 1.099 | test  Acc: 74.36%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 19 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.027 | Train Acc: 99.29%\n",
      "\t test  Loss: 1.162 | test  Acc: 74.46%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 20 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.018 | Train Acc: 99.64%\n",
      "\t test  Loss: 1.231 | test  Acc: 74.55%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 21 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.015 | Train Acc: 99.66%\n",
      "\t test  Loss: 1.242 | test  Acc: 74.27%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 22 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.010 | Train Acc: 99.80%\n",
      "\t test  Loss: 1.302 | test  Acc: 74.75%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 23 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.010 | Train Acc: 99.78%\n",
      "\t test  Loss: 1.352 | test  Acc: 74.28%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 24 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.009 | Train Acc: 99.82%\n",
      "\t test  Loss: 1.383 | test  Acc: 74.32%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 25 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.005 | Train Acc: 99.93%\n",
      "\t test  Loss: 1.454 | test  Acc: 73.81%\n",
      "\t best  test acc: 78.56%\n",
      "Epoch: 26 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.005 | Train Acc: 99.94%\n",
      "\t test  Loss: 1.490 | test  Acc: 73.67%\n",
      "\t best  test acc: 78.56%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'SST'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: SST\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([13772, 100])\n",
      "13772\n",
      "13772\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # sentiment_weight = inputs[2]\n",
    "        # sentiment_weight = sentiment_weight.permute(1, 0)\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrix(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(projection_CalculateMatrix, self).__init__()  # projection是子类名\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        real_part = inputs[0]\n",
    "        imag_part = inputs[1]\n",
    "\n",
    "        # --- 求欧拉展开式之后的虚数乘法，一个句子一个句子的乘得到【每个单词的密度矩阵】\n",
    "        real_part_expand = torch.unsqueeze(real_part, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(imag_part, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # ================ 分开实数和虚数密度矩阵 ================\n",
    "        v_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                           imag_part_expand_transpose)\n",
    "        v_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                           imag_part_expand_transpose)\n",
    "        # --- 将单词的密度矩阵直接求平均值，得到句子的密度矩阵\n",
    "\n",
    "        v_real_avg = torch.mean(v_real, dim=1)\n",
    "        v_imag_avg = torch.mean(v_imag, dim=1)\n",
    "\n",
    "        return [v_real_avg, v_imag_avg]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "source": [
    "# -------------------- 01 Model_best_copy_mean ------------------------\n",
    "print(\"Model_best_copy_mean\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.layer_norm1 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.layer_norm2 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "        # ================ 3、自注意力机制 ================\n",
    "        self.attention = self_attention(embedding_dim)\n",
    "\n",
    "        # ================ 4、计算密度矩阵 ================\n",
    "        self.projection_Euler = projection_Euler()\n",
    "        self.projection_CalculateMatrix = projection_CalculateMatrix()\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 5、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 6、池化 ================\n",
    "        #         self.avgPool1 = nn.AvgPool2d((embedding_dim-2, 1), 1)\n",
    "        #         self.avgPool2 = nn.AvgPool2d((embedding_dim-2, 1), 1)\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 7、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        # phase_is_sentiment = sentiment_unsqueeze\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_sentiment = self.phase_embedding_sentiment(sentiment)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.attention(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1,0,2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.attention(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 4、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrix(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 5、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 6、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 7、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy_mean\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,672,001 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 1m 11s\n",
      "\t Train Loss: 0.411 | Train Acc: 80.57%\n",
      "\t test  Loss: 0.390 | test  Acc: 82.97%\n",
      "\t best  test acc: 82.97%\n",
      "Epoch: 02 | Epoch Time: 1m 11s\n",
      "\t Train Loss: 0.201 | Train Acc: 92.56%\n",
      "\t test  Loss: 0.366 | test  Acc: 85.91%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 03 | Epoch Time: 1m 8s\n",
      "\t Train Loss: 0.143 | Train Acc: 94.85%\n",
      "\t test  Loss: 0.429 | test  Acc: 85.32%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 04 | Epoch Time: 1m 9s\n",
      "\t Train Loss: 0.113 | Train Acc: 96.06%\n",
      "\t test  Loss: 0.486 | test  Acc: 84.60%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 05 | Epoch Time: 1m 9s\n",
      "\t Train Loss: 0.092 | Train Acc: 96.81%\n",
      "\t test  Loss: 0.510 | test  Acc: 84.78%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 06 | Epoch Time: 1m 13s\n",
      "\t Train Loss: 0.079 | Train Acc: 97.31%\n",
      "\t test  Loss: 0.613 | test  Acc: 83.73%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 07 | Epoch Time: 1m 4s\n",
      "\t Train Loss: 0.067 | Train Acc: 97.74%\n",
      "\t test  Loss: 0.557 | test  Acc: 83.47%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 08 | Epoch Time: 1m 10s\n",
      "\t Train Loss: 0.058 | Train Acc: 98.00%\n",
      "\t test  Loss: 0.728 | test  Acc: 83.51%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 09 | Epoch Time: 1m 16s\n",
      "\t Train Loss: 0.054 | Train Acc: 98.13%\n",
      "\t test  Loss: 0.676 | test  Acc: 83.14%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 10 | Epoch Time: 1m 15s\n",
      "\t Train Loss: 0.047 | Train Acc: 98.37%\n",
      "\t test  Loss: 0.770 | test  Acc: 82.97%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 11 | Epoch Time: 1m 12s\n",
      "\t Train Loss: 0.045 | Train Acc: 98.39%\n",
      "\t test  Loss: 0.699 | test  Acc: 82.25%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 12 | Epoch Time: 1m 13s\n",
      "\t Train Loss: 0.042 | Train Acc: 98.51%\n",
      "\t test  Loss: 0.823 | test  Acc: 82.58%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 13 | Epoch Time: 1m 17s\n",
      "\t Train Loss: 0.038 | Train Acc: 98.61%\n",
      "\t test  Loss: 0.843 | test  Acc: 82.03%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 14 | Epoch Time: 1m 12s\n",
      "\t Train Loss: 0.035 | Train Acc: 98.66%\n",
      "\t test  Loss: 0.836 | test  Acc: 82.95%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 15 | Epoch Time: 1m 15s\n",
      "\t Train Loss: 0.033 | Train Acc: 98.74%\n",
      "\t test  Loss: 0.903 | test  Acc: 82.53%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 16 | Epoch Time: 1m 16s\n",
      "\t Train Loss: 0.031 | Train Acc: 98.79%\n",
      "\t test  Loss: 0.968 | test  Acc: 80.97%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 17 | Epoch Time: 1m 13s\n",
      "\t Train Loss: 0.028 | Train Acc: 98.85%\n",
      "\t test  Loss: 0.981 | test  Acc: 81.64%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 18 | Epoch Time: 1m 12s\n",
      "\t Train Loss: 0.027 | Train Acc: 98.89%\n",
      "\t test  Loss: 1.008 | test  Acc: 82.86%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 19 | Epoch Time: 1m 17s\n",
      "\t Train Loss: 0.026 | Train Acc: 98.95%\n",
      "\t test  Loss: 0.980 | test  Acc: 81.41%\n",
      "\t best  test acc: 85.91%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # sentiment_weight = inputs[2]\n",
    "        # sentiment_weight = sentiment_weight.permute(1, 0)\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrix(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(projection_CalculateMatrix, self).__init__()  # projection是子类名\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        real_part = inputs[0]\n",
    "        imag_part = inputs[1]\n",
    "\n",
    "        # --- 求欧拉展开式之后的虚数乘法，一个句子一个句子的乘得到【每个单词的密度矩阵】\n",
    "        real_part_expand = torch.unsqueeze(real_part, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(imag_part, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # ================ 分开实数和虚数密度矩阵 ================\n",
    "        v_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                           imag_part_expand_transpose)\n",
    "        v_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                           imag_part_expand_transpose)\n",
    "        # --- 将单词的密度矩阵直接求平均值，得到句子的密度矩阵\n",
    "\n",
    "        v_real_avg = torch.mean(v_real, dim=1)\n",
    "        v_imag_avg = torch.mean(v_imag, dim=1)\n",
    "\n",
    "        return [v_real_avg, v_imag_avg]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# -------------------- 01 Model_best_copy_mean ------------------------\n",
    "print(\"Model_best_copy_mean\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.layer_norm1 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.layer_norm2 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "        # ================ 3、自注意力机制 ================\n",
    "        self.attention = self_attention(embedding_dim)\n",
    "\n",
    "        # ================ 4、计算密度矩阵 ================\n",
    "        self.projection_Euler = projection_Euler()\n",
    "        self.projection_CalculateMatrix = projection_CalculateMatrix()\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 5、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 6、池化 ================\n",
    "        #         self.avgPool1 = nn.AvgPool2d((embedding_dim-2, 1), 1)\n",
    "        #         self.avgPool2 = nn.AvgPool2d((embedding_dim-2, 1), 1)\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 7、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        # phase_is_sentiment = sentiment_unsqueeze\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_sentiment = self.phase_embedding_sentiment(sentiment)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.attention(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1,0,2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.attention(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 4、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrix(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 5、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 6、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 7、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy_mean\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 851,601 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.621 | Train Acc: 68.66%\n",
      "\t test  Loss: 0.617 | test  Acc: 68.38%\n",
      "\t best  test acc: 68.38%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.502 | Train Acc: 77.60%\n",
      "\t test  Loss: 0.407 | test  Acc: 85.26%\n",
      "\t best  test acc: 85.26%\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.310 | Train Acc: 89.95%\n",
      "\t test  Loss: 0.393 | test  Acc: 83.30%\n",
      "\t best  test acc: 85.26%\n",
      "Epoch: 04 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.241 | Train Acc: 92.49%\n",
      "\t test  Loss: 0.372 | test  Acc: 83.77%\n",
      "\t best  test acc: 85.26%\n",
      "Epoch: 05 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.201 | Train Acc: 93.96%\n",
      "\t test  Loss: 0.377 | test  Acc: 84.24%\n",
      "\t best  test acc: 85.26%\n",
      "Epoch: 06 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.172 | Train Acc: 95.03%\n",
      "\t test  Loss: 0.382 | test  Acc: 83.40%\n",
      "\t best  test acc: 85.26%\n",
      "Epoch: 07 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.150 | Train Acc: 95.79%\n",
      "\t test  Loss: 0.379 | test  Acc: 85.91%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 08 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.134 | Train Acc: 96.33%\n",
      "\t test  Loss: 0.397 | test  Acc: 83.96%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 09 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.123 | Train Acc: 96.53%\n",
      "\t test  Loss: 0.421 | test  Acc: 82.37%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 10 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.112 | Train Acc: 96.77%\n",
      "\t test  Loss: 0.435 | test  Acc: 83.86%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 11 | Epoch Time: 0m 6s\n",
      "\t Train Loss: 0.100 | Train Acc: 97.14%\n",
      "\t test  Loss: 0.471 | test  Acc: 82.84%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 12 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.090 | Train Acc: 97.26%\n",
      "\t test  Loss: 0.521 | test  Acc: 80.60%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 13 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.083 | Train Acc: 97.50%\n",
      "\t test  Loss: 0.492 | test  Acc: 82.46%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 14 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.084 | Train Acc: 97.38%\n",
      "\t test  Loss: 0.523 | test  Acc: 81.81%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 15 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.071 | Train Acc: 97.74%\n",
      "\t test  Loss: 0.538 | test  Acc: 80.78%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 16 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.067 | Train Acc: 97.90%\n",
      "\t test  Loss: 0.562 | test  Acc: 80.69%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.062 | Train Acc: 97.98%\n",
      "\t test  Loss: 0.576 | test  Acc: 80.41%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 18 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.058 | Train Acc: 98.03%\n",
      "\t test  Loss: 0.555 | test  Acc: 82.46%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 19 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.050 | Train Acc: 98.28%\n",
      "\t test  Loss: 0.595 | test  Acc: 80.22%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 20 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.050 | Train Acc: 98.16%\n",
      "\t test  Loss: 0.597 | test  Acc: 80.88%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 21 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.047 | Train Acc: 98.20%\n",
      "\t test  Loss: 0.648 | test  Acc: 79.94%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 22 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.041 | Train Acc: 98.43%\n",
      "\t test  Loss: 0.654 | test  Acc: 81.44%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 23 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.043 | Train Acc: 98.36%\n",
      "\t test  Loss: 0.637 | test  Acc: 80.32%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 24 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.040 | Train Acc: 98.43%\n",
      "\t test  Loss: 0.629 | test  Acc: 81.44%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 25 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.038 | Train Acc: 98.54%\n",
      "\t test  Loss: 0.667 | test  Acc: 79.48%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 26 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.035 | Train Acc: 98.61%\n",
      "\t test  Loss: 0.650 | test  Acc: 81.53%\n",
      "\t best  test acc: 85.91%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # sentiment_weight = inputs[2]\n",
    "        # sentiment_weight = sentiment_weight.permute(1, 0)\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrix(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(projection_CalculateMatrix, self).__init__()  # projection是子类名\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        real_part = inputs[0]\n",
    "        imag_part = inputs[1]\n",
    "\n",
    "        # --- 求欧拉展开式之后的虚数乘法，一个句子一个句子的乘得到【每个单词的密度矩阵】\n",
    "        real_part_expand = torch.unsqueeze(real_part, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(imag_part, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # ================ 分开实数和虚数密度矩阵 ================\n",
    "        v_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                           imag_part_expand_transpose)\n",
    "        v_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                           imag_part_expand_transpose)\n",
    "        # --- 将单词的密度矩阵直接求平均值，得到句子的密度矩阵\n",
    "\n",
    "        v_real_avg = torch.mean(v_real, dim=1)\n",
    "        v_imag_avg = torch.mean(v_imag, dim=1)\n",
    "\n",
    "        return [v_real_avg, v_imag_avg]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# -------------------- 01 Model_best_copy_mean ------------------------\n",
    "print(\"Model_best_copy_mean\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.layer_norm1 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.layer_norm2 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "        # ================ 3、自注意力机制 ================\n",
    "        self.attention = self_attention(embedding_dim)\n",
    "\n",
    "        # ================ 4、计算密度矩阵 ================\n",
    "        self.projection_Euler = projection_Euler()\n",
    "        self.projection_CalculateMatrix = projection_CalculateMatrix()\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 5、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 6、池化 ================\n",
    "        #         self.avgPool1 = nn.AvgPool2d((embedding_dim-2, 1), 1)\n",
    "        #         self.avgPool2 = nn.AvgPool2d((embedding_dim-2, 1), 1)\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 7、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        # phase_is_sentiment = sentiment_unsqueeze\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_sentiment = self.phase_embedding_sentiment(sentiment)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.attention(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1,0,2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.attention(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 4、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrix(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 5、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 6、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 7、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy_mean\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 851,601 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.621 | Train Acc: 68.66%\n",
      "\t test  Loss: 0.618 | test  Acc: 68.38%\n",
      "\t best  test acc: 68.38%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.492 | Train Acc: 78.65%\n",
      "\t test  Loss: 0.395 | test  Acc: 85.45%\n",
      "\t best  test acc: 85.45%\n",
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.279 | Train Acc: 90.93%\n",
      "\t test  Loss: 0.332 | test  Acc: 87.13%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 04 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.207 | Train Acc: 93.75%\n",
      "\t test  Loss: 0.356 | test  Acc: 86.19%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 05 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.171 | Train Acc: 95.02%\n",
      "\t test  Loss: 0.379 | test  Acc: 83.68%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 06 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.146 | Train Acc: 95.83%\n",
      "\t test  Loss: 0.396 | test  Acc: 84.05%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 07 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.128 | Train Acc: 96.22%\n",
      "\t test  Loss: 0.406 | test  Acc: 84.24%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 08 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.113 | Train Acc: 96.70%\n",
      "\t test  Loss: 0.428 | test  Acc: 82.46%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 09 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.102 | Train Acc: 96.88%\n",
      "\t test  Loss: 0.472 | test  Acc: 80.69%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 10 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.092 | Train Acc: 97.26%\n",
      "\t test  Loss: 0.473 | test  Acc: 82.09%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 11 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.081 | Train Acc: 97.41%\n",
      "\t test  Loss: 0.486 | test  Acc: 81.62%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 12 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.072 | Train Acc: 97.68%\n",
      "\t test  Loss: 0.521 | test  Acc: 82.28%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 13 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.067 | Train Acc: 97.90%\n",
      "\t test  Loss: 0.498 | test  Acc: 83.58%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 14 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.065 | Train Acc: 97.94%\n",
      "\t test  Loss: 0.533 | test  Acc: 82.93%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 15 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.063 | Train Acc: 97.83%\n",
      "\t test  Loss: 0.529 | test  Acc: 82.93%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 16 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.059 | Train Acc: 97.93%\n",
      "\t test  Loss: 0.530 | test  Acc: 83.12%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.054 | Train Acc: 98.15%\n",
      "\t test  Loss: 0.557 | test  Acc: 82.56%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 18 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.053 | Train Acc: 98.08%\n",
      "\t test  Loss: 0.558 | test  Acc: 82.56%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 19 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.046 | Train Acc: 98.40%\n",
      "\t test  Loss: 0.598 | test  Acc: 82.18%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 20 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.046 | Train Acc: 98.31%\n",
      "\t test  Loss: 0.626 | test  Acc: 82.46%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 21 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.040 | Train Acc: 98.58%\n",
      "\t test  Loss: 0.661 | test  Acc: 82.65%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 22 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.040 | Train Acc: 98.56%\n",
      "\t test  Loss: 0.650 | test  Acc: 82.37%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 23 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.038 | Train Acc: 98.63%\n",
      "\t test  Loss: 0.669 | test  Acc: 82.56%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 24 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.043 | Train Acc: 98.51%\n",
      "\t test  Loss: 0.599 | test  Acc: 82.65%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 25 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.038 | Train Acc: 98.61%\n",
      "\t test  Loss: 0.646 | test  Acc: 82.09%\n",
      "\t best  test acc: 87.13%\n",
      "Epoch: 26 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.036 | Train Acc: 98.76%\n",
      "\t test  Loss: 0.685 | test  Acc: 82.84%\n",
      "\t best  test acc: 87.13%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # sentiment_weight = inputs[2]\n",
    "        # sentiment_weight = sentiment_weight.permute(1, 0)\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrix(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(projection_CalculateMatrix, self).__init__()  # projection是子类名\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        real_part = inputs[0]\n",
    "        imag_part = inputs[1]\n",
    "\n",
    "        # --- 求欧拉展开式之后的虚数乘法，一个句子一个句子的乘得到【每个单词的密度矩阵】\n",
    "        real_part_expand = torch.unsqueeze(real_part, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(imag_part, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # ================ 分开实数和虚数密度矩阵 ================\n",
    "        v_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                           imag_part_expand_transpose)\n",
    "        v_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                           imag_part_expand_transpose)\n",
    "        # --- 将单词的密度矩阵直接求平均值，得到句子的密度矩阵\n",
    "\n",
    "        v_real_avg = torch.mean(v_real, dim=1)\n",
    "        v_imag_avg = torch.mean(v_imag, dim=1)\n",
    "\n",
    "        return [v_real_avg, v_imag_avg]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "# -------------------- 01 Model_best_copy_mean ------------------------\n",
    "print(\"Model_best_copy_mean\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.layer_norm1 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.layer_norm2 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "        # ================ 3、自注意力机制 ================\n",
    "        self.attention = self_attention(embedding_dim)\n",
    "\n",
    "        # ================ 4、计算密度矩阵 ================\n",
    "        self.projection_Euler = projection_Euler()\n",
    "        self.projection_CalculateMatrix = projection_CalculateMatrix()\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 5、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 6、池化 ================\n",
    "        #         self.avgPool1 = nn.AvgPool2d((embedding_dim-2, 1), 1)\n",
    "        #         self.avgPool2 = nn.AvgPool2d((embedding_dim-2, 1), 1)\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 7、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        # phase_is_sentiment = sentiment_unsqueeze\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_sentiment = self.phase_embedding_sentiment(sentiment)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.attention(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1,0,2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.attention(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 4、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrix(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 5、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 6、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 7、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy_mean\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 851,601 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.622 | Train Acc: 68.61%\n",
      "\t test  Loss: 0.615 | test  Acc: 68.38%\n",
      "\t best  test acc: 68.38%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.491 | Train Acc: 77.86%\n",
      "\t test  Loss: 0.417 | test  Acc: 84.61%\n",
      "\t best  test acc: 84.61%\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.312 | Train Acc: 89.62%\n",
      "\t test  Loss: 0.364 | test  Acc: 85.91%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 04 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.238 | Train Acc: 92.55%\n",
      "\t test  Loss: 0.373 | test  Acc: 85.73%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 05 | Epoch Time: 0m 6s\n",
      "\t Train Loss: 0.200 | Train Acc: 94.14%\n",
      "\t test  Loss: 0.390 | test  Acc: 85.63%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 06 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.173 | Train Acc: 95.02%\n",
      "\t test  Loss: 0.405 | test  Acc: 85.73%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 07 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.150 | Train Acc: 95.75%\n",
      "\t test  Loss: 0.429 | test  Acc: 85.26%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 08 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.133 | Train Acc: 96.06%\n",
      "\t test  Loss: 0.459 | test  Acc: 85.54%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 09 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.119 | Train Acc: 96.47%\n",
      "\t test  Loss: 0.481 | test  Acc: 84.89%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 10 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.109 | Train Acc: 96.61%\n",
      "\t test  Loss: 0.487 | test  Acc: 83.86%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 11 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.098 | Train Acc: 97.12%\n",
      "\t test  Loss: 0.525 | test  Acc: 83.68%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 12 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.091 | Train Acc: 97.09%\n",
      "\t test  Loss: 0.528 | test  Acc: 82.65%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 13 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.083 | Train Acc: 97.38%\n",
      "\t test  Loss: 0.530 | test  Acc: 84.70%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 14 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.076 | Train Acc: 97.55%\n",
      "\t test  Loss: 0.531 | test  Acc: 83.21%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 15 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.065 | Train Acc: 97.89%\n",
      "\t test  Loss: 0.549 | test  Acc: 83.21%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 16 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.060 | Train Acc: 98.12%\n",
      "\t test  Loss: 0.570 | test  Acc: 82.65%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.059 | Train Acc: 98.08%\n",
      "\t test  Loss: 0.593 | test  Acc: 82.28%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 18 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.057 | Train Acc: 98.12%\n",
      "\t test  Loss: 0.596 | test  Acc: 82.09%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 19 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.053 | Train Acc: 98.32%\n",
      "\t test  Loss: 0.581 | test  Acc: 82.74%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 20 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.045 | Train Acc: 98.60%\n",
      "\t test  Loss: 0.620 | test  Acc: 82.18%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 21 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.042 | Train Acc: 98.60%\n",
      "\t test  Loss: 0.642 | test  Acc: 82.28%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 22 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.045 | Train Acc: 98.59%\n",
      "\t test  Loss: 0.618 | test  Acc: 82.84%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 23 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.047 | Train Acc: 98.42%\n",
      "\t test  Loss: 0.616 | test  Acc: 82.84%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 24 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.041 | Train Acc: 98.67%\n",
      "\t test  Loss: 0.635 | test  Acc: 82.93%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 25 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.038 | Train Acc: 98.74%\n",
      "\t test  Loss: 0.666 | test  Acc: 81.72%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 26 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.037 | Train Acc: 98.69%\n",
      "\t test  Loss: 0.672 | test  Acc: 81.16%\n",
      "\t best  test acc: 85.91%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'SUBJ'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: SUBJ\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([18512, 100])\n",
      "18512\n",
      "18512\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # sentiment_weight = inputs[2]\n",
    "        # sentiment_weight = sentiment_weight.permute(1, 0)\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrix(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(projection_CalculateMatrix, self).__init__()  # projection是子类名\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        real_part = inputs[0]\n",
    "        imag_part = inputs[1]\n",
    "\n",
    "        # --- 求欧拉展开式之后的虚数乘法，一个句子一个句子的乘得到【每个单词的密度矩阵】\n",
    "        real_part_expand = torch.unsqueeze(real_part, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(imag_part, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # ================ 分开实数和虚数密度矩阵 ================\n",
    "        v_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                           imag_part_expand_transpose)\n",
    "        v_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                           imag_part_expand_transpose)\n",
    "        # --- 将单词的密度矩阵直接求平均值，得到句子的密度矩阵\n",
    "\n",
    "        v_real_avg = torch.mean(v_real, dim=1)\n",
    "        v_imag_avg = torch.mean(v_imag, dim=1)\n",
    "\n",
    "        return [v_real_avg, v_imag_avg]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "source": [
    "# -------------------- 01 Model_best_copy_mean ------------------------\n",
    "print(\"Model_best_copy_mean\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.layer_norm1 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.layer_norm2 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "        # ================ 3、自注意力机制 ================\n",
    "        self.attention = self_attention(embedding_dim)\n",
    "\n",
    "        # ================ 4、计算密度矩阵 ================\n",
    "        self.projection_Euler = projection_Euler()\n",
    "        self.projection_CalculateMatrix = projection_CalculateMatrix()\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 5、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 6、池化 ================\n",
    "        #         self.avgPool1 = nn.AvgPool2d((embedding_dim-2, 1), 1)\n",
    "        #         self.avgPool2 = nn.AvgPool2d((embedding_dim-2, 1), 1)\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 7、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        # phase_is_sentiment = sentiment_unsqueeze\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_sentiment = self.phase_embedding_sentiment(sentiment)\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.attention(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1,0,2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.attention(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 4、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrix(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 5、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 6、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 7、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy_mean\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 2,146,001 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.688 | Train Acc: 56.53%\n",
      "\t test  Loss: 0.670 | test  Acc: 84.42%\n",
      "\t best  test acc: 84.42%\n",
      "Epoch: 02 | Epoch Time: 0m 6s\n",
      "\t Train Loss: 0.501 | Train Acc: 87.66%\n",
      "\t test  Loss: 0.363 | test  Acc: 88.49%\n",
      "\t best  test acc: 88.49%\n",
      "Epoch: 03 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.218 | Train Acc: 94.59%\n",
      "\t test  Loss: 0.237 | test  Acc: 92.76%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 04 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.126 | Train Acc: 96.89%\n",
      "\t test  Loss: 0.228 | test  Acc: 92.46%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 05 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.072 | Train Acc: 98.51%\n",
      "\t test  Loss: 0.247 | test  Acc: 92.36%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 06 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.043 | Train Acc: 99.22%\n",
      "\t test  Loss: 0.274 | test  Acc: 92.56%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 07 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.025 | Train Acc: 99.66%\n",
      "\t test  Loss: 0.324 | test  Acc: 91.96%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 08 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.018 | Train Acc: 99.80%\n",
      "\t test  Loss: 0.417 | test  Acc: 90.97%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 09 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.025 | Train Acc: 99.55%\n",
      "\t test  Loss: 0.405 | test  Acc: 90.97%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 10 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.024 | Train Acc: 99.61%\n",
      "\t test  Loss: 0.389 | test  Acc: 91.27%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 11 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.016 | Train Acc: 99.74%\n",
      "\t test  Loss: 0.404 | test  Acc: 91.96%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 12 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.013 | Train Acc: 99.79%\n",
      "\t test  Loss: 0.432 | test  Acc: 90.87%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 13 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.011 | Train Acc: 99.85%\n",
      "\t test  Loss: 0.382 | test  Acc: 92.26%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 14 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.010 | Train Acc: 99.83%\n",
      "\t test  Loss: 0.578 | test  Acc: 88.99%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 15 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.008 | Train Acc: 99.88%\n",
      "\t test  Loss: 0.445 | test  Acc: 91.77%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 16 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.006 | Train Acc: 99.92%\n",
      "\t test  Loss: 0.476 | test  Acc: 91.67%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 17 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.006 | Train Acc: 99.92%\n",
      "\t test  Loss: 0.491 | test  Acc: 91.57%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 18 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.005 | Train Acc: 99.91%\n",
      "\t test  Loss: 0.471 | test  Acc: 91.67%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 19 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.006 | Train Acc: 99.90%\n",
      "\t test  Loss: 0.588 | test  Acc: 89.88%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 20 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.020 | Train Acc: 99.55%\n",
      "\t test  Loss: 0.465 | test  Acc: 91.07%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 21 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.008 | Train Acc: 99.86%\n",
      "\t test  Loss: 0.505 | test  Acc: 90.77%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 22 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.006 | Train Acc: 99.91%\n",
      "\t test  Loss: 0.471 | test  Acc: 91.57%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 23 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.005 | Train Acc: 99.89%\n",
      "\t test  Loss: 0.602 | test  Acc: 88.99%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 24 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.006 | Train Acc: 99.90%\n",
      "\t test  Loss: 0.477 | test  Acc: 91.87%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 25 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.003 | Train Acc: 99.94%\n",
      "\t test  Loss: 0.506 | test  Acc: 91.96%\n",
      "\t best  test acc: 92.76%\n",
      "Epoch: 26 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.002 | Train Acc: 99.95%\n",
      "\t test  Loss: 0.600 | test  Acc: 90.67%\n",
      "\t best  test acc: 92.76%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}