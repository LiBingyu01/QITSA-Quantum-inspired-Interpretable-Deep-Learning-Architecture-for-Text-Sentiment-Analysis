{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 529,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2\n",
    "    \n",
    "# ===================== 02 Model_best_copy8672_cnn_diagonal =====================\n",
    "\n",
    "# print(\"Model_best_copy8672_cnn_diagonal\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim-2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、取对角线 ================\n",
    "#         diagonal_elements_real = Conv_real[:, 0, torch.arange(Conv_real.size(2)), torch.arange(Conv_real.size(3))]\n",
    "#         diagonal_elements_imag = Conv_imag[:, 0, torch.arange(Conv_imag.size(2)), torch.arange(Conv_imag.size(3))]\n",
    "\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "source": [
    "# ===================== 03 Model_best_copy8672_diagonal =====================\n",
    "# print(\"Model_best_copy8672_diagonal\")\n",
    "    \n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、取对角线 ================\n",
    "#         diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "#         diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 5、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "source": [
    "# ===================== 04 Model_best_copy8672_maxpooling =====================\n",
    "# print(\"Model_best_copy8672_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、池化 ================\n",
    "#         # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 5、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(MatrixReal))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(MatrixImag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 932,401 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.530 | Train Acc: 75.88%\n",
      "\t test  Loss: 0.399 | test  Acc: 85.45%\n",
      "\t best  test acc: 85.45%\n",
      "Epoch: 02 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.321 | Train Acc: 89.04%\n",
      "\t test  Loss: 0.339 | test  Acc: 86.94%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.250 | Train Acc: 91.90%\n",
      "\t test  Loss: 0.363 | test  Acc: 85.45%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 04 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.211 | Train Acc: 93.66%\n",
      "\t test  Loss: 0.338 | test  Acc: 87.50%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 05 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.187 | Train Acc: 94.46%\n",
      "\t test  Loss: 0.351 | test  Acc: 86.19%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 06 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.165 | Train Acc: 95.30%\n",
      "\t test  Loss: 0.370 | test  Acc: 85.45%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 07 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.147 | Train Acc: 95.89%\n",
      "\t test  Loss: 0.377 | test  Acc: 86.66%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 08 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.135 | Train Acc: 96.21%\n",
      "\t test  Loss: 0.386 | test  Acc: 86.85%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 09 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.123 | Train Acc: 96.65%\n",
      "\t test  Loss: 0.432 | test  Acc: 86.29%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 10 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.115 | Train Acc: 96.80%\n",
      "\t test  Loss: 0.453 | test  Acc: 84.42%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 11 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.108 | Train Acc: 96.96%\n",
      "\t test  Loss: 0.437 | test  Acc: 85.45%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 12 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.104 | Train Acc: 97.05%\n",
      "\t test  Loss: 0.444 | test  Acc: 85.54%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 13 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.093 | Train Acc: 97.21%\n",
      "\t test  Loss: 0.427 | test  Acc: 85.26%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 14 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.088 | Train Acc: 97.35%\n",
      "\t test  Loss: 0.467 | test  Acc: 84.14%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 15 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.087 | Train Acc: 97.12%\n",
      "\t test  Loss: 0.499 | test  Acc: 84.42%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 16 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.076 | Train Acc: 97.60%\n",
      "\t test  Loss: 0.522 | test  Acc: 84.42%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 17 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.075 | Train Acc: 97.56%\n",
      "\t test  Loss: 0.586 | test  Acc: 83.02%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 18 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.063 | Train Acc: 97.86%\n",
      "\t test  Loss: 0.560 | test  Acc: 83.77%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 19 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.057 | Train Acc: 98.05%\n",
      "\t test  Loss: 0.591 | test  Acc: 84.61%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 20 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.055 | Train Acc: 97.94%\n",
      "\t test  Loss: 0.622 | test  Acc: 84.33%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 21 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.061 | Train Acc: 97.69%\n",
      "\t test  Loss: 0.586 | test  Acc: 85.35%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 22 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.054 | Train Acc: 97.99%\n",
      "\t test  Loss: 0.714 | test  Acc: 81.53%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 23 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.046 | Train Acc: 98.12%\n",
      "\t test  Loss: 0.719 | test  Acc: 82.56%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 24 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.044 | Train Acc: 98.20%\n",
      "\t test  Loss: 0.658 | test  Acc: 83.77%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 25 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.041 | Train Acc: 98.53%\n",
      "\t test  Loss: 0.735 | test  Acc: 82.37%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 26 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.044 | Train Acc: 98.38%\n",
      "\t test  Loss: 0.703 | test  Acc: 82.65%\n",
      "\t best  test acc: 87.50%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2\n",
    "    \n",
    "# ===================== 02 Model_best_copy8672_cnn_diagonal =====================\n",
    "\n",
    "# print(\"Model_best_copy8672_cnn_diagonal\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim-2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、取对角线 ================\n",
    "#         diagonal_elements_real = Conv_real[:, 0, torch.arange(Conv_real.size(2)), torch.arange(Conv_real.size(3))]\n",
    "#         diagonal_elements_imag = Conv_imag[:, 0, torch.arange(Conv_imag.size(2)), torch.arange(Conv_imag.size(3))]\n",
    "\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_maxpooling\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "source": [
    "# ===================== 03 Model_best_copy8672_diagonal =====================\n",
    "# print(\"Model_best_copy8672_diagonal\")\n",
    "    \n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、取对角线 ================\n",
    "#         diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "#         diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 5、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "source": [
    "# ===================== 04 Model_best_copy8672_maxpooling =====================\n",
    "# print(\"Model_best_copy8672_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、池化 ================\n",
    "#         # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 5、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(MatrixReal))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(MatrixImag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 932,401 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.519 | Train Acc: 76.25%\n",
      "\t test  Loss: 0.397 | test  Acc: 85.82%\n",
      "\t best  test acc: 85.82%\n",
      "Epoch: 02 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.329 | Train Acc: 88.72%\n",
      "\t test  Loss: 0.345 | test  Acc: 86.75%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.256 | Train Acc: 91.65%\n",
      "\t test  Loss: 0.361 | test  Acc: 87.03%\n",
      "\t best  test acc: 87.03%\n",
      "Epoch: 04 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.213 | Train Acc: 93.57%\n",
      "\t test  Loss: 0.363 | test  Acc: 87.50%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 05 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.183 | Train Acc: 94.90%\n",
      "\t test  Loss: 0.384 | test  Acc: 86.85%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 06 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.174 | Train Acc: 94.96%\n",
      "\t test  Loss: 0.444 | test  Acc: 85.63%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 07 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.168 | Train Acc: 95.32%\n",
      "\t test  Loss: 0.394 | test  Acc: 86.01%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 08 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.152 | Train Acc: 95.97%\n",
      "\t test  Loss: 0.390 | test  Acc: 86.47%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 09 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.143 | Train Acc: 96.10%\n",
      "\t test  Loss: 0.396 | test  Acc: 86.19%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 10 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.133 | Train Acc: 96.39%\n",
      "\t test  Loss: 0.386 | test  Acc: 86.75%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 11 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.128 | Train Acc: 96.61%\n",
      "\t test  Loss: 0.415 | test  Acc: 86.10%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 12 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.128 | Train Acc: 96.53%\n",
      "\t test  Loss: 0.426 | test  Acc: 86.01%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 13 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.121 | Train Acc: 96.79%\n",
      "\t test  Loss: 0.441 | test  Acc: 85.73%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 14 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.118 | Train Acc: 96.83%\n",
      "\t test  Loss: 0.456 | test  Acc: 84.51%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 15 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.110 | Train Acc: 96.92%\n",
      "\t test  Loss: 0.469 | test  Acc: 85.54%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 16 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.107 | Train Acc: 96.93%\n",
      "\t test  Loss: 0.497 | test  Acc: 85.63%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 17 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.098 | Train Acc: 97.28%\n",
      "\t test  Loss: 0.497 | test  Acc: 85.07%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 18 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.097 | Train Acc: 97.25%\n",
      "\t test  Loss: 0.496 | test  Acc: 84.98%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 19 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.089 | Train Acc: 97.33%\n",
      "\t test  Loss: 0.502 | test  Acc: 85.45%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 20 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.079 | Train Acc: 97.40%\n",
      "\t test  Loss: 0.505 | test  Acc: 84.79%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 21 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.075 | Train Acc: 97.72%\n",
      "\t test  Loss: 0.529 | test  Acc: 85.82%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 22 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.077 | Train Acc: 97.48%\n",
      "\t test  Loss: 0.522 | test  Acc: 85.35%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 23 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.073 | Train Acc: 97.70%\n",
      "\t test  Loss: 0.553 | test  Acc: 85.17%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 24 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.081 | Train Acc: 97.50%\n",
      "\t test  Loss: 0.523 | test  Acc: 85.35%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 25 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.066 | Train Acc: 97.76%\n",
      "\t test  Loss: 0.544 | test  Acc: 85.35%\n",
      "\t best  test acc: 87.50%\n",
      "Epoch: 26 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.060 | Train Acc: 98.18%\n",
      "\t test  Loss: 0.595 | test  Acc: 84.61%\n",
      "\t best  test acc: 87.50%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}