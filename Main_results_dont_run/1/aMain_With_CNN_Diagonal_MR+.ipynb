{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MR'\n",
    "N_EPOCHS = 16\n",
    " \n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MR\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([16143, 100])\n",
      "16143\n",
      "16143\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "# print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 5、池化 ================\n",
    "\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2\n",
    "    \n",
    "# ===================== 02 Model_best_copy8672_cnn_diagonal =====================\n",
    "\n",
    "print(\"Model_best_copy8672_cnn_diagonal\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim-2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_is_sentiment = self.phase_embedding(text)\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.self_attention2(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、取对角线 ================\n",
    "        diagonal_elements_real = Conv_real[:, 0, torch.arange(Conv_real.size(2)), torch.arange(Conv_real.size(3))]\n",
    "        diagonal_elements_imag = Conv_imag[:, 0, torch.arange(Conv_imag.size(2)), torch.arange(Conv_imag.size(3))]\n",
    "\n",
    "        diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "        diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "        fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "        fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "        return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_diagonal\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "source": [
    "# ===================== 03 Model_best_copy8672_diagonal =====================\n",
    "# print(\"Model_best_copy8672_diagonal\")\n",
    "    \n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、取对角线 ================\n",
    "#         diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "#         diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 5、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "source": [
    "# ===================== 04 Model_best_copy8672_maxpooling =====================\n",
    "# print(\"Model_best_copy8672_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、池化 ================\n",
    "#         # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 5、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(MatrixReal))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(MatrixImag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,989,901 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.656 | Train Acc: 61.15%\n",
      "\t test  Loss: 0.588 | test  Acc: 70.91%\n",
      "\t best  test acc: 70.91%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.520 | Train Acc: 76.78%\n",
      "\t test  Loss: 0.552 | test  Acc: 74.59%\n",
      "\t best  test acc: 74.59%\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.392 | Train Acc: 84.88%\n",
      "\t test  Loss: 0.513 | test  Acc: 76.69%\n",
      "\t best  test acc: 76.69%\n",
      "Epoch: 04 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.280 | Train Acc: 91.01%\n",
      "\t test  Loss: 0.610 | test  Acc: 75.86%\n",
      "\t best  test acc: 76.69%\n",
      "Epoch: 05 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.212 | Train Acc: 93.73%\n",
      "\t test  Loss: 0.587 | test  Acc: 79.72%\n",
      "\t best  test acc: 79.72%\n",
      "Epoch: 06 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.167 | Train Acc: 95.47%\n",
      "\t test  Loss: 0.582 | test  Acc: 79.25%\n",
      "\t best  test acc: 79.72%\n",
      "Epoch: 07 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.131 | Train Acc: 96.77%\n",
      "\t test  Loss: 0.650 | test  Acc: 79.39%\n",
      "\t best  test acc: 79.72%\n",
      "Epoch: 08 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.114 | Train Acc: 97.38%\n",
      "\t test  Loss: 0.779 | test  Acc: 76.31%\n",
      "\t best  test acc: 79.72%\n",
      "Epoch: 09 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.099 | Train Acc: 97.81%\n",
      "\t test  Loss: 0.821 | test  Acc: 77.26%\n",
      "\t best  test acc: 79.72%\n",
      "Epoch: 10 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.091 | Train Acc: 97.93%\n",
      "\t test  Loss: 0.787 | test  Acc: 77.16%\n",
      "\t best  test acc: 79.72%\n",
      "Epoch: 11 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.074 | Train Acc: 98.54%\n",
      "\t test  Loss: 0.838 | test  Acc: 76.42%\n",
      "\t best  test acc: 79.72%\n",
      "Epoch: 12 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.071 | Train Acc: 98.53%\n",
      "\t test  Loss: 0.872 | test  Acc: 76.46%\n",
      "\t best  test acc: 79.72%\n",
      "Epoch: 13 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.065 | Train Acc: 98.71%\n",
      "\t test  Loss: 0.881 | test  Acc: 77.86%\n",
      "\t best  test acc: 79.72%\n",
      "Epoch: 14 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.057 | Train Acc: 98.88%\n",
      "\t test  Loss: 0.947 | test  Acc: 75.06%\n",
      "\t best  test acc: 79.72%\n",
      "Epoch: 15 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.052 | Train Acc: 98.96%\n",
      "\t test  Loss: 1.049 | test  Acc: 74.60%\n",
      "\t best  test acc: 79.72%\n",
      "Epoch: 16 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.051 | Train Acc: 98.96%\n",
      "\t test  Loss: 1.056 | test  Acc: 75.35%\n",
      "\t best  test acc: 79.72%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAG2CAYAAACXuTmvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABO/klEQVR4nO3deXgT1f4G8HeSNum+0NKNlhZl35FCBcTlWsANBUQQkVWvPxSV0isCF1lEBUVFEFDEqyAugCIgKrJVQBQEBBERKCpbKV2FJrSlW3J+fwwNDd3SNsk0nffzPPMkmUwy32FJ3pw5c44khBAgIiIiUhGN0gUQERERORsDEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqY6iAeiHH35A//79ERERAUmSsGHDhmpfs3PnTtx0003Q6/Vo3rw5VqxY4fA6iYiIqGFRNADl5eWhU6dOWLJkiU3bnz59Gvfeey/uuOMOHD58GAkJCXj88cexZcsWB1dKREREDYlUXyZDlSQJ69evx4ABAyrdZvLkyfj2229x9OhRy7qHH34YOTk52Lx5sxOqJCIioobATekCamLv3r2Ij4+3WtevXz8kJCRU+prCwkIUFhZaHpvNZly8eBFBQUGQJMlRpRIREZEdCSFw+fJlREREQKOp+wkslwpA6enpCA0NtVoXGhoKo9GIK1euwNPTs9xr5s6dixdffNFZJRIREZEDpaSkIDIyss7v41IBqDamTp2KxMREy2ODwYCmTZsiJSUFfn5+ClZGRFRHGzcCkycDFy5cWxcRAbz2GnD//Y7fv8kE7NkDpKcDYWFAz56AVuv4/Sp13Bs3AiNGVP78xx87bv9q3XcZRqMRUVFR8PX1tcv7uVQACgsLQ0ZGhtW6jIwM+Pn5Vdj6AwB6vR56vb7cej8/PwYgInJd69YBI0cC13fjTEuT169dCwwa5Nj9T5gAnD9/bV1kJLBwoeP3q8Rxm0zA1KmVPy9JwH//CwwbVvsQaDbLi8lkfVtUJAe+qvY9eTLQu7f9A6jJBDz/fNX7rutx15C9uq+4VADq0aMHNm3aZLVu27Zt6NGjh0IVEVG9YTIBu3fLX4Th4Y75Mqgv+zaZ5PBR0TUsQshfSgkJwAMPOKaOdeuAwYPL7z81VV5vjxAihHycxcVyACgqAgoKgPHjKz9uAPi//5Pvm83ya8suJSXl19m6ZGRYh72K9p+SAkRFAXp9+RBTelvRutLbuvxZXbgAxMTU/j3qsu+UFPnf/+23O3//daBoAMrNzcVff/1leXz69GkcPnwYjRo1QtOmTTF16lSkpqZi5cqVAIBx48Zh8eLFeP755zF27Fh8//33+Pzzz/Htt98qdQhEVB8o1RrhzH2bTMClS8DFi8D27bZ9GQ8dKn8hlyr7y7km98uuEwJYurTqEFLaEmMyXQsvZYNMdfdLb2tzkXJ2thzClJKWpty+tVrADp2DrZQGtOooedy1pOhl8Dt37sQdd9xRbv2oUaOwYsUKjB49GmfOnMHOnTutXjNx4kQcO3YMkZGRmD59OkaPHm3zPo1GI/z9/WEwGHgKjMjelGiFqaw1ovRL25Gngmqzb5MJMBjkIPPPP9a3Va3LyXHMMbgSjca2lpLmzeV/f+7uNVvc3Cp/7q+/5D5G1Vm0COjWTa61NJCUvV+b2927gb59q9/3jh32b4XZuROo4HvaKfu+jr2/v+vNOEDOwgBE5CBKtMKYTHKzf2WtIZIk13D69LUvz5IS+XW23Fb1XFGR3NKRnV15fV5ewK23XgsyFy/KrTh1+dj19ZXf97r+kBV65BGgadNrj8vut7L71W134gRwXVeECg0fDtx8sxwedDp5qct9Nzfghx+q/DI2eXmhODhY7pTbvXv1NdaEyQTceaf8517R358kyR3Bt293TD8clexbp9NVeok7A1AdMQBRg+eqrTBmM5CXB1y+XPViNF67//ffwK5d1ddna8uBM/n4AI0ayUtQkPVtZesaNZJDQWnwS02t/EupNPjZ++9eyRaBSo5bSBLSx4xBzv33A56e8rE7Ypy3/HwgK6vy5xs3lsOpI6hk3xqNBs2aNYNOpyv3HANQHTEAUYOmRCtMScm1L6XK+PrKV4lUFnCMRvk5pT6OJEluYdBqbb+9fBk4d676937iCeCee6yDTWCg3FG2LkpDJ2D95+boU39Khi+gwuNOGzsWOcOGISQgAF5RUZD8/e2/31IGg3zZf3HxtXXu7nIriCP3q4J9m81mXLhwAe7u7mjatGm5q70YgOqIAYgarLq2wggh/9Krri/K9euys+UQZC8ajRyYKlv8/K7dT0+X+1xU54sv5JYwN7fyQaa2HUfrQ9+IigJvVBSwYIHjL0VXInyV3f/V4zZ5e+Pkp58iJDoaQdHRcrh0NCGA3Fz5NKhOJ7fmOWtmgQa+b4PBgAsXLqB58+Zwd3e3eo4BqI4YgKhBqq4vDCB/MUyadO1KooqCTZlpY+xu0CB5oLzqwo2np+0fqkq2RijdElK2DiUu/1cqfJW6etwF2dk4feONiGnVCp6OOgVETnPlyhWcOXMGzZo1g4eHh9Vz9v7+dqlxgIjoOrm5QHIysH591eEHkIPPf/9b/Xu6uVXfF6XsuuRk4OGHq3/fZ56xf0uIViuf3hs8WA4cFbVGLFjgmECg5L6vr0OJ8VcGDZLHGVJq7KXS4y4oAE6fhmTvy79JEc6co5MBiMgR7Pmr3GyW+5okJ8vLiRPX7lfV76YivXsDsbFVB5uaNmt36CC3dFTXEtK7d81qtdWgQfIpl4r6Pjm6NULJfdcHSoUvIjtgACKyt9p2RL58ueKQc/Kk/Cu3Mo0bA6GhwNGj1dc2e3bDaoUppWRrhNItIUQAYmJikJCQgISEhDq/V+kYfZcuXUJAQECd36++YgAisqfqpgj4/HOga9fyIefEiapHUnV3lwd3a90aaNVKXkrvBwba3h+lIbbClFKyNYItIQ2Dk/tT3X777ejcuTMWLFhQ5/c6cOAAvL29616UijAAEdlLdfMzAcBDD1X9HqGh1wJO2ZATEyP3zamM2lthiOpKyelUKiGEgMlkgltV//evaty4sRMqaljYa4yoroSQB+R78cXqOyIDcpBp107+UJ06FfjoI+Dnn+VOyunp8sB+y5YB//kPcO+9csuPDR+AllaYJk2s10dGOv6y5FKlLSHDhsm3DD/kCkpbbq///1vacrtund13OXr0aOzatQsLFy6EJEmQJAkrVqyAJEn47rvv0LVrV+j1evz444/4+++/8cADDyA0NBQ+Pj7o1q0btm/fbvV+MTExVi1JkiThf//7HwYOHAgvLy+0aNECGzdurHW9X375Jdq1awe9Xo+YmBi8+eabVs+/8847aNGiBTw8PBAaGorBZeZjW7t2LTp06ABPT08EBQUhPj4eeXl5ta7FXtgCRFRTqanAgQPy8ssv8nLxou2vX7FCnibAEdgKQ3RtTCtbmEzAs89W3nIrSXLLUHy8bf+PvLxsuohg4cKFOHnyJNq3b4/Zs2cDAP744w8AwJQpU/DGG2/ghhtuQGBgIFJSUnDPPffglVdegV6vx8qVK9G/f38kJyejadmpTq7z4osvYt68eXj99dexaNEiDB8+HGfPnkWjRo2qP44yDh48iCFDhmDWrFkYOnQo9uzZg6eeegpBQUEYPXo0fvnlFzz77LP4+OOP0bNnT1y8eBG7d+8GAKSlpWHYsGGYN28eBg4ciMuXL2P37t2oFyPwCJUxGAwCgDAYDEqXQs5QUiLEjh1CfPaZfFtSUrPXZ2UJ8d13QsyeLUT//kKEhwshfyxaLzqdEK1aVfzc9cuOHQ44UCJ1unLlijh27Ji4cuXKtZW5ubb9X3TEkptrc+233XabmDBhguXxjh07BACxYcOGal/brl07sWjRIsvj6Oho8dZbb1keAxAvvPBCmT+SXAFAfPfdd9W+d2kdly5dEkII8cgjj4g+ffpYbTNp0iTRtm1bIYQQX375pfDz8xNGo7Hcex08eFAAEGfOnKl2v0JU8vd5lb2/v9kCRA1XTc/pG43AwYNyi05pC8+ZM+W302jkU1jdul1bOnSQfx0q2RGZiBqE2NhYq8e5ubmYNWsWvv32W6SlpaGkpARXrlzBuWqmYunYsaPlvre3N/z8/JCZmVnjeo4fP44HHnjAal2vXr2wYMECmEwm9OnTB9HR0bjhhhtw11134a677rKceuvUqRPuvPNOdOjQAf369UPfvn0xePBgBDpjxO5qMABRw1Td1ViffiqHldLTWAcOyFdjVRRcWraUx84pDTtdulQ+8Z/SHZGJSP7/mZtr27Y//CDP1VadTZuAW2+1bd91dP3VXM899xy2bduGN954A82bN4enpycGDx6MoqKiKt/n+qkkJEmC2QGTAvv6+uLQoUPYuXMntm7dihkzZmDWrFk4cOAAAgICsG3bNuzZswdbt27FokWLMG3aNOzbtw/NmjWzey01wQBEDY8tV2M98kjFr23aVA45pYGna1egJuNg1IfLwYnUTpIAWy8J79vXtoE8+/a1+48XnU4Hk8lU7XY//fQTRo8ejYEDBwKQW4TOVNQ67SBt2rTBTz/9VK6mli1bQnv1z8TNzQ3x8fGIj4/HzJkzERAQgO+//x6DBg2CJEno1asXevXqhRkzZiA6Ohrr169HYmKi046hIgxA1PDs3m3b1VgBAUCvXtdadmJjgZCQuu+fHZGJXIeCQ0jExMRg3759OHPmDHx8fCptnWnRogXWrVuH/v37Q5IkTJ8+3SEtOZX5z3/+g27duuGll17C0KFDsXfvXixevBjvvPMOAOCbb77BqVOncOuttyIwMBCbNm2C2WxGq1atsG/fPiQlJaFv374ICQnBvn37kJWVhTZt2jit/sowAFHDkZYGbNgALFli2/ZLllTeElRXHBiPyHUo1HL73HPPYdSoUWjbti2uXLmC5cuXV7jd/PnzMXbsWPTs2RPBwcGYPHkyjEajQ2qqyE033YTPP/8cM2bMwEsvvYTw8HDMnj0bo0ePBgAEBARg3bp1mDVrFgoKCtCiRQusWrUK7dq1w/Hjx/HDDz9gwYIFMBqNiI6Oxptvvom7777bafVXhrPBk2s7dUqeCHTdOmDv3oqbsCuzYwdDCpGLKygowOnTpyucPbzGnDwSNJVX1d8nZ4MndRMCOHZMDjzr1gGHD1s/f/PNwIAB8q+2jAxejUVEtmPLraowAFH9J4R8eXpp6ElOvvacRgPcdpvcRD1ggBxsAKBFC16NRURUgXHjxuGTTz6p8LlHH30US5cudXJFymAAovrJZAJ++ula6ElJufacTgf06SOHnvvvB4KDy7+eV2MREVVo9uzZeO655yp8Tk1dQxiAyPFsPa9eVAR8/70ceDZsALKyrj3n7S2P1TFokHxry39SXo1FRFROSEgIQuxxxauLYwAix6puNOb8fGDLFuDLL4FvvgEMhmvbBQTILTwPPii3+Hh61nz/PKdPREQVYAAix6lqNOYHHwTi4oAjR4ArV649FxoKDBwoh6PbbweuG8mUiIjIHhiAyDFsGY153z75NjpaDkSDBslXcfEUFRERORgDEDmGraMxL1sGPP74tauziIiInECjdAHUQKWl2badjw/DDxEROR0DEDnG0aO2bRce7tg6iIioQmfOnIEkSTh8/YCyKsEARPZ1+TIwciQwZ07V20kSEBXF0ZiJSLVuv/12JCQk2O39Ro8ejQEDBtjt/Ro6BiCynwMHgJtuAj7+WB6hecgQOehcf4qLozETUT31i9GIfx0+jF+cONkoKYMBiOrObAZefx3o2RP46y+5ZWfXLmDNGnk05iZNrLePjJTXczRmIqpnVmZkYEdODj7OyHDofkaPHo1du3Zh4cKFkCQJkiThzJkzOHr0KO6++274+PggNDQUI0aMQHZ2tuV1a9euRYcOHeDp6YmgoCDEx8cjLy8Ps2bNwkcffYSvvvrK8n47d+6scV27du1C9+7dodfrER4ejilTpqCkpKTa/QPAzp070b17d3h7eyMgIAC9evXC2bNn6/xn5Si8CozqJi0NGDUK2LZNfjx4sHxlV2Cg/JijMRORkwkhkG8227z9uYIC/FNcDEmSsDozEwCwKjMTQ0JCIIRAkLs7mto407yXRgPJhgs7Fi5ciJMnT6J9+/aYPXs2AMDd3R3du3fH448/jrfeegtXrlzB5MmTMWTIEHz//fdIS0vDsGHDMG/ePAwcOBCXL1/G7t27IYTAc889h+PHj8NoNGL58uUAgEaNGtn8ZwAAqampuOeeezB69GisXLkSJ06cwL///W94eHhg1qxZVe6/pKQEAwYMwL///W+sWrUKRUVF2L9/v01/FkphAKLa27RJDj/Z2fIozW+/DTz2WPlTXhyNmYicKN9shs/u3XV6j6ziYtzy6681fl1u797wtuEHnr+/P3Q6Hby8vBAWFgYAePnll9GlSxfMKdOH8sMPP0RUVBROnjyJ3NxclJSUYNCgQYiOjgYAdOjQwbKtp6cnCgsLLe9XU++88w6ioqKwePFiSJKE1q1b48KFC5g8eTJmzJiBtLS0Svd/8eJFGAwG3HfffbjxxhsBAG3atKlVHc7CU2BUc4WFQEICcO+9cvjp2FGerZ3j+RAR1dpvv/2GHTt2wMfHx7K0bt0aAPD333+jU6dOuPPOO9GhQwc89NBDeP/993Hp0iW77f/48ePo0aOHVatNr169kJubi/Pnz1e5/0aNGmH06NHo168f+vfvj4ULFyLN1uFQFMIWIKqZEyeAYcOA0ssmn30WeO01wMbmYSIiR/PSaJBbwytMD+fmVtji82OXLujs41OjfddWbm4u+vfvj9dee63cc+Hh4dBqtdi2bRv27NmDrVu3YtGiRZg2bRr27duHZs2a1Xq/tqpu/8uXL8ezzz6LzZs3Y82aNXjhhRewbds23HzzzQ6vrTbYAkS2EQL44AOga1c5/AQHA19/LU9qyvBDRPWIJEnw1mprtHheDS6lX4qlt54aTY3epyZ9XnQ6HUwmk+XxTTfdhD/++AMxMTFo3ry51eLt7W05tl69euHFF1/Er7/+Cp1Oh/Xr11f4fjXVpk0b7N27F6LMFEY//fQTfH19ERkZWe3+AaBLly6YOnUq9uzZg/bt2+Ozzz6rdT2OxgBE1cvJAYYOlU9x5ecDd94J/PYbcN99SldGRGQXIe7uCHN3R1dfXyxt2RJdfX0R5u6OEAdOyBwTE4N9+/bhzJkzyM7Oxvjx43Hx4kUMGzYMBw4cwN9//40tW7ZgzJgxMJlM2LdvH+bMmYNffvkF586dw7p165CVlWXpaxMTE4MjR44gOTkZ2dnZKC4urlE9Tz31FFJSUvDMM8/gxIkT+OqrrzBz5kwkJiZCo9FUuf/Tp09j6tSp2Lt3L86ePYutW7fizz//rN/9gITKGAwGAUAYDAalS3ENP/4oRNOmQgBCuLkJ8eqrQphMSldFRCSEEOLKlSvi2LFj4sqVK3V+rwKTSZjNZiGEEGazWRQ4+LMuOTlZ3HzzzcLT01MAEKdPnxYnT54UAwcOFAEBAcLT01O0bt1aJCQkCLPZLI4dOyb69esnGjduLPR6vWjZsqVYtGiR5f0yMzNFnz59hI+PjwAgduzYUeX+T58+LQCIX3/91bJu586dolu3bkKn04mwsDAxefJkUVxcLIQQVe4/PT1dDBgwQISHhwudTieio6PFjBkzhKmGf4ZV/X3a+/tbEqKi6bobLqPRCH9/fxgMBvj5+SldTv1lMsmjOc+aJY/zc8MNwKpVQPfuSldGRGRRUFCA06dPo1mzZvDg6XiXV9Xfp72/v9kJmspLSQEefRT44Qf58aOPAkuWAAyMRETUQLAPEFlbtw7o1EkOPz4+wMqV8tQWDD9ERC5lzpw5VpfUl13uvvtupctTHFuASJafDyQmAu+9Jz+OjZVPeTVvrmxdRERUK+PGjcOQIUMqfM7T09PJ1dQ/DEAEHDkij+1z7Jj8+PnngZdeAnQ6ZesiIqJaa9SoUY2nw1ATBiC1MJnKz8el0ch9e557Th7dOSxMPuXVp4/S1RIRETkUA5AarFsHTJgAnD9/bV1EhLz88ov8+J57gOXLgZAQZWokIqoDcw0mP6X6y5kXpjMANXTr1skztF//j+rCBXlxcwPeeEOe0oLzeBGRi9HpdNBoNLhw4QIaN24MnU5Xr2cgp8oJIZCVlQVJkuDuwAEoS3EcoIbMZAJiYqxbfq4XGgqkpsozthMRuaCioiKkpaUhPz9f6VKojiRJQmRkJHwqmH+N4wCR7Xbvrjr8AEBGhrzd7bc7pSQiInvT6XRo2rQpSkpK6jQXFinP3d0dWif9IGcAasjS0uy7HRFRPVV62sQZp06oYeBAiA1ZeLh9tyMiImogGIAaMj8/+VL3ykgSEBUlXxJPRESkIgxADdX+/cCdd8oTmQLlr/AqfbxgATtAExGR6jAANUQ//ADExwM5OUCPHvLghk2aWG8TGQmsXQsMGqRIiUREREpiJ+iGZutWYMAA4MoV4I47gI0b5UlNH3mk/EjQbPkhIiKVYgBqSL76ChgyBCgqkkd2XrsWKJ3wTqvlpe5ERERX8RRYQ7F6NfDgg3L4efBBYP36a+GHiIiIrDAANQTLl8unuEwm4NFH5TDEmdyJiIgqxQDk6pYsAcaOlef6euIJ4KOP5Pm9iIiIqFIMQK5s3jzg6afl+wkJwNKlVY/7Q0RERAAYgFyTEMDMmcDkyfLjadOA+fM5mzsREZGNeK7E1QgBTJoEvPmm/HjOHGDqVGVrIiIicjEMQK7EbAbGj5dPdQHAwoXAs88qWxMREZELUvwU2JIlSxATEwMPDw/ExcVh//79VW6/YMECtGrVCp6enoiKisLEiRNRUFDgpGoVVFICjBkjhx9JAt5/n+GHiIiolhQNQGvWrEFiYiJmzpyJQ4cOoVOnTujXrx8yMzMr3P6zzz7DlClTMHPmTBw/fhwffPAB1qxZg//+979OrtzJiorky9xXrpQHNPzkE+Dxx5WuymX8YjTiX4cP4xejUelSiIionlA0AM2fPx///ve/MWbMGLRt2xZLly6Fl5cXPvzwwwq337NnD3r16oVHHnkEMTEx6Nu3L4YNG1Ztq5FLKyiQ5+v64gvA3V2+feQRpatyKSszMrAjJwcfZ2QoXQoREdUTigWgoqIiHDx4EPHx8deK0WgQHx+PvXv3Vvianj174uDBg5bAc+rUKWzatAn33HNPpfspLCyE0Wi0WlxGXh5w333At98CHh7yvF4DBypdlUs4W1CAg5cv49Dly1hztUVxdWYmDl2+jIOXL+OsE06bKtnyxFYvIqKqKdYJOjs7GyaTCaGhoVbrQ0NDceLEiQpf88gjjyA7Oxu33HILhBAoKSnBuHHjqjwFNnfuXLz44ot2rd0pDAbg3nuBn34CvL2Bb77hXF41EPPzz+XWZRYXo+vBg5bH/2vVCn5aLfzc3OBfeuvmBj+tFt5aLTR1HFagbMtTrJ9fnd7LlfZNROQKXOoqsJ07d2LOnDl45513EBcXh7/++gsTJkzASy+9hOnTp1f4mqlTpyIxMdHy2Gg0Iioqylkl184//wB33QX88gvg7w9s3gzcfLPSVbkMY0kJhjVujFVZWVVu93hycqXPSYAlHPlptXIwKhOUyq6z3NdqkW8yoRiAj0aD1WVanoaHhKBYCAS4uSFCr0exECgRwnJbIgSKzeZr98uut3HbzKIiGEwmmITAR+npAICPMzIwMjQUkCQEu7sj2sPDXn/MREQuTbEAFBwcDK1Wi4zr+mVkZGQgLCyswtdMnz4dI0aMwONXOwB36NABeXl5eOKJJzBt2jRoKhgFWa/XQ6/X2/8AHCU9HejTBzh6FAgOBrZuBbp0Uboql5BaWIiF58/jvQsXYDSZKt1ucHAwdBoNjCYTjCUlMJSUXLtvMqFECAgABpMJhirex1aZxcWI+/XXOr9PbVwqKUHsoUOWx4KtiEREABQMQDqdDl27dkVSUhIGDBgAADCbzUhKSsLTpdM7XCc/P79cyNFqtQAAIYRD63WK8+eBO+8ETp4EwsOB7duBtm2VrqreO5qbizdSUvBZZiaKr/47aOPlhYcaN8bss2ehAWAGLLdTo6Nxk69vhe8lhECB2VwuFBmvPjaUlFjfv27dhcJC/FNSYlPdbpIEN0mC+9XbKu9rNNVuc76wEHuNRlT1P+H2X3/FiLAwDG7cGP6cM46IVEzRT8DExESMGjUKsbGx6N69OxYsWIC8vDyMGTMGADBy5Eg0adIEc+fOBQD0798f8+fPR5cuXSynwKZPn47+/ftbgpDLOnVKDj9nzgBNmwJJSUDz5kpXVW8JIbAzJwevp6Tgu4sXLetv9ffHpKgo3BMUhAuFhVh24QKiPDzwWHg4PkhLQ0pBAULc3St9X0mS4KnVwlOrRcXtkNU7dPmyVV+jUrs7d0asry/cJAlaSYLkgKlLKtt3rI8PDubmYpfBgF0GA57+80/cHxSEkWFh6BsYCHfOIUcu6BejEc+fOoV5N9zAvm5UY4oGoKFDhyIrKwszZsxAeno6OnfujM2bN1s6Rp87d86qxeeFF16AJEl44YUXkJqaisaNG6N///545ZVXlDoE+zhxQg4/Fy7IoScpSQ5BVE6J2Ywvs7Px+rlzOJibC0Bu2RnUuDEmRUWhe5kPwUgPD5zp0QO6q2HjifBwFAkBvZO+7K9vefLSauHhpKB+/b7fa9UKjd3d8WlGBj7OyMCx/Hx8npWFz7Oy0NjdHQ+HhGBEaChifX0dEsyIHIGd/akuJNEgzh3Zzmg0wt/fHwaDAX714T/MkSNAfDyQlSWf7tq+XT79RVbyTCZ8mJaG+efP48zVS9g9NRqMCQtDYlQUbvT0VLjCa84XFKDbwYPlWp4OdO2KSAd3QrZl30IIHMrNxcfp6ViVmYnM4mLL61t7eWFEaCiGh4a6ZIdptgg0fGcLCpBdXAwJwN1HjiCzuBgh7u74rmNHCICd/Rswe39/MwA5k8kE7N4NpKXJIUevly91v3RJ7ui8davc8ZksMoqKsDg1Fe+kpuLi1b41we7ueLpJE4yPiECwTqdwhRUrNJstLU9CCKe2PNVk3yVmM7ZeuoSPMzKwITsbBWaz5bnb/P1drr/Qs3/+iUWpqXi2SRMsbNHCqftm+HIsIQRSCwsRVcEQF+W2ZWf/Bsne39+u8anWEKxbB0yYIHd0LiVJ8uzuPXoAmzYBAQEOLcGVPqCT8/PxZkoKVqano/BqRm/u6Yn/REZiZFgYvOp5n6+ygUOSJOideFqpJvt202hwT1AQ7gkKgrGkBF9mZeHjjAzszMkp119oRGgo+jVqVO/6C5VtESg76OWosDCntgjwdIx9CCGQUliIY3l5OJafjz+u3h7Ly6vy6s5S8QEB2HnpEnoHBEDL07lUBbYAOcO6dcDgwXLYqcgnnwDDhzu8DCV/HdvqJ4MBr587h43//GO5mulmPz9MiorCA8HB/EBzkpSCAqv+QqXqU3+hfJMJKYWFaG3DVDiPhoZCC0B7tQO6psx9rSRZntOUuV/httdtl1NSgnyzGVpJwvyUFBhNJgS4ueG9Fi3QyN0dN3h64gYnnJ5V8sdNbfdtFgLnCgrKhZxj+fnIrSToaAG08PJCuE6HHTk5Vb5/iLs7BjVujIcaN8at/v5wq2fBnWqOp8DqyOkByGQCYmKsW37KkiQgMhI4fVqe6NTOXOF8uUkIbMzOxuspKdhbZuqG+4OCMCkqCr38/dkxVyG16S9kjy/j0nBz/uqSUlAg35Y+LizEJRuHG1BaqLs7QnQ6hOp0VvdD3N2tb3W6Wp8mVfLHTXX7NguBMwUF5ULO8bw85JU55VqWmyShpacn2np7o52XF9p6e6OtlxdaenlBp9FYrna8vrP/282b49fcXGzIzrb699HY3R0Dg4PxUOPGuD0ggGHIRTEA1ZHTA9DOncAdd1S/3Y4dDpnqQtq5s9pt8nv3hqeDTylV9KV4xWTCyowMvJmSgj+vXAEA6CQJI8PC8J/ISLT29nZoTVQztvYXmn76dJVfiPkmk3WYqUO48dFqEaXXw0+rxb7Ll8s9PykyEhF6PUyQg7ZJCJjL3DcJYXnOXOZ+hdtW8B5nCwrwa25ulWMv1YS/VmsJQ9UFp4vFxfinpESRHzeV/bBa1rIl/iooQEZhIdKKi/FHXh5O5OfjSiVBx12S0MrLC229vNDuashp6+2NFp6eVZ5qra6zf7HZjO9zcvBFZibWZ2db+g8CQJCbGwZebRm6IyCg3p3SpcoxANWR0wPQqlW2zd7+2WfAsGF13p0QAn9euYJdOTnYmZOD7/75B5dsOG/ur9UiXK9HhE6HcJ0O4Xq9fFvmcYROB99adoYt+ytxRkwM3klNxaLUVGRdbVEIcHPDUxEReKZJE4S50sjdKnV9f6HSDxGdJEECUCgEfLVajAgNRXpRES5d/bI+X1ho9WVUldJwE6nXl7/18EDk1eAjSVKlLQIHu3atdNBLe6ls7KV9XbogysMDGUVFyCwutrq1Wnf1frEDPoofCQmBGfLnggCs7gvIrTPV3a/ouR8MhhrVoZMktL4u5LTz9saNHh61bo2xtbN/sdmMnTk5WJuVhXXZ2cgu04rZyM0NA662DP0rMBA6hqF6jQGojhpaC5AQAsn5+dc6rebkIK2oyGobNwAVfeU00enwT0mJ1S/56nhrNJWGo7LBKdDNDecKC8v9SvTUaOTRlq/+s4vW6zExKgqPhYXBx0WuNCJrKQUFaGrDlTllVRRurg84peHGFkoOPWCP8CWEQE5JSeUhqUxYyigurrSPTH3R088P9wYFWVp2mtUh6NhTidmMXQaDHIaysqxO6Qa6ueGBq2EonmGoUkr2N2MAqiNF+gBFRwOpqRU/X8M+QEIIHMvPt7Tw/JCTg4wy/4kBQC9JuNnPD7cFBOC2gADoNRrc8uuvFX5Ad/HxgaGkBGlFRdeWwkLL/Qtl7l+uwYeuXpIsV29VpfjWW+vFByPVzacZGRh94gRKKvg71wAYc/X0WG3Cja2UGnpAifCVbzIhs6gIuwwGjD5xotzzCZGRiNLroYF8JaAEeYJfTZn75R5f7fAtlXlNVa8/U1CA50+dKrdvZ7S62YNJCPxwtWXoy6wsq89Rf63WEob6NGpU4b8jV7qq1p6U7G/Gy+BdjVYrtwB98kn550q/ABYsqDT8mIXA0bw87MrJkReDwaoJFwA8NBr08PPD7VcDT5yvr9WIw+cLChDm7l7hlBCSJCHA3R0B7u5oU02fmzyTySocXR+QSp+7WFJSbfhxkySsaN2a4aeBGB4aijZeXhWeCjrgpC9EpYYeUGLEcS+tFjGenpbTidf/uBkRGuqUU38V7dtVaCUJdwQG4o7AQLzdogV+vNoy9GVWFtKKirAyIwMrMzLgp9Xi/uBgDG7cGP0CAy2frWoa9qC+DDVhbwxAjnbxIvD11/L9wED80rgxnv+//8O8995D7JUrcvgZNMiyuUkIHMnNtYSdH3JyyvWZ8NJo0NPfH7f5++P2gAB08/Or8sPWXh/Q3lotmnt5obmXV5XbFZrNSL8aiH40GDCpgl+J+266ySV+JVLNueoXYl0oFb5C3N0r/XHTkPdtb1pJsrSYL2zeHHsMBnyRlYW1WVm4UFSETzIy8ElGBrw1GvT298edgYFYrWAQcHTrU6HZLJ9uvXr69d7ffy+3TWZxsdUPHlccfJIByNHmzAEMBqBjR+DAAazcswc7AHz83nuI7d0bJo0Ghy9flvvw5ORgt8GAnOsCj7dGg1v8/S3/QWN9fWt8ftqZH9B6jQbRHh6I9vCw1KnGL0W1aUhfiK5CyfnulJ5rz1E0koRbAgJwS0AA3mreHD8bjZYwdL6wEJsvXcLmS5cs218fBJa3agU/Nzf4abWWW9+rt95aLTR2+OytaeuTEAKXTaYqO+JnFBdbQo+hBt0dSlvzXRH7ADnS2bNAy5Y4GxiI7BUrIPXqhbuOHEFWcTF8NBp08vHB4dzccmNh+Gq1uOVq685tAQG4ycfHZS/VVLJzKjmfklOAEDmSWQi8dOYMZp89W+sfcRLkz/eyAclXq7UKS9eHptLHuSYTioWAj1aLh48dQ1ZxMYLd3bG4eXNcLClBkRAQQlgFmdL7mcXFNbrYBZCHKAgpM/yCG4BvLl4st50z+3yxE3QdOTUAjRoFrFwJaceOaje9LygIt11t5eni49Og+sbwS5GIGorKhj0YGBwMnSTBaDLBWFICo8mEy1fvG0pKUB+u2/PRai3jSFU0GGfZ+wFublYXKig51EQpdoJ2Fb/9BvHxx9gWG4uOkoQjleRMLYDlrVtjRFiYc+tzIiXnxSIicoTrg8AL0dGVBgEhBArMZks4ulwmJF1/W9lz1Z2aauPlhY7e3lYDaV4/qGZd5lBsiKe4GYAcIM9kwserV+PtDz/E8ZiYyucAA7DfRS4ZJSKi2gUBSZLgqdXC8+pI37VVWeuTM1phGmKfLwYgOzpXUIAlqal4/9w5XOrXDwDgK0kYGxGBOwICMOCPP9gZmIjIhdWHIKDU90hDa81nAKojIQR+MhiwMDUV67Oy5PO8koQbU1PxTHY2xowfDz83tyrH4iEiItehxmEPGiJ2gq6lQrMZn2dmYuH58ziYm2tZ/6/CQkyYPRv3Hj0K7Z9/AiEhVq9hZ2AiIqotNX+PsBO0wjKKivDehQt4JzXVMnS6h0aDR0ND8WxICDrExgKnTgEvvmgVfoCG13xIRETOxe8R+2EAstGvly9j4fnzWJWZiaKrjWYROh3GN2mCJ8LDEazTAYsXy+EnNBRITFS4YiIiIqoMA1AVTELgq+xsLDx/Hj8YDJb1cb6+mBAZicGNG18boNBoBGbPlu/PmgX4+Di/YCIiIrIJA1AFcoqL8UF6OhanpuJMQQEAebjvwY0bY0KTJrjZ37/8i954A8jKAlq2BB57zMkVExERUU0wAJWRnJ+Pt8+fx0fp6ZbpKYLc3PB/ERF4qkkTNNHrK35hWhrw5pvy/TlzAPbIJyIiqtdUG4DuO3IE8zt2RFdfX2y9dAkLz5/Hd2XmOWnv7Y0JTZpgeGgoPKsbPXP2bCA/H7j5ZquZ3YmIiKh+Um0A2m0w4PlTp5BWVIQT+fkA5Inq7gsKwoTISPwrIMBqHpRKJScD778v33/tNYA98omIiOo91QYgANiRkwMA8NJoMKRxY0yLjkZzL6+avcl//wuYTMB99wG33mr/IomIiMju1DF6UjXyzWasyMioefj5+Wdg3TpAowFefdUxxREREZHdMQBBvsLrkzZtavYiIYDnn5fvjx4NtGtn97qIiIjIMVR9CqzUvptuqvlMut98A+zeDXh4yKM+ExERkctQdQtQrQ++pASYMkW+P2ECEBlpr5KIiIjICVQbgN5q3hxdfX0R5u5e85l0V64Ejh0DAgOvBSEiIiJyGao9BTY2PBwTfH1rPpNufj4wY4Z8f9o0ICDAIfURERGR46g2AAG1nEn37beB1FSgaVNg/HjHFEZEREQOpdpTYLXyzz/XLnd/+WW5AzQRERG5HAagmpgzBzAYgE6dgOHDla6GiIiIaokByFZnzgCLF8v3X31VHvyQiIiIXBK/xW01fTpQVAT8619Av35KV0NERER1wABki8OHgU8/le9zwlMiIiKXxwBkiylT5Kkvhg4FYmOVroaIiIjqiAGoOklJwJYtgLs78MorSldDREREdsAAVBWzGZg8Wb4/bhxw443K1kNERER2wQBUlc8/Bw4eBHx95U7QRERE1CAwAFWmqEie6gIAJk0CGjdWth4iIiKyGwagyixdCpw6BYSFAYmJSldDREREdsQAVBGjEXjpJfn+rFmAt7ei5RAREZF9MQBV5PXXgexsoGVLYOxYpashIiIiO2MAul5aGjB/vnx/7lz58nciIiJqUBiArvfii0B+PtCjBzBwoNLVEBERkQMwAJWVnAz873/yfU55QURE1GAxAJU1dSpgMgH9+wO9eytdDRERETkIA1CpPXuA9esBjQZ49VWlqyEiIiIHYgAC5IlOS6e8GDMGaNtW2XqIiIjIoRiAAODrr4EffwQ8PORxf4iIiKhBYwAqKQGmTJHvJyQAkZGKlkNERESOxwD00UfA8eNAo0bXToMRERFRg6buAJSfD8yYId+fNg0ICFC0HCIiInIOdQeghQuBCxeA6Ghg/HilqyEiIiInUW8AWr4cePll+f7LLwN6vbL1EBERkdO4KV2AYhIS5Ft3d/nqLyIiIlIN9bYAlSouBoYMAdatU7oSIiIichIGoFIJCfI0GERERNTgMQAB8kjQKSnA7t1KV0JEREROoHgAWrJkCWJiYuDh4YG4uDjs37+/yu1zcnIwfvx4hIeHQ6/Xo2XLlti0aZN9iklLs8/7EBERUb2maCfoNWvWIDExEUuXLkVcXBwWLFiAfv36ITk5GSEhIeW2LyoqQp8+fRASEoK1a9eiSZMmOHv2LALsNX5PeLh93oeIiIjqNUkIIZTaeVxcHLp164bFixcDAMxmM6KiovDMM89gSun0FGUsXboUr7/+Ok6cOAF3d/da7dNoNMLf3x8GAH6lKyVJngLj9GlAq63dwRAREZHDWL6/DQb4+flV/4JqKHYKrKioCAcPHkR8fPy1YjQaxMfHY+/evRW+ZuPGjejRowfGjx+P0NBQtG/fHnPmzIGpis7LhYWFMBqNVosVSZJvFyxg+CEiIlIJxQJQdnY2TCYTQkNDrdaHhoYiPT29wtecOnUKa9euhclkwqZNmzB9+nS8+eabeLl0QMMKzJ07F/7+/pYlKirKeoPISGDtWmDQoDofExEREbkGlxoI0Ww2IyQkBMuWLYNWq0XXrl2RmpqK119/HTNnzqzwNVOnTkViYqLlsdFolEPQ//4H3Hgj0Ls3W36IiIhURrEAFBwcDK1Wi4yMDKv1GRkZCAsLq/A14eHhcHd3h7ZMYGnTpg3S09NRVFQEnU5X7jV6vR76iqa5eOghwA7nEImIiMj1KHYKTKfToWvXrkhKSrKsM5vNSEpKQo8ePSp8Ta9evfDXX3/BbDZb1p08eRLh4eEVhh8iIiKiiig6DlBiYiLef/99fPTRRzh+/DiefPJJ5OXlYcyYMQCAkSNHYurUqZbtn3zySVy8eBETJkzAyZMn8e2332LOnDkYz5nciYiIqAYU7QM0dOhQZGVlYcaMGUhPT0fnzp2xefNmS8foc+fOQaO5ltGioqKwZcsWTJw4ER07dkSTJk0wYcIETJ48WalDICIiIhek6DhASrD3OAJERETkeA1mHCAiIiIipTAAERERkeowABEREZHqMAARERGR6jAAERERkerUOAClpKTg/Pnzlsf79+9HQkICli1bZtfCiIiIiBylxgHokUcewY4dOwAA6enp6NOnD/bv349p06Zh9uzZdi+QiIiIyN5qHICOHj2K7t27AwA+//xztG/fHnv27MGnn36KFStW2Ls+IiIiIrurcQAqLi62TC66fft23H///QCA1q1bIy0tzb7VERERETlAjQNQu3btsHTpUuzevRvbtm3DXXfdBQC4cOECgoKC7F4gERERkb3VOAC99tpreO+993D77bdj2LBh6NSpEwBg48aNllNjRERERPVZreYCM5lMMBqNCAwMtKw7c+YMvLy8EBISYtcC7Y1zgREREbkexecCu3LlCgoLCy3h5+zZs1iwYAGSk5PrffghIiIiAmoRgB544AGsXLkSAJCTk4O4uDi8+eabGDBgAN599127F0hERERkbzUOQIcOHULv3r0BAGvXrkVoaCjOnj2LlStX4u2337Z7gURERET2VuMAlJ+fD19fXwDA1q1bMWjQIGg0Gtx88804e/as3QskIiIisrcaB6DmzZtjw4YNSElJwZYtW9C3b18AQGZmJjsVExERkUuocQCaMWMGnnvuOcTExKB79+7o0aMHALk1qEuXLnYvkIiIiMjeanUZfHp6OtLS0tCpUydoNHKG2r9/P/z8/NC6dWu7F2lPvAyeiIjI9dj7+9utNi8KCwtDWFiYZVb4yMhIDoJIRERELqPGp8DMZjNmz54Nf39/REdHIzo6GgEBAXjppZdgNpsdUSMRERGRXdW4BWjatGn44IMP8Oqrr6JXr14AgB9//BGzZs1CQUEBXnnlFbsXSURERGRPNe4DFBERgaVLl1pmgS/11Vdf4amnnkJqaqpdC7Q39gEiIiJyPYpPhXHx4sUKOzq3bt0aFy9erHNBRERERI5W4wDUqVMnLF68uNz6xYsXW2aGJyIiIqrPatwHaN68ebj33nuxfft2yxhAe/fuRUpKCjZt2mT3AomIiIjsrcYtQLfddhtOnjyJgQMHIicnBzk5ORg0aBCSk5Mtc4QRERER1We1GgixIufPn8fs2bOxbNkye7ydw7ATNBERketRvBN0Zf755x988MEH9no7IiIiIoexWwAiIiIichUMQERERKQ6DEBERESkOjZfBj9o0KAqn8/JyalrLUREREROYXMA8vf3r/b5kSNH1rkgIiIiIkezOQAtX77ckXUQEREROQ37ABEREZHqMAARERGR6jAAERERkeowABEREZHq2DUAXblyxZ5vR0REROQQdglAhYWFePPNN9GsWTN7vB0RERGRQ9kcgAoLCzF16lTExsaiZ8+e2LBhAwD58vhmzZphwYIFmDhxoqPqJCIiIrIbm8cBmjFjBt577z3Ex8djz549eOihhzBmzBj8/PPPmD9/Ph566CFotVpH1kpERERkFzYHoC+++AIrV67E/fffj6NHj6Jjx44oKSnBb7/9BkmSHFkjERERkV3ZfArs/Pnz6Nq1KwCgffv20Ov1mDhxIsMPERERuRybA5DJZIJOp7M8dnNzg4+Pj0OKIiIiInIkm0+BCSEwevRo6PV6AEBBQQHGjRsHb29vq+3WrVtn3wqJiIiI7MzmADRq1Cirx48++qjdiyEiIiJyBs4GT0RERKrDqTCIiIhIdWxuARo7dqxN23344Ye1LoaIiIjIGWwOQCtWrEB0dDS6dOkCIYQjayIiIiJyKJsD0JNPPolVq1bh9OnTGDNmDB599FE0atTIkbUREREROYTNfYCWLFmCtLQ0PP/88/j6668RFRWFIUOGYMuWLWwRIiIiIpciiVqml7Nnz2LFihVYuXIlSkpK8Mcff7jEwIhGoxH+/v4wGAzw8/NTuhwiIiKygb2/v2t9FZhGo4EkSRBCwGQy1bkQIiIiImepUQAqLCzEqlWr0KdPH7Rs2RK///47Fi9ejHPnzrlE6w8RERERUINO0E899RRWr16NqKgojB07FqtWrUJwcLAjayMiIiJyCJv7AGk0GjRt2hRdunSpcgb4+j4XGPsAERERuR57f3/b3AI0cuTIKoMPERERkauo0UCIRERERA0B5wIjIiIi1WEAIiIiItWpFwFoyZIliImJgYeHB+Li4rB//36bXrd69WpIkoQBAwY4tkAiIiJqUBQPQGvWrEFiYiJmzpyJQ4cOoVOnTujXrx8yMzOrfN2ZM2fw3HPPoXfv3k6qlIiIiBoKxQPQ/Pnz8e9//xtjxoxB27ZtsXTpUnh5eeHDDz+s9DUmkwnDhw/Hiy++iBtuuMGJ1RIREVFDoGgAKioqwsGDBxEfH29Zp9FoEB8fj71791b6utmzZyMkJASPPfZYtfsoLCyE0Wi0WoiIiEjdFA1A2dnZMJlMCA0NtVofGhqK9PT0Cl/z448/4oMPPsD7779v0z7mzp0Lf39/yxIVFVXnuomIiMi1KX4KrCYuX76MESNG4P3337d5Go6pU6fCYDBYlpSUFAdXSURERPWdzQMhOkJwcDC0Wi0yMjKs1mdkZCAsLKzc9n///TfOnDmD/v37W9aZzWYAgJubG5KTk3HjjTdavUav10Ov1zugeiIiInJVirYA6XQ6dO3aFUlJSZZ1ZrMZSUlJ6NGjR7ntW7dujd9//x2HDx+2LPfffz/uuOMOHD58mKe3iIiIyCaKtgABQGJiIkaNGoXY2Fh0794dCxYsQF5eHsaMGQNAnoOsSZMmmDt3Ljw8PNC+fXur1wcEBABAufVERERElVE8AA0dOhRZWVmYMWMG0tPT0blzZ2zevNnSMfrcuXPQaFyqqxIRERHVc5IQQihdhDMZjUb4+/vDYDDAz89P6XKIiIjIBvb+/mbTChEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpDgMQERERqQ4DEBEREakOAxARERGpTr0IQEuWLEFMTAw8PDwQFxeH/fv3V7rt+++/j969eyMwMBCBgYGIj4+vcnsiIiKi6ykegNasWYPExETMnDkThw4dQqdOndCvXz9kZmZWuP3OnTsxbNgw7NixA3v37kVUVBT69u2L1NRUJ1dORERErkoSQgglC4iLi0O3bt2wePFiAIDZbEZUVBSeeeYZTJkypdrXm0wmBAYGYvHixRg5cmS12xuNRvj7+8NgMMDPz6/O9RMREZHj2fv7W9EWoKKiIhw8eBDx8fGWdRqNBvHx8di7d69N75Gfn4/i4mI0atSowucLCwthNBqtFiIiIlI3RQNQdnY2TCYTQkNDrdaHhoYiPT3dpveYPHkyIiIirEJUWXPnzoW/v79liYqKqnPdRERE5NoU7wNUF6+++ipWr16N9evXw8PDo8Jtpk6dCoPBYFlSUlKcXCURERHVN25K7jw4OBharRYZGRlW6zMyMhAWFlbla9944w28+uqr2L59Ozp27Fjpdnq9Hnq93i71EhERUcOgaAuQTqdD165dkZSUZFlnNpuRlJSEHj16VPq6efPm4aWXXsLmzZsRGxvrjFKJiIioAVG0BQgAEhMTMWrUKMTGxqJ79+5YsGAB8vLyMGbMGADAyJEj0aRJE8ydOxcA8Nprr2HGjBn47LPPEBMTY+kr5OPjAx8fH8WOg4iIiFyH4gFo6NChyMrKwowZM5Ceno7OnTtj8+bNlo7R586dg0ZzraHq3XffRVFREQYPHmz1PjNnzsSsWbOcWToRERG5KMXHAXI2jgNERETkehrUOEBERERESmAAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItWpFwFoyZIliImJgYeHB+Li4rB///4qt//iiy/QunVreHh4oEOHDti0aZOTKiUiIqKGQPEAtGbNGiQmJmLmzJk4dOgQOnXqhH79+iEzM7PC7ffs2YNhw4bhsccew6+//ooBAwZgwIABOHr0qJMrJyIiIlclCSGEkgXExcWhW7duWLx4MQDAbDYjKioKzzzzDKZMmVJu+6FDhyIvLw/ffPONZd3NN9+Mzp07Y+nSpdXuz2g0wt/fHwaDAX5+fvY7ECIiInIYe39/K9oCVFRUhIMHDyI+Pt6yTqPRID4+Hnv37q3wNXv37rXaHgD69etX6faFhYUwGo1WCxEREambogEoOzsbJpMJoaGhVutDQ0ORnp5e4WvS09NrtP3cuXPh7+9vWaKiouxTPBEREbksxfsAOdrUqVNhMBgsS0pKitIlERERkcLclNx5cHAwtFotMjIyrNZnZGQgLCyswteEhYXVaHu9Xg+9Xm+fgomIiKhBUDQA6XQ6dO3aFUlJSRgwYAAAuRN0UlISnn766Qpf06NHDyQlJSEhIcGybtu2bejRo4dN+yzt882+QERERK6j9HvbbtduCYWtXr1a6PV6sWLFCnHs2DHxxBNPiICAAJGeni6EEGLEiBFiypQplu1/+ukn4ebmJt544w1x/PhxMXPmTOHu7i5+//13m/aXkpIiAHDhwoULFy5cXHD5+++/7ZI/FG0BAuTL2rOysjBjxgykp6ejc+fO2Lx5s6Wj87lz56DRXOuq1LNnT3z22Wd44YUX8N///hctWrTAhg0b0L59e5v2FxERgWPHjqFt27ZISUlR1aXwRqMRUVFRPG4VUOMxAzxuHrc6qPW4DQYDmjZtikaNGtnl/RQfB0gJah0LiMetnuNW4zEDPG4etzrwuBvAOEBERERESmAAIiIiItVRZQDS6/WYOXOm6i6P53Gr57jVeMwAj5vHrQ48bvsctyr7ABEREZG6qbIFiIiIiNSNAYiIiIhUhwGIiIiIVIcBiIiIiFRHdQFoyZIliImJgYeHB+Li4rB//36lS3KouXPnolu3bvD19UVISAgGDBiA5ORkpctyuldffRWSJFnNIddQpaam4tFHH0VQUBA8PT3RoUMH/PLLL0qX5VAmkwnTp09Hs2bN4OnpiRtvvBEvvfSS/eYMqid++OEH9O/fHxEREZAkCRs2bLB6XgiBGTNmIDw8HJ6enoiPj8eff/6pTLF2VNVxFxcXY/LkyejQoQO8vb0RERGBkSNH4sKFC8oVbCfV/X2XNW7cOEiShAULFjitPkex5biPHz+O+++/H/7+/vD29ka3bt1w7ty5Gu1HVQFozZo1SExMxMyZM3Ho0CF06tQJ/fr1Q2ZmptKlOcyuXbswfvx4/Pzzz9i2bRuKi4vRt29f5OXlKV2a0xw4cADvvfceOnbsqHQpDnfp0iX06tUL7u7u+O6773Ds2DG8+eabCAwMVLo0h3rttdfw7rvvYvHixTh+/Dhee+01zJs3D4sWLVK6NLvKy8tDp06dsGTJkgqfnzdvHt5++20sXboU+/btg7e3N/r164eCggInV2pfVR13fn4+Dh06hOnTp+PQoUNYt24dkpOTcf/99ytQqX1V9/ddav369fj5558RERHhpMocq7rj/vvvv3HLLbegdevW2LlzJ44cOYLp06fDw8OjZjuyy4xiLqJ79+5i/Pjxlscmk0lERESIuXPnKliVc2VmZgoAYteuXUqX4hSXL18WLVq0ENu2bRO33XabmDBhgtIlOdTkyZPFLbfconQZTnfvvfeKsWPHWq0bNGiQGD58uEIVOR4AsX79estjs9kswsLCxOuvv25Zl5OTI/R6vVi1apUCFTrG9cddkf379wsA4uzZs84pygkqO+7z58+LJk2aiKNHj4ro6Gjx1ltvOb02R6rouIcOHSoeffTROr+3alqAioqKcPDgQcTHx1vWaTQaxMfHY+/evQpW5lwGgwEA7DaZXH03fvx43HvvvVZ/7w3Zxo0bERsbi4ceegghISHo0qUL3n//faXLcriePXsiKSkJJ0+eBAD89ttv+PHHH3H33XcrXJnznD59Gunp6Vb/1v39/REXF6eqzzhA/pyTJAkBAQFKl+JQZrMZI0aMwKRJk9CuXTuly3EKs9mMb7/9Fi1btkS/fv0QEhKCuLi4Kk8PVkY1ASg7Oxsmk8kyy3yp0NBQpKenK1SVc5nNZiQkJKBXr15o37690uU43OrVq3Ho0CHMnTtX6VKc5tSpU3j33XfRokULbNmyBU8++SSeffZZfPTRR0qX5lBTpkzBww8/jNatW8Pd3R1dunRBQkIChg8frnRpTlP6OabmzzgAKCgowOTJkzFs2LAGP1Hoa6+9Bjc3Nzz77LNKl+I0mZmZyM3Nxauvvoq77roLW7duxcCBAzFo0CDs2rWrRu/l5qAaqR4aP348jh49ih9//FHpUhwuJSUFEyZMwLZt22p+XtiFmc1mxMbGYs6cOQCALl264OjRo1i6dClGjRqlcHWO8/nnn+PTTz/FZ599hnbt2uHw4cNISEhAREREgz5uslZcXIwhQ4ZACIF3331X6XIc6uDBg1i4cCEOHToESZKULsdpzGYzAOCBBx7AxIkTAQCdO3fGnj17sHTpUtx22202v5dqWoCCg4Oh1WqRkZFhtT4jIwNhYWEKVeU8Tz/9NL755hvs2LEDkZGRSpfjcAcPHkRmZiZuuukmuLm5wc3NDbt27cLbb78NNzc3mEwmpUt0iPDwcLRt29ZqXZs2bWp8dYSrmTRpkqUVqEOHDhgxYgQmTpyoqta/0s8xtX7GlYafs2fPYtu2bQ2+9Wf37t3IzMxE06ZNLZ9xZ8+exX/+8x/ExMQoXZ7DBAcHw83NzS6fc6oJQDqdDl27dkVSUpJlndlsRlJSEnr06KFgZY4lhMDTTz+N9evX4/vvv0ezZs2ULskp7rzzTvz+++84fPiwZYmNjcXw4cNx+PBhaLVapUt0iF69epUb5uDkyZOIjo5WqCLnyM/Ph0Zj/XGm1WotvxbVoFmzZggLC7P6jDMajdi3b1+D/owDroWfP//8E9u3b0dQUJDSJTnciBEjcOTIEavPuIiICEyaNAlbtmxRujyH0el06Natm10+51R1CiwxMRGjRo1CbGwsunfvjgULFiAvLw9jxoxRujSHGT9+PD777DN89dVX8PX1tfQF8Pf3h6enp8LVOY6vr2+5fk7e3t4ICgpq0P2fJk6ciJ49e2LOnDkYMmQI9u/fj2XLlmHZsmVKl+ZQ/fv3xyuvvIKmTZuiXbt2+PXXXzF//nyMHTtW6dLsKjc3F3/99Zfl8enTp3H48GE0atQITZs2RUJCAl5++WW0aNECzZo1w/Tp0xEREYEBAwYoV7QdVHXc4eHhGDx4MA4dOoRvvvkGJpPJ8jnXqFEj6HQ6pcqus+r+vq8Peu7u7ggLC0OrVq2cXapdVXfckyZNwtChQ3HrrbfijjvuwObNm/H1119j586dNdtRna8jczGLFi0STZs2FTqdTnTv3l38/PPPSpfkUAAqXJYvX650aU6nhsvghRDi66+/Fu3btxd6vV60bt1aLFu2TOmSHM5oNIoJEyaIpk2bCg8PD3HDDTeIadOmicLCQqVLs6sdO3ZU+P951KhRQgj5Uvjp06eL0NBQodfrxZ133imSk5OVLdoOqjru06dPV/o5t2PHDqVLr5Pq/r6v11Aug7fluD/44APRvHlz4eHhITp16iQ2bNhQ4/1IQjSwoVKJiIiIqqGaPkBEREREpRiAiIiISHUYgIiIiEh1GICIiIhIdRiAiIiISHUYgIiIiEh1GICIiIhIdRiAiEj1JEnChg0blC6DiJyIAYiIFDV69GhIklRuueuuu5QujYgaMFXNBUZE9dNdd92F5cuXW63T6/UKVUNEasAWICJSnF6vR1hYmNUSGBgIQD499e677+Luu++Gp6cnbrjhBqxdu9bq9b///jv+9a9/wdPTE0FBQXjiiSeQm5trtc2HH36Idu3aQa/XIzw8HE8//bTV89nZ2Rg4cCC8vLzQokULbNy40bEHTUSKYgAionpv+vTpePDBB/Hbb79h+PDhePjhh3H8+HEAQF5eHvr164fAwEAcOHAAX3zxBbZv324VcN59912MHz8eTzzxBH7//Xds3LgRzZs3t9rHiy++iCFDhuDIkSO45557MHz4cFy8eNGpx0lETmS36VuJiGph1KhRQqvVCm9vb6vllVdeEUIIAUCMGzfO6jVxcXHiySefFEIIsWzZMhEYGChyc3Mtz3/77bdCo9GI9PR0IYQQERERYtq0aZXWAEC88MILlse5ubkCgPjuu+/sdpxEVL+wDxARKe6OO+7Au+++a7WuUaNGlvs9evSweq5Hjx44fPgwAOD48ePo1KkTvL29Lc/36tULZrMZycnJkCQJFy5cwJ133lllDR07drTc9/b2hp+fHzIzM2t7SERUzzEAEZHivL29y52SshdPT0+btnN3d7d6LEkSzGazI0oionqAfYCIqN77+eefyz1u06YNAKBNmzb47bffkJeXZ3n+p59+gkajQatWreDr64uYmBgkJSU5tWYiqt/YAkREiissLER6errVOjc3NwQHBwMAvvjiC8TGxuKWW27Bp59+iv379+ODDz4AAAwfPhwzZ87EqFGjMGvWLGRlZeGZZ57BiBEjEBoaCgCYNWsWxo0bh5CQENx99924fPkyfvrpJzzzzDPOPVAiqjcYgIhIcZs3b0Z4eLjVulatWuHEiRMA5Cu0Vq9ejaeeegrh4eFYtWoV2rZtCwDw8vLCli1bMGHCBHTr1g1eXl548MEHMX/+fMt7jRo1CgUFBXjrrbfw3HPPITg4GIMHD3beARJRvSMJIYTSRRARVUaSJKxfvx4DBgxQuhQiakDYB4iIiIhUhwGIiIiIVId9gIioXuNZeiJyBLYAERERkeowABEREZHqMAARERGR6jAAERERkeowABEREZHqMAARERGR6jAAERERkeowABEREZHqMAARERGR6vw/+ACGNTYN3UkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MR'\n",
    "N_EPOCHS = 16\n",
    " \n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MR\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([16143, 100])\n",
      "16143\n",
      "16143\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "# print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 5、池化 ================\n",
    "\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2\n",
    "    \n",
    "# ===================== 02 Model_best_copy8672_cnn_diagonal =====================\n",
    "\n",
    "print(\"Model_best_copy8672_cnn_diagonal\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim-2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_is_sentiment = self.phase_embedding(text)\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.self_attention2(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、取对角线 ================\n",
    "        diagonal_elements_real = Conv_real[:, 0, torch.arange(Conv_real.size(2)), torch.arange(Conv_real.size(3))]\n",
    "        diagonal_elements_imag = Conv_imag[:, 0, torch.arange(Conv_imag.size(2)), torch.arange(Conv_imag.size(3))]\n",
    "\n",
    "        diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "        diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "        fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "        fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "        return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_diagonal\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "source": [
    "# ===================== 03 Model_best_copy8672_diagonal =====================\n",
    "# print(\"Model_best_copy8672_diagonal\")\n",
    "    \n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、取对角线 ================\n",
    "#         diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "#         diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 5、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "source": [
    "# ===================== 04 Model_best_copy8672_maxpooling =====================\n",
    "# print(\"Model_best_copy8672_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、池化 ================\n",
    "#         # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 5、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(MatrixReal))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(MatrixImag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,989,901 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.630 | Train Acc: 64.01%\n",
      "\t test  Loss: 0.543 | test  Acc: 75.02%\n",
      "\t best  test acc: 75.02%\n",
      "Epoch: 02 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.450 | Train Acc: 80.84%\n",
      "\t test  Loss: 0.502 | test  Acc: 79.02%\n",
      "\t best  test acc: 79.02%\n",
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.308 | Train Acc: 89.00%\n",
      "\t test  Loss: 0.520 | test  Acc: 79.21%\n",
      "\t best  test acc: 79.21%\n",
      "Epoch: 04 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.221 | Train Acc: 93.02%\n",
      "\t test  Loss: 0.607 | test  Acc: 77.67%\n",
      "\t best  test acc: 79.21%\n",
      "Epoch: 05 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.157 | Train Acc: 95.92%\n",
      "\t test  Loss: 0.641 | test  Acc: 78.19%\n",
      "\t best  test acc: 79.21%\n",
      "Epoch: 06 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.127 | Train Acc: 96.84%\n",
      "\t test  Loss: 0.651 | test  Acc: 79.16%\n",
      "\t best  test acc: 79.21%\n",
      "Epoch: 07 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.107 | Train Acc: 97.52%\n",
      "\t test  Loss: 0.642 | test  Acc: 80.15%\n",
      "\t best  test acc: 80.15%\n",
      "Epoch: 08 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.095 | Train Acc: 97.94%\n",
      "\t test  Loss: 0.768 | test  Acc: 77.91%\n",
      "\t best  test acc: 80.15%\n",
      "Epoch: 09 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.087 | Train Acc: 98.08%\n",
      "\t test  Loss: 0.726 | test  Acc: 77.72%\n",
      "\t best  test acc: 80.15%\n",
      "Epoch: 10 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.075 | Train Acc: 98.51%\n",
      "\t test  Loss: 0.817 | test  Acc: 77.40%\n",
      "\t best  test acc: 80.15%\n",
      "Epoch: 11 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.069 | Train Acc: 98.58%\n",
      "\t test  Loss: 0.839 | test  Acc: 76.84%\n",
      "\t best  test acc: 80.15%\n",
      "Epoch: 12 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.066 | Train Acc: 98.62%\n",
      "\t test  Loss: 0.833 | test  Acc: 77.91%\n",
      "\t best  test acc: 80.15%\n",
      "Epoch: 13 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.062 | Train Acc: 98.76%\n",
      "\t test  Loss: 0.870 | test  Acc: 77.68%\n",
      "\t best  test acc: 80.15%\n",
      "Epoch: 14 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.059 | Train Acc: 98.85%\n",
      "\t test  Loss: 0.839 | test  Acc: 77.26%\n",
      "\t best  test acc: 80.15%\n",
      "Epoch: 15 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.055 | Train Acc: 98.86%\n",
      "\t test  Loss: 0.897 | test  Acc: 77.35%\n",
      "\t best  test acc: 80.15%\n",
      "Epoch: 16 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.049 | Train Acc: 98.95%\n",
      "\t test  Loss: 0.848 | test  Acc: 76.88%\n",
      "\t best  test acc: 80.15%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}