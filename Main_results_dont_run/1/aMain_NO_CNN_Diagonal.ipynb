{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MR'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MR\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([16143, 100])\n",
      "16143\n",
      "16143\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "# print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 5、池化 ================\n",
    "\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2\n",
    "    \n",
    "# ===================== 02 Model_best_copy8672_cnn_diagonal =====================\n",
    "\n",
    "# print(\"Model_best_copy8672_cnn_diagonal\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim-2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、取对角线 ================\n",
    "#         diagonal_elements_real = Conv_real[:, 0, torch.arange(Conv_real.size(2)), torch.arange(Conv_real.size(3))]\n",
    "#         diagonal_elements_imag = Conv_imag[:, 0, torch.arange(Conv_imag.size(2)), torch.arange(Conv_imag.size(3))]\n",
    "\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "# ===================== 03 Model_best_copy8672_diagonal =====================\n",
    "print(\"Model_best_copy8672_diagonal\")\n",
    "    \n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_is_sentiment = self.phase_embedding(text)\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.self_attention2(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、取对角线 ================\n",
    "        diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "        diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "        diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "        diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "        # ================ 5、全连接 ================\n",
    "        diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "        fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "        fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "        return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_diagonal\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "# ===================== 04 Model_best_copy8672_maxpooling =====================\n",
    "# print(\"Model_best_copy8672_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、池化 ================\n",
    "#         # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 5、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(MatrixReal))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(MatrixImag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,989,921 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.624 | Train Acc: 65.13%\n",
      "\t test  Loss: 0.530 | test  Acc: 76.04%\n",
      "\t best  test acc: 76.04%\n",
      "Epoch: 02 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.450 | Train Acc: 80.57%\n",
      "\t test  Loss: 0.501 | test  Acc: 78.32%\n",
      "\t best  test acc: 78.32%\n",
      "Epoch: 03 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.295 | Train Acc: 89.33%\n",
      "\t test  Loss: 0.517 | test  Acc: 79.77%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 04 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.188 | Train Acc: 94.37%\n",
      "\t test  Loss: 0.555 | test  Acc: 79.44%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 05 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.139 | Train Acc: 96.20%\n",
      "\t test  Loss: 0.632 | test  Acc: 78.70%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 06 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.102 | Train Acc: 97.55%\n",
      "\t test  Loss: 0.695 | test  Acc: 78.93%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 07 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.082 | Train Acc: 98.13%\n",
      "\t test  Loss: 0.747 | test  Acc: 78.60%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 08 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.071 | Train Acc: 98.48%\n",
      "\t test  Loss: 0.825 | test  Acc: 78.10%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 09 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.065 | Train Acc: 98.72%\n",
      "\t test  Loss: 0.806 | test  Acc: 78.42%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 10 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.057 | Train Acc: 98.90%\n",
      "\t test  Loss: 0.910 | test  Acc: 77.76%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 11 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.055 | Train Acc: 98.85%\n",
      "\t test  Loss: 0.944 | test  Acc: 76.51%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 12 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.044 | Train Acc: 99.24%\n",
      "\t test  Loss: 1.060 | test  Acc: 76.32%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 13 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.046 | Train Acc: 99.15%\n",
      "\t test  Loss: 1.069 | test  Acc: 75.58%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 14 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.049 | Train Acc: 99.03%\n",
      "\t test  Loss: 0.951 | test  Acc: 75.95%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 15 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.044 | Train Acc: 99.12%\n",
      "\t test  Loss: 1.362 | test  Acc: 70.35%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 16 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.055 | Train Acc: 98.86%\n",
      "\t test  Loss: 0.997 | test  Acc: 75.07%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 17 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.040 | Train Acc: 99.24%\n",
      "\t test  Loss: 1.093 | test  Acc: 75.44%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 18 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.036 | Train Acc: 99.31%\n",
      "\t test  Loss: 1.106 | test  Acc: 76.93%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 19 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.032 | Train Acc: 99.47%\n",
      "\t test  Loss: 1.149 | test  Acc: 75.77%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 20 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.032 | Train Acc: 99.49%\n",
      "\t test  Loss: 1.108 | test  Acc: 76.00%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 21 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.031 | Train Acc: 99.46%\n",
      "\t test  Loss: 1.078 | test  Acc: 75.81%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 22 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.032 | Train Acc: 99.39%\n",
      "\t test  Loss: 1.093 | test  Acc: 76.56%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 23 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.030 | Train Acc: 99.45%\n",
      "\t test  Loss: 1.110 | test  Acc: 75.95%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 24 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.023 | Train Acc: 99.57%\n",
      "\t test  Loss: 1.146 | test  Acc: 75.68%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 25 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.021 | Train Acc: 99.65%\n",
      "\t test  Loss: 1.207 | test  Acc: 75.91%\n",
      "\t best  test acc: 79.77%\n",
      "Epoch: 26 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.018 | Train Acc: 99.73%\n",
      "\t test  Loss: 1.232 | test  Acc: 76.84%\n",
      "\t best  test acc: 79.77%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'SUBJ'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: SUBJ\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([18512, 100])\n",
      "18512\n",
      "18512\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "# print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 5、池化 ================\n",
    "\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2\n",
    "    \n",
    "# ===================== 02 Model_best_copy8672_cnn_diagonal =====================\n",
    "\n",
    "# print(\"Model_best_copy8672_cnn_diagonal\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim-2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、取对角线 ================\n",
    "#         diagonal_elements_real = Conv_real[:, 0, torch.arange(Conv_real.size(2)), torch.arange(Conv_real.size(3))]\n",
    "#         diagonal_elements_imag = Conv_imag[:, 0, torch.arange(Conv_imag.size(2)), torch.arange(Conv_imag.size(3))]\n",
    "\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "source": [
    "# ===================== 03 Model_best_copy8672_diagonal =====================\n",
    "print(\"Model_best_copy8672_diagonal\")\n",
    "    \n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_is_sentiment = self.phase_embedding(text)\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.self_attention2(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、取对角线 ================\n",
    "        diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "        diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "        diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "        diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "        # ================ 5、全连接 ================\n",
    "        diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "        fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "        fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "        return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_diagonal\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "source": [
    "# ===================== 04 Model_best_copy8672_maxpooling =====================\n",
    "# print(\"Model_best_copy8672_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、池化 ================\n",
    "#         # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 5、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(MatrixReal))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(MatrixImag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 2,226,821 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.487 | Train Acc: 79.39%\n",
      "\t test  Loss: 0.375 | test  Acc: 85.81%\n",
      "\t best  test acc: 85.81%\n",
      "Epoch: 02 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.233 | Train Acc: 92.90%\n",
      "\t test  Loss: 0.329 | test  Acc: 87.90%\n",
      "\t best  test acc: 87.90%\n",
      "Epoch: 03 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.146 | Train Acc: 95.97%\n",
      "\t test  Loss: 0.244 | test  Acc: 91.77%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 04 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.089 | Train Acc: 97.81%\n",
      "\t test  Loss: 0.264 | test  Acc: 91.67%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 05 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.056 | Train Acc: 98.90%\n",
      "\t test  Loss: 0.299 | test  Acc: 92.26%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 06 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.038 | Train Acc: 99.25%\n",
      "\t test  Loss: 0.280 | test  Acc: 91.57%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 07 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.029 | Train Acc: 99.44%\n",
      "\t test  Loss: 0.322 | test  Acc: 91.67%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 08 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.021 | Train Acc: 99.69%\n",
      "\t test  Loss: 0.415 | test  Acc: 90.67%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 09 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.017 | Train Acc: 99.70%\n",
      "\t test  Loss: 0.389 | test  Acc: 91.07%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 10 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.011 | Train Acc: 99.86%\n",
      "\t test  Loss: 0.425 | test  Acc: 91.96%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 11 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.017 | Train Acc: 99.60%\n",
      "\t test  Loss: 0.558 | test  Acc: 87.90%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 12 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.011 | Train Acc: 99.83%\n",
      "\t test  Loss: 0.517 | test  Acc: 89.78%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 13 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.008 | Train Acc: 99.86%\n",
      "\t test  Loss: 0.434 | test  Acc: 90.18%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 14 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.006 | Train Acc: 99.91%\n",
      "\t test  Loss: 0.489 | test  Acc: 90.28%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 15 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.004 | Train Acc: 99.96%\n",
      "\t test  Loss: 0.512 | test  Acc: 90.18%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 16 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.004 | Train Acc: 99.96%\n",
      "\t test  Loss: 0.556 | test  Acc: 89.68%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 17 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.003 | Train Acc: 99.98%\n",
      "\t test  Loss: 0.579 | test  Acc: 89.48%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 18 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.003 | Train Acc: 99.98%\n",
      "\t test  Loss: 0.599 | test  Acc: 89.68%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 19 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.002 | Train Acc: 99.98%\n",
      "\t test  Loss: 0.618 | test  Acc: 89.68%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 20 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.002 | Train Acc: 99.98%\n",
      "\t test  Loss: 0.635 | test  Acc: 89.68%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 21 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.002 | Train Acc: 99.98%\n",
      "\t test  Loss: 0.651 | test  Acc: 89.68%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 22 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.002 | Train Acc: 99.98%\n",
      "\t test  Loss: 0.666 | test  Acc: 89.68%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 23 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.002 | Train Acc: 99.98%\n",
      "\t test  Loss: 0.681 | test  Acc: 89.68%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 24 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.002 | Train Acc: 99.98%\n",
      "\t test  Loss: 0.695 | test  Acc: 89.58%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 25 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.002 | Train Acc: 99.98%\n",
      "\t test  Loss: 0.709 | test  Acc: 89.78%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 26 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.002 | Train Acc: 99.98%\n",
      "\t test  Loss: 0.722 | test  Acc: 89.68%\n",
      "\t best  test acc: 92.26%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "# print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 5、池化 ================\n",
    "\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2\n",
    "    \n",
    "# ===================== 02 Model_best_copy8672_cnn_diagonal =====================\n",
    "\n",
    "# print(\"Model_best_copy8672_cnn_diagonal\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim-2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、取对角线 ================\n",
    "#         diagonal_elements_real = Conv_real[:, 0, torch.arange(Conv_real.size(2)), torch.arange(Conv_real.size(3))]\n",
    "#         diagonal_elements_imag = Conv_imag[:, 0, torch.arange(Conv_imag.size(2)), torch.arange(Conv_imag.size(3))]\n",
    "\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "source": [
    "# ===================== 03 Model_best_copy8672_diagonal =====================\n",
    "print(\"Model_best_copy8672_diagonal\")\n",
    "    \n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_is_sentiment = self.phase_embedding(text)\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.self_attention2(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、取对角线 ================\n",
    "        diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "        diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "        diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "        diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "        # ================ 5、全连接 ================\n",
    "        diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "        fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "        fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "        return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_diagonal\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "source": [
    "# ===================== 04 Model_best_copy8672_maxpooling =====================\n",
    "# print(\"Model_best_copy8672_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、池化 ================\n",
    "#         # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 5、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(MatrixReal))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(MatrixImag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 932,421 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.456 | Train Acc: 80.40%\n",
      "\t test  Loss: 0.360 | test  Acc: 85.91%\n",
      "\t best  test acc: 85.91%\n",
      "Epoch: 02 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.307 | Train Acc: 89.23%\n",
      "\t test  Loss: 0.334 | test  Acc: 86.66%\n",
      "\t best  test acc: 86.66%\n",
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.239 | Train Acc: 92.17%\n",
      "\t test  Loss: 0.343 | test  Acc: 86.75%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 04 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.198 | Train Acc: 94.06%\n",
      "\t test  Loss: 0.348 | test  Acc: 84.89%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 05 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.171 | Train Acc: 94.99%\n",
      "\t test  Loss: 0.387 | test  Acc: 85.54%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 06 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.151 | Train Acc: 95.56%\n",
      "\t test  Loss: 0.399 | test  Acc: 85.54%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 07 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.137 | Train Acc: 96.01%\n",
      "\t test  Loss: 0.412 | test  Acc: 85.91%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 08 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.126 | Train Acc: 96.45%\n",
      "\t test  Loss: 0.411 | test  Acc: 85.91%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 09 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.119 | Train Acc: 96.49%\n",
      "\t test  Loss: 0.420 | test  Acc: 86.29%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 10 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.109 | Train Acc: 96.92%\n",
      "\t test  Loss: 0.429 | test  Acc: 85.63%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 11 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.108 | Train Acc: 96.89%\n",
      "\t test  Loss: 0.427 | test  Acc: 85.54%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 12 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.101 | Train Acc: 96.96%\n",
      "\t test  Loss: 0.441 | test  Acc: 86.10%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 13 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.094 | Train Acc: 97.33%\n",
      "\t test  Loss: 0.466 | test  Acc: 85.17%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 14 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.092 | Train Acc: 97.18%\n",
      "\t test  Loss: 0.482 | test  Acc: 84.42%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 15 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.082 | Train Acc: 97.63%\n",
      "\t test  Loss: 0.496 | test  Acc: 84.61%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 16 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.093 | Train Acc: 97.10%\n",
      "\t test  Loss: 0.493 | test  Acc: 84.70%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 17 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.088 | Train Acc: 97.41%\n",
      "\t test  Loss: 0.508 | test  Acc: 84.33%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 18 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.076 | Train Acc: 97.79%\n",
      "\t test  Loss: 0.526 | test  Acc: 84.61%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 19 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.073 | Train Acc: 97.69%\n",
      "\t test  Loss: 0.502 | test  Acc: 84.89%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 20 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.069 | Train Acc: 97.82%\n",
      "\t test  Loss: 0.530 | test  Acc: 84.51%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 21 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.065 | Train Acc: 97.86%\n",
      "\t test  Loss: 0.563 | test  Acc: 83.96%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 22 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.063 | Train Acc: 98.05%\n",
      "\t test  Loss: 0.590 | test  Acc: 83.40%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 23 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.060 | Train Acc: 98.00%\n",
      "\t test  Loss: 0.616 | test  Acc: 81.81%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 24 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.065 | Train Acc: 97.88%\n",
      "\t test  Loss: 0.568 | test  Acc: 83.77%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 25 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.058 | Train Acc: 98.20%\n",
      "\t test  Loss: 0.639 | test  Acc: 81.90%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 26 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.054 | Train Acc: 98.19%\n",
      "\t test  Loss: 0.607 | test  Acc: 83.40%\n",
      "\t best  test acc: 86.75%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'CR'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: CR\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([4749, 100])\n",
      "4749\n",
      "4749\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "# print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 5、池化 ================\n",
    "\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2\n",
    "    \n",
    "# ===================== 02 Model_best_copy8672_cnn_diagonal =====================\n",
    "\n",
    "# print(\"Model_best_copy8672_cnn_diagonal\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim-2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、取对角线 ================\n",
    "#         diagonal_elements_real = Conv_real[:, 0, torch.arange(Conv_real.size(2)), torch.arange(Conv_real.size(3))]\n",
    "#         diagonal_elements_imag = Conv_imag[:, 0, torch.arange(Conv_imag.size(2)), torch.arange(Conv_imag.size(3))]\n",
    "\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "source": [
    "# ===================== 03 Model_best_copy8672_diagonal =====================\n",
    "print(\"Model_best_copy8672_diagonal\")\n",
    "    \n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_is_sentiment = self.phase_embedding(text)\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.self_attention2(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、取对角线 ================\n",
    "        diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "        diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "        diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "        diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "        # ================ 5、全连接 ================\n",
    "        diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "        fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "        fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "        return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_diagonal\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "source": [
    "# ===================== 04 Model_best_copy8672_maxpooling =====================\n",
    "# print(\"Model_best_copy8672_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、池化 ================\n",
    "#         # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 5、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(MatrixReal))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(MatrixImag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 850,521 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.622 | Train Acc: 66.77%\n",
      "\t test  Loss: 0.631 | test  Acc: 63.54%\n",
      "\t best  test acc: 63.54%\n",
      "Epoch: 02 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.582 | Train Acc: 68.58%\n",
      "\t test  Loss: 0.585 | test  Acc: 70.31%\n",
      "\t best  test acc: 70.31%\n",
      "Epoch: 03 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.527 | Train Acc: 74.70%\n",
      "\t test  Loss: 0.487 | test  Acc: 77.34%\n",
      "\t best  test acc: 77.34%\n",
      "Epoch: 04 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.402 | Train Acc: 84.52%\n",
      "\t test  Loss: 0.467 | test  Acc: 78.39%\n",
      "\t best  test acc: 78.39%\n",
      "Epoch: 05 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.324 | Train Acc: 88.59%\n",
      "\t test  Loss: 0.439 | test  Acc: 80.21%\n",
      "\t best  test acc: 80.21%\n",
      "Epoch: 06 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.264 | Train Acc: 91.40%\n",
      "\t test  Loss: 0.420 | test  Acc: 81.77%\n",
      "\t best  test acc: 81.77%\n",
      "Epoch: 07 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.228 | Train Acc: 92.99%\n",
      "\t test  Loss: 0.420 | test  Acc: 81.25%\n",
      "\t best  test acc: 81.77%\n",
      "Epoch: 08 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.201 | Train Acc: 93.92%\n",
      "\t test  Loss: 0.437 | test  Acc: 84.11%\n",
      "\t best  test acc: 84.11%\n",
      "Epoch: 09 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.171 | Train Acc: 95.24%\n",
      "\t test  Loss: 0.436 | test  Acc: 83.85%\n",
      "\t best  test acc: 84.11%\n",
      "Epoch: 10 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.145 | Train Acc: 96.46%\n",
      "\t test  Loss: 0.528 | test  Acc: 81.77%\n",
      "\t best  test acc: 84.11%\n",
      "Epoch: 11 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.130 | Train Acc: 96.69%\n",
      "\t test  Loss: 0.515 | test  Acc: 82.81%\n",
      "\t best  test acc: 84.11%\n",
      "Epoch: 12 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.119 | Train Acc: 97.22%\n",
      "\t test  Loss: 0.501 | test  Acc: 85.68%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 13 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.107 | Train Acc: 97.65%\n",
      "\t test  Loss: 0.511 | test  Acc: 84.11%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 14 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.103 | Train Acc: 97.59%\n",
      "\t test  Loss: 0.561 | test  Acc: 82.81%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 15 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.100 | Train Acc: 97.72%\n",
      "\t test  Loss: 0.613 | test  Acc: 81.51%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 16 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.107 | Train Acc: 97.55%\n",
      "\t test  Loss: 0.567 | test  Acc: 83.59%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 17 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.096 | Train Acc: 97.95%\n",
      "\t test  Loss: 0.563 | test  Acc: 83.85%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 18 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.090 | Train Acc: 98.15%\n",
      "\t test  Loss: 0.591 | test  Acc: 84.64%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 19 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.090 | Train Acc: 98.02%\n",
      "\t test  Loss: 0.539 | test  Acc: 83.33%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 20 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.099 | Train Acc: 97.69%\n",
      "\t test  Loss: 0.637 | test  Acc: 82.03%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 21 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.098 | Train Acc: 97.78%\n",
      "\t test  Loss: 0.639 | test  Acc: 80.99%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 22 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.077 | Train Acc: 98.31%\n",
      "\t test  Loss: 0.664 | test  Acc: 81.51%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 23 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.071 | Train Acc: 98.41%\n",
      "\t test  Loss: 0.665 | test  Acc: 81.77%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 24 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.063 | Train Acc: 98.51%\n",
      "\t test  Loss: 0.685 | test  Acc: 83.85%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 25 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.057 | Train Acc: 98.71%\n",
      "\t test  Loss: 0.696 | test  Acc: 83.07%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 26 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.050 | Train Acc: 99.04%\n",
      "\t test  Loss: 0.698 | test  Acc: 82.29%\n",
      "\t best  test acc: 85.68%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}