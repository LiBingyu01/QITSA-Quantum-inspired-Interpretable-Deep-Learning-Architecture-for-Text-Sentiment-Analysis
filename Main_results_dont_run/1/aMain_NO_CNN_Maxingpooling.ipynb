{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "已连接到 base (Python 3.8.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "# print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 5、池化 ================\n",
    "\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2\n",
    "    \n",
    "# ===================== 02 Model_best_copy8672_cnn_diagonal =====================\n",
    "\n",
    "# print(\"Model_best_copy8672_cnn_diagonal\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim-2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、取对角线 ================\n",
    "#         diagonal_elements_real = Conv_real[:, 0, torch.arange(Conv_real.size(2)), torch.arange(Conv_real.size(3))]\n",
    "#         diagonal_elements_imag = Conv_imag[:, 0, torch.arange(Conv_imag.size(2)), torch.arange(Conv_imag.size(3))]\n",
    "\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== 03 Model_best_copy8672_diagonal =====================\n",
    "# print(\"Model_best_copy8672_diagonal\")\n",
    "    \n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、取对角线 ================\n",
    "#         diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "#         diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 5、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_best_copy8672_maxpooling\n"
     ]
    }
   ],
   "source": [
    "# ===================== 04 Model_best_copy8672_maxpooling =====================\n",
    "print(\"Model_best_copy8672_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、池化 ================\n",
    "        # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "        # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 5、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_is_sentiment = self.phase_embedding(text)\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.self_attention2(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(MatrixReal))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(MatrixImag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 932,421 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.581 | Train Acc: 68.71%\n",
      "\t test  Loss: 0.538 | test  Acc: 68.38%\n",
      "\t best  test acc: 68.38%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.381 | Train Acc: 86.39%\n",
      "\t test  Loss: 0.341 | test  Acc: 86.94%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.251 | Train Acc: 91.61%\n",
      "\t test  Loss: 0.332 | test  Acc: 86.29%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 04 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.193 | Train Acc: 94.21%\n",
      "\t test  Loss: 0.341 | test  Acc: 86.47%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 05 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.162 | Train Acc: 95.19%\n",
      "\t test  Loss: 0.358 | test  Acc: 86.75%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 06 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.143 | Train Acc: 95.90%\n",
      "\t test  Loss: 0.388 | test  Acc: 84.98%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 07 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.128 | Train Acc: 96.37%\n",
      "\t test  Loss: 0.378 | test  Acc: 86.47%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 08 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.117 | Train Acc: 96.61%\n",
      "\t test  Loss: 0.403 | test  Acc: 86.10%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 09 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.109 | Train Acc: 96.70%\n",
      "\t test  Loss: 0.397 | test  Acc: 85.54%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 10 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.101 | Train Acc: 96.95%\n",
      "\t test  Loss: 0.401 | test  Acc: 85.45%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 11 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.090 | Train Acc: 97.13%\n",
      "\t test  Loss: 0.422 | test  Acc: 86.01%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 12 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.084 | Train Acc: 97.27%\n",
      "\t test  Loss: 0.452 | test  Acc: 85.73%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 13 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.087 | Train Acc: 97.07%\n",
      "\t test  Loss: 0.461 | test  Acc: 85.45%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 14 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.077 | Train Acc: 97.20%\n",
      "\t test  Loss: 0.501 | test  Acc: 85.17%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 15 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.067 | Train Acc: 97.56%\n",
      "\t test  Loss: 0.510 | test  Acc: 85.17%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 16 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.064 | Train Acc: 97.66%\n",
      "\t test  Loss: 0.548 | test  Acc: 83.40%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.060 | Train Acc: 97.75%\n",
      "\t test  Loss: 0.526 | test  Acc: 85.17%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 18 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.059 | Train Acc: 97.83%\n",
      "\t test  Loss: 0.585 | test  Acc: 85.26%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 19 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.053 | Train Acc: 97.96%\n",
      "\t test  Loss: 0.585 | test  Acc: 85.35%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 20 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.049 | Train Acc: 98.14%\n",
      "\t test  Loss: 0.608 | test  Acc: 85.45%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 21 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.065 | Train Acc: 97.48%\n",
      "\t test  Loss: 0.550 | test  Acc: 84.89%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 22 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.048 | Train Acc: 98.08%\n",
      "\t test  Loss: 0.594 | test  Acc: 85.91%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 23 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.047 | Train Acc: 98.13%\n",
      "\t test  Loss: 0.583 | test  Acc: 84.33%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 24 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.038 | Train Acc: 98.39%\n",
      "\t test  Loss: 0.614 | test  Acc: 84.24%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 25 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.040 | Train Acc: 98.35%\n",
      "\t test  Loss: 0.651 | test  Acc: 84.61%\n",
      "\t best  test acc: 86.94%\n",
      "Epoch: 26 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.039 | Train Acc: 98.33%\n",
      "\t test  Loss: 0.624 | test  Acc: 85.54%\n",
      "\t best  test acc: 86.94%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABOHElEQVR4nO3deXwTdf4/8NckTdL7pgdQKFe5KXctCOtKoYWVFZEviIgUFRYFBLusgMrlAR67LKyg7PrzWP1yCYLiVcQKqFBBOQS+lENsKUdPSu87+fz+SBuankmbdtLp6/l4zCPNZPKZd6Zp8upnPjMjCSEEiIiIiBRCJXcBRERERLbEcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIoia7j5/vvvMXHiRLRv3x6SJOHTTz9t8DmHDh3C4MGDodPp0L17d3zwwQfNXicRERG1HrKGm4KCAoSGhmLz5s0WLZ+YmIg//elP+OMf/4jTp09j8eLFeOKJJ7B///5mrpSIiIhaC8leLpwpSRL27t2LSZMm1bnM0qVL8eWXX+LcuXOmeQ899BCys7MRGxvbAlUSERGRvXOQuwBrxMfHIyIiwmxeZGQkFi9eXOdzSkpKUFJSYrpvMBiQlZUFHx8fSJLUXKUSERGRDQkhkJeXh/bt20Olqn/HU6sKN6mpqfD39zeb5+/vj9zcXBQVFcHJyanGc9atW4c1a9a0VIlERETUjK5du4aOHTvWu0yrCjeNsXz5csTExJju5+TkoFOnTrh27Rrc3d1lrIyIiMgG9Hrg6FEgNRUICABGjADUamW1BSA3NxdBQUFwc3NrcNlWFW4CAgKQlpZmNi8tLQ3u7u619toAgE6ng06nqzHf3d2d4YaIyB7p9cAPPwApKUBgIDBqVJO+FO2yLlu1tWcPsGgRcP36nXkdOwIbNwKTJyujrWosGVLSqs5zEx4ejri4OLN5Bw4cQHh4uEwVERG1ML0eOHQI2L7deKvXK6utPXuA4GDgj38EHn7YeBscbJwvJ1vWZau29uwBpkwxDxAAcOOGcb417dlrW40lZJSXlydOnTolTp06JQCI9evXi1OnTomrV68KIYRYtmyZmDlzpmn533//XTg7O4u//e1vIiEhQWzevFmo1WoRGxtr8TpzcnIEAJGTk2Pz10NEClFeLsTBg0Js22a8LS+3j/Y++USIjh2FAO5MHTsa5yuhrU8+EUKSzNsBjPMkqXG12WLb27IuW7VVXl5zm1dvLyjIstdrr21VY833t6zh5uDBgwJAjWnWrFlCCCFmzZol/vCHP9R4zsCBA4VWqxVdu3YV77//vlXrZLghaiJbf/Hbij0GCFu2Z49fsLZsqzm+FG2x7Ztal8EgRFmZECUlQuTnC9GhQ91tAUL4+grxv/8rxL//LcTf/y7EqlVC/PWvQsydK8T06UJMnCjEPfcIERJSfzuVk0olhEYjhFYrhKOjEM7OQri4COHmJoSHhxBeXsafLWnL31+Irl2F6NZNiO7dhejRw1hHr15C9O4tRJ8+QgQHW9bWwYOW/w4qWPP9bTfnuWkpubm58PDwQE5ODsfckH1T+v59e6yrsju9+sdi5T7+3bvlaU+vN+62qN7NX7W9jh2BxMSGt58lbQUEAAcPAuXlQGmpcSopMb8tLQWKioCYGOD27brX5+wMjB8PFBcbp6Ii41T954IC4/oa8swzQGQk0KUL0KkT4OhY+3JN2fa5ucC1a8bpwAFg/fqG63J0NLZtMBgnvd54S7Xbtg2YPt2qp1jz/c1wQ2RL9vZlbcu2muOL357qsuRLPzAQOHbM+KVVVmb8Mq56W/XnkhLg0UeBW7fqXqenJ7B0ac32qrednAxYcib2Xr0AJyfjc+qaioqA/PyG22otAgONQSc42Dh16QIEBQHR0cajdGojSUC7dsDrrxvHgSQnG4NM5W1OTgu+gFr06QN07w64uRknV9eaPycmAs8913Bbu3YBd91l/PuoDF4Gg/n9n34CZs9uuK3Nm4FBg+70v1S2U3U6dQr4618bbuvgQeCeexpergqGm3ow3CiEkns1bBki7LHnQI66EhKMX1hZWXVPFy4Ahw83vM62wskJcHEBtFpApzO/rfz51i3gzJmG24qOBu6+29imk5Oxl6P6z6dPA9OmNdzWXXcBeXlAUpKxt6e5eHkZQ5Kzs/HLvyFbt9451FmlMk7Vfz5yBPjTnxpuy5Iv/sr3/o0bNf+OgMb15tlbW9Uw3NSD4UYBlNyrYW2IKCuru6s/P994JEZmZt3rc3Mz/sdW2dNQdarcBVFSYmzj8uWG6x8yxFifs7PxC8vZ2Xyq/DJbutQYKOri6wts2mTcHnXtEikpAa5cMf5n2pIkyfjlrtEADg7mt1V/zssDrl5tuL1Ro4CQkJrPr9rm1avAO+803Nbatcb/rB0czKfK9hwcgBMngFmzGm7Lki/YQ4eMR/rYoi1rvxSFMIarxERj0Km8TUoCfv0VuHmz4br69AGGDzeGmE6dzG9dXRtXly1fY0MqP3cA8/aa8o+QvbVVhVXf31aP6GnlOKBYRm35qIUOHYS4ckWIc+eEiI8X4sABIfbuFeKjj4R4+20h3njDOHBw6lTLBuM5OgqhVlu2LCfjpFYbB2uGhAhx111CTJggxCOPCPH000KsXi3EwoWWtWPpQMiDB23XXuV7rLb3a+V7zNqjWeytLSHu/E1Wb8/av0lbbntb1mXrtirbq/75ExRku6Pe7KGtChxQXA/23MjEFj0k1vZqGAxAYaGxB6OgwPw2JweYN6/+3gMXF+DBBxseD3HrlnG3h9x0ujtd/U5Oxp6NGzcaft6f/2z8b1+nM58qdz3odMDFi8CyZQ239dxzxt9RYWHtU1GRsQfo9OmG2+rZ0/j7rG13SOVtaiqwY0fDbX3xBTBhwp3/HGtj6/+q+V+69W1Vtlf9syIoCNiwwfrPClvuGrFFXc3RFmCfu+lt3RbYc1Mv9tzIoCk9JOXlQqSlCXHmjPGwSEv+G/P0NB7uKHdPQfVJozH2HHTpIkT//kKEhwsxdqwQDzwgxMyZQjz5pBDTplnW1v/+rxA3bghx65YQhYVC6PU1t5299hzYa11CNM9/1fwv3Xq27OW11ba3VV3N0VYbwZ6berDnxkpNTd4N9bYAgLe3cQxGRgaQlmacUlONtxkZTT+cUpKMvTAuLsb96K6uxl4ES8aQPPQQMHRo3eMqNBpjr80LLzTcVmseJAjY7j90e62ranu2/K+a/6XLx9bbnmTFnpt6sOfGCo09AZbBIERmphDHjgnx/PO26fXw8RGic2fLln33XeP4lrQ0IQoKjPVU11Z6D+y158Be66pkr2coJutx2ysGe27qwZ4bCzV09M/HHxsPybxyBfjtN+Nt5fTbb9afJ2LECCAsDPD3N58CAozno9Bo2kavRtX2lL5/317rIiK7xEPB69Emwk1L7EqyRPv2gI8PcPZsw8taekInpQ+ErErpuwzsuS4isjsMN/VQfLhp7FFJer2xx+X0aeCzz4xX9m2ISmU8G2i3bsazaXbrdmfq2tV4XhMetcAvayIiG2C4qYeiw42lJ5IrLDT2ppw+fWc6c8Y43xoffQQ88ojldQG26SEB2kavBhERmTDc1EOx4caSXUnOzsZeicuXaz8CydkZGDDAOMbl888bXqc11wbhUQtERNQEDDf1UGy4sfQ06JX8/Iwnbhs48M7Uo4exx6K5rg3CHhIiImoka76/HVqoJmpullxHBTCeT2bxYuNRSHVRq41jdKZMMQaZ2nYlbdhgfTBRq62+CiwREZG1VHIXQE0kBHDggPGCeZaIiqo/2FSaPNk4FqZDB/P5HTs2+qJnRERELYG7pVorIYBvvwVWrwaOHm14ee5KIiKiVoy7pZSstlDj6Aj85S9Av37A3Ll3lqvEXUlERNSGMNy0FpW7n1avBuLjjfMcHY1Xtn72WWOvCmC8TlNt57nhUUlERNRGMNzYi7p2/1gaaipNngzcfz93JRERUZvFcGMP6jqrcHS0cRfUTz8Z5zk6Ak8+CfztbzVDTVXclURERG0Yw43c6jqr8PXrwMsvG392croTaiw50omIiKgNY7iRk15v7LGp74A1NzcgIaHmIdlERERUK57nRk4//NDwlbfz8oyXSyAiIiKLMNzIKSXFtssRERERw42sLB0/U9/gYSIiIjLDMTdyEQL4+uv6l6k8q/CoUS1TExERkQKw50YOQgDLlwNvvHFnXuVZhKvfb8xZhYmIiNowhpuWVhlsXnvNeH/TJuCTT3iBSiIiIhvhbqmWVFuwmT/f+DPPKkxERGQTDDctpb5gA/CswkRERDbC3VItoaFgQ0RERDbDcNPcGGyIiIhaFMNNcxICeO45BhsiIqIWxHDTXCqDzauvGu8z2BAREbUIhpvmwGBDREQkG4YbW2OwISIikhXDTRP9kpuLe0+fxi+5uQw2REREdoDhpin0enx48iQOZmfjoxMngGXL7gSbN99UTLAxC3BERER2juGmEa4WF+PEZ5/h5B/+gO3Z2QCAHdnZOLl3L06EhODqli3AggVWt2vLEGHLtj5MSzMGuLS0JrdlSwxdRERUG56huBGCf/oJ8PAAXn7ZNC/d0xND/vMf0/13bt5EsKMjgh0dEeToCJ2q4RxZNUQMdXdvUo3WtKUXAnnl5cjV65Gn1yO3vByXi4qQUlKCQoMB76emAgB2pKdjVkAABABfjQadHR2bVGNT2XJ7/ZKbi2d//x2vd+3a5LbsVVt4jUREAMON9fR6/O/bbyN6zhyUO1TZfNWu6j3n0qU7DwFor9Wawk7VSSNJ0KlU0KpU2JmeDqD2ECGEQKkQKNLrUWQwoMhgQGGVn4sMBlwtKkJGWRlKhDAFkv+XkoLUkhLkGwwoMxigB5BbEWBy9XrklZejwGCw6KWnl5VhyIkTpvtChstFXC0uRmZZGbLLyvDfitf439RU9HdxgbuDA7o4OiLU1RVaC8JkVbYMSvaKYZCo6fjebx0kIYSQu4iWlJubCw8PD+Tk5MC9MW/MQ4eAP/4RR/v0wcjNm2s8/PTu3Sh3cEDSpElIdHZGUnExiiwMD3VxVqlQZDCguX9RGkmCu1oNdwcH6IXAtZKSOtfp7eCA6IAATPPzwzA3N0jVwp2tGYTAL3l5CDt50qLlXVQq+Gg08NZo4O3gYPzZwQHeGo3p53IhoALg4eCAJy9dQmZ5Ofw0Gnw9YECTeqds+eHX1LYqw6AEYPyZM0gvK7PJa3z68mW8eeMGnu7QARt79LD6+VXxy4JqY6/vC1u+99sCW/4erfn+Zs+NtVJSAACnKt/UQgCSBJXBAINKhVnffIPBly8DYWHA9OkQQiCjrAxJxcW1Tr8VFaGsgXxZWC0cqQA4qVRwUquNtxVTgcGAK0VFtQYSFYBZAQEY6+UFt4oAUxlkKu9X33V2Mi/PrKemkrNKhazycqy/fh3rr19HF0dHTG3XDtP8/DDQ1dVmQSeztBTf3L6Nr27dwv7bt5FZVtbgcyQAAkCBwYCCkhIkl5RYtc7qvVPrunRBB50OHXU6dKiYXBq4WrtcuxcrlRkMSCktxY2SEow4darG49Vf44bu3eGuVtf5vnBVq6GWJLOgVF8vY0u8xrrYU7BsTvb6Om3Zlj31pl4tLkZGaSnSysrwYUWP8XY7201vr+T6PTLcWCswEADwa7duAADfnBy8/N57eHfCBFxr1w5+t2+bLSdJEvy0WvhptRheyy9WCIG427cx9syZGo992KsXBru5mQUYJ7UaWkmqM0DUFUh+HjIEg93cGvWSVQAMVW6/DQ1Famkpdqan4/Nbt5BYXIzXrl3Da9euIcTJCdP8/DDNzw99XVxqtFXfh59BCJzIy8PXWVn4OisLx3JzzYKau1qNsV5e6OPigpeuXq3R9okhQzDQ1RU55eXIKi9HVlkZbpWV3fm54jarvBy3yspwqbAQV4qL633tyxMTa8zzdHAwhh2t1hR6Kn83ARoNtjfxi7++EFGo16NMCAgAN0pKcL2k5M5taSmul5QgrbTUql6+xb/91uAyrmo18vX6GvOrB6XNPXqYwpG7Wg23KmHJXa2Go0oFqZUEJXv6cq3OXl9nU9tqrveFtaFLCIHE4mKczMvDyfx8rEtOrrFMhh3sprdXzfV7tAZ3S1lLrweCg9H3pZdwPjgYH69ahf/5/nsIAKUaDXTl5UDHjkBiItDAf/iVKgNJ9RBxohGBxJZtXS8uxrATJxDk6IjHAwPxbkoKrhUX4+chQ9Cx4o1ZoNfjy1u3sDM9HV9lZaG4Si9TX2dnU9AJcXYGULNL91ZZGb6pCDOxWVnIqNY7M8DFBeO9vTHexwcj3N2hUamaZXtVtzQoCGpJMgsP10tKLB6fVJt2Gg00kgQHSbpzq1LVmPd9Tk6j11FJI0loXxG+nFUqHKg4qq+qR/z84KRWI7e83DiQvNpYrBy9HuU2/nhwkCS4qdW4XV7e4LLvhISY9SBV7V1yU6uhqehptOWut+bajWcLzf0622k02NuvH8qFgIdajQCtFuVCoEyI2m8NBpQJgRslJbhVXg6DEFiTlIQcvR7uajWe6dgR5UJAp1LBvWI3cJnBYGqjtvb+XdEzXp/bI0fCw8HBqh7i+nYlGYTAb0VFpiBzouI224L3aCU1gHu9vPBnHx9M9PVt9b04je2BKzEYcKGwEAN/+aXBZRsTBq35/ma4aYTkTz9FZ09PqPV6ZN5/PzwLCowPVP6x7d4NTJ5scXuWhAg52gKMb9bKnqLKQc11HfmVV16OfRVBJzYry2x3W4iTE8Z5eWF7ejpulZfDRaVCVycnnCsoMOtlcKvonRnv7Y0ob+9aa7bla7QmKAkhkKvX1+wxKSnBsdxcnK58HzQznSShi5OTWc9R9dt2Gg1UFe/HxoZBIQRKDAazo+h+ycvD3CqD5Ss91K4dHKsGpYqQVHk/T6+3+ZgxR5UK7mo10i3YXfmwn59FbW6r+C+zPnL9hy4dOtTgMqM9PGqGhyqBovK2+j8RrY2LSlXr+75qj2qRwYCs8vIaYfCtHj1wvrAQV4uLcbmoCKfy85FXS6+kRpLQ38UFQ9zcMNjVFS5qNR69cKHGcp11Olyttvs71MUFE3198WcfHwxxczP9LVZnr7s+GxpXJITA9ZISnC0owJn8fJypuL1YVNTgP0QOkoQPevXCDH9/q+tiuKmHLcLNOzduYO7lyxhx7hyOLFx454GgIGDDBquCTSVrQkRLttVY2WVl+DQzEzszMhCbldXg8s8GBWG8tzdGeHhYdKSTrV5jcwSl6j7t1w89nZxqfMHU9uVTOe9yURFWJyXVaOvwwIEY7ekp+2u0NigZhEBBRe9Q5WkHTuTm4qladolN8fWFTqUy70mq8nNxEwfoN5YEYGGHDni1a1c4WdgrawvFej2+zsrCa8nJOJaX12LrBYxf8JpqPY1mPY+ShDy9HtfqGNsmARjq6opuzs41nld5W73NtNJS/OvGjRptdXd0NO5itqJHxVKOKhVCXVwwuCLIDHFzQ18XF7PPovre+y5qNT7PzMS+W7dwJCcHVd+hgVotJvr44M++vrjX09PsvWNPA/Pr6hn8pG9f/FZUhNTSUtwoLTWFmbp6tjwdHDDAxQUBWi0+zsio8XhjetgrcUBxM4utGIcRdeoUsH8/cOuWcYzNqFEW74qqruoXsyRJ0DVhUK4t22osT40G0YGBiA4MxJYbNzD/8mXU9pXU2BRvq9fY0dERSeHhpqA0NzCwyWGw+odfkE6HXrWMP6rPybw8rE5KqtGWayPeX7Z8jX4aDQI0mhpByU+jqfd5KkmCm4MD3BwcAJ0OgPF3D9TcXss7d673w6/MYKjRO3QqPx9P1xKUYjp2RMeK9VnqekkJ1l+/XmO+APCvGzfwXmoq/uzjg4f8/DDO27tZ/nEoNRjwTVYWdmZk4LPMzFp7FqpaHRyMHk5OFu32rAwUFwoLMencuRptxQ8ahGHu7lBb8TdVV7D/pZG7iv9140aN98XOvn0x2M0NhXo9blYbZ1a9NzW1tLTWz5tKEoCxXl6Y7ueHIW5u6OXsbNrNWZf63vsdHR3Rs1MnLOnUCZmlpfgqKwv7MjOx//ZtpJSW4j8pKfhPSgqcVSrc7eGBu9zdMcrDQ7bxZkII5On1ZmMRx9Uy7jO9rAyjTp+utQ01gF7Ozhjg6ooBLi4Y4OqK/i4u6KjTQZIknMzLw8cZGTV+jy2F4cZKZQYDvi0uBhwcEKXRAOPGyV2S3ZvXoQOGu7vX+uF3bPDgRqd4W7FVUGrsF39ztwXYZxhs7GvUqFTwVqngXWU554rQV/2DdIa/f6O+XNdfv16jrUf9/XEoOxvJJSXYlp6Obenp8FCr8UC7dpjWrh3GeHk1+AVZnzKDAd9lZ2Nnejr2Zmaa/WccpNNhart2CHV1xaMXLtSobaKPj9Wvs6AiMFVvS6tSWRVsqrLFF1lD7wtntRrdnZ3RvWIcX23KDQaklpYiLjsb0bXsSmpM6LL0ve+r1eLRgAA8GhCAEoMBh7Kzsa+iV+d6SQm+uX0b31QeeFKh+sD8tV261AipNQKqJCGrrAyFBgMcJMl0BvkPUlPhrFIhR683jYuqPIgiq8pBFdaOp+vv7IxIHx8McHFBfxcX9HZxqffv3tafYdbibikr/ZCdjdGnT8M3Oxtpt25B9fjjzVCl8thyELA9U9ruxeZmj7sX62urg06HY7m52JmRgY/T03GztNT0PB8HB0yuOCXCHzw84FDtddS220AvBA5XBJpPMjJwq0qgCdRq8T8V7d3l7g6VJNnt+Dw5x/rVx54+d4QQOJ2fj5evXsWezMwWXXdddJIEnyrn/lJJEg7WcvBBY7eXrT/DOOamHk0NN8+fPYu1t27h4W+/xdb5802HfFP9bP3hR1RdSwdLgxD4MScHO9PTsTsjw2xgs59GgykVweRuDw+oJMk0vmJhhw6Y2q4ddmZkYHdGBlKrBKR21Z5XWw+KvQZoewzj9vq5U9duvKnt2sGr8siyeo5Qq5yXVlqK3+s4nYUEYIK3N0Z5et45gWnFbeWJTauPHbOnMFgbhpt6NDXcDN2/Hyd0Ony4bRtmVrmWFDXMHj/8iGyh3GDA4Yqg80lGhtmgV18HB4z18sJXWVnI0etr7LLxcnDAZF9fPOTnh3s8PWv0+FDT2OPnTkuczqK5Tv8hJw4obibppaU4UTE4cVznzjJX0/rYw0BnoubgoFJhjJcXxnh5YXOPHoi7fRs7MzLwQWoqMsvLsb3KUSPVx6Kkjhhh9bXQyHL2+LnTHONRbDHeqTkOsJALw40Vvqn4gBp06RL8OZCYiGqhUakQ5eODKB8f/MHDA09cvIjajnWqPFKQwabtsYeB+XWxxzDYGAw3Voi9eBFQqRB1/jzwxBNyl0NEdi46MBADXF3t9khBko89HsGoJG371VvBIAT2VwwYjHJ0BNr4G4eIrKOqdktkK7qKa7YBFUGJ30/8O7PUybw8ZOp0cCsoQPjw4XKXQ0StROVugyFubtgSEoIhbm4I0Gha7HwfRG0Rd0tZKPbyZQBAxKlT0CxaJHM1RNRacLcBUcvjX5eF9ldcrTYqJwfgfnIisgJ3GxC1LP6FWSC7rAzxFaf6jgwOlrcYIiIiqhfDjQXibt6EXqVCr6tX0ZmHgBMREdk12cPN5s2bERwcDEdHR4SFheH48eP1Lr9hwwb07NkTTk5OCAoKwjPPPIPiOk4/bSuxCQkAgKjLl4EmXpaeiIiImpes4Wbnzp2IiYnBqlWrcPLkSYSGhiIyMhLpFZeBr27btm1YtmwZVq1ahYSEBLz77rvYuXMnnnvuuWarUQiB2Iqr50a5uDTbeoiIiMg2ZA0369evx5w5czB79mz06dMHW7ZsgbOzM957771alz969ChGjhyJhx9+GMHBwRg3bhymT5/eYG9PU5zPz8d1Fxc4lpRgdFhYs62HiIiIbEO2cFNaWooTJ04gIiLiTjEqFSIiIhAfH1/rc0aMGIETJ06Ywszvv/+Or776ChMmTKhzPSUlJcjNzTWbrBF79iwA4J5z5+B0991WPZeIiIhanmznucnMzIRer4e/v7/ZfH9/f1y4cKHW5zz88MPIzMzE3XffDSEEysvLMW/evHp3S61btw5r1qxpdJ37U1MBb29EFRYCWm2j2yEiIqKWIfuAYmscOnQIa9euxVtvvYWTJ09iz549+PLLL/HSSy/V+Zzly5cjJyfHNF27ds3i9RXo9ThccVn1yK5dm1w/ERERNT/Zem58fX2hVquRlpZmNj8tLQ0BAQG1PmfFihWYOXMmnqi4aGX//v1RUFCAuXPn4vnnn4eqlhNj6XQ66HS6RtV4+PffUerggM6pqeg5Zkyj2iAiIqKWJVvPjVarxZAhQxAXF2eaZzAYEBcXh/Dw8FqfU1hYWCPAqNVqAMajmmwt9v/+DwAQlZQEqY7ARURERPZF1mtLxcTEYNasWRg6dCiGDx+ODRs2oKCgALNnzwYAPProo+jQoQPWrVsHAJg4cSLWr1+PQYMGISwsDL/99htWrFiBiRMnmkKOLcVWBKaoil1TREREZP9kDTfTpk1DRkYGVq5cidTUVAwcOBCxsbGmQcbJyclmPTUvvPACJEnCCy+8gBs3bqBdu3aYOHEiXnnlFZvXdiUnB5e9vOBQXo57eQg4ERFRqyGJ5tifY8dyc3Ph4eGBnJwcuNfTI/PWt99ivoMD/nD+PA49+SRQcdE7IiIianmWfn8DrexoqZYUm5EBAIgqKWGwISIiakUYbmpRqtfjOy8vAEBk9+4yV0NERETWYLipxZFz51Dg6Aj/rCyE3nOP3OUQERGRFRhuahF7/jwAIPLGDajc3GSuhoiIiKzBcFOL2IoxNlEeHjJXQkRERNZiuKnmZkYGzgQEQDIYMLaOkwkSERGR/WK4qWZ/xRXJh129Ct8ePWSuhoiIiKzFcFNN7K1bAICosjKZKyEiIqLGYLipQl9ejgPt2gEAIkNCZK6GiIiIGoPhpoqfjx/HbVdXeObnY/iIEXKXQ0RERI3AcFNF7IULAICxqalw0GplroaIiIgag+GmitiKi3RGeXvLXAkRERE1FsNNhVtXr+J4p04AgMi77pK5GiIiImoshpsKB44ehVCp0D8lBR3at5e7HCIiImokhpsKsVlZAIBIg0HmSoiIiKgpGG4AiMJC7A8MBABE9ewpczVERETUFAw3AM58/z1Svb3hXFKCuwcNkrscIiIiagKGGwCxly8DAO7NzIROrZa5GiIiImoKhhshEOvgAACI8vGRuRgiIiJqqjYfbvLOncOPFRfIjBo+XOZqiIiIqKnafLj5Lj4e5Q4O6H77Nrrx5H1EREStXpsPN7HZ2QB4CDgREZFStOlwI27dQmxQEAAgqndvmashIiIiW2jT4eZyXBySAgOhLSvDPSEhcpdDRERENtCmw03slSsAgFE5OXCtOGKKiIiIWre2G270esTqdACAqHbtZC6GiIiIbKXNhpui48dxqE8fAEDUwIHyFkNEREQ202bDzdGff0aRoyM65Oejr7u73OUQERGRjbTZcPNtfj4AIFKSIEmSzNUQERGRrbTdcNO5MwAeAk5ERKQ0bTbcXOrUCSqDAREV57khIiIiZWiz4QYA7rp4EV6ffy53GURERGRDbTrcRMXHA1OmAHv2yF0KERER2UjbDjfHjxt/WLwY0OtlrYWIiIhso+2GG4MBkhA40aMHrpaWAj/8IHdFREREZANt95oDkoRh//636a5ISZGxGCIiIrKVtttzU3FuG4fycvzvK68AgYEyF0RERES20HZ7biocmz8fg4uKgFGj5C6FiIiIbKDN9txIBsOdOxs2AGq1bLUQERGR7bTZcDPot98QkJ0Nv1dfBSZPlrscIiIispE2u1vqu5AQOI4bB51GI3cpREREZENttudGGjWKwYaIiEiB2my4ISIiImViuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFkT3cbN68GcHBwXB0dERYWBiOHz9e7/LZ2dmYP38+AgMDodPpEBISgq+++qqFqiUiIiJ75yDnynfu3ImYmBhs2bIFYWFh2LBhAyIjI3Hx4kX4+fnVWL60tBRjx46Fn58fdu/ejQ4dOuDq1avw9PRs+eKJiIjILklCCCHXysPCwjBs2DBs2rQJAGAwGBAUFISFCxdi2bJlNZbfsmUL3njjDVy4cAEajaZR68zNzYWHhwdycnLg7u7epPqJiIioZVjz/S3bbqnS0lKcOHECERERd4pRqRAREYH4+Phan7Nv3z6Eh4dj/vz58Pf3R79+/bB27Vro9fo611NSUoLc3FyziYiIiJRLtnCTmZkJvV4Pf39/s/n+/v5ITU2t9Tm///47du/eDb1ej6+++gorVqzAP/7xD7z88st1rmfdunXw8PAwTUFBQTZ9HURERGRfZB9QbA2DwQA/Pz/85z//wZAhQzBt2jQ8//zz2LJlS53PWb58OXJyckzTtWvXWrBiIiIiammyDSj29fWFWq1GWlqa2fy0tDQEBATU+pzAwEBoNBqo1WrTvN69eyM1NRWlpaXQarU1nqPT6aDT6WxbPBEREdmtRvXcnDx5EmfPnjXd/+yzzzBp0iQ899xzKC0ttagNrVaLIUOGIC4uzjTPYDAgLi4O4eHhtT5n5MiR+O2332AwGEzzLl26hMDAwFqDDREREbU9jQo3f/nLX3Dp0iUAxnEwDz30EJydnbFr1y48++yzFrcTExODd955B//973+RkJCAJ598EgUFBZg9ezYA4NFHH8Xy5ctNyz/55JPIysrCokWLcOnSJXz55ZdYu3Yt5s+f35iXQURERArUqN1Sly5dwsCBAwEAu3btwujRo7Ft2zYcOXIEDz30EDZs2GBRO9OmTUNGRgZWrlyJ1NRUDBw4ELGxsaZBxsnJyVCp7uSvoKAg7N+/H8888wwGDBiADh06YNGiRVi6dGljXgYREREpUKPOc+Pu7o4TJ06gR48eGDt2LO677z4sWrQIycnJ6NmzJ4qKipqjVpvgeW6IiIhan2Y/z83QoUPx8ssv46OPPsLhw4fxpz/9CQCQmJhY49BuIiIiopbUqHCzYcMGnDx5EgsWLMDzzz+P7t27AwB2796NESNG2LRAIiIiImvY9PILxcXFUKvVjb40QkvgbikiIqLWp9l3S127dg3Xr1833T9+/DgWL16MDz/80K6DDRERESlfo8LNww8/jIMHDwIAUlNTMXbsWBw/fhzPP/88XnzxRZsWSERERGSNRoWbc+fOYfjw4QCAjz/+GP369cPRo0exdetWfPDBB7asj4iIiMgqjQo3ZWVlpksafPvtt/jzn/8MAOjVqxdSUlJsVx0RERGRlRoVbvr27YstW7bghx9+wIEDBxAVFQUAuHnzJnx8fGxaIBEREZE1GhVuXnvtNfz73//GPffcg+nTpyM0NBQAsG/fPtPuKiIiIiI5NPpQcL1ej9zcXHh5eZnmJSUlwdnZGX5+fjYr0NZ4KDgREVHrY833d6OuLQUAarUa5eXl+PHHHwEAPXv2RHBwcGObIyIiIrKJRu2WKigowGOPPYbAwECMHj0ao0ePRvv27fH444+jsLDQ1jUSERERWaxR4SYmJgaHDx/G559/juzsbGRnZ+Ozzz7D4cOH8de//tXWNRIRERFZrFFjbnx9fbF7927cc889ZvMPHjyIqVOnIiMjw1b12RzH3BAREbU+zX75hcLCwlqv/u3n58fdUkRERCSrRoWb8PBwrFq1CsXFxaZ5RUVFWLNmDcLDw21WHBEREZG1GnW01MaNGxEZGYmOHTuaznHz66+/QqfT4ZtvvrFpgURERETWaPR5bgoLC7F161ZcuHABANC7d2/MmDEDTk5ONi3Q1jjmhoiIqPVpkfPcODs7Y86cOWbzfv/9d8ybN4+9N0RERCSbRo25qUteXh7i4uJs2SQRERGRVWwaboiIiIjkxnBDREREisJwQ0RERIpi1YDiQYMGQZKkOh/nCfyIiIhIblaFm0mTJjVTGURERES20ejz3LRWPM8NERFR69Ps15YiIiIislcMN0RERKQoDDdERESkKAw3REREpCg2DTfZ2dnYtGmTLZskIiIisopNwk1cXBwefvhhBAYGYtWqVbZokoiIiKhRGh1url27hhdffBFdunTBuHHjIEkS9u7di9TUVFvWR0RERGQVq8JNWVkZdu3ahcjISPTs2ROnT5/GG2+8AZVKheeffx5RUVHQaDTNVSsRERFRg6w6Q3GHDh3Qq1cvPPLII9ixYwe8vLwAANOnT2+W4oiIiIisZVXPTXl5OSRJgiRJUKvVzVUTERERUaNZFW5u3ryJuXPnYvv27QgICMCDDz6IvXv31nsxTSIiIqKWZFW4cXR0xIwZM/Ddd9/h7Nmz6N27N55++mmUl5fjlVdewYEDB6DX65urViIiIqIGNfpoqW7duuHll1/G1atX8cUXX6CkpAT33Xcf/P39bVkfERERkVWsGlBcG5VKhQkTJmDChAnIyMjARx99ZIu6iIiIiBpFEkIIa59UVFSEAwcO4NKlS9BqtQgJCcHYsWNbxSBjay6ZTkRERPbBmu9vq3tu9u3bhyeeeAKZmZlm8zt06ICtW7di9OjRAIDExER06dLF2uaJiIiImsSqMTdHjx7FlClTMHr0aBw5cgRZWVnIysrCjz/+iOHDhyMyMhIXLlzA0qVLuXuKiIiIZGHVbqkJEyYgKCgI//73v2t9/C9/+Qv27NkDIQTi4uIQGhpqs0JthbuliIiIWh9rvr+t6rn56aefsGDBgjofnz9/Pm7duoVvv/3WLoMNERERKZ9V4aaoqKjetOTh4QGdToeBAwc2tS4iIiKiRrEq3PTo0QPfffddnY/HxcWhR48eTS6KiIiIqLGsCjezZ8/GkiVL8NVXX9V47Msvv8Szzz6L6OhoW9VGREREZDWrDgVftGgRjh49ivvuuw89e/ZE7969IYRAQkICLl++jPvvvx+LFy9uplKJiIiIGmZVz41KpcKuXbuwfft2hISE4MKFC7h48SJ69uyJrVu3Ys+ePVCpGn1FByIiIqIma9QZilszHgpORETU+jTboeAGgwGvvfYaRo4ciWHDhmHZsmUoKipqUrFEREREtmRVuHnllVfw3HPPwdXVFR06dMDGjRsxf/785qqNiIiIyGpWhZsPP/wQb731Fvbv349PP/0Un3/+ObZu3QqDwdBc9RERERFZxapwk5ycjAkTJpjuR0REQJIk3Lx50+aFERERETWGVeGmvLwcjo6OZvM0Gg3KyspsWhQRERFRY1l1nhshBKKjo6HT6UzziouLMW/ePLi4uJjm7dmzx3YVEhEREVnBqnAza9asGvMeeeQRmxVDRERE1FRWhZv333+/ueogIiIisgmeTpiIiIgUxaqem8cee8yi5d57771GFUNERETUVFaFmw8++ACdO3fGoEGD0Mau2kBERESthFXh5sknn8T27duRmJiI2bNn45FHHoG3t3dz1UZERERkNavG3GzevBkpKSl49tln8fnnnyMoKAhTp07F/v37m9STs3nzZgQHB8PR0RFhYWE4fvy4Rc/bsWMHJEnCpEmTGr1uIiIiUharBxTrdDpMnz4dBw4cwPnz59G3b1889dRTCA4ORn5+vtUF7Ny5EzExMVi1ahVOnjyJ0NBQREZGIj09vd7nJSUlYcmSJRg1apTV6yQiIiLlatLRUiqVCpIkQQgBvV7fqDbWr1+POXPmYPbs2ejTpw+2bNkCZ2fnegcl6/V6zJgxA2vWrEHXrl0bWz4REREpkNXhpqSkBNu3b8fYsWMREhKCs2fPYtOmTUhOToarq6tVbZWWluLEiROIiIi4U5BKhYiICMTHx9f5vBdffBF+fn54/PHHLao3NzfXbCIiIiLlsmpA8VNPPYUdO3YgKCgIjz32GLZv3w5fX99GrzwzMxN6vR7+/v5m8/39/XHhwoVan/Pjjz/i3XffxenTpy1ax7p167BmzZpG10hERESti1XhZsuWLejUqRO6du2Kw4cP4/Dhw7Uu11zXlsrLy8PMmTPxzjvvWByqli9fjpiYGNP93NxcBAUFNUt9REREJD+rws2jjz4KSZJstnJfX1+o1WqkpaWZzU9LS0NAQECN5a9cuYKkpCRMnDjRNM9gMAAAHBwccPHiRXTr1s3sOTqdzuxCn0RERKRsVp/Ez5a0Wi2GDBmCuLg40+HcBoMBcXFxWLBgQY3le/XqhbNnz5rNe+GFF5CXl4eNGzeyR4aIiIisCzfNISYmBrNmzcLQoUMxfPhwbNiwAQUFBZg9ezYAY29Rhw4dsG7dOjg6OqJfv35mz/f09ASAGvOJiIiobZI93EybNg0ZGRlYuXIlUlNTMXDgQMTGxpoGGScnJ0Ol4vU9iYiIyDKSaGMXicrNzYWHhwdycnLg7u4udzlERERkAWu+v9klQkRERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKYhfhZvPmzQgODoajoyPCwsJw/PjxOpd95513MGrUKHh5ecHLywsRERH1Lk9ERERti+zhZufOnYiJicGqVatw8uRJhIaGIjIyEunp6bUuf+jQIUyfPh0HDx5EfHw8goKCMG7cONy4caOFKyciIiJ7JAkhhJwFhIWFYdiwYdi0aRMAwGAwICgoCAsXLsSyZcsafL5er4eXlxc2bdqERx99tMHlc3Nz4eHhgZycHLi7uze5fiIiImp+1nx/y9pzU1paihMnTiAiIsI0T6VSISIiAvHx8Ra1UVhYiLKyMnh7e9f6eElJCXJzc80mIiIiUi5Zw01mZib0ej38/f3N5vv7+yM1NdWiNpYuXYr27dubBaSq1q1bBw8PD9MUFBTU5LqJiIjIfsk+5qYpXn31VezYsQN79+6Fo6NjrcssX74cOTk5punatWstXCURERG1JAc5V+7r6wu1Wo20tDSz+WlpaQgICKj3uX//+9/x6quv4ttvv8WAAQPqXE6n00Gn09mkXiIiIrJ/svbcaLVaDBkyBHFxcaZ5BoMBcXFxCA8Pr/N5r7/+Ol566SXExsZi6NChLVEqERERtRKy9twAQExMDGbNmoWhQ4di+PDh2LBhAwoKCjB79mwAwKOPPooOHTpg3bp1AIDXXnsNK1euxLZt2xAcHGwam+Pq6gpXV1fZXgcRERHZB9nDzbRp05CRkYGVK1ciNTUVAwcORGxsrGmQcXJyMlSqOx1Mb7/9NkpLSzFlyhSzdlatWoXVq1e3ZOlERERkh2Q/z01L43luiIiIWp9Wc54bIiIiIltjuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRXGQuwB7pdfrUVZWJncZ1ARarRYqFfM7EVFbw3BTjRACqampyM7OlrsUaiKVSoUuXbpAq9XKXQoREbUghptqKoONn58fnJ2dIUmS3CVRIxgMBty8eRMpKSno1KkTf49ERG0Iw00Ver3eFGx8fHzkLoeaqF27drh58ybKy8uh0WjkLoeIiFoIByRUUTnGxtnZWeZKyBYqd0fp9XqZKyEiopbEcFML7sJQBv4eiYjaJoYbIiIiUhSGGyIiIlIUhpvmotcDhw4B27cbb1vRuI/g4GBs2LDBJm0dOnQIkiTx0HoiImoxPFqqOezZAyxaBFy/fmdex47Axo3A5MnNssp77rkHAwcOtEko+fnnn+Hi4tL0ooiIiGTAnhtb27MHmDLFPNgAwI0bxvl79shSlhAC5eXlFi3brl07HjFGREStFsNNQ4QACgosm3JzgaefNj6ntnYAY49Obq5l7dXWTi2io6Nx+PBhbNy4EZIkQZIkfPDBB5AkCV9//TWGDBkCnU6HH3/8EVeuXMH9998Pf39/uLq6YtiwYfj222/N2qu+W0qSJPy///f/8MADD8DZ2Rk9evTAvn37GrtF8cknn6Bv377Q6XQIDg7GP/7xD7PH33rrLfTo0QOOjo7w9/fHlClTTI/t3r0b/fv3h5OTE3x8fBAREYGCgoJG10JERMrDcNOQwkLA1dWyycPD2ENTFyGMPToeHpa1V1hoUYkbN25EeHg45syZg5SUFKSkpCAoKAgAsGzZMrz66qtISEjAgAEDkJ+fjwkTJiAuLg6nTp1CVFQUJk6ciOTk5HrXsWbNGkydOhVnzpzBhAkTMGPGDGRlZVm8GSudOHECU6dOxUMPPYSzZ89i9erVWLFiBT744AMAwC+//IKnn34aL774Ii5evIjY2FiMHj0aAJCSkoLp06fjscceQ0JCAg4dOoTJkydDWBgCiYiobeCYGwXw8PCAVquFs7MzAgICAAAXLlwAALz44osYO3asaVlvb2+Ehoaa7r/00kvYu3cv9u3bhwULFtS5jujoaEyfPh0AsHbtWvzrX//C8ePHERUVZVWt69evx5gxY7BixQoAQEhICM6fP4833ngD0dHRSE5OhouLC+677z64ubmhc+fOGDRoEABjuCkvL8fkyZPRuXNnAED//v2tWj8RESkfe24a4uwM5OdbNn31lWVtfvWVZe3ZYNzL0KFDze7n5+djyZIl6N27Nzw9PeHq6oqEhIQGe24GDBhg+tnFxQXu7u5IT0+3up6EhASMHDnSbN7IkSNx+fJl6PV6jB07Fp07d0bXrl0xc+ZMbN26FYUVPVihoaEYM2YM+vfvj//5n//BO++8g9u3b1tdAxERKRvDTUMkCXBxsWwaN854VFRdZ8aVJCAoyLicJe3Z4Ay71Y96WrJkCfbu3Yu1a9fihx9+wOnTp9G/f3+UlpbW2071azNJkgSDwdDk+qpzc3PDyZMnsX37dgQGBmLlypUIDQ1FdnY21Go1Dhw4gK+//hp9+vTBm2++iZ49eyIxMdHmdRARUevFcGNLarXxcG+gZjCpvL9hg3E5G9NqtRZdQ+nIkSOIjo7GAw88gP79+yMgIABJSUk2r6cuvXv3xpEjR2rUFBISAnXFdnFwcEBERARef/11nDlzBklJSfjuu+8AGEPVyJEjsWbNGpw6dQparRZ79+5tsfqJiMj+ccyNrU2eDOzeXft5bjZsaLbz3AQHB+PYsWNISkqCq6trnb0qPXr0wJ49ezBx4kRIkoQVK1Y0Sw9MXf76179i2LBheOmllzBt2jTEx8dj06ZNeOuttwAAX3zxBX7//XeMHj0aXl5e+Oqrr2AwGNCzZ08cO3YMcXFxGDduHPz8/HDs2DFkZGSgd+/eLVY/ERHZP/bcNIfJk4GkJODgQWDbNuNtYmKzBRvAuLtJrVajT58+aNeuXZ1jaNavXw8vLy+MGDECEydORGRkJAYPHtxsdVU3ePBgfPzxx9ixYwf69euHlStX4sUXX0R0dDQAwNPTE3v27MG9996L3r17Y8uWLdi+fTv69u0Ld3d3fP/995gwYQJCQkLwwgsv4B//+AfGjx/fYvUTEZH9k0QbO442NzcXHh4eyMnJgbu7u9ljxcXFSExMRJcuXeDo6ChThWQr/H0SESlHfd/f1bHnhoiIiBSF4YaaZN68eXB1da11mjdvntzlERFRG8QBxdQkL774IpYsWVLrYw11GxIRETUHhhtqEj8/P/j5+cldBhERkQl3SxEREZGiMNwQERGRojDcEBERkaIw3BAREZGiMNwQERGRojDckE0kJSVBkiScPn1a7lKIiKiNY7hpRr/k5uLe06fxS25us6/rnnvuweLFi23WXnR0NCZNmmSz9oiIiFoKw00z+jAtDQezs/FRWprcpRAREbUZDDcNEEKgQK+3eEooKMCP2dk4kpODHenpAIDt6ek4kpODH7OzkVBQYHFbll7TNDo6GocPH8bGjRshSRIkSUJSUhLOnTuH8ePHw9XVFf7+/pg5cyYyMzNNz9u9ezf69+8PJycn+Pj4ICIiAgUFBVi9ejX++9//4rPPPjO1d+jQIau33eHDhzF8+HDodDoEBgZi2bJlKC8vb3D9AHDo0CEMHz4cLi4u8PT0xMiRI3H16lWrayAioraHZyhuQKHBANcffmhSGxllZbj71Cmrn5c/ahRc1OoGl9u4cSMuXbqEfv364cUXXwQAaDQaDB8+HE888QT++c9/oqioCEuXLsXUqVPx3XffISUlBdOnT8frr7+OBx54AHl5efjhhx8ghMCSJUuQkJCA3NxcvP/++wAAb29vq2q/ceMGJkyYgOjoaHz44Ye4cOEC5syZA0dHR6xevbre9ZeXl2PSpEmYM2cOtm/fjtLSUhw/fhySJFm9DYmIqO1huFEADw8PaLVaODs7IyAgAADw8ssvY9CgQVi7dq1puffeew9BQUG4dOkS8vPzUV5ejsmTJ6Nz584AgP79+5uWdXJyQklJiak9a7311lsICgrCpk2bIEkSevXqhZs3b2Lp0qVYuXIlUlJS6lx/VlYWcnJycN9996Fbt24AgN69ezeqDiIiansYbhrgrFIhf9Qoq55zOj+/1p6aHwcNwkBXV6vW3Vi//vorDh48CNda1nflyhWMGzcOY8aMQf/+/REZGYlx48ZhypQp8PLyavQ6q0pISEB4eLhZb8vIkSORn5+P69evIzQ0tM71e3t7Izo6GpGRkRg7diwiIiIwdepUBAYG2qQ2IiJSNo65aYAkSXBRq62anCpCSeXGrbx1Uqmsaqcpu2Hy8/MxceJEnD592my6fPkyRo8eDbVajQMHDuDrr79Gnz598Oabb6Jnz55ITExs2gazUEPrf//99xEfH48RI0Zg586dCAkJwU8//dQitRERUevGcNMM/DQaBGg0GOLmhi0hIRji5oYAjQZ+Gk2zrVOr1UKv15vuDx48GP/3f/+H4OBgdO/e3WxycXEBYAxuI0eOxJo1a3Dq1ClotVrs3bu31vas1bt3b8THx5sNij5y5Ajc3NzQsWPHBtcPAIMGDcLy5ctx9OhR9OvXD9u2bWt0PURE1HYw3DSDjo6OSAoPx7HBg/GX9u1xbPBgJIWHo6OjY7OtMzg4GMeOHUNSUhIyMzMxf/58ZGVlYfr06fj5559x5coV7N+/H7Nnz4Zer8exY8ewdu1a/PLLL0hOTsaePXuQkZFhGtsSHByMM2fO4OLFi8jMzERZWZlV9Tz11FO4du0aFi5ciAsXLuCzzz7DqlWrEBMTA5VKVe/6ExMTsXz5csTHx+Pq1av45ptvcPnyZY67ISIiy4g2JicnRwAQOTk5NR4rKioS58+fF0VFRTJU1jQXL14Ud911l3BychIARGJiorh06ZJ44IEHhKenp3BychK9evUSixcvFgaDQZw/f15ERkaKdu3aCZ1OJ0JCQsSbb75pai89PV2MHTtWuLq6CgDi4MGD9a4/MTFRABCnTp0yzTt06JAYNmyY0Gq1IiAgQCxdulSUlZUJIUS9609NTRWTJk0SgYGBQqvVis6dO4uVK1cKvV5v1TZpzb9PIiIyV9/3d3WSEBaeTEUhcnNz4eHhgZycHLi7u5s9VlxcjMTERHTp0gWOzdjLQi2Dv08iIuWo7/u7Ou6WIiIiIkVhuCGLrF27Fq6urrVO48ePl7s8IiIiE57nhiwyb948TJ06tdbHnJycWrgaIiKiujHckEW8vb2tvgQDERGRHLhbqhZtbIy1YvH3SETUNjHcVKGpOMleYWGhzJWQLZSWlgIwng2ZiIjaDrvYLbV582a88cYbSE1NRWhoKN58800MHz68zuV37dqFFStWICkpCT169MBrr72GCRMmNLkOtVoNT09PpKenAwCcnZ15JepWymAwICMjA87OznBwsIu3ORERtRDZP/V37tyJmJgYbNmyBWFhYdiwYQMiIyNx8eJF+Pn51Vj+6NGjmD59OtatW4f77rsP27Ztw6RJk3Dy5En069evyfVUXgW7MuBQ66VSqdCpUycGVCKiNkb2k/iFhYVh2LBh2LRpEwDjf9xBQUFYuHAhli1bVmP5adOmoaCgAF988YVp3l133YWBAwdiy5YtDa7P0pMA6fV6qy85QPZFq9VC1YQrqxMRkf2w5iR+svbclJaW4sSJE1i+fLlpnkqlQkREBOLj42t9Tnx8PGJiYszmRUZG4tNPP611+ZKSEpSUlJju5+bmWlSbWq3mWA0iIqJWSNZ/azMzM6HX6+Hv728239/fH6mpqbU+JzU11arl161bBw8PD9MUFBRkm+KJiIjILim+z3758uXIyckxTdeuXZO7JCIiImpGsu6W8vX1hVqtRlpamtn8tLQ008De6gICAqxaXqfTQafT2aZgIiIisnuyhhutVoshQ4YgLi4OkyZNAmAcUBwXF4cFCxbU+pzw8HDExcVh8eLFpnkHDhxAeHi4ReusHD9t6dgbIiIikl/l97ZFx0EJme3YsUPodDrxwQcfiPPnz4u5c+cKT09PkZqaKoQQYubMmWLZsmWm5Y8cOSIcHBzE3//+d5GQkCBWrVolNBqNOHv2rEXru3LligDAiRMnTpw4cWqF07Vr1xr8rpf9PDfTpk1DRkYGVq5cidTUVAwcOBCxsbGmQcPJyclmh/OOGDEC27ZtwwsvvIDnnnsOPXr0wKeffmrxOW4qr4+UnJwMDw8P278gqldubi6CgoJw7dq1Bg/lI9vitpcXt798uO3lY8ttL4RAXl4e2rdv3+Cysp/npqVZc5w82R63v3y47eXF7S8fbnv5yLXtFX+0FBEREbUtDDdERESkKG0u3Oh0OqxatYqHh8uE218+3Pby4vaXD7e9fOTa9m1uzA0REREpW5vruSEiIiJlY7ghIiIiRWG4ISIiIkVhuCEiIiJFaXPhZvPmzQgODoajoyPCwsJw/PhxuUtqE1avXg1JksymXr16yV2WIn3//feYOHEi2rdvD0mS8Omnn5o9LoTAypUrERgYCCcnJ0RERODy5cvyFKswDW376OjoGn8HUVFR8hSrMOvWrcOwYcPg5uYGPz8/TJo0CRcvXjRbpri4GPPnz4ePjw9cXV3x4IMP1rgQM1nPkm1/zz331Hjvz5s3r9lqalPhZufOnYiJicGqVatw8uRJhIaGIjIyEunp6XKX1ib07dsXKSkppunHH3+UuyRFKigoQGhoKDZv3lzr46+//jr+9a9/YcuWLTh27BhcXFwQGRmJ4uLiFq5UeRra9gAQFRVl9newffv2FqxQuQ4fPoz58+fjp59+woEDB1BWVoZx48ahoKDAtMwzzzyDzz//HLt27cLhw4dx8+ZNTJ48WcaqlcGSbQ8Ac+bMMXvvv/76681XlLUXumzNhg8fLubPn2+6r9frRfv27cW6detkrKptWLVqlQgNDZW7jDYHgNi7d6/pvsFgEAEBAeKNN94wzcvOzhY6nU5s375dhgqVq/q2F0KIWbNmifvvv1+Wetqa9PR0AUAcPnxYCGF8n2s0GrFr1y7TMgkJCQKAiI+Pl6tMRaq+7YUQ4g9/+INYtGhRi9XQZnpuSktLceLECURERJjmqVQqREREID4+XsbK2o7Lly+jffv26Nq1K2bMmIHk5GS5S2pzEhMTkZqaavZ34OHhgbCwMP4dtJBDhw7Bz88PPXv2xJNPPolbt27JXZIi5eTkALhzseQTJ06grKzM7L3fq1cvdOrUie99G6u+7Stt3boVvr6+6NevH5YvX47CwsJmq0H2q4K3lMzMTOj1etPVxiv5+/vjwoULMlXVdoSFheGDDz5Az549kZKSgjVr1mDUqFE4d+4c3Nzc5C6vzUhNTQWAWv8OKh+j5hMVFYXJkyejS5cuuHLlCp577jmMHz8e8fHxUKvVcpenGAaDAYsXL8bIkSPRr18/AMb3vlarhaenp9myfO/bVm3bHgAefvhhdO7cGe3bt8eZM2ewdOlSXLx4EXv27GmWOtpMuCF5jR8/3vTzgAEDEBYWhs6dO+Pjjz/G448/LmNlRC3noYceMv3cv39/DBgwAN26dcOhQ4cwZswYGStTlvnz5+PcuXMc1yeDurb93LlzTT/3798fgYGBGDNmDK5cuYJu3brZvI42s1vK19cXarW6xsj4tLQ0BAQEyFRV2+Xp6YmQkBD89ttvcpfSplS+1/l3YB+6du0KX19f/h3Y0IIFC/DFF1/g4MGD6Nixo2l+QEAASktLkZ2dbbY83/u2U9e2r01YWBgANNt7v82EG61WiyFDhiAuLs40z2AwIC4uDuHh4TJW1jbl5+fjypUrCAwMlLuUNqVLly4ICAgw+zvIzc3FsWPH+Hcgg+vXr+PWrVv8O7ABIQQWLFiAvXv34rvvvkOXLl3MHh8yZAg0Go3Ze//ixYtITk7me7+JGtr2tTl9+jQANNt7v03tloqJicGsWbMwdOhQDB8+HBs2bEBBQQFmz54td2mKt2TJEkycOBGdO3fGzZs3sWrVKqjVakyfPl3u0hQnPz/f7L+hxMREnD59Gt7e3ujUqRMWL16Ml19+GT169ECXLl2wYsUKtG/fHpMmTZKvaIWob9t7e3tjzZo1ePDBBxEQEIArV67g2WefRffu3REZGSlj1cowf/58bNu2DZ999hnc3NxM42g8PDzg5OQEDw8PPP7444iJiYG3tzfc3d2xcOFChIeH46677pK5+tatoW1/5coVbNu2DRMmTICPjw/OnDmDZ555BqNHj8aAAQOap6gWOy7LTrz55puiU6dOQqvViuHDh4uffvpJ7pLahGnTponAwECh1WpFhw4dxLRp08Rvv/0md1mKdPDgQQGgxjRr1iwhhPFw8BUrVgh/f3+h0+nEmDFjxMWLF+UtWiHq2/aFhYVi3Lhxol27dkKj0YjOnTuLOXPmiNTUVLnLVoTatjsA8f7775uWKSoqEk899ZTw8vISzs7O4oEHHhApKSnyFa0QDW375ORkMXr0aOHt7S10Op3o3r27+Nvf/iZycnKarSapojAiIiIiRWgzY26IiIiobWC4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4IaI2T5IkfPrpp3KXQUQ2wnBDRLKKjo6GJEk1pqioKLlLI6JWqk1dW4qI7FNUVBTef/99s3k6nU6maoiotWPPDRHJTqfTISAgwGzy8vICYNxl9Pbbb2P8+PFwcnJC165dsXv3brPnnz17Fvfeey+cnJzg4+ODuXPnIj8/32yZ9957D3379oVOp0NgYCAWLFhg9nhmZiYeeOABODs7o0ePHti3b1/zvmgiajYMN0Rk91asWIEHH3wQv/76K2bMmIGHHnoICQkJAICCggJERkbCy8sLP//8M3bt2oVvv/3WLLy8/fbbmD9/PubOnYuzZ89i37596N69u9k61qxZg6lTp+LMmTOYMGECZsyYgaysrBZ9nURkI812SU4iIgvMmjVLqNVq4eLiYja98sorQgjjFYfnzZtn9pywsDDx5JNPCiGE+M9//iO8vLxEfn6+6fEvv/xSqFQq0xW327dvL55//vk6awAgXnjhBdP9/Px8AUB8/fXXNnudRNRyOOaGiGT3xz/+EW+//bbZPG9vb9PP4eHhZo+Fh4fj9OnTAICEhASEhobCxcXF9PjIkSNhMBhw8eJFSJKEmzdvYsyYMfXWMGDAANPPLi4ucHd3R3p6emNfEhHJiOGGiGTn4uJSYzeRrTg5OVm0nEajMbsvSRIMBkNzlEREzYxjbojI7v3000817vfu3RsA0Lt3b/z6668oKCgwPX7kyBGoVCr07NkTbm5uCA4ORlxcXIvWTETyYc8NEcmupKQEqampZvMcHBzg6+sLANi1axeGDh2Ku+++G1u3bsXx48fx7rvvAgBmzJiBVatWYdasWVi9ejUyMjKwcOFCzJw5E/7+/gCA1atXY968efDz88P48eORl5eHI0eOYOHChS37QomoRTDcEJHsYmNjERgYaDavZ8+euHDhAgDjkUw7duzAU089hcDAQGzfvh19+vQBADg7O2P//v1YtGgRhg0bBmdnZzz44INYv369qa1Zs2ahuLgY//znP7FkyRL4+vpiypQpLfcCiahFSUIIIXcRRER1kSQJe/fuxaRJk+QuhYhaCY65ISIiIkVhuCEiIiJF4ZgbIrJr3HNORNZizw0REREpCsMNERERKQrDDRERESkKww0REREpCsMNERERKQrDDRERESkKww0REREpCsMNERERKQrDDRERESnK/wdOc3YZ3TlK8wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,989,921 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.687 | Train Acc: 54.08%\n",
      "\t test  Loss: 0.686 | test  Acc: 54.96%\n",
      "\t best  test acc: 54.96%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.682 | Train Acc: 55.43%\n",
      "\t test  Loss: 0.688 | test  Acc: 53.15%\n",
      "\t best  test acc: 54.96%\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.631 | Train Acc: 64.55%\n",
      "\t test  Loss: 0.551 | test  Acc: 73.44%\n",
      "\t best  test acc: 73.44%\n",
      "Epoch: 04 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.419 | Train Acc: 83.02%\n",
      "\t test  Loss: 0.526 | test  Acc: 76.98%\n",
      "\t best  test acc: 76.98%\n",
      "Epoch: 05 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.281 | Train Acc: 90.59%\n",
      "\t test  Loss: 0.544 | test  Acc: 78.89%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 06 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.205 | Train Acc: 94.03%\n",
      "\t test  Loss: 0.616 | test  Acc: 77.40%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 07 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.165 | Train Acc: 95.51%\n",
      "\t test  Loss: 0.670 | test  Acc: 77.49%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 08 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.134 | Train Acc: 96.68%\n",
      "\t test  Loss: 0.757 | test  Acc: 74.83%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 09 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.121 | Train Acc: 97.12%\n",
      "\t test  Loss: 0.813 | test  Acc: 76.04%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 10 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.106 | Train Acc: 97.60%\n",
      "\t test  Loss: 0.908 | test  Acc: 74.64%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 11 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.104 | Train Acc: 97.58%\n",
      "\t test  Loss: 0.889 | test  Acc: 74.47%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 12 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.094 | Train Acc: 97.85%\n",
      "\t test  Loss: 1.012 | test  Acc: 72.46%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 13 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.083 | Train Acc: 98.06%\n",
      "\t test  Loss: 0.977 | test  Acc: 74.51%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 14 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.074 | Train Acc: 98.16%\n",
      "\t test  Loss: 0.963 | test  Acc: 75.58%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 15 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.062 | Train Acc: 98.49%\n",
      "\t test  Loss: 1.037 | test  Acc: 74.79%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 16 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.052 | Train Acc: 98.74%\n",
      "\t test  Loss: 1.062 | test  Acc: 74.23%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 17 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.046 | Train Acc: 98.90%\n",
      "\t test  Loss: 1.166 | test  Acc: 72.55%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 18 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.043 | Train Acc: 99.11%\n",
      "\t test  Loss: 1.135 | test  Acc: 74.04%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 19 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.037 | Train Acc: 99.17%\n",
      "\t test  Loss: 1.181 | test  Acc: 72.60%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 20 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.037 | Train Acc: 99.15%\n",
      "\t test  Loss: 1.215 | test  Acc: 74.69%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 21 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.026 | Train Acc: 99.49%\n",
      "\t test  Loss: 1.384 | test  Acc: 71.20%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 22 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.020 | Train Acc: 99.65%\n",
      "\t test  Loss: 1.294 | test  Acc: 73.76%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 23 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.019 | Train Acc: 99.67%\n",
      "\t test  Loss: 1.331 | test  Acc: 74.32%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 24 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.019 | Train Acc: 99.60%\n",
      "\t test  Loss: 1.339 | test  Acc: 73.67%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 25 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.012 | Train Acc: 99.79%\n",
      "\t test  Loss: 1.514 | test  Acc: 72.32%\n",
      "\t best  test acc: 78.89%\n",
      "Epoch: 26 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.010 | Train Acc: 99.86%\n",
      "\t test  Loss: 1.479 | test  Acc: 73.76%\n",
      "\t best  test acc: 78.89%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWMUlEQVR4nO3deXwTZeI/8E/SJul90wsKLXLKUaBArYgCFgrsFwVUEFkFvH4gKse6IotyuYKyK+IKigeo7MqxIqCrHEIBRaigHAJyY6GF3pQ2bemZPL8/pg090jZp00w6/bxfr3k1mUwmT4Yp8+kzz6ESQggQERERKYRa7gIQERER2RLDDRERESkKww0REREpCsMNERERKQrDDRERESkKww0REREpCsMNERERKQrDDRERESkKww0REREpCsMNERERKYqs4ebHH3/EqFGjEBoaCpVKhW3bttX7nv3796NPnz7Q6XTo0KEDPvvssyYvJxERETUfsoabgoICREZGYtWqVRZtn5iYiD/96U8YPHgwTpw4gZkzZ+Lpp5/Grl27mrikRERE1FyoHGXiTJVKha1bt2L06NG1bjNnzhx89913OH36tGndo48+ipycHOzcudMOpSQiIiJH5yx3AayRkJCA2NjYKuvi4uIwc+bMWt9TXFyM4uJi03Oj0Yjs7Gz4+/tDpVI1VVGJiIjIhoQQyMvLQ2hoKNTqum88Natwk5aWhqCgoCrrgoKCoNfrUVhYCFdX1xrvWbp0KRYtWmSvIhIREVETSk5ORps2bercplmFm4aYO3cuZs+ebXqem5uLtm3bIjk5GV5eXjKWjIgclsEAHDoEpKUBwcHA3XcDTk4N29c33wBz5gApKbfXhYYCb70FPPCAdft5/PHaX//3vy3bn8EAdO9etTzVtW4NnDpV/3e2976Cg4HNm4H8fCAnx/ySmwtcvQqcOVP355H1AgIAb2/p39LZ+fZPtfr28xs3gPPn69/XJ58Ajzxi1cfr9XqEhYXB09Oz3m2bVbgJDg5Genp6lXXp6enw8vIyW2sDADqdDjqdrsZ6Ly8vhhsiuRkMwIEDQGoqEBICDBzY8BBhq31t2QLMmAFcu3Z7XZs2wLvvAmPHWr+vJ54AqjdtTE2V1m/ebNk+DQZg7tzaX1eppADVvz9QXAwUFAC3bklL9cdnztQdIADg+nUgNhbw8pI+22AAjMbbjysWvd6yfXXvDri7S+WsWNTqqs8LCurfV1oacM89dW9jjYAAaXFxAVxdpZ/Vlxs3pGBZnxdeADp3rvqdqn/X8+eBf/yj/n1Nnw5ERABlZdJxrv7TYABOnwYsaWs6aZJ0zNzcpO9YealYd/y4ZUHjyy+BQYPq3mb/fmDw4Pr3dccd0vnVAJY0KWl2DYq3b9+OU6dOmdY99thjyM7OtrhBsV6vh7e3N3JzcxluiBrCUUOELfa1ZQvw8MM1w0jFf6aWhJGyMqlmITcXuOsu6YJcGx8fYNYsoKQEKCqSlsLC248rlvR04PffLf8eSubpCQQFAb6+0uLjU/NxSgpgSXOEffvqv1gbDEB4uBTSzF0uVSrpXEtMtKx2ylb7sjRENOfvWI01129Zw01+fj4uXboEAOjduzeWL1+OwYMHw8/PD23btsXcuXNx/fp1rFu3DoDUFbx79+6YPn06nnzySezduxcvvvgivvvuO8TFxVn0mQw31GwouVbDFiHClvsqLpb+Qo+KqjuMuLsDDz4o1YLk59dc8vKkfclFp5NuG7i7S3+Vu7nVfHzzpmU1EfPmAT16SOeJk5NU+1DxuGI5dUoKZ/X517+A3r2lf6Pqi9Eo/TxxAvjrX+vfl70v1sDtcwyour/GnK+N3VdL+I7VWHX9FjLat2+fAFBjmTRpkhBCiEmTJon77ruvxnt69eoltFqtaN++vfj000+t+szc3FwBQOTm5trmSxA1ha++EqJNm6qXgTZtpPVy7eurr4RQqWpenlQqabF0f2VlNctTfX9hYdJ2lRmNQpSUCFFQIEROjhAZGUIkJQkRElL7vgAhvL2FmDNHiGnThJgwQYgRI4SIiRGia1chgoOFcHGp+/0NXdRqy7YbPFiIF18U4uWXhZg/X4glS4RYvlyI998XYu1aIdavF2LxYsv2tW+f5cff3L9lXce/Oe1LiNvna/X9WXu+Vt5f9fM2LMx2v5MN2VdL+I6VWHP9dpjbUvbCmhtqUraoIXG0Wg3g9l+JlWtsqu8vMBD4z3+k2yi1tfe4dQu4fNmytgJeXtJ+S0ul2zZlZfW/xx4mTpT+XT086l4SEhzztgHguH+lN3JfBoMBpaWlt1d8/z2wZEnV2riQEKn90rBhlpWp6gcAR48CGRnS+R4V1bjaVFvsS2HfUavV1trNu9nclpIDww3V4Ei3bCwJEcHBwE8/3e6lUFsDRqMR6NOn7kaaAQHAe+9JwSMvT1r0+tuPK56npAAXL1p8KOxGpTJ/sa8uLg6IjpbaZFS0y6h4XLEcPSo1oq2PJWEEcOxAUrG/6udrWBiwYoVt2jzZcV9CCKSlpSEnJ8fci9KtQoNBOs463e1jphQK+o5qtRoRERHQarU1XmO4qQPDDVVh7zYkRiOQnS39lZWWJjUUrfzzzBnpIttctW4tdXOurb2Hm5v0PT/+uP59rV0LDBgAaDTSotXeflyx/Pij49aOAI4dSADHbNfVgH2lpqYiJycHgYGBcHNz4wCtzZTRaERKSgo0Gg3atm1b49+R4aYODDdkYqtbNsXFUrfN1NTat9FopFqSzEzb3F6pqLWp3CCzYrFWly5St0xPT2nx8rr9uOJ5YmLdXZErNPeeGU3RENKRA4kCGAwGXLhwAYGBgfD395e7ONRIubm5SElJQYcOHaDRaKq8xnBTB4YbAmDZ7Z+gIGDjRqkXTUaGFEwyMmouWVnWf76/v7T/4ODbP4ODpVqdt96q//31hQghgL17bXebxZFDhKPXjgAMJE2oqKgIiYmJCA8Pr3W8M2o+CgsLceXKFURERMDFxaXKaww3dWC4IQCWjxFhS3//OzB5MtCqlXSLxZyWVKvhqG0+AIaRZqQi3Ji7GFLzU9e/pzXX72Y1QjGRSUMuPteuSUPqJyQA//ufZZ8TFCTdsgkMlJZWrW4/rlguXrTsAjpggNQmpS5OTlJ7n4cfrtlYtiJErFhh2YXWlvsCpO+4ebP5NkoNCRFjx0pjxtgiRNhyX4D0PksaDRORY2pwh/NmiuPcKIAl47YUFwtx+LAQ77wjxLhxdY+r4kjjhtT1HR1lvImyMum4rF8v/bTmexHZWGFhoThz5owoLCyUuyiyateunXjnnXdssq+KMehu3rxpk/1Zo65/T2uu36y5oealtkbA168DDz0k/fV+4wbw66/SeCuVOTkBkZHSJIjR0dJoqOnpdd+yGTiw/jLZuoYEYK0GkRzsfDty0KBB6NWrF1asWNHoff3yyy9wd3dvfKEUguGGmg+DQbolYi6MVKz7+uvb6/z9gZgYKczExAD9+kndkSu4uTnuLRvAtiGCgYSobrac68xGhBAwGAxwdq7/Ut2qVSs7lKj5MD8MIJGjKSoC3n679t5Nlc2ZI82+m5kpta2ZO1e6sFf/q6YikFRvB9OmTcO6/I4dC1y5IvU+Wr9e+pmYKNt/jERkoYoa4er/v1y/Lq3fssXmHzl58mT88MMPePfdd6FSqaBSqfDZZ59BpVJhx44diIqKgk6nw08//YTLly/jwQcfRFBQEDw8PNCvXz/s2bOnyv7Cw8Or1ACpVCp88sknGDNmDNzc3NCxY0d8Y8mcYrX46quv0K1bN+h0OoSHh+Ptt9+u8vr777+Pjh07wsXFBUFBQXi4ovMBgM2bN6NHjx5wdXWFv78/YmNjUVBQ0OCyWII1N2Q/1lb5XrwoDdO/Y4fUu6mw0LLPiYwEOnWybFvesiFSHiGkqT4sYTAAL75Ye42wSiXV6MTGWvb/gpubRaMDv/vuu7hw4QK6d++OxYsXAwB+L5/5/ZVXXsE///lPtG/fHr6+vkhOTsbIkSPxxhtvQKfTYd26dRg1ahTOnz+Ptm3b1voZixYtwrJly/CPf/wD7733HiZOnIirV6/Cz8+v/u9RydGjRzFu3DgsXLgQ48ePx6FDh/Dcc8/B398fkydPxq+//ooXX3wR//73v3H33XcjOzsbBw4cACANsDhhwgQsW7YMY8aMQV5eHg4cOADR1B21bd8cyLGxQbFMLGkEnJ8vxLffCjF9uhB33FGzYW5AgO0aARORIphtgJqf37AOBLZY8vMtLvt9990nZsyYYXpe0ZB327Zt9b63W7du4r333jM9r96gGIB49dVXKx2SfAFA7Nixo959V29Q/Nhjj4mhQ4dW2eavf/2ruPPOO4UQQnz11VfCy8tL6PX6Gvs6evSoACCuXLlS7+cKYbsGxbwtRU2vvirfyZOBoUMBPz/g//4PWLVKmlxRowGGDAGWLQNOnZJqVtq0qf2vIpVKGtvEkkbAREQOqm/fvlWe5+fn46WXXkLXrl3h4+MDDw8PnD17FklJSXXup2fPnqbH7u7u8PLyQkZGhtXlOXv2LAYMGFBl3YABA3Dx4kUYDAYMHToU7dq1Q/v27fH444/jiy++wK3ymrPIyEjcf//96NGjBx555BF8/PHHuHnzptVlsBbDDTWt+hoBCwF8/jmwZ48083O7dsDUqVLD4Bs3gPh4qVdT9+7SlAPvviu9t3rAaWivJCJSHjc3ID/fsmX7dsv2uX27Zftzc2t08av3enrppZewdetWLFmyBAcOHMCJEyfQo0cPlJSU1Lmf6tMXqFQqGI3GRpevOk9PTxw7dgwbNmxASEgI5s+fj8jISOTk5MDJyQm7d+/Gjh07cOedd+K9995D586dkZiYaPNyVMZwQ03rwAHLGgFPnw6cPSs1wP3gA+CBB6R5jaqzdSNgIlIelUrqQGDJMmyYZTXCw4ZZtj8rJu3UarUwGAz1bnfw4EFMnjwZY8aMQY8ePRAcHIwrV65Y/DmN1bVrVxw8eLBGmTp16gSn8j8mnZ2dERsbi2XLluHkyZO4cuUK9u7dC0AKVQMGDMCiRYtw/PhxaLVabN26tUnLzAbF1LTqmkyysgEDpAkcLWHrRsBE1HI1xThVFgoPD8fhw4dx5coVeHh41Fqr0rFjR2zZsgWjRo2CSqXCa6+91iQ1MLX5y1/+gn79+uH111/H+PHjkZCQgJUrV+L9998HAHz77bf4448/cO+998LX1xfbt2+H0WhE586dcfjwYcTHx2PYsGEIDAzE4cOHkZmZia5duzZpmVlzQ03HYACqpf1ahYRYt++KXkkTJkg/GWyIqKFkqhF+6aWX4OTkhDvvvBOtWrWqtQ3N8uXL4evri7vvvhujRo1CXFwc+vTp0yRlMqdPnz7473//i40bN6J79+6YP38+Fi9ejMmTJwMAfHx8sGXLFgwZMgRdu3bF6tWrsWHDBnTr1g1eXl748ccfMXLkSHTq1Amvvvoq3n77bYwYMaJJy8yJM6lpnD8PPPmkNJdTXaydvJGIqBKbTpzJCVNlx4kzyTEZDMDy5cD8+dLAex4ewMSJwEcfSa/bscqXiMgqHKdKMXhbimznzBlpqoOXX5aCzbBhwO+/A6tXsxEwEZGDmDp1Kjw8PMwuU6dOlbt4NsHbUtR4ZWXSWDSLFkndub29pdqbKVOq9hxglS8R2ZhNb0u1EBkZGdDr9WZf8/LyQmBgoJ1LdBtvS5FjOHlSCjHHjknP//Qn4MMPa9bSAKzyJSJyAIGBgbIGGHvgbSlqmJISqaamb18p2Pj6AuvWSRNVmgs2REREdsKaG6qbuVtJJ09KUyacPClt8+CD0sB71nbnJiIiagIMN1S7LVukqRMqjzDs6QkUFABGI+DvD6xcCYwfb9WonERERE2J4YbMq5jssnp787w86WdMDLBtG6Dw+7ZERNT8sM0N1VTXZJcVrl2Tam6IiIgcDMMN1WTJZJfJydJ2RETULF25cgUqlQonTpyQuyg2x3BDNVk62aWl2xERUQ2DBg3CzJkzbba/yZMnY/To0TbbX3PGcEM1Wdrrib2jiEhhftXrMeTECfxayyB31Dww3FBNAwdKc0LVRqUCwsKk7YiIFGRdejr25eTg3+npTfo5kydPxg8//IB3330XKpUKKpUKV65cwenTpzFixAh4eHggKCgIjz/+OLKyskzv27x5M3r06AFXV1f4+/sjNjYWBQUFWLhwIT7//HN8/fXXpv3t37/f6nL98MMP6N+/P3Q6HUJCQvDKK6+grKys3s8HgP3796N///5wd3eHj48PBgwYgKtXrzb6WDUEe0tRTQcPAvn55l/jZJdE5OCEELhlNFq8fVJREW6UlkKlUmFjRgYAYENGBsYFBkIIAX+NBm0tnNrBTa2GyoKhMd59911cuHAB3bt3x+LFiwEAGo0G/fv3x9NPP4133nkHhYWFmDNnDsaNG4e9e/ciNTUVEyZMwLJlyzBmzBjk5eXhwIEDEELgpZdewtmzZ6HX6/Hpp58CAPz8/Cw+BgBw/fp1jBw5EpMnT8a6detw7tw5PPPMM3BxccHChQvr/PyysjKMHj0azzzzDDZs2ICSkhIcOXLEomPRFBhuqKq8PGDSJOnx/fcD589XbVzcpo0UbDjZJRE5qFtGIzwa2eEhs7QU9xw/bvX78gcOhLsFf/h5e3tDq9XCzc0NwcHBAIC///3v6N27N5YsWWLabu3atQgLC8OFCxeQn5+PsrIyjB07Fu3atQMA9OjRw7Stq6sriouLTfuz1vvvv4+wsDCsXLkSKpUKXbp0QUpKCubMmYP58+cjNTW11s/Pzs5Gbm4u/u///g933HEHAKBr164NKoctMNxQVbNnA1euAOHhwNatgJsbJ7skIrKD3377Dfv27YOHmWYBly9fxrBhw3D//fejR48eiIuLw7Bhw/Dwww/D19fXJp9/9uxZxMTEVKltGTBgAPLz83Ht2jVERkbW+vl+fn6YPHky4uLiMHToUMTGxmLcuHEIkaltJsMN3fbtt8Ann0i3nj7/XBqNGOBkl0TUrLip1ci3sk3gifx8szU1P/XujV51tUE089kNlZ+fj1GjRuGtt96q8VpISAicnJywe/duHDp0CN9//z3ee+89zJs3D4cPH0ZERESDP9dS9X3+p59+ihdffBE7d+7Epk2b8Oqrr2L37t246667mrxs1bFBMUkyM4Gnn5Ye/+UvwL33ylseIqIGUqlUcHdysmpxLQ8lFRfFip+uarVV+7GmjYlWq4XBYDA979OnD37//XeEh4ejQ4cOVRZ3d3fTdxswYAAWLVqE48ePQ6vVYuvWrWb3Z62uXbsiISEBotIArgcPHoSnpyfatGlT7+cDQO/evTF37lwcOnQI3bt3x/r16xtcnsZguCFpJOKpU4H0dKBbN+D11+UuERGRXQVqNAjWaBDl6YnVnTohytMTwRoNAjWaJvvM8PBwHD58GFeuXEFWVhamT5+O7OxsTJgwAb/88gsuX76MXbt2YcqUKTAYDDh8+DCWLFmCX3/9FUlJSdiyZQsyMzNNbVvCw8Nx8uRJnD9/HllZWSgtLbWqPM899xySk5Pxwgsv4Ny5c/j666+xYMECzJ49G2q1us7PT0xMxNy5c5GQkICrV6/i+++/x8WLF+VrdyNamNzcXAFA5Obmyl0Ux/HvfwsBCOHsLMSxY3KXhojIYoWFheLMmTOisLCw0fsqMhiE0WgUQghhNBpFkcHQ6H3W5fz58+Kuu+4Srq6uAoBITEwUFy5cEGPGjBE+Pj7C1dVVdOnSRcycOVMYjUZx5swZERcXJ1q1aiV0Op3o1KmTeO+990z7y8jIEEOHDhUeHh4CgNi3b1+dn5+YmCgAiOPHj5vW7d+/X/Tr109otVoRHBws5syZI0pLS4UQos7PT0tLE6NHjxYhISFCq9WKdu3aifnz5wuDlcewrn9Pa67fKiHqmkBIefR6Pby9vZGbmwsvLy+5iyO/5GSgRw8gNxf4+9+BefPkLhERkcWKioqQmJiIiIgIuFjYXZscV13/ntZcv3lbqiUzGoEpU6Rgc9ddwJw5cpeIiIio0RhuWrL33wfi46Xu3uvWAc7sPEdEpBRLliyBh4eH2WXEiBFyF69J8WrWUp0/D7z8svT4H/8AOnaUtzxERGRTU6dOxbhx48y+5urqaufS2BfDTUtUVgY8/jhQWAgMHQpMmyZ3iYiIyMb8/PysnoJBKXhbqiVauhT45RfAxwdYu/b2fFFEREQKwHDT0hw9CpRP0oZVq6S5ooiImjmjFRNlkuOyVQdu3pZqSQoLpdtRZWXAI48AEybIXSIiokbRarVQq9VISUlBq1atoNVqZZuJmhpHCIHMzEyoVCpoGjl4IsNNSzJvHnD2LBAcDHzwAW9HEVGzp1arERERgdTUVKSkpMhdHGoklUqFNm3awKmREzQz3LQU+/YB77wjPV6zBvD3l7c8REQ2otVq0bZtW5SVlTVqbiWSn0ajaXSwARhuWga9Hpg8WXr87LPAyJGyFoeIyNYqbmU09nYGKQMbFLcEM2cCSUlA+/bA22/LXRoiIqImxZobJTIYgAMHgNRU4PJl4NNPpfY1n38OeHjIXToiIqImxXCjNFu2ADNmANeuVV3/4IPAPffIUyYiIiI74m0pJdmyBXj44ZrBBgC+/lp6nYiISOEYbpTCYJBqbOoaAGnmTGk7IiIiBWO4UYoDB8zX2FQQAkhOlrYjIiJSMIYbpUhNte12REREzRTDjVKEhNh2OyIiomaK4UYpBg6UJsGsbUoFlQoIC5O2IyIiUjCGG6VwcgLefdd8g+KKwLNihbQdERGRgjHcKMnYsUBsbM31bdoAmzdLrxMRESkcB/FTEiGA8+elx2+9Jd2GCgmRbkWxxoaIiFoIhhslOXtW6u7t4gK88ALg6ip3iYiIiOxO9ttSq1atQnh4OFxcXBAdHY0jR47Uuf2KFSvQuXNnuLq6IiwsDLNmzUJRUZGdSuvgdu6Uft53H4MNERG1WLKGm02bNmH27NlYsGABjh07hsjISMTFxSEjI8Ps9uvXr8crr7yCBQsW4OzZs1izZg02bdqEv/3tb3YuuYPasUP6OXy4vOUgIiKSkazhZvny5XjmmWcwZcoU3HnnnVi9ejXc3Nywdu1as9sfOnQIAwYMwGOPPYbw8HAMGzYMEyZMqLe2p0UoKAB+/FF6PGKEvGUhIiKSkWzhpqSkBEePHkVspd49arUasbGxSEhIMPueu+++G0ePHjWFmT/++APbt2/HyJEja/2c4uJi6PX6Kosi7d8PlJQA4eFAp05yl4aIiEg2soWbrKwsGAwGBAUFVVkfFBSEtLQ0s+957LHHsHjxYtxzzz3QaDS44447MGjQoDpvSy1duhTe3t6mJSwszKbfw2FUtLcZPrz2gfwa6Fe9HkNOnMCvSg2GRESkKLI3KLbG/v37sWTJErz//vs4duwYtmzZgu+++w6vv/56re+ZO3cucnNzTUtycrIdS2xHTdjeZl16Ovbl5ODf6ek23zcREZGtydYVPCAgAE5OTkivdsFMT09HcHCw2fe89tprePzxx/H0008DAHr06IGCggI8++yzmDdvHtTqmllNp9NBp9PZ/gs4kkuXgMuXAY0GGDLEJru8WlSErNJSqABsKm/gvTEjA5OCgyEABGg0aOfiYpPPIiIisiXZwo1Wq0VUVBTi4+MxevRoAIDRaER8fDyef/55s++5detWjQDjVD44nTA37UBLUXFL6p57AE9Pm+wy/Oefa6zLKC1F1NGjpudi0CCbfBYREZEtyXpbavbs2fj444/x+eef4+zZs5g2bRoKCgowZcoUAMATTzyBuXPnmrYfNWoUPvjgA2zcuBGJiYnYvXs3XnvtNYwaNcoUclqkyu1tGkkIgWN5eRju51frNioAU0NCkFlS0ujPIyIisjVZRygeP348MjMzMX/+fKSlpaFXr17YuXOnqZFxUlJSlZqaV199FSqVCq+++iquX7+OVq1aYdSoUXjjjTfk+gryKyoC9u6VHjci3FwvLsYX6elYl5aG32/dqnNbAWB1aio+TE1FX09PjPTzwwh/f/T19ISTjRsz1+VXvR4v//EHlrVvj75eXnb7XCIicmwq0cLu5+j1enh7eyM3NxdeSrgg7t4NDBsGhIYC165Z1VMqv6wMW7OysC49HfE3b6LiRNCpVBgdEIAYb2/MvHQJagBGwPTzyeBgHMvPx4n8/Cr783d2xvDyoBPn64sArbbGZ9oykLx48SLeu34dL7ZujXc7dmzUvoiIyLFZc/3m3FLNXS1dwGsLEQYhsO/mTfw7PR1fZWaiwGg0vTbQ2xtPBAXh4Vat4KPR4FpREd68ehVhLi54KiQEa1JTkVxUhEXh4Wjj4oLU4mLszM7G9uxs7M7Oxo2yMnyRkYEvMjKgAtDf0xMj/P0xws8PfT09oVapqvS8aki4YUNnIiKqD2tumrtu3YAzZ4D//hd45BHT6uq1Gr8XFODfaWn4T3o6rldqK9PB1RVPBAXhz0FBiDAzH1Wx0QitSgWVSgUhBEqEgM5Mr7RSoxE/6/XYnp2NHTdu4LeCgiqv+zg7I8bLCwdzc6E3GODj7Iw3wsNRBsBNrYafRoNSIVBqNKJMCJQKYfppemw04rUrV2p8tgpA5ZOYDZ2JiJTHmus3w01zlpQEtGsHqNVAVhauurqaajVGnDyJjNJSeDg5oY1Wi3OFhaa3+Tg749HAQDwRFIS7vLygaoJ2MtfLa3V23LiBr7KybL5/c5xVKnzWpQsmVhsYkoiImj/elmopKm5JxcQAvr4I37+/xib5BkOVYPNVt274k7+/2doXW2qt0+GpkBA8FRKCz1NT8dT58zDUsu0dLi4I1mqhUavhrFJBo1KZfpoeV3otu7QUmzIza+wnTKeDVqWCUQio7diwmYiIHAvDTXNWrQv4ui5dMPncORjNbFpRqzG2VSv7la/cpJAQ9PDwqDJGToWjUVHoY+XYPMfy8rApM9PUwLnitlRiURHGnTmDSHd3LIqIwAP+/k1SK1Uf9uIiIpJXs5p+gSopLQX27JEeDx+OxMJCrElNNRtsAOBwnz4OcbtGXe1nQwRqNAjWaBDl6YnVnTqhr6cnAjUazGzdGp5OTvitoACjT59G/2PHsOPGDbsP8MjpKuTDedCICGDNTfOVkADk5UEEBOCTkBDM/vVX5BsMcFGpUCREje7bcqsIJNV7XgVqNFbvq42LC67ExJgaOj8bEmJq6PxaeDj+mZyMf127hl/z8jDy1CnEeHlhcXg47vf1bbKanIpeXBACX5SHGvbisr/G9sYjImVgg+Lmau5cXP/kEzy9fDl2ls90PtDbG0siIvDI77/XCBG/REWhjcwXV0t7XtlCRkkJliUlYVVKCorKu7vf6+2N1yMicK+Pj80+p9hoxNG8PAw4frzebdmLq2lUHh6goiF9oEaDHT17MlgSKQh7S9VBCeFGCIH1Tz+N50ePRo6nJ3QqFZa0b48ZbdrASaWya4hwdKnFxVialIQPU1JQUn6qx/r64vXwcNzl7W3aztJ2MtmlpTiUm4ufcnNxUK/HL3o9ii38Ferh7o6hvr6I9fXFvT4+cG/JU4bYkMpMQ/rqGhIs2XaKyLEw3NShuYebzJISTD15ElvKRwfu6+KCdT16oKu7u8wlc2zXiorwRlIS1qSmorT8lB/p54fFERGI8vQ0O9qxEAKJRUVSkCkPNGfMTE0RqNFggLc3wl1c8M61azVe7+LqivOFhVXG4tGqVLjb29sUdqJqmbqiJVxgrf2OBiFw4dYt/JKXh1/z8rAjOxuXKvUIrM5NrUYPd3d0dnNDJzc3dHZ1RWc3N3RwdYVrHQGTI2DLqyWc+2Qdhps6NOdwsy0zE89euIDM0lI4l5VhwZ49eGXJEji30FqZhrhSWIjXr17F52lppq7p93l741RBAbLLyuDr7Iwng4NxIj8fJwsKkFlaWmMfXdzcMMDLC/d4e2OAtzc6uLpCpVLhWF4eoo4erdHe6WhUFNrqdIjPycGemzexOzsbV4uLq+zT19kZQ3x8MNTPD0N9fdG+fEBFW15gHfViUdd3FELgj6Ii/JqXh1/0evyal4ej+fnIN9Q2sIDlVADa6nTo7OYmBR9XV/g4O8PX2RlBWi3+dOqUTW9xOerxd1QtIVzynLAOx7lRmJulpZhx6ZKp9033Gzew7pVX0PvRR6UB/Mhi4a6uWNOlC+a2bYuOR44AAH7IzTW9frOsDG9Xqn3RqFTo6+lpCjJ3e3mhlZk5s4C6G00HaLUYHxiI8YGBEELgUmEhdt+8iT03b2LvzZu4WVaGr7KyTAMehmq1uMvLC3tu3gQArM/IwMOtWkGrUiFYp2vQBdaRGtvWNo3GcD8//F5QgCtFRbhQWIhf8/Jws6ysxvvd1Gr08fRE3/LFTa3G2N9/rxEsD/buDU8nJ5y/dQsXCgtx/tYtaSksRE5ZGa4WF+NqcTG+Lz/O5mSUllYZxiAxOhqhOh20Vv7uOdLxr8yRLrAV54VRCPynBTTMd9RzQglYc+PgdmVn46lz53C9pARqAC+3aYOFd98NXWYmcPAgcPfdchex2foiPR2Tzp41O7igGsDf2rbF39q1q/PWRXUNae9UZjTi17w87L55E7tv3sSBSmGrNh5OTnBVq+GiVsO1fHFRq+Favr7ieVn5r7dOrcZXmZm4ZTQiQKPBLpkb21rSTqaCVqVCpIcH+np6ol/50sXNrUqN5bWiIvQ7etTihvRCCGSVlpqCTkXo+SUvD6mVpiepS6BGgzY6HVrrdFV/arWm59llZQ7f2NmRakiaqv2ULTU2DDZVA3hHCqmV2bJcvC1VB0cON5VPgi5ubnjp8mV8mJoKAOjo6orPu3RBzNmz0ojEPj5AZibgzMq3xqi4lVRdQwYXtJU1KSn4fxcu1Dqis63Z+2IhhMDiK1ew6OpV1Pafz33e3ng0MBD9vLzQw93doloSWzWkP5Kbi2gzvd96eXggt6wM14uLTY3TG8IR5kJzpB5mRiGw5+ZNfJiSgm1ZWbUOXeEo06tYEwbzy8pwrbgY10tKpJ/FxZiXmFjvZ+zq2RPhLi5oq9PBxcI/rhwppFZmy3LxtlQzVVFF+WZSEo7l5yOxqAgA8GLr1ljavj3cnJxuj0o8dCiDjQ050rhAT4WGorenp9nQtTcyEp3c3FBkNKLQYECh0YhCo1F6XmldxfMEvR5bMjNr/U7+zs5YmJiIKSEhTX4xyy4txX/S0/FxaipOV5tYtbKGBsvKQUalUkHXwDGNKmqEqp8Tazp3Rh9PT1OtT8XFqvrFq+KnvpZ2QRXBRg1glUwXofCff66xrvrtt6YOXeklJVibmoqPU1NN/9cBQE93d5w0c364qFQoNRohhLD7yOPmbqOuz8jAXV5eSC8pwa3y37fK//7X6jgH6hN38qTpcYhWi3AXF9MSUemxAJBnMNS4vSv3bbzabjvbs1y8Osqs8kmwsfwkqGh3EazRYHmHDphQ+S+ValMuUOPYcnDBplD9Auvt7IzWOp1V+6itdspDrcaNsjIsunoVi69eRayvL54KCcGD/v4W/7VYHyEEfsjJwcepqfgqM9PUbd5Frcb9Pj74LjvboYIlUP85oVKp0EqrRSutFr3rCGF55bU8+3NyMO3ixRqvGwE8f/EiNmdmYmyrVhgTEIAQK/9tLWUUwtSzbPuNG/Vuf4+XF9anp2Oor2+tbcwaWo69N2/iw9RUbMvKMt029XZywuPBwfh/5QNyVm6YX1HTlW80Ysr589icmYmPOndGaBMdK3PMhcGs0lI8dvZsve/1cnKqcfvSKASWJCXV2HZcq1a4ZTQisbAQV4qKUGA0IrWkBKklJUiwcNRte4dUc8wdr0w7l4u3pWRm1T3mrCwgMBAQArh+HQgNbdKytRSOOC6QtW1I6lJbL66DvXvjSlER1qSmYm9Ojml7P2dnTAwKwlMhIYj08GhQ+dNLSvB5Who+SU3FxUrdtCPd3fFMaCgmBgYi32Cw2Xe0NVueE9WPf8XFuqOLCy5WqrFQAYjx8sJDrVphbEAAwst7zDXUjdJS7MrOxo7sbOzMzpZG0K6k+uebowLQx8MDcX5+GObnhxgvrzpvEdbWviKjpASfpaXho5QUXK70mXd5eeH/hYRgXGCgVDMN8+d+UlERpgQHY/m1aygRAj7OzvhXhw74c1BQk9fiGITAzEuXsPL69Vq36ePhgWgvrxptr1rrdPA0U8NeV8/KilpLIQRulJbiSlGR2SWxqAi3jLX/OaACMCEwEC+FhSHSw6PJJxNOK2+Yvys7G/+7cQN5tdRaNeb2Itvc1MHRws0X6emYfO6c6S+YymqcBBs2AI89BvTsCfz2m51LSvZmqwusJUHpj8JCfJaWhk/T0nCtUjf1KA8PPBkSgscCA+FTqTbL3EXMUN524uOUFHx944bpnPZwcsKEwEA8ExKCvp6eVS5Gjhgsba2u418sBLZkZmJLVhZ+rvaXeR8PD4xt1QoPBQSgS7VxrMwdf6MQOFpeO7MjOxuH9foqbXu8nJww1NcXI/39MdzPD2klJWYvsB907IjEoiLsys7Gb9VuD3k4OWGIjw/i/PwQ5+eHO6oFsMrtK1Z06ID9OTn4MCUFW7KyTONLeTk54c9BQfh/oaHoWUt4ru28+L2gAJPOnsXR8nG+HvD3x4edOiG4CWpxyoxGbMzIwBtJSThnZnyrCg25jWqLP14qws+O7Gw8ce5cndv6OTtjkI8P7vf1xRAfH3R2c6szFFrSCLjYaMRPubnYlZ2NXdnZNW4luqrVKDQTvhrTnpHhpg6OFm4AKxq1TpoErFsHvPwy8NZbdiwhNXeWhgiDENidnY01aWn4utIFyUWtxkMBAXgqJAT3+fhg5qVLpovYX8PCsDYtDWtTU6uM3xPt6YlnQkMxvlUreLTw9mGWHP/rxcXYWh50fsjJqXKLrqubm6lGp5eHB2aUH/9nQ0IwyMfHVDtTfVymnu7uGOHnhxH+/rjbywsaK3uYVf5rfPfNmzX2f4eLC2K8vNDL0xP9PT3x8O+/I6O0FB5OTvBzdkZSpfOhv6cn/l9oKMYHBjZqdO4yoxHLkpOx8MoVlAoBP2dnvNexIyYEBtqkFqfUaMQX6el4IynJNDikr7MzxrdqhdWpqXXWtljDVsG+tlqg2W3a4EJhIX7IyalRixKi1WJIRdjx9a3R/qW2QU3P37qFXTdv4vvsbOzPyalRcxRVXssX5+cHF5UK0ceP2+x4AQw3dXLEcHMgJwf3njhhem72JDAapdtQ6enA3r3A4MFyFJVakKySEvwnPR1r0tKqNABurdUip6wMBeX/OZcKYaoh8HF2xuNBQXgmJAQ9GnhLi6SRyL+5cQNfZWZiz82bppAJSGMgZZeVmeZMq8yzvHZmhJ8fhvv51VsLYM0F1igETuTnm/5SP6jXm61xNud4VBR62bj34an8fEw+dw7HymtxxgQE4INOnRDUwDZCJUYj1qWlYUlSkqmBs7+zM/4SFobprVtDX1bmkLdR6wupFUNN7M3Jwd6bN3FQr69x7rR3cUE/T0/0cHdHfy8v/PnsWWSUliJAo8HLYWE4pNfjiF6PlGrDJARrtYjz9cWw8sFHK7fPsuWt9QoMN3VwxHCzLi0Nk86dg1alwr86djR/Ehw7BkRFAR4ewI0bgA0b+RHVRQiBX/LyEH3sWL3b3ho40Kpxgah+uWVl+PbGDfzZgsarxffea/Xggg2VV1aGfTk5eO/aNeyp1Garsqbuvl1qNOLNpCQsvnoVZULA39kZqzp1wrhWrSyuxSk2GrE2NRVvJiWZapoCNRq8FBaGaaGhVWodHfU2qjXlKjIYkKDXm8LOYb3e4mEntCoVBnp7m2pneri713mcbX28GG7q4Ijh5qVLl/D2tWt4MigIa7p2NX8SLFkCzJsHPPggsG2bbGWllsuq9mFkc458/OUeL+q38lqcE+W1OA8FBOD9Tp0QWMcfgYUGAz5JTcVbSUm4Xl4jEazVYk5YGJ4NDTU1cFa6vLIyHMjNxarr17E9O9vsNmpIt7kWRkTIOuGvNddv+SMnYV/5Xz33+/kBKB+jo3q6ZRdwktnEoCAc7tPH7GuH+/RhsGlizeH4q6v9tJdIDw8c7tMHC9q1g7NKha+ystDtl1/wZfnwGr/q9Rhy4gR+1etRYDBgeXIy2h8+jBcvXcL1khK01mrxXocO+CM6GjPDwlpMsAEAT2dnjPT3x3c9e+JoVJTZbX6JisI/OnSQNdhYq2W38nMA2aWlOF7+18ZgHx/zG+XmAocOSY/j4uxTMKI6ONrYNC2Nox1/RxgvSqtWY2FEBB4MCMCkc+dwqqAA486cwbjMTHg5OWFfTg5mXrqEC4WFpobRbXU6zG3bFlNCQhzi9pKjcLTzqyEYbmT2Q04OBKTeELUO4LVnD2AwAJ07AxERdi0fUWWOcBFryRz1+LdxccGVmBhT+4pnywfjkyMw9Pb0xK9RUfjL5ct4//p1/DczExWtQg6Wd7cP1Woxo00bzGzTxm5tlJoDRz2/GoLhRmYVg6fVWmsD3L4lNWJEk5eHqC6OdBFriRz5+Ntq+gtb0KrVVQbdq95KKaWkBHP++AMvt21r34I5OEc+v6zV/EqsMPtu3gQADPH1Nb+BEGxvQw5Fp1abekiYbR9GTYrH3zL/6doVzrUELGeVCv/p2tXOJWoelHJ+seZGRuklJfi9fOTLQbXV3Jw5A1y7Bri4APfea7/CERE1YxODgtDVzc1sL67DffrYpRcXyad5RjKFqKi16eXhAf/a7mlW1NoMGgQ0cq4ZIqKWSK5eXCQf/lvLqKK9zZC62tvs2CH9ZHsbIiKrVDSQjfL0xOpOnRDl6YlgjaZZNpAl6/C2lIz21deYOD8fOHBAesz2NkREVlFSA1myDsONTJKKinCpsBBOAO6tLdzs3w+UlEjdv8snLyMiIss5Ui8ush/GV5lU1Nr09fSEV20zJlfuJcVfSCIiIosw3MhkryVdwNnehoiIyGoMNzIQQtTf3ubSJeCPPwCNBhg82G5lIyIiau4YbmRwubAQycXF0KhUGODtbX6jiltSAwcCHh72KxwREVEzx3Ajg4ou4DFeXrXPPstRiYmIiBqE4UYG9ba3KSoC9u2THrO9DRERkVUYbuzMovY2P/4IFBYCrVsD3brZrWxERERKwHBjZ2du3UJGaSlc1WpEe3mZ34hdwImIiBqM4cbOKm5J3ePtXfsomWxvQ0RE1GAMN3ZW73xSV68CZ88CTk5AbKzdykVERKQUDDd2ZBACP1SEm9oaE1fU2sTEAHVNqElERERmMdzY0W/5+bhZVgZPJyf0qW3sGt6SIiIiahSGGzuqaG9zn48PnM21tykpAeLjpccMN0RERA3CcGNHdba3MRiA998H8vKk21E9e9qzaERERIrBcGMnpUYjfqytvc2WLUB4ODBrlvQ8Jwdo315aT0RERFZhuLGTX/PyUGA0wt/ZGT3c3W+/sGUL8PDDwLVrVd9w/bq0ngGHiIjIKgw3dlJxS2qQjw/UFQPzGQzAjBmAEDXfULFu5kxpOyIiIrIIw42dmJ1P6sCBmjU2lQkBJCdL2xEREZFFGG7soMhgwMHcXADVGhOnplq2A0u3IyIiIoYbe/hZr0exEAjWatHZze32CyEhlu3A0u2IiIiI4cYeKncBV1WeCHPgQCA4uPY3qlRAWJi0HREREVmE4cYOzLa3AaT5o9q1M/+mihC0YoW0HREREVmE4aaJ5ZeV4XBeHgAzg/ft3w8cPgyo1UBQUNXX2rQBNm8Gxo61SzmJiIiUwlnuAijdQb0eZUKgnU6HCFfX2y8YDFI3bwCYNg14912pV1RqqtTGZuBA1tgQERE1AMNNE6v1ltSnnwK//SZNtbBwoRRkBg2yd/GIiIgUh7elmpjZ+aT0emDePOnxggVAQIDdy0VERKRUDDdNKKe0FMfK29sMrlxz88YbQEYG0LkzMH26TKUjIiJSJoabJvRjbi6MADq7uqK1TietvHxZ6gEFAG+/DWg0chWPiIhIkRhumlBFe5sqtTZ//StQUgIMGwaMHClTyYiIiJSL4aYJ1Whvs28fsHWr1Hh4+fLbY9kQERGRzcgeblatWoXw8HC4uLggOjoaR44cqXP7nJwcTJ8+HSEhIdDpdOjUqRO2b99up9JaLrOkBKcKCgBIM4HDYABmzZJenDoV6NZNvsIREREpmKxdwTdt2oTZs2dj9erViI6OxooVKxAXF4fz588jMDCwxvYlJSUYOnQoAgMDsXnzZrRu3RpXr16FT/XB8RzA/vJam57u7mil1QIff1y16zcRERE1CVnDzfLly/HMM89gypQpAIDVq1fju+++w9q1a/HKK6/U2H7t2rXIzs7GoUOHoClviBseHm7PIlus4pbUYB8fIDf3dtfvhQvZ9ZuIiKgJyXZbqqSkBEePHkVsbOztwqjViI2NRUJCgtn3fPPNN4iJicH06dMRFBSE7t27Y8mSJTAYDLV+TnFxMfR6fZXFHqoM3rdkCZCZKXX9fu45u3w+ERFRSyVbuMnKyoLBYEBQtTmVgoKCkJaWZvY9f/zxBzZv3gyDwYDt27fjtddew9tvv42///3vtX7O0qVL4e3tbVrCwsJs+j3MuV5cjAuFhVADuPfmTXb9JiIisiPZGxRbw2g0IjAwEB999BGioqIwfvx4zJs3D6tXr671PXPnzkVubq5pSU5ObvJy7iuvtYny9ITPnDlS1++4OHb9JiIisgPZ2twEBATAyckJ6enpVdanp6cjODjY7HtCQkKg0WjgVGlCya5duyItLQ0lJSXQarU13qPT6aCrGEDPTkztbfT6212/336bXb+JiIjsQLaaG61Wi6ioKMTHx5vWGY1GxMfHIyYmxux7BgwYgEuXLsFoNJrWXbhwASEhIWaDjRyEEIivaG/z4YfSSnb9JiIishtZb0vNnj0bH3/8MT7//HOcPXsW06ZNQ0FBgan31BNPPIG5c+eatp82bRqys7MxY8YMXLhwAd999x2WLFmC6Q40P1NiURGSiovhLATu+fprqev3okVyF4uIiKjFkLUr+Pjx45GZmYn58+cjLS0NvXr1ws6dO02NjJOSkqBW385fYWFh2LVrF2bNmoWePXuidevWmDFjBubMmSPXV6hhX/ktqbvOnYN7URHw5puAv7+8hSIiImpBVEIIIXch7Emv18Pb2xu5ubnw8vKy+f4nnjmD9RkZmP/551iUkACcOsUeUkRERI1kzfW7WfWWcnRCCOzNygIADD5+XJo/isGGiIjIrhhubOjcrVtIMxrhUlyMu1q3BkaMkLtIRERELQ7DjQ3tK5/0c8Dvv8PlH/9g128iIiIZMNzYisGAvb/9BgAYotUCd94pc4GIiIhaJoYbGzGuXYt9EREAgMEPPCBzaYiIiFouq8NNcnIyrl27Znp+5MgRzJw5Ex999JFNC9YsGAzA/v3AmjU4+f77yPb2hofBgL5t2shdMiIiohbL6nDz2GOPYd++fQCAtLQ0DB06FEeOHMG8efOwePFimxfQYW3ZAoSHA4MHA08/jX0dOgAA7i0rg0bNCjEiIiK5WH0VPn36NPr37w8A+O9//4vu3bvj0KFD+OKLL/DZZ5/ZunyOacsW4OGHgUo1WHt79wYADFm7VnqdiIiIZGF1uCktLTVNRLlnzx48UN6+pEuXLkhNTbVt6ZrQMb2+YW80GIAZM4BKYx+WqdX4ITISADD4xAlg5kxpOyIiIrI7q8NNt27dsHr1ahw4cAC7d+/G8OHDAQApKSnwb0bTDGzMzGzYGw8cqFJjAwBHO3dGnrs7fPV6RF66BCQnS9sRERGR3Vkdbt566y18+OGHGDRoECZMmIDI8hqLb775xnS7qjn4KiUFx3JzcTQvD1eLiureODcX+N//gFmzgCeeqPHyvl69AACDTpyAU8WM5c2oFouIiEhJrJ44c9CgQcjKyoJer4evr69p/bPPPgs3NzebFq4pZQmBqOPHTc/FoEG3X7x1Czh0CNi7V1p++QWoCC1mmNrbVNofQkJsXWQiIiKygNXhprCwEEIIU7C5evUqtm7diq5duyIuLs7mBWwylUYP7lhWhpU//ohHDh5E0K5dQEICUFJSdfuOHYEhQ4BBg4C//EWqmRECxRoNfurRA0B5exuVCmjTBhg40H7fhYiIiEysDjcPPvggxo4di6lTpyInJwfR0dHQaDTIysrC8uXLMW3atKYoZ9MxGnHR2RkvGI2Y0b8/hmg0mODmhjGXL8M3JkYKNIMHA2Fht9+j1Uq9pVQqHO7aFYUuLgjMzsadV69Kr69YATg5yfJ1iIiIWjqr29wcO3YMA8trJTZv3oygoCBcvXoV69atw7/+9S+bF7CpqMpvM+2cMwfvrFyJ/hcuwOjkhD19++Kpl19G8Ecf4cG//AUb4+JQEBpa9c1jxwKbNwOtW5va2ww5fhyqNm2k9WPH2vnbEBERUQWrw82tW7fg6ekJAPj+++8xduxYqNVq3HXXXbhaUXPRDPS+dAnBN26g25UrmPnVVzjs7o5L0dF4IyIC3d3dUSIEvrlxAxPOnkXgwYN47MwZfJOVhZKKtjdjxwJXruDrKVMAAO3vvx9ITGSwISIikpnVt6U6dOiAbdu2YcyYMdi1axdmzZoFAMjIyICXl5fNC9hU9s6eDReNBrrSUmlF69a4w9UVf2vXDn9r1w6n8/OxISMDGzMy8EdRETZkZGBDRgZ8nJ3xUEAAJgQFob+nJ34r39/1oCDeiiIiInIAKiEqjUZngc2bN+Oxxx6DwWDAkCFDsHv3bgDA0qVL8eOPP2LHjh1NUlBb0ev18Pb2Ri4AL+B2A+DERLPhRAiBX/LysCEjA5syMpBaqaGxu1qNgvKanECNBjt69oQAEKDRoJ2Li12+DxERUUtgun7n5tZbmWJ1uAGkOaVSU1MRGRkJdfk8SkeOHIGXlxe6dOnSsFLbSZVwU9FjysJ2MgYhcCAnB4N/+63GayoAlQ9kla7lRERE1CjWhJsGzfAYHByM3r17IyUlxTRDeP/+/R0+2NRgZQNgJ5UKg3x98Z+uXeFcqSs5cDvYOKtU+E/XrjYuKBEREVnK6nBjNBqxePFieHt7o127dmjXrh18fHzw+uuvw1jHQHcO59tvG9wAeGJQEA736WP2tcN9+mBiUFBjS0dEREQNZHWD4nnz5mHNmjV48803MWDAAADATz/9hIULF6KoqAhvvPGGzQvZJAYOtEkDYDUAY6WfREREJC+rw83nn3+OTz75xDQbOAD07NkTrVu3xnPPPdd8wk0jBWo0CNZoEObigqdCQrAmNRXJRUUI1GjkLhoREVGLZnW4yc7ONtu2pkuXLsjOzrZJoZqDNi4uuBITA61KBZVKhWdDQlAiBHTqBjVjIiIiIhux+kocGRmJlStX1li/cuVK0wzhLYVOrYaqvGGxSqVisCEiInIAVtfcLFu2DH/605+wZ88exMTEAAASEhKQnJyM7du327yARERERNawuqrhvvvuw4ULFzBmzBjk5OQgJycHY8eOxfnz501zThERERHJpUGD+Jlz7do1LF68GB999JEtdtdkrBkEiIiIiBxDkw/iZ86NGzewZs0aW+2OiIiIqEHYApaIiIgUheGGiIiIFIXhhoiIiBTF4q7gY+uZgyknJ6exZSEiIiJqNIvDjbe3d72vP/HEE40uEBEREVFjWBxuPv3006YsBxEREZFNsM0NERERKQrDDRERESkKww0REREpCsMNERERKYpNw01hYaEtd0dERERkNZuEm+LiYrz99tuIiIiwxe6IiIiIGszicFNcXIy5c+eib9++uPvuu7Ft2zYAUhfxiIgIrFixArNmzWqqchIRERFZxOJxbubPn48PP/wQsbGxOHToEB555BFMmTIFP//8M5YvX45HHnkETk5OTVlWIiIionpZHG6+/PJLrFu3Dg888ABOnz6Nnj17oqysDL/99htUKlVTlpGIiIjIYhbflrp27RqioqIAAN27d4dOp8OsWbMYbIiIiMihWBxuDAYDtFqt6bmzszM8PDyapFBEREREDWXxbSkhBCZPngydTgcAKCoqwtSpU+Hu7l5luy1btti2hERERERWsDjcTJo0qcrzP//5zzYvDBEREVFjcVZwIiIiUhROv0BERESKYnHNzZNPPmnRdmvXrm1wYYiIiIgay+Jw89lnn6Fdu3bo3bs3hBBNWSYiIiKiBrM43EybNg0bNmxAYmIipkyZgj//+c/w8/NryrIRERERWc3iNjerVq1CamoqXn75Zfzvf/9DWFgYxo0bh127drEmh4iIiByGSjQwmVy9ehWfffYZ1q1bh7KyMvz+++/NYlA/vV4Pb29v5ObmwsvLS+7iEBERkQWsuX43uLeUWq2GSqWCEAIGg6GhuyEiIiKyKavCTXFxMTZs2IChQ4eiU6dOOHXqFFauXImkpKRmUWtDREREymdxg+LnnnsOGzduRFhYGJ588kls2LABAQEBTVk2IiIiIqtZ3OZGrVajbdu26N27d50zgTv63FJsc0NERNT8WHP9trjm5oknnqgz1BARERE5AqsG8SMiIiJydJxbioiIiBSF4YaIiIgUxSHCzapVqxAeHg4XFxdER0fjyJEjFr1v48aNUKlUGD16dNMWkIiIiJoN2cPNpk2bMHv2bCxYsADHjh1DZGQk4uLikJGRUef7rly5gpdeegkDBw60U0mJiIioOZA93CxfvhzPPPMMpkyZgjvvvBOrV6+Gm5sb1q5dW+t7DAYDJk6ciEWLFqF9+/Z2LC0RERE5OlnDTUlJCY4ePYrY2FjTOrVajdjYWCQkJNT6vsWLFyMwMBBPPfVUvZ9RXFwMvV5fZSEiIiLlkjXcZGVlwWAwICgoqMr6oKAgpKWlmX3PTz/9hDVr1uDjjz+26DOWLl0Kb29v0xIWFtbochMREZHjkv22lDXy8vLw+OOP4+OPP7Z46oe5c+ciNzfXtCQnJzdxKYmIiEhOFg/i1xQCAgLg5OSE9PT0KuvT09MRHBxcY/vLly/jypUrGDVqlGmd0WgEADg7O+P8+fO44447qrxHp9NBp9M1QemJiIjIEclac6PVahEVFYX4+HjTOqPRiPj4eMTExNTYvkuXLjh16hROnDhhWh544AEMHjwYJ06c4C0nIiIikrfmBgBmz56NSZMmoW/fvujfvz9WrFiBgoICTJkyBYA0p1Xr1q2xdOlSuLi4oHv37lXe7+PjAwA11hMREVHLJHu4GT9+PDIzMzF//nykpaWhV69e2Llzp6mRcVJSEtTqZtU0iIiIiGSkEkIIuQthT9ZMmU5ERESOwZrrN6tEiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRHCLcrFq1CuHh4XBxcUF0dDSOHDlS67Yff/wxBg4cCF9fX/j6+iI2NrbO7YmIiKhlkT3cbNq0CbNnz8aCBQtw7NgxREZGIi4uDhkZGWa3379/PyZMmIB9+/YhISEBYWFhGDZsGK5fv27nkhMREZEjUgkhhJwFiI6ORr9+/bBy5UoAgNFoRFhYGF544QW88sor9b7fYDDA19cXK1euxBNPPFHv9nq9Ht7e3sjNzYWXl1ejy09ERERNz5rrt6w1NyUlJTh69ChiY2NN69RqNWJjY5GQkGDRPm7duoXS0lL4+fmZfb24uBh6vb7KQkRERMola7jJysqCwWBAUFBQlfVBQUFIS0uzaB9z5sxBaGholYBU2dKlS+Ht7W1awsLCGl1uIiIiclyyt7lpjDfffBMbN27E1q1b4eLiYnabuXPnIjc317QkJyfbuZRERERkT85yfnhAQACcnJyQnp5eZX16ejqCg4PrfO8///lPvPnmm9izZw969uxZ63Y6nQ46nc4m5SUiIiLHJ2vNjVarRVRUFOLj403rjEYj4uPjERMTU+v7li1bhtdffx07d+5E37597VFUIiIiaiZkrbkBgNmzZ2PSpEno27cv+vfvjxUrVqCgoABTpkwBADzxxBNo3bo1li5dCgB46623MH/+fKxfvx7h4eGmtjkeHh7w8PCQ7XsQERGRY5A93IwfPx6ZmZmYP38+0tLS0KtXL+zcudPUyDgpKQlq9e0Kpg8++AAlJSV4+OGHq+xnwYIFWLhwoT2LTkRERA5I9nFu7I3j3BARETU/zWacGyIiIiJbY7ghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRXGIcLNq1SqEh4fDxcUF0dHROHLkSJ3bf/nll+jSpQtcXFzQo0cPbN++3U4lJSIiIkcne7jZtGkTZs+ejQULFuDYsWOIjIxEXFwcMjIyzG5/6NAhTJgwAU899RSOHz+O0aNHY/To0Th9+rSdS05ERESOSCWEEHIWIDo6Gv369cPKlSsBAEajEWFhYXjhhRfwyiuv1Nh+/PjxKCgowLfffmtad9ddd6FXr15YvXp1vZ+n1+vh7e2N3NxceHl52e6LEBERUZOx5vota81NSUkJjh49itjYWNM6tVqN2NhYJCQkmH1PQkJCle0BIC4urtbti4uLodfrqyxERESkXLKGm6ysLBgMBgQFBVVZHxQUhLS0NLPvSUtLs2r7pUuXwtvb27SEhYXZpvBERETkkGRvc9PU5s6di9zcXNOSnJwsd5GIiIioCTnL+eEBAQFwcnJCenp6lfXp6ekIDg42+57g4GCrttfpdNDpdLYpMBERETk8WcONVqtFVFQU4uPjMXr0aABSg+L4+Hg8//zzZt8TExOD+Ph4zJw507Ru9+7diImJsegzK9pPs+0NERFR81Fx3baoH5SQ2caNG4VOpxOfffaZOHPmjHj22WeFj4+PSEtLE0II8fjjj4tXXnnFtP3BgweFs7Oz+Oc//ynOnj0rFixYIDQajTh16pRFn3f58mUBgAsXLly4cOHSDJfk5OR6r/Wy1twAUtfuzMxMzJ8/H2lpaejVqxd27txpajSclJQEtfp206C7774b69evx6uvvoq//e1v6NixI7Zt24bu3btb9Hl+fn6m/Xp7e9v+C1Gd9Ho9wsLCkJyczK74dsZjLy8ef/nw2MvHlsdeCIG8vDyEhobWu63s49zYG8e5kRePv3x47OXF4y8fHnv5yHXsFd9bioiIiFoWhhsiIiJSlBYXbnQ6HRYsWMDu4TLh8ZcPj728ePzlw2MvH7mOfYtrc0NERETK1uJqboiIiEjZGG6IiIhIURhuiIiISFEYboiIiEhRWly4WbVqFcLDw+Hi4oLo6GgcOXJE7iK1CAsXLoRKpaqydOnSRe5iKdKPP/6IUaNGITQ0FCqVCtu2bavyuhAC8+fPR0hICFxdXREbG4uLFy/KU1iFqe/YT548ucbvwfDhw+UprMIsXboU/fr1g6enJwIDAzF69GicP3++yjZFRUWYPn06/P394eHhgYceeqjGRMxkPUuO/aBBg2qc+1OnTm2yMrWocLNp0ybMnj0bCxYswLFjxxAZGYm4uDhkZGTIXbQWoVu3bkhNTTUtP/30k9xFUqSCggJERkZi1apVZl9ftmwZ/vWvf2H16tU4fPgw3N3dERcXh6KiIjuXVHnqO/YAMHz48Cq/Bxs2bLBjCZXrhx9+wPTp0/Hzzz9j9+7dKC0txbBhw1BQUGDaZtasWfjf//6HL7/8Ej/88ANSUlIwduxYGUutDJYcewB45plnqpz7y5Yta7pCWTvRZXPWv39/MX36dNNzg8EgQkNDxdKlS2UsVcuwYMECERkZKXcxWhwAYuvWrabnRqNRBAcHi3/84x+mdTk5OUKn04kNGzbIUELlqn7shRBi0qRJ4sEHH5SlPC1NRkaGACB++OEHIYR0nms0GvHll1+atjl79qwAIBISEuQqpiJVP/ZCCHHfffeJGTNm2K0MLabmpqSkBEePHkVsbKxpnVqtRmxsLBISEmQsWctx8eJFhIaGon379pg4cSKSkpLkLlKLk5iYiLS0tCq/B97e3oiOjubvgZ3s378fgYGB6Ny5M6ZNm4YbN27IXSRFys3NBXB7suSjR4+itLS0yrnfpUsXtG3blue+jVU/9hW++OILBAQEoHv37pg7dy5u3brVZGWQfVZwe8nKyoLBYDDNNl4hKCgI586dk6lULUd0dDQ+++wzdO7cGampqVi0aBEGDhyI06dPw9PTU+7itRhpaWkAYPb3oOI1ajrDhw/H2LFjERERgcuXL+Nvf/sbRowYgYSEBDg5OcldPMUwGo2YOXMmBgwYgO7duwOQzn2tVgsfH58q2/Lcty1zxx4AHnvsMbRr1w6hoaE4efIk5syZg/Pnz2PLli1NUo4WE25IXiNGjDA97tmzJ6Kjo9GuXTv897//xVNPPSVjyYjs59FHHzU97tGjB3r27Ik77rgD+/fvx/333y9jyZRl+vTpOH36NNv1yaC2Y//ss8+aHvfo0QMhISG4//77cfnyZdxxxx02L0eLuS0VEBAAJyenGi3j09PTERwcLFOpWi4fHx906tQJly5dkrsoLUrFuc7fA8fQvn17BAQE8PfAhp5//nl8++232LdvH9q0aWNaHxwcjJKSEuTk5FTZnue+7dR27M2Jjo4GgCY791tMuNFqtYiKikJ8fLxpndFoRHx8PGJiYmQsWcuUn5+Py5cvIyQkRO6itCgREREIDg6u8nug1+tx+PBh/h7I4Nq1a7hx4wZ/D2xACIHnn38eW7duxd69exEREVHl9aioKGg0mirn/vnz55GUlMRzv5HqO/bmnDhxAgCa7NxvUbelZs+ejUmTJqFv377o378/VqxYgYKCAkyZMkXuoineSy+9hFGjRqFdu3ZISUnBggUL4OTkhAkTJshdNMXJz8+v8tdQYmIiTpw4AT8/P7Rt2xYzZ87E3//+d3Ts2BERERF47bXXEBoaitGjR8tXaIWo69j7+flh0aJFeOihhxAcHIzLly/j5ZdfRocOHRAXFydjqZVh+vTpWL9+Pb7++mt4enqa2tF4e3vD1dUV3t7eeOqppzB79mz4+fnBy8sLL7zwAmJiYnDXXXfJXPrmrb5jf/nyZaxfvx4jR46Ev78/Tp48iVmzZuHee+9Fz549m6ZQduuX5SDee+890bZtW6HVakX//v3Fzz//LHeRWoTx48eLkJAQodVqRevWrcX48ePFpUuX5C6WIu3bt08AqLFMmjRJCCF1B3/ttddEUFCQ0Ol04v777xfnz5+Xt9AKUdexv3Xrlhg2bJho1aqV0Gg0ol27duKZZ54RaWlpchdbEcwddwDi008/NW1TWFgonnvuOeHr6yvc3NzEmDFjRGpqqnyFVoj6jn1SUpK49957hZ+fn9DpdKJDhw7ir3/9q8jNzW2yMqnKC0ZERESkCC2mzQ0RERG1DAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3RNTiqVQqbNu2Te5iEJGNMNwQkawmT54MlUpVYxk+fLjcRSOiZqpFzS1FRI5p+PDh+PTTT6us0+l0MpWGiJo71twQkex0Oh2Cg4OrLL6+vgCkW0YffPABRowYAVdXV7Rv3x6bN2+u8v5Tp05hyJAhcHV1hb+/P5599lnk5+dX2Wbt2rXo1q0bdDodQkJC8Pzzz1d5PSsrC2PGjIGbmxs6duyIb775pmm/NBE1GYYbInJ4r732Gh566CH89ttvmDhxIh599FGcPXsWAFBQUIC4uDj4+vril19+wZdffok9e/ZUCS8ffPABpk+fjmeffRanTp3CN998gw4dOlT5jEWLFmHcuHE4efIkRo4ciYkTJyI7O9uu35OIbKTJpuQkIrLApEmThJOTk3B3d6+yvPHGG0IIacbhqVOnVnlPdHS0mDZtmhBCiI8++kj4+vqK/Px80+vfffedUKvVphm3Q0NDxbx582otAwDx6quvmp7n5+cLAGLHjh02+55EZD9sc0NEshs8eDA++OCDKuv8/PxMj2NiYqq8FhMTgxMnTgAAzp49i8jISLi7u5teHzBgAIxGI86fPw+VSoWUlBTcf//9dZahZ8+epsfu7u7w8vJCRkZGQ78SEcmI4YaIZOfu7l7jNpGtuLq6WrSdRqOp8lylUsFoNDZFkYioibHNDRE5vJ9//rnG865duwIAunbtit9++w0FBQWm1w8ePAi1Wo3OnTvD09MT4eHhiI+Pt2uZiUg+rLkhItkVFxcjLS2tyjpnZ2cEBAQAAL788kv07dsX99xzD7744gscOXIEa9asAQBMnDgRCxYswKRJk7Bw4UJkZmbihRdewOOPP46goCAAwMKFCzF16lQEBgZixIgRyMvLw8GDB/HCCy/Y94sSkV0w3BCR7Hbu3ImQkJAq6zp37oxz584BkHoybdy4Ec899xxCQkKwYcMG3HnnnQAANzc37Nq1CzNmzEC/fv3g5uaGhx56CMuXLzfta9KkSSgqKsI777yDl156CQEBAXj44Yft9wWJyK5UQgghdyGIiGqjUqmwdetWjB49Wu6iEFEzwTY3REREpCgMN0RERKQobHNDRA6Nd86JyFqsuSEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkVhuCEiIiJFYbghIiIiRWG4ISIiIkX5/0Ho9jXawvFVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: SST\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'SST'\n",
    "N_EPOCHS = 16\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13772, 100])\n",
      "13772\n",
      "13772\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "# print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 5、池化 ================\n",
    "\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2\n",
    "    \n",
    "# ===================== 02 Model_best_copy8672_cnn_diagonal =====================\n",
    "\n",
    "# print(\"Model_best_copy8672_cnn_diagonal\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim-2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、取对角线 ================\n",
    "#         diagonal_elements_real = Conv_real[:, 0, torch.arange(Conv_real.size(2)), torch.arange(Conv_real.size(3))]\n",
    "#         diagonal_elements_imag = Conv_imag[:, 0, torch.arange(Conv_imag.size(2)), torch.arange(Conv_imag.size(3))]\n",
    "\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== 03 Model_best_copy8672_diagonal =====================\n",
    "# print(\"Model_best_copy8672_diagonal\")\n",
    "    \n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、取对角线 ================\n",
    "#         diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "#         diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 5、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_best_copy8672_maxpooling\n"
     ]
    }
   ],
   "source": [
    "# ===================== 04 Model_best_copy8672_maxpooling =====================\n",
    "print(\"Model_best_copy8672_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、池化 ================\n",
    "        # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "        # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 5、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_is_sentiment = self.phase_embedding(text)\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.self_attention2(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(MatrixReal))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(MatrixImag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,752,821 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 1m 3s\n",
      "\t Train Loss: 0.402 | Train Acc: 81.61%\n",
      "\t test  Loss: 0.380 | test  Acc: 83.14%\n",
      "\t best  test acc: 83.14%\n",
      "Epoch: 02 | Epoch Time: 1m 2s\n",
      "\t Train Loss: 0.209 | Train Acc: 92.09%\n",
      "\t test  Loss: 0.408 | test  Acc: 84.79%\n",
      "\t best  test acc: 84.79%\n",
      "Epoch: 03 | Epoch Time: 1m 2s\n",
      "\t Train Loss: 0.154 | Train Acc: 94.39%\n",
      "\t test  Loss: 0.404 | test  Acc: 84.29%\n",
      "\t best  test acc: 84.79%\n",
      "Epoch: 04 | Epoch Time: 1m 3s\n",
      "\t Train Loss: 0.121 | Train Acc: 95.59%\n",
      "\t test  Loss: 0.440 | test  Acc: 84.51%\n",
      "\t best  test acc: 84.79%\n",
      "Epoch: 05 | Epoch Time: 1m 2s\n",
      "\t Train Loss: 0.098 | Train Acc: 96.48%\n",
      "\t test  Loss: 0.482 | test  Acc: 82.83%\n",
      "\t best  test acc: 84.79%\n",
      "Epoch: 06 | Epoch Time: 1m 4s\n",
      "\t Train Loss: 0.083 | Train Acc: 96.98%\n",
      "\t test  Loss: 0.624 | test  Acc: 83.86%\n",
      "\t best  test acc: 84.79%\n",
      "Epoch: 07 | Epoch Time: 1m 3s\n",
      "\t Train Loss: 0.075 | Train Acc: 97.20%\n",
      "\t test  Loss: 0.564 | test  Acc: 83.09%\n",
      "\t best  test acc: 84.79%\n",
      "Epoch: 08 | Epoch Time: 1m 2s\n",
      "\t Train Loss: 0.066 | Train Acc: 97.60%\n",
      "\t test  Loss: 0.640 | test  Acc: 82.81%\n",
      "\t best  test acc: 84.79%\n",
      "Epoch: 09 | Epoch Time: 1m 3s\n",
      "\t Train Loss: 0.061 | Train Acc: 97.77%\n",
      "\t test  Loss: 0.639 | test  Acc: 83.09%\n",
      "\t best  test acc: 84.79%\n",
      "Epoch: 10 | Epoch Time: 1m 3s\n",
      "\t Train Loss: 0.055 | Train Acc: 98.06%\n",
      "\t test  Loss: 0.617 | test  Acc: 82.32%\n",
      "\t best  test acc: 84.79%\n",
      "Epoch: 11 | Epoch Time: 1m 2s\n",
      "\t Train Loss: 0.050 | Train Acc: 98.14%\n",
      "\t test  Loss: 0.725 | test  Acc: 83.14%\n",
      "\t best  test acc: 84.79%\n",
      "Epoch: 12 | Epoch Time: 1m 6s\n",
      "\t Train Loss: 0.048 | Train Acc: 98.18%\n",
      "\t test  Loss: 0.722 | test  Acc: 83.43%\n",
      "\t best  test acc: 84.79%\n",
      "Epoch: 13 | Epoch Time: 1m 3s\n",
      "\t Train Loss: 0.046 | Train Acc: 98.27%\n",
      "\t test  Loss: 0.714 | test  Acc: 82.27%\n",
      "\t best  test acc: 84.79%\n",
      "Epoch: 14 | Epoch Time: 1m 4s\n",
      "\t Train Loss: 0.041 | Train Acc: 98.46%\n",
      "\t test  Loss: 0.799 | test  Acc: 81.77%\n",
      "\t best  test acc: 84.79%\n",
      "Epoch: 15 | Epoch Time: 1m 4s\n",
      "\t Train Loss: 0.039 | Train Acc: 98.49%\n",
      "\t test  Loss: 0.850 | test  Acc: 81.33%\n",
      "\t best  test acc: 84.79%\n",
      "Epoch: 16 | Epoch Time: 1m 4s\n",
      "\t Train Loss: 0.035 | Train Acc: 98.63%\n",
      "\t test  Loss: 0.859 | test  Acc: 81.72%\n",
      "\t best  test acc: 84.79%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: SUBJ\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'SUBJ'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18512, 100])\n",
      "18512\n",
      "18512\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "# print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 5、池化 ================\n",
    "\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2\n",
    "    \n",
    "# ===================== 02 Model_best_copy8672_cnn_diagonal =====================\n",
    "\n",
    "# print(\"Model_best_copy8672_cnn_diagonal\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim-2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、取对角线 ================\n",
    "#         diagonal_elements_real = Conv_real[:, 0, torch.arange(Conv_real.size(2)), torch.arange(Conv_real.size(3))]\n",
    "#         diagonal_elements_imag = Conv_imag[:, 0, torch.arange(Conv_imag.size(2)), torch.arange(Conv_imag.size(3))]\n",
    "\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== 03 Model_best_copy8672_diagonal =====================\n",
    "# print(\"Model_best_copy8672_diagonal\")\n",
    "    \n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、取对角线 ================\n",
    "#         diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "#         diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 5、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_best_copy8672_maxpooling\n"
     ]
    }
   ],
   "source": [
    "# ===================== 04 Model_best_copy8672_maxpooling =====================\n",
    "print(\"Model_best_copy8672_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、池化 ================\n",
    "        # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "        # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 5、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_is_sentiment = self.phase_embedding(text)\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.self_attention2(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(MatrixReal))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(MatrixImag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 2,226,821 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.492 | Train Acc: 79.29%\n",
      "\t test  Loss: 0.344 | test  Acc: 87.40%\n",
      "\t best  test acc: 87.40%\n",
      "Epoch: 02 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.229 | Train Acc: 93.12%\n",
      "\t test  Loss: 0.280 | test  Acc: 90.18%\n",
      "\t best  test acc: 90.18%\n",
      "Epoch: 03 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.148 | Train Acc: 95.97%\n",
      "\t test  Loss: 0.245 | test  Acc: 91.96%\n",
      "\t best  test acc: 91.96%\n",
      "Epoch: 04 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.099 | Train Acc: 97.58%\n",
      "\t test  Loss: 0.257 | test  Acc: 91.47%\n",
      "\t best  test acc: 91.96%\n",
      "Epoch: 05 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.067 | Train Acc: 98.59%\n",
      "\t test  Loss: 0.281 | test  Acc: 92.26%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 06 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.057 | Train Acc: 98.89%\n",
      "\t test  Loss: 0.351 | test  Acc: 91.07%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 07 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.057 | Train Acc: 98.75%\n",
      "\t test  Loss: 0.333 | test  Acc: 91.17%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 08 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.041 | Train Acc: 99.26%\n",
      "\t test  Loss: 0.355 | test  Acc: 91.57%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 09 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.044 | Train Acc: 99.14%\n",
      "\t test  Loss: 0.391 | test  Acc: 91.27%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 10 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.041 | Train Acc: 99.25%\n",
      "\t test  Loss: 0.389 | test  Acc: 91.17%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 11 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.053 | Train Acc: 98.95%\n",
      "\t test  Loss: 0.301 | test  Acc: 89.58%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 12 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.043 | Train Acc: 99.12%\n",
      "\t test  Loss: 0.533 | test  Acc: 88.59%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 13 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.041 | Train Acc: 99.24%\n",
      "\t test  Loss: 0.495 | test  Acc: 88.49%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 14 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.043 | Train Acc: 99.16%\n",
      "\t test  Loss: 0.560 | test  Acc: 88.69%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 15 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.036 | Train Acc: 99.35%\n",
      "\t test  Loss: 0.362 | test  Acc: 91.96%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 16 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.031 | Train Acc: 99.46%\n",
      "\t test  Loss: 0.426 | test  Acc: 90.87%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.036 | Train Acc: 99.29%\n",
      "\t test  Loss: 0.410 | test  Acc: 90.87%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 18 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.032 | Train Acc: 99.39%\n",
      "\t test  Loss: 0.435 | test  Acc: 90.58%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 19 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.033 | Train Acc: 99.38%\n",
      "\t test  Loss: 0.391 | test  Acc: 90.38%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 20 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.030 | Train Acc: 99.35%\n",
      "\t test  Loss: 0.433 | test  Acc: 90.87%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 21 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.027 | Train Acc: 99.35%\n",
      "\t test  Loss: 0.489 | test  Acc: 90.58%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 22 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.019 | Train Acc: 99.55%\n",
      "\t test  Loss: 0.501 | test  Acc: 89.58%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 23 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.031 | Train Acc: 99.30%\n",
      "\t test  Loss: 0.406 | test  Acc: 90.87%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 24 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.018 | Train Acc: 99.59%\n",
      "\t test  Loss: 0.549 | test  Acc: 90.08%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 25 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.013 | Train Acc: 99.74%\n",
      "\t test  Loss: 0.544 | test  Acc: 90.08%\n",
      "\t best  test acc: 92.26%\n",
      "Epoch: 26 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.018 | Train Acc: 99.56%\n",
      "\t test  Loss: 0.518 | test  Acc: 90.38%\n",
      "\t best  test acc: 92.26%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: CR\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'CR'\n",
    "N_EPOCHS = 26\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4749, 100])\n",
      "4749\n",
      "4749\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "# print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 5、池化 ================\n",
    "\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2\n",
    "    \n",
    "# ===================== 02 Model_best_copy8672_cnn_diagonal =====================\n",
    "\n",
    "# print(\"Model_best_copy8672_cnn_diagonal\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim-2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、取对角线 ================\n",
    "#         diagonal_elements_real = Conv_real[:, 0, torch.arange(Conv_real.size(2)), torch.arange(Conv_real.size(3))]\n",
    "#         diagonal_elements_imag = Conv_imag[:, 0, torch.arange(Conv_imag.size(2)), torch.arange(Conv_imag.size(3))]\n",
    "\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== 03 Model_best_copy8672_diagonal =====================\n",
    "# print(\"Model_best_copy8672_diagonal\")\n",
    "    \n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、取对角线 ================\n",
    "#         diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "#         diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 5、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_best_copy8672_maxpooling\n"
     ]
    }
   ],
   "source": [
    "# ===================== 04 Model_best_copy8672_maxpooling =====================\n",
    "print(\"Model_best_copy8672_maxpooling\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、池化 ================\n",
    "        # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "        # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 5、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_is_sentiment = self.phase_embedding(text)\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.self_attention2(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(MatrixReal))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(MatrixImag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 850,521 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.649 | Train Acc: 63.62%\n",
      "\t test  Loss: 0.637 | test  Acc: 64.06%\n",
      "\t best  test acc: 64.06%\n",
      "Epoch: 02 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.632 | Train Acc: 63.72%\n",
      "\t test  Loss: 0.629 | test  Acc: 64.06%\n",
      "\t best  test acc: 64.06%\n",
      "Epoch: 03 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.616 | Train Acc: 64.88%\n",
      "\t test  Loss: 0.618 | test  Acc: 64.06%\n",
      "\t best  test acc: 64.06%\n",
      "Epoch: 04 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.613 | Train Acc: 64.35%\n",
      "\t test  Loss: 0.612 | test  Acc: 64.06%\n",
      "\t best  test acc: 64.06%\n",
      "Epoch: 05 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.610 | Train Acc: 64.29%\n",
      "\t test  Loss: 0.619 | test  Acc: 64.06%\n",
      "\t best  test acc: 64.06%\n",
      "Epoch: 06 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.570 | Train Acc: 70.50%\n",
      "\t test  Loss: 0.528 | test  Acc: 76.30%\n",
      "\t best  test acc: 76.30%\n",
      "Epoch: 07 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.453 | Train Acc: 81.98%\n",
      "\t test  Loss: 0.474 | test  Acc: 78.12%\n",
      "\t best  test acc: 78.12%\n",
      "Epoch: 08 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.347 | Train Acc: 87.37%\n",
      "\t test  Loss: 0.449 | test  Acc: 81.25%\n",
      "\t best  test acc: 81.25%\n",
      "Epoch: 09 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.274 | Train Acc: 90.84%\n",
      "\t test  Loss: 0.459 | test  Acc: 80.73%\n",
      "\t best  test acc: 81.25%\n",
      "Epoch: 10 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.227 | Train Acc: 92.76%\n",
      "\t test  Loss: 0.446 | test  Acc: 84.11%\n",
      "\t best  test acc: 84.11%\n",
      "Epoch: 11 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.185 | Train Acc: 94.35%\n",
      "\t test  Loss: 0.449 | test  Acc: 84.64%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 12 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.151 | Train Acc: 95.80%\n",
      "\t test  Loss: 0.510 | test  Acc: 80.99%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 13 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.130 | Train Acc: 96.76%\n",
      "\t test  Loss: 0.530 | test  Acc: 82.29%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 14 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.118 | Train Acc: 96.96%\n",
      "\t test  Loss: 0.549 | test  Acc: 81.77%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 15 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.113 | Train Acc: 97.19%\n",
      "\t test  Loss: 0.595 | test  Acc: 81.77%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 16 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.099 | Train Acc: 97.62%\n",
      "\t test  Loss: 0.582 | test  Acc: 82.81%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 17 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.089 | Train Acc: 97.98%\n",
      "\t test  Loss: 0.620 | test  Acc: 82.03%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 18 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.084 | Train Acc: 98.05%\n",
      "\t test  Loss: 0.668 | test  Acc: 81.51%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 19 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.077 | Train Acc: 98.31%\n",
      "\t test  Loss: 0.613 | test  Acc: 82.81%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 20 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.077 | Train Acc: 98.28%\n",
      "\t test  Loss: 0.651 | test  Acc: 81.51%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 21 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.087 | Train Acc: 97.88%\n",
      "\t test  Loss: 0.637 | test  Acc: 81.25%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 22 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.067 | Train Acc: 98.48%\n",
      "\t test  Loss: 0.655 | test  Acc: 82.29%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 23 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.070 | Train Acc: 98.38%\n",
      "\t test  Loss: 0.823 | test  Acc: 79.17%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 24 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.067 | Train Acc: 98.41%\n",
      "\t test  Loss: 0.720 | test  Acc: 81.25%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 25 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.060 | Train Acc: 98.74%\n",
      "\t test  Loss: 0.731 | test  Acc: 81.51%\n",
      "\t best  test acc: 84.64%\n",
      "Epoch: 26 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.060 | Train Acc: 98.71%\n",
      "\t test  Loss: 0.748 | test  Acc: 81.51%\n",
      "\t best  test acc: 84.64%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
