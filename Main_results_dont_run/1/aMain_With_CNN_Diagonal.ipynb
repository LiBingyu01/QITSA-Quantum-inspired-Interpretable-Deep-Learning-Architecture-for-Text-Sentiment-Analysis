{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'CR'\n",
    "N_EPOCHS = 21\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: CR\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([4749, 100])\n",
      "4749\n",
      "4749\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "# print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 5、池化 ================\n",
    "\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2\n",
    "    \n",
    "# ===================== 02 Model_best_copy8672_cnn_diagonal =====================\n",
    "\n",
    "print(\"Model_best_copy8672_cnn_diagonal\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim-2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_is_sentiment = self.phase_embedding(text)\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.self_attention2(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、取对角线 ================\n",
    "        diagonal_elements_real = Conv_real[:, 0, torch.arange(Conv_real.size(2)), torch.arange(Conv_real.size(3))]\n",
    "        diagonal_elements_imag = Conv_imag[:, 0, torch.arange(Conv_imag.size(2)), torch.arange(Conv_imag.size(3))]\n",
    "\n",
    "        diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "        diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "        fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "        fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "        return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_diagonal\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "source": [
    "# ===================== 03 Model_best_copy8672_diagonal =====================\n",
    "# print(\"Model_best_copy8672_diagonal\")\n",
    "    \n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、取对角线 ================\n",
    "#         diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "#         diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 5、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "source": [
    "# ===================== 04 Model_best_copy8672_maxpooling =====================\n",
    "# print(\"Model_best_copy8672_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、池化 ================\n",
    "#         # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 5、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(MatrixReal))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(MatrixImag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 850,501 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.622 | Train Acc: 66.70%\n",
      "\t test  Loss: 0.618 | test  Acc: 65.62%\n",
      "\t best  test acc: 65.62%\n",
      "Epoch: 02 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.583 | Train Acc: 69.05%\n",
      "\t test  Loss: 0.603 | test  Acc: 65.10%\n",
      "\t best  test acc: 65.62%\n",
      "Epoch: 03 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.568 | Train Acc: 70.67%\n",
      "\t test  Loss: 0.591 | test  Acc: 66.15%\n",
      "\t best  test acc: 66.15%\n",
      "Epoch: 04 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.563 | Train Acc: 71.16%\n",
      "\t test  Loss: 0.577 | test  Acc: 69.27%\n",
      "\t best  test acc: 69.27%\n",
      "Epoch: 05 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.564 | Train Acc: 70.11%\n",
      "\t test  Loss: 0.590 | test  Acc: 68.49%\n",
      "\t best  test acc: 69.27%\n",
      "Epoch: 06 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.564 | Train Acc: 71.26%\n",
      "\t test  Loss: 0.571 | test  Acc: 69.27%\n",
      "\t best  test acc: 69.27%\n",
      "Epoch: 07 | Epoch Time: 0m 4s\n",
      "\t Train Loss: 0.551 | Train Acc: 71.79%\n",
      "\t test  Loss: 0.553 | test  Acc: 70.31%\n",
      "\t best  test acc: 70.31%\n",
      "Epoch: 08 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.482 | Train Acc: 78.41%\n",
      "\t test  Loss: 0.422 | test  Acc: 83.33%\n",
      "\t best  test acc: 83.33%\n",
      "Epoch: 09 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.355 | Train Acc: 86.81%\n",
      "\t test  Loss: 0.411 | test  Acc: 82.55%\n",
      "\t best  test acc: 83.33%\n",
      "Epoch: 10 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.266 | Train Acc: 91.57%\n",
      "\t test  Loss: 0.390 | test  Acc: 83.85%\n",
      "\t best  test acc: 83.85%\n",
      "Epoch: 11 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.216 | Train Acc: 93.62%\n",
      "\t test  Loss: 0.396 | test  Acc: 85.68%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 12 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.164 | Train Acc: 95.77%\n",
      "\t test  Loss: 0.459 | test  Acc: 83.59%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 13 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.134 | Train Acc: 97.06%\n",
      "\t test  Loss: 0.517 | test  Acc: 82.29%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 14 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.114 | Train Acc: 97.45%\n",
      "\t test  Loss: 0.531 | test  Acc: 83.85%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 15 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.103 | Train Acc: 97.85%\n",
      "\t test  Loss: 0.490 | test  Acc: 85.42%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 16 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.096 | Train Acc: 98.05%\n",
      "\t test  Loss: 0.562 | test  Acc: 83.07%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 17 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.093 | Train Acc: 98.08%\n",
      "\t test  Loss: 0.589 | test  Acc: 83.85%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 18 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.104 | Train Acc: 97.52%\n",
      "\t test  Loss: 0.546 | test  Acc: 83.33%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 19 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.088 | Train Acc: 98.18%\n",
      "\t test  Loss: 0.554 | test  Acc: 84.38%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 20 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.085 | Train Acc: 98.18%\n",
      "\t test  Loss: 0.511 | test  Acc: 85.68%\n",
      "\t best  test acc: 85.68%\n",
      "Epoch: 21 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.079 | Train Acc: 98.41%\n",
      "\t test  Loss: 0.528 | test  Acc: 85.42%\n",
      "\t best  test acc: 85.68%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MR'\n",
    "N_EPOCHS = 21\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MR\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([16143, 100])\n",
      "16143\n",
      "16143\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "# print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 5、池化 ================\n",
    "\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2\n",
    "    \n",
    "# ===================== 02 Model_best_copy8672_cnn_diagonal =====================\n",
    "\n",
    "print(\"Model_best_copy8672_cnn_diagonal\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim-2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_is_sentiment = self.phase_embedding(text)\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.self_attention2(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、取对角线 ================\n",
    "        diagonal_elements_real = Conv_real[:, 0, torch.arange(Conv_real.size(2)), torch.arange(Conv_real.size(3))]\n",
    "        diagonal_elements_imag = Conv_imag[:, 0, torch.arange(Conv_imag.size(2)), torch.arange(Conv_imag.size(3))]\n",
    "\n",
    "        diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "        diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "        fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "        fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "        return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_diagonal\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "source": [
    "# ===================== 03 Model_best_copy8672_diagonal =====================\n",
    "# print(\"Model_best_copy8672_diagonal\")\n",
    "    \n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、取对角线 ================\n",
    "#         diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "#         diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 5、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "source": [
    "# ===================== 04 Model_best_copy8672_maxpooling =====================\n",
    "# print(\"Model_best_copy8672_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、池化 ================\n",
    "#         # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 5、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(MatrixReal))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(MatrixImag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 1,989,901 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.679 | Train Acc: 57.12%\n",
      "\t test  Loss: 0.688 | test  Acc: 53.99%\n",
      "\t best  test acc: 53.99%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.676 | Train Acc: 57.62%\n",
      "\t test  Loss: 0.671 | test  Acc: 58.24%\n",
      "\t best  test acc: 58.24%\n",
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.615 | Train Acc: 66.25%\n",
      "\t test  Loss: 0.518 | test  Acc: 76.98%\n",
      "\t best  test acc: 76.98%\n",
      "Epoch: 04 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.389 | Train Acc: 84.62%\n",
      "\t test  Loss: 0.502 | test  Acc: 78.52%\n",
      "\t best  test acc: 78.52%\n",
      "Epoch: 05 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.234 | Train Acc: 92.30%\n",
      "\t test  Loss: 0.601 | test  Acc: 76.55%\n",
      "\t best  test acc: 78.52%\n",
      "Epoch: 06 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.145 | Train Acc: 96.00%\n",
      "\t test  Loss: 0.649 | test  Acc: 76.75%\n",
      "\t best  test acc: 78.52%\n",
      "Epoch: 07 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.095 | Train Acc: 97.94%\n",
      "\t test  Loss: 0.727 | test  Acc: 76.37%\n",
      "\t best  test acc: 78.52%\n",
      "Epoch: 08 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.079 | Train Acc: 98.27%\n",
      "\t test  Loss: 0.798 | test  Acc: 76.27%\n",
      "\t best  test acc: 78.52%\n",
      "Epoch: 09 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.070 | Train Acc: 98.53%\n",
      "\t test  Loss: 0.876 | test  Acc: 76.47%\n",
      "\t best  test acc: 78.52%\n",
      "Epoch: 10 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.062 | Train Acc: 98.77%\n",
      "\t test  Loss: 0.909 | test  Acc: 76.04%\n",
      "\t best  test acc: 78.52%\n",
      "Epoch: 11 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.053 | Train Acc: 98.99%\n",
      "\t test  Loss: 0.956 | test  Acc: 75.16%\n",
      "\t best  test acc: 78.52%\n",
      "Epoch: 12 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.047 | Train Acc: 99.08%\n",
      "\t test  Loss: 1.013 | test  Acc: 75.72%\n",
      "\t best  test acc: 78.52%\n",
      "Epoch: 13 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.041 | Train Acc: 99.23%\n",
      "\t test  Loss: 1.029 | test  Acc: 75.16%\n",
      "\t best  test acc: 78.52%\n",
      "Epoch: 14 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.041 | Train Acc: 99.18%\n",
      "\t test  Loss: 1.134 | test  Acc: 74.41%\n",
      "\t best  test acc: 78.52%\n",
      "Epoch: 15 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.038 | Train Acc: 99.30%\n",
      "\t test  Loss: 1.188 | test  Acc: 75.06%\n",
      "\t best  test acc: 78.52%\n",
      "Epoch: 16 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.038 | Train Acc: 99.29%\n",
      "\t test  Loss: 1.222 | test  Acc: 73.48%\n",
      "\t best  test acc: 78.52%\n",
      "Epoch: 17 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.032 | Train Acc: 99.49%\n",
      "\t test  Loss: 1.209 | test  Acc: 73.63%\n",
      "\t best  test acc: 78.52%\n",
      "Epoch: 18 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.034 | Train Acc: 99.36%\n",
      "\t test  Loss: 1.122 | test  Acc: 75.16%\n",
      "\t best  test acc: 78.52%\n",
      "Epoch: 19 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.032 | Train Acc: 99.43%\n",
      "\t test  Loss: 1.127 | test  Acc: 74.93%\n",
      "\t best  test acc: 78.52%\n",
      "Epoch: 20 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.030 | Train Acc: 99.50%\n",
      "\t test  Loss: 1.214 | test  Acc: 74.23%\n",
      "\t best  test acc: 78.52%\n",
      "Epoch: 21 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.026 | Train Acc: 99.56%\n",
      "\t test  Loss: 1.213 | test  Acc: 74.14%\n",
      "\t best  test acc: 78.52%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABUbElEQVR4nO3deXwTZeIG8GeSJundAqUXFArIfYNQC4tntYILAiqILAKeIB7IsgusCoi/FU+EFYRdFdDd5RAEREFYKIcIFRRQQRFQCy3QE3ofSZu8vz+mCU3PpM05fb6fz3yaTGbevNMh5On7vjOvJIQQICIiIlIIlbsrQERERORIDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQobg03X331FUaOHIno6GhIkoRt27Y1uM+BAwcwYMAA6HQ63HDDDVi7dq3T60lERETew63hpri4GH379sWKFSts2j4lJQX33HMPbrvtNnz//feYOXMmHnvsMezevdvJNSUiIiJvIXnKxJmSJGHr1q0YPXp0ndvMmTMHO3bswOnTpy3rHnzwQeTl5WHXrl0uqCURERF5Oh93V8AeycnJSEhIsFqXmJiImTNn1rmPXq+HXq+3PDeZTLh27RpatWoFSZKcVVUiIiJyICEECgsLER0dDZWq/o4nrwo3GRkZiIiIsFoXERGBgoIClJaWws/Pr8Y+ixcvxssvv+yqKhIREZETpaWloW3btvVu41XhpjHmzZuHWbNmWZ7n5+ejXbt2SEtLQ3BwsBtrRlTJaASOHAEyMoDISGDIEECt9vyyt28H5swBrly5vi46Gnj9dWDUqKaXPWlS3a//+9+Nfw9nll1RAfTqBaSn171NVBSQnAxoNIBKdX2RJOvH1RmNctlVf9/VtWkDnDgBCAGUl8v1qaiQH5eXy2WY11d/Xa8HnngCuHat7vJbtADeeMO6jnX9rL7OaASefx7Iza27/OBg4KmnAIMBKCuT62Reysqur6v602AA8vPrr7eZvz/g5yf/7mtbfHxqX5+bCxw61HD5t98OhIUBJpN8vObF/LzqevPj3Fzgl18aLjssTK5LQ+UZjfL59zRffAEMG9akIgoKChATE4OgoKAGt/WqcBMZGYnMzEyrdZmZmQgODq611QYAdDoddDpdjfXBwcEMN+R+W7YAzz0HXLp0fV3btsCyZcDYsZ5d9sMP1/xPND1dXr95s33vIcT1L6uiIuAvf6l/++efl7+kAPnL2fyfetXHtT03GIC33qq/7CefBD77TP7CNxjsW6p0gdcpPR2IjW14u+rBRwj5Pepz+TJQrXXboXJzgccfd175BQXAa685r/ySEnlxln37nFd2To7zygYAnQ7QauU/fqr+26v6vLbHhYXW/8fUpaBADq8OYMuQEq8KN/Hx8di5c6fVuj179iA+Pt5NNaJmwWiU/2pLT5f/6h42zDGtH1u2APffXzMgXL4sr7c3IDiybPMXaUkJUFp6/UuhpEQOH08+Wftfh+Z1kyfLLSTmwFJaar1UX1dWZt9fmzk58nE4Q0mJ/PtxN5NJXhyhequE+XHVdYWFQFpaw2X16AGEh8uPzees+s/a1mVlAefPN1z+HXfILVS+vtcXnc76efXl9Gm51akhH30EDBhwvSXLHGCrPq++GAzAzz8DtlzV++STQJcu17/8qy51rTtzBpg/v+GyV64EBg9uuLzq6w4fBv74x4bL37ULuPXWhrer7sAB4LbbGt4uKsr+spvArVdLFRUV4ddffwUA9O/fH0uWLMFtt92Gli1bol27dpg3bx4uX76Mjz/+GIB8KXivXr0wY8YMPPLII9i3bx+effZZ7NixA4mJiTa9Z0FBAUJCQpCfn8+WG2qYs1o/jEb5r/e6/uKRJPl9UlJqBimjUf4CLi62Dh3m50VFwPTp9Tf/+/kBf/jD9XBRtRzzc0d9sdrL3ErRkM6d5a62qv+R+/jU//ziRWD//obLnjxZ7sLTam1fdDrg22+B++5ruPzdu+Xfv8kkH6s5yFRdqq8/cgSYMKHhsrdvl7+kzOFFra69m6s6W7+k9u937pdgY8o3f54uX6793059nyd3l+/NdXdF+VXY9f0t3Gj//v0CQI1l8uTJQgghJk+eLG655ZYa+/Tr109otVrRsWNHsWbNGrveMz8/XwAQ+fn5jjkIUq5PPxVCkoSQP7LXF0mSl08/rX//igohcnOFSE0V4qefhPjmGyH27BFiyxYh5s6tWW5tS6dOQnTuLESbNkKEhgqh1dq2nyMXtVqIoCAhIiKE6NBBrost+40fL8Q77wixapUQH30kxCefCLF9u/w7+PprIY4fF+Lnn4VISREiPV2IvDwh9Hoh9u2zrfz9++0/p/v3O69s8zlv27b2fzfmfzsxMfJ2nlS2Eso3f16rl2/r59Wd5Xtz3V1RfiV7vr895j43rsKWG7JJQy0rABAQAIwYIbeYFBbWXEpLnVtHSZIHSPr7y3UxPy4qsm2A4vTpcheAn9/1fc0DLqs+12is93P2X/je/FcycL1LELB+D3PriSO6G51RtgLKN27divLXXgOqjs2MigLmzQPuuqvR5Vr873/Aq6/KA/QdXb4zy/ai8rVabZ2Xedvz/c1wQ1SbHTts66e2hVYLBAVZL+XlchdGQ954Q+4eqRo2zGFGp6u9u8Gbw4eZNwcE83tU786MiQGWLvXssr20fCEEMjIykJeXJ59TvV7+d6pW1/05aSxnlu/NdXdQ+SqVCh06dIBWq63xGsNNPRhuqE4XLgCffy4v+/bJH9CGTJokB4Tq4SUoSL4yIChIDjfVsXXCtvfw1oAAOG8gurPL9sLy09PTkZeXh/DwcPj7+/MGrV7KZDLhypUr0Gg0aNeuXY3zyHBTD4YbsjCZgGPH5DCzfbt8xYW9Gtv6AbB1whbeHBDIJYxGI86dO4fw8HC0atXK3dWhJsrPz8eVK1dwww03QFOtS5zhph4MNwpl6xdVURGwZ48caHbskC9PNVOp5CtYRo6Ux9IkJjr/CgC2ThA1SVlZGVJSUhAbG1vn/c7Ie5SWluLChQvo0KEDfH19rV6z5/vbq+5zQ1Srhi7XTku73t20f7/1jdaCg4G775YDzfDhQNW//JYtk1s/ql+abG79WLq06V/kY8cC997rnIDgzLLN1OrGt1wRORC7opTBUeeR4Ya8W103q7t0Sb7fSPv28r1NqurYUQ4zI0fKX/a1jYkB5HCweXPtwcmRrR/ODAgMH0TUDDHckPcyGuXgUV/P6sWLckvLkCHXA0337raP4HdF6wcRURPFxsZi5syZmDlzZpPLOnDgAG677Tbk5uYiNDS0yeW5A8MNea9Dh2yb02TLFmD06Ma/D1s/iJoHF48hu/XWW9GvXz8sXbq0yWV9++23CAgIaHqlFILhhrzX99/btp2zb6ZHRN7PmRPNNpIQAkajET4+DX9Vt27d2gU18h613waQyJMVFAB//WvDM0ebuXjCNiLyMuaxe9Vbgs0TzW7Z4vC3nDJlCg4ePIhly5ZBkiRIkoS1a9dCkiR8+eWXGDhwIHQ6Hb7++mv89ttvuPfeexEREYHAwEAMGjQIe/futSovNjbWqgVIkiR88MEHGDNmDPz9/dG5c2ds37690fX99NNP0bNnT+h0OsTGxuLtt9+2ev29995D586d4evri4iICNxfZWLbzZs3o3fv3vDz80OrVq2QkJCA4uLiRtfFFgw35D2MRuCDD+QJE998E6ioqP8OmJIkX/o8bJhr60lE7iWEPC2KLUtBAfDss7WP3TOve+45eTtbyrPx7irLli1DfHw8Hn/8caSnpyM9PR0xMTEAgLlz5+K1117DmTNn0KdPHxQVFWHEiBFISkrCyZMncffdd2PkyJFITU2t9z1efvlljBs3Dj/++CNGjBiBiRMn4tq1a3b9KgHg+PHjGDduHB588EGcOnUKCxcuxEsvvYS1a9cCAL777js8++yzWLRoEc6ePYtdu3bh5ptvBiDfYHHChAl45JFHcObMGRw4cABjx46F0+9C45DZrLwIJ870UgcOCNGv3/UJ2bp0EeKLL4TYvNklE7YRkWcqLS0VP//8sygtLb2+sqjIdRPLVl+Kimyu+y233CKee+45y3PzZNLbtm1rcN+ePXuKd9991/K8ffv24p133rE8ByBefPHFKr+SIgFAfPnllw2Wba5Hbm6uEEKIhx56SNx5551W2/zlL38RPXr0EEII8emnn4rg4GBRUFBQo6zjx48LAOLChQsNvq8QdZzPSvZ8f7PlhjxbSorcLHzrrfIYm5AQYMkS4NQp4J575Mu9N28G2rSx3q9tW8fchZeIyMVuvPFGq+dFRUWYPXs2unfvjtDQUAQGBuLMmTMNttz06dPH8jggIADBwcHIqnrjUhudOXMGQ4cOtVo3dOhQnD9/HkajEXfeeSfat2+Pjh07YtKkSfjvf/+LkpISAEDfvn1xxx13oHfv3njggQfw/vvvIzc31+462IvhhjxTYSHwt7/Jl21/+ql89+Dp04Hz54Hnn7e+N83YsfK8UPv3A+vWyT9TUhhsiJorf3/5buS2LDt32lbmzp22lefv3+TqV7/qafbs2di6dSteffVVHDp0CN9//z169+4Ng8FQbznVpy+QJAkmk6nJ9asuKCgIJ06cwPr16xEVFYX58+ejb9++yMvLg1qtxp49e/Dll1+iR48eePfdd9G1a1ekpKQ4vB5V8Wop8iwmE/DRR3KwyciQ191xB/DOO0Dv3nXvx8u1ichMkgBbL4u+6y65pbehqVbuusvhl4VrtVoYbZig9/Dhw5gyZQrGjBkDQG7JuXDhgkPrUp/u3bvj8OHDNerUpUsXqCt/Jz4+PkhISEBCQgIWLFiA0NBQ7Nu3D2PHjoUkSRg6dCiGDh2K+fPno3379ti6dStmzZrltDoz3JDn+PprYOZM4Phx+XmnTsDbbwOjRtl+0z0iInuo1a6ZaqUWsbGxOHr0KC5cuIDAwMA6W1U6d+6MLVu2YOTIkZAkCS+99JJTWmDq8uc//xmDBg3CK6+8gvHjxyM5ORnLly/He++9BwD44osv8Pvvv+Pmm29GixYtsHPnTphMJnTt2hVHjx5FUlIS7rrrLoSHh+Po0aPIzs5G9+7dnVpndkuRaxiNwIEDwPr18s+qf61cvAiMHy9f1XT8uDzf05tvAj/9JN8dmMGGiJzJPNWKi8fuzZ49G2q1Gj169EDr1q3rHEOzZMkStGjRAkOGDMHIkSORmJiIAQMGOKVOtRkwYAA++eQTbNiwAb169cL8+fOxaNEiTJkyBQAQGhqKLVu24Pbbb0f37t2xatUqrF+/Hj179kRwcDC++uorjBgxAl26dMGLL76It99+G8OHD3dqnTkrODlfXTfHeu014JdfgLfeAsrK5BDz2GPAK68AERHuqy8ReQ3zrOC1zSJtN85y73b1nU/OCk6eo76JLf/0p+vPb71VHlfTr58ra0dEdB3H7ikGu6XIeWyZ2FKtBj75BNi3j8GGiMgFpk2bhsDAwFqXadOmubt6DsGWG3IeWya2NBqB1q05roaIyEUWLVqE2bNn1/qaUoZrMNyQ86SnO3Y7IiJqsvDwcISHh7u7Gk7FbilyHlsnrOTElkRE5EAMN+Q8w4YBYWF1v86JLYmIyAkYbsh5zp6VZ8mtjZNvjkVERM0Xww05R3Y28Mc/AqWl8vxQnNiSiIhchAOKyfH0ejm0pKQAHTsCX30FtGjBm2MREZFLMNyQYwkBPPmkPE9UcDDw+efXx93w5lhERB7jwoUL6NChA06ePIl+CrvPGLulyLHeeEOe1Vulkm/O16OHu2tEROSRbr31VsycOdNh5U2ZMgWjR492WHnejOGGHGfbNmDePPnxsmVAYqJbq0NEZK/vCgpw+/ff47uCAndXhZqA4YYc4+RJYOJEuVvqqaeAp592d42IiOz2cWYm9ufl4d+ZmU59nylTpuDgwYNYtmwZJEmCJEm4cOECTp8+jeHDhyMwMBARERGYNGkScnJyLPtt3rwZvXv3hp+fH1q1aoWEhAQUFxdj4cKF+Oijj/DZZ59Zyjtw4IDd9Tp48CAGDx4MnU6HqKgozJ07FxUVFQ2+PwAcOHAAgwcPRkBAAEJDQzF06FBcvHixyb+rxuCYG2q6K1eAkSOBkhLgzjvlVhsiIjcRQqDEZLJ5+9SyMlwtL4ckSdiQlQUAWJ+VhXHh4RBCoJVGg3Y2zjjur1JBsmE6mWXLluHcuXPo1asXFi1aBADQaDQYPHgwHnvsMbzzzjsoLS3FnDlzMG7cOOzbtw/p6emYMGEC3njjDYwZMwaFhYU4dOgQhBCYPXs2zpw5g4KCAqxZswYA0LJlS5t/BwBw+fJljBgxAlOmTMHHH3+MX375BY8//jh8fX2xcOHCet+/oqICo0ePxuOPP47169fDYDDg2LFjNv0unIHhhpqmpAS4917g8mWgWzd5nI0P/1kRkfuUmEwIPHSoSWVkl5fjDydP2r1f0bBhCLDhStCQkBBotVr4+/sjMjISAPB///d/6N+/P1599VXLdqtXr0ZMTAzOnTuHoqIiVFRUYOzYsWjfvj0AoHfv3pZt/fz8oNfrLeXZ67333kNMTAyWL18OSZLQrVs3XLlyBXPmzMH8+fORnp5e5/tfu3YN+fn5+OMf/4hOnToBALp3796oejgCu6Wo8UwmYMoU4LvvgFatgC++AEJD3V0rIiKv9MMPP2D//v1Ws3R369YNAPDbb7+hb9++uOOOO9C7d2888MADeP/995Gbm+uw9z9z5gzi4+OtWluGDh2KoqIiXLp0qd73b9myJaZMmYLExESMHDkSy5YtQ7ob5w3kn9jUeAsXAps2ARoNsGULUJnWiYjcyV+lQpGd07p8X1RUa0vN1/37o19goF3v3VhFRUUYOXIkXn/99RqvRUVFQa1WY8+ePThy5Aj+97//4d1338ULL7yAo0ePokOHDo1+X1s19P5r1qzBs88+i127dmHjxo148cUXsWfPHtx0001Or1t1bLmhxlm3DnjlFfnxP/8J3Hyze+tDRFRJkiQEqNV2LX6VocT8pWj+6adS2VWOPWNMtFotjEaj5fmAAQPw008/ITY2FjfccIPVEhAQYDm2oUOH4uWXX8bJkyeh1WqxdevWWsuzV/fu3ZGcnAwhhGXd4cOHERQUhLZt2zb4/gDQv39/zJs3D0eOHEGvXr2wbt26RtenKRhuyH7JycAjj8iP//IXYOpU99aHiKiJwjUaRGo0GBgUhFVdumBgUBAiNRqEazROe8/Y2FgcPXoUFy5cQE5ODmbMmIFr165hwoQJ+Pbbb/Hbb79h9+7dmDp1KoxGI44ePYpXX30V3333HVJTU7FlyxZkZ2dbxrbExsbixx9/xNmzZ5GTk4Py8nK76vPUU08hLS0NzzzzDH755Rd89tlnWLBgAWbNmgWVSlXv+6ekpGDevHlITk7GxYsX8b///Q/nz59337gb0czk5+cLACI/P9/dVfFOFy4IER4uBCDEqFFCVFS4u0ZE1IyVlpaKn3/+WZSWlja5rDKjUZhMJiGEECaTSZQZjU0usz5nz54VN910k/Dz8xMAREpKijh37pwYM2aMCA0NFX5+fqJbt25i5syZwmQyiZ9//lkkJiaK1q1bC51OJ7p06SLeffddS3lZWVnizjvvFIGBgQKA2L9/f73vn5KSIgCIkydPWtYdOHBADBo0SGi1WhEZGSnmzJkjysvLhRCi3vfPyMgQo0ePFlFRUUKr1Yr27duL+fPnC6Odv8P6zqc939+SEFXan5qBgoIChISEID8/H8HBwe6ujncpLASGDgVOnQL69pWnWLCjL5qIyNHKysqQkpKCDh06wNfGy7XJc9V3Pu35/ma3FNnGaAQeekgONhERwPbtDDZEROSRGG7INn/9q3ypt04HfPYZ0K6du2tERET1ePXVV60uK6+6DB8+3N3VcypeCk4N++ADYMkS+fFHHwFxce6tDxERNWjatGkYN25cra/5+fm5uDauxXBD9du/H5g+XX68cCEwfrxbq0NERLZp2bKl3VMwKAW7pahu588D990HVFQADz4IzJ/v7hoRERE1iC03JDMagUOHgPR0ICoK6NUL+OMfgdxcuRtq9WrATROgERE1xGTHRJnkuRx1ATfDDclTJzz3HHDp0vV1Oh2g1wMxMcC2bYDC+2eJyDtptVqoVCpcuXIFrVu3hlarddtM1NQ0QghkZ2dDkiRomnjzRIab5m7LFuD++4HqaVmvl3/OnAk0coZZIiJnU6lU6NChA9LT03HlyhV3V4eaSJIktG3bFmobZlavtxzexK8ZMxqB2FjrFpvqYmKAlBSgif/QiIicSQiBioqKJs2tRO6n0WjqDDb2fH+z5aY5O3So/mADAGlp8na33uqSKhERNYa5K6Op3RmkDLxaqjlLT3fsdkRERB6A4aY5i4py7HZEREQegOGmORs2DGjbtu5LvCVJHnMzbJhr60VERNQEDDfNmVoNLFtW+2vmwLN0KQcTExGRV2G4ae7GjgVee63m+rZtgc2b5deJiIi8CK+WousDhm+/HXjsMXmMzbBhbLEhIiKvxHDT3BmNwIYN8uOZM4GRI91aHSIioqZit1Rzd+AAkJEBtGgBJCa6uzZERERNxnDT3K1bJ/984AFAq3VvXYiIiByA4aY50+uBTz+VHz/0kHvrQkRE5CAMN83Zl18C+flAmza8lw0RESkGw01zZu6SmjABUPGfAhERKQO/0ZqrggLg88/lx+ySIiIiBXF7uFmxYgViY2Ph6+uLuLg4HDt2rN7tly5diq5du8LPzw8xMTF4/vnnUVZW5qLaKsi2bUBZGdCtG9Cvn7trQ0RE5DBuDTcbN27ErFmzsGDBApw4cQJ9+/ZFYmIisrKyat1+3bp1mDt3LhYsWIAzZ87gww8/xMaNG/G3v/3NxTVXAHOX1EMP1T23FBERkReShBDCXW8eFxeHQYMGYfny5QAAk8mEmJgYPPPMM5g7d26N7Z9++mmcOXMGSUlJlnV//vOfcfToUXz99dc2vWdBQQFCQkKQn5+P4OBgxxyIt8nMlAcRG43A+fPADTe4u0ZERET1suf7220tNwaDAcePH0dCQsL1yqhUSEhIQHJycq37DBkyBMePH7d0Xf3+++/YuXMnRowYUef76PV6FBQUWC3N3qZNcrAZNIjBhoiIFMdt0y/k5OTAaDQiIiLCan1ERAR++eWXWvd56KGHkJOTgz/84Q8QQqCiogLTpk2rt1tq8eLFePnllx1ad6+3fr38kwOJiYhIgdw+oNgeBw4cwKuvvor33nsPJ06cwJYtW7Bjxw688sorde4zb9485OfnW5a0tDQX1tgDpaQAR47I42zGj3d3bYiIiBzObS03YWFhUKvVyMzMtFqfmZmJyMjIWvd56aWXMGnSJDz22GMAgN69e6O4uBhPPPEEXnjhBahquVeLTqeDTqdz/AF4K/MkmbffLs/+XcV3BQX46++/442OHXFjcx2PREREXs9tLTdarRYDBw60GhxsMpmQlJSE+Pj4WvcpKSmpEWDUajUAwI3jor1L1aukqvk4MxP78/Lw72qBk4iIyJu4reUGAGbNmoXJkyfjxhtvxODBg7F06VIUFxdj6tSpAICHH34Ybdq0weLFiwEAI0eOxJIlS9C/f3/ExcXh119/xUsvvYSRI0daQg7V49Qp4PRpeYLMsWMBABfLypBTXg4Igf9Whpr1WVmYHBkJASBMo0F7X183VpqIiMg+bg0348ePR3Z2NubPn4+MjAz069cPu3btsgwyTk1NtWqpefHFFyFJEl588UVcvnwZrVu3xsiRI/H3v//dXYfgXcytNvfcA2NICH4sLMSA48drbJZdXo6BVdaLW291UQWJiIiazq33uXGH5nqfG31FBb67+258FRGBQ5Mn47CfHwqMRpv2HRQUhFGtWmFUWBh6BwRA4k3/iIjIxez5/ma48TK2DvotrKhAckEBvsrLw6H8fBzNz4e+2jZBajWGBAejk58f3rtypUYZvfz9cbqkxGpdrK+vJejcHBICDSfcJCIiF7Dn+9ut3VJkv6qDfquGm2yDAYfy8+UlLw8ni4pgqrZv69xcDMvPx7A77sDNoaHoExAAH5UKJwoL8d6VK1ABMAGWnx91744orRY7rl7F9qtXsSc3FxfKyvCPy5fxj8uXEaJWY3irVhjVqhWGt2yJUI3Gdb+IWvBqLyIiAhhuvIJ50K8EYGPlvFv/zcxEmEaDE0VFOFVUhN9qmTw01tcXw0JCMCwwEDf/8Y/o8uOPkHbtAmJirLYL12gQqdEgxtcXj0ZF4cP0dKSVlSFco0GUTofHoqPxWHQ0SoxG7MnNxfacHHx+9Sqyy8uxISsLG7Ky4CNJuDkkBKPCwjCqVSt08POrUR9nh4+6gl9zx9BHRM0Nu6W8gHTggE3b9fT3x7DQUNwcEoJhISFoa77KadcuYPhwoHVr4MoVwKdmptWbTNBKEiRJghACBiGgq6fLySgEjhUUYPvVq9iek4Ofq3Vf9QoIsHRfDQoKgkqS8Oz583j38mU826YNlnXubPPx16dq8Bv+44/IKi9HuEaDL/v0cejVXs4OCM4s3xm/dyIiV2O3lML8p3t3TPnlF1TUkkNVAJ5r2xYvtG+PVnV1C5mvkho/vtZgA8AqyEiSBF0Dg4bVkoT4kBDEh4RgcceO+LWkBJ9Xdl8dysvD6eJinC4uxqupqWjl44ObQ0OxLzdXPp7MTMQFB0NvMsFXpUKojw/0JhPKqix6IayfV3+98ufOa9dq1C2r2tVei2JjEeLjgxAfHwSr1ZbHIZWPg3186g1ygPNbhRxdfm2tfRucdIk/W4aIyNOw5cZLnCgstPrCNjs+cCAGBAXVvWNJCRARARQVydMu1HGDREe6Vl6OL69dw2c5OdiUne3093MEnSRdDz2VwcdHkqBRqRCkUuGzq1dRYjIhUK3G9KgoqCu3j9Bq4SNJjVoyDQYUGI3wkSRMPnMGORUVaOXjgxWdO8MgBPwqg19DYa+24LfRht/7qx06oIWPD1poNPJPHx+EVvnpY+NgcW9uGWIwI/IebLlRoAyDweq5edBvg774Qg42sbHATTc5oWY1tdRoMDEiAhMjIrA2PR2PnT2Lui46b6PVIkKrha9KBZ1KBd8qS43nklTra5f1evzl999rlD0tKgqBPj7Ir6i4vhiNKKjyuKjycni9EMgqL0dWeXm9x1ZkNOLNS5ea+iuq09WKCjx45ozTyq/qbykp9b4epFZbh54qIUiC3HoXpFbj44wMAN5580eO0yJSJoYbL5FcUAAACFSr8VanTlaDfutVdboFN9yfZkpUFPoEBjau1clGJwoLAaDG1V6PR0c3WL5RCBRUVKDAaKwRgvZeu4aPMzNrDZESgP6BgYjSalEhBCqEQHnlT1uXUqMRpfU0nEZoNAivK/hVCXp1BcMMgwELLlyoUe60qCj4qdXIq6hAbkUFcsvL5Z+ViznwFRqNKDQakaqvfhOB2lW/+eOL7dujk68vOvn5oZOfH6K02kbdI8nRrStVu+w2sMuuTt5cd2fj78bzMdx4iV2VY0te79ABT0ZH44moqAYH/SI3F9i5U35cy1xSrlY9fDhKfVd7NUQtSXKLRC3bToyIwDNt29YazL5zYDBzVvA7UViIBRcu2B36yk0m5FcJO1UDkDkQfVtYiIN5eaivT/v/Ll60eu6nUqFjlbDTyc/PEn7a+/pCW8e/ZXtaV4QQyK+oQFZ5OTINBrk1rtrPzbV02VUfpzU1MhLhleEyQqu1PA7XaBCm0dh8fydvbhny5ro7mzN/NwxOjsFw4wV+LSnBd4WFUAN4IDwcgG2DfrFlC1BeDvTuDfTs6fyK1qEp4cMWbX19cSE+3nK1l03Bz07OCmbOLL+xv3eNSoUwrRZhWm2929UVzN7o2BECwG+lpfJSVobUsjKUmkz4qaQEP1W7sg6Qj7udr68l7LSs7AaL0emwvrJ15d+ZmbjBzw/XKiqgNxpRDlgCS6bBYHlc7oBhhGsqu9rq0srHxxJ2qv6M0GoBIeCjUqGVj4+l7s5qGXI0Vw5E9zau+t0wVDoGw40XMA8OTWjRAq0b+MKxUs8M4K7kivBh79VetnJ2MHNm+a74vQM1g9kdLVrUaBkymEy4WFZmCTuW4FNait8rg8+FsjJcKCtDUl5ere+TW1GBZ3/91aY6BavVltBRveUlXKtFfkUFnjh3rsZ+73TqhCAfH2QZDLW2/GSXl8MEeWzU1YoK2Do6qnrL0JquXRHj64t2Oh1idDr4NmLiX0f9hV9hMiGzvBxX9HoMPnGiwbo3x7nmio1GxH7zTY311X83Pf394adWw0+lgp9KBf8qj/1UKqvXqj4vqqiAQQj4qlT4T+UExuuysvBwRAQgSewqbQSGGy9gHhfwYGWrjU2uXAH275cfP/igE2plH2eFD2dzdkBwdvnO/L3bE8y0KhU6+/ujs79/jdeEEEg3GKxaepJycy3jzKqTAAwJDsZNwcE1Wk8itFq01mgaDAt1jdO6OTS03i47oxC4VjnwvLZWoyyDAT+VlODX0tJ633/q2bNWz1trNHLQqQw87Xx9EaPTWdZFarVQVzt3Df2FX24yIdNgwBWDAekGA67o9dY/DQak6/XIKi+vt3uxqttDQ7EhMxM3h4YiWqezcS/vc7W8HF9X3u39UH4+ThQV2bRfba2SjZVTXo4bq4TNh8LD0Vanq7GE1/Jvoz7ObhnylPDEcOPhThcV4XRxMbSShNFhYbbvuHEjIAQwdKh8pRQ1mrODWXMPfpIkIVqnQ7ROh2GhoQCAVzp0qLPbyxHjnRrbYqaWJLTWatFaq0XPgIA6t6ur7k9GRaFCCKTp9UjV65FaVoYSkwnZ5eXILi/H8Tq+RH0kCW11OrTWaNDKxweROh0+rWzRXZORgWKjETnl5civqECe0Ygrej2y7QgtagBROh2itFr4q1Q4mJ9f63b78vKwr7Jl7QY/P9wcEoJbKm8cGlvLXcm9RWpZmWXqmkP5+TVuSgoAMTodevr7Y1fl/bqqWte9O2J9fVFqMqHEaESpyXR9qee5eduLZWU420AgXlf5R251PpKEaK22RuhpU+WxwWRCvtHoku5GT+lWY7jxcOZWG7vnbvKQLilSNlcEM2eMR3JXl90T1QZzCyGQW1GB1LIypOr1cugpK7P8TNXrcUWvR4UQlm676gqNRnxYxxihqqElWqtFtPlxlXVRlaFJVXnuzMGset3f6tgRlwwGfJWXh++LivBraSl+LS3F6sr3bqfTWYLOLaGhuMHPr96r45z5F359ZZuEwJmSEkuQOZSfj7Rargjs7u8vT18TEoJhoaFo7+uLE4WF2FXL76arv79DLgCoLRB/0KULAtRqXNLrayzpBgMqhJCDso1XNZpV71L7a0yM5R5c6ir346r62EeSoAZqvHatvBzFJhN8JAn/rvz34O6xWgw3HkwI0bguqXPngO++A9Rq4IEHnFQ7Iudy9ngnT+iykyQJLTUatNRo0K+OL8cKkwnpBgNS9Xqsz8zEyitXag15KgCPREVhbFiYJcCEVQktTa37+PBwy5Qu+RUV+Do/H1/l5eFgXh6+KyxEql6Pf2dm4t+VY0aitNrrLTuhoejh728Vdpz5F37VsvsGBuJEUZElzBzOz8fVigqr7dUABgYF4Q+VYeYPISG1Dqh39r9JoGYg7h8UVGdwMo+Xqi34mJfLer1Ng+zfSEtz2DEANW8N4eqxWrxDsQf7rqAAg06cgL9KhayhQxFg66DDl18GFi6U55MyXwpO5IXsnfPMkzir7s68fYCZvXUvqqhAckEBDubl4av8fBwtKICh2ldLmEaDgYGB6BUQgAFBQZj566/IrmUuOHM3ikEIGEwmlFf+NFTeS8ryuNo2l/V6XC0vRwWAt9PSUGg0QlPZ0lBWrS7+KhVuCg62tMrcFBxs8/+vzjqvl8rKMOj48RrB6duBA6/PE9gIJiGQXV6Ovbm5+FMtNwh9JDISYRoNKoSAsdq9uIzA9cdV11d7fMVgwPk6utV8JAlru3XDxIiIRh+DGe9QrBDmVptRYWG2Bxsh2CVFiuGt45EA59fdmbcnsLfugT4+uLNlS9zZsiUAoNRoxLHKeyEdzMtDckEBcsrLsTs3F7urjVmp3j3iSOVCoOo9x9/s2BHDQkMxIDDQ5nsVVees8+qsrlKVJCFCq0X3ysH81f/dzGjTxqn37Do6YIDDQrc9GG48lEkIyyXgdnVJnTwpd0v5+QH33uuk2hGRu7iia6Sp/NRq3BIailsqB4gbTCZ8V1iIZZcuYVN2ts0DnQH5L3+NJEErSdCqVNBWzvlmfm5+La+iAudKS2st25GtB87kCV2lTeXse4LZiuHGQx3Jz8clvR4hajXurvxryCbmVpuRIwE3pGUici5XDYZ2JK1KhSEhIRgSEoI5dfyF/0Xv3hgYGGgVYDSSZNeYIU9rPfAkzv5342mhm+HGQ5nvbDqmdWvb//EZjcD69fJjdkkRKZY3d9eZVf8LP0qrRaSD7p3jKa0HnsaZ/248LXR7btRvxipMJmxqTJfUoUPyzftCQ4G773ZO5YiImsD8F/7AoCCs6tIFA4OCEKnROOQvfGeWTQ3TqVSWK+IkSXJrayJbbjzQ/rw8ZJeXI0yjwe2VfdY2MXdJ3X8/oOC7hxKR93LmX/ie1npA7sNw44HMV0k90Lq17SP69Xpg82b5MbukiMiDObN7RAlddtR0jLMeRm8yYUtODgA7u6R27wZyc4HoaODmm51UOyIiIs/HcONh/nftGvIqKhCt1eIPISG272juknrwQfnOxERERM0Uw42HMV8lNT483PZLIIuKgO3b5cfskiIiomaO4caDFBuN+KwxXVKffQaUlgKdOwMDBjipdkRERN6B4caD7Lh6FSUmEzr4+mKQPTecqjrdAgfPERFRM8dw40GqzgAu2RpSsrPlwcQAMGGCk2pGRETkPRhuPER+RQV2Xr0KAJhgT5fU5s3ynYkHDgS6dnVS7YiIiLwHw42H+CwnB3oh0MPfH70CAmzfkTOAExERWWG48RDrG9MldfEi8PXX8jib8eOdWDsiIiLvwXDjAXIMBuy5dg2AfAm4zTZskH/eeivQpo3jK0ZEROSFGG48wKc5OTACGBAYiC7+/rbvyBnAiYiIamC48QBVr5Ky2U8/AT/8AGg0wH33OalmRERE3ofhxs2u6PU4mJcHwM4uKXOrzfDhQIsWjq8YERGRl2K4cbNN2dkQAIYGB6Odr69tOwnBq6SIiIjqwHDjZuszMwHY2SV19CiQkgIEBAAjRzqpZkRERN6J4caNUkpLcbSwECoA97dubfuO5labMWMAewYgExERNQM+7q5Ac7axciDxbaGhiNTpGt7BaAQOHAA++kh+znvbEBER1cCWGzey6yqpLVuA2FggIQEoKJDXTZsmryciIiILhhs3OVNcjB+Ki6GRJIxtqEtqyxbg/vuBS5es11+5Iq9nwCEiIrJguHETc5dUYsuWaKnR1L2h0Qg895x8hVR15nUzZ8rbEREREcONOwghrOaSqtehQzVbbKwLA9LS5O2IiIiI4cYdvi8qwrnSUviqVBjVqlX9G6en21aordsREREpHMONG5gHEv+xVSsE+TRwwVpUlG2F2rodERGRwjHcuJgQwr6rpIYOBeq7c7EkATExwLBhDqohERGRd2O4cbFvCgqQqtcjSK3GiJYtG95h6VKgrEx+LEnWr5mfL10KqNWOrCYREZHXYrhxMXOrzeiwMPg1FEiOHAHmzZMfP/kk0KaN9ett2wKbNwNjxzqhpkRERN6Jdyh2IaMQ+CQ7G4ANXVJXrwIPPihf4j1hArByJWAyyVdFpafLY2yGDWOLDRERUTUMNy50MC8PGQYDWvr4IKFFi7o3FAKYMkW+xLtzZ+Cf/5S7oNRq4NZbXVVdIiIir8RuKRcyd0nd17o1tKp6fvVLlgBffAHodMAnnwBBQS6qIRERkfdjuHERg8mET23pkvrmG2DuXPnx0qVAv35OrxsREZGSMNy4yN7cXFyrqECkVotbQkNr3+jaNXmm74oK+eeTT7q0jkRERErAcOMi5i6pca1bQ139km5AHmczdSqQmgrccAPwr3/VvPSbiIiIGsRw4wKlRiO25uQAqKdLaulSYPt2QKuVx9kEB7uugkRERArCcOMCO69dQ5HRiPY6HW6qLbQcOwbMmSM/fucdoH9/11aQiIhIQRhuXMDcJTU+PBxS9a6m3Fxg3DigvBy4/35g+nQ31JCIiEg5GG6crLCiAl9cvQqgli4pIYBHHgEuXgQ6dgQ++IDjbIiIiJqI4cbJtl+9ijKTCV38/NAvMND6xX/8A9i27fo4m5AQt9SRiIhISRhunMzcJTWhepfUt98Cf/mL/Pjtt4GBA91QOyIiIuVhuHGia+Xl2H3tGgB5vI1FXt71cTZjxwIzZringkRERArk9nCzYsUKxMbGwtfXF3FxcTh27Fi92+fl5WHGjBmIioqCTqdDly5dsHPnThfV1j5bsrNRLgT6BgSge0CAvFII4NFHgQsXgA4dgA8/5DgbIiIiB3LrxJkbN27ErFmzsGrVKsTFxWHp0qVITEzE2bNnEV7L/WAMBgPuvPNOhIeHY/PmzWjTpg0uXryI0Lru+Otm5i4pq4HEy5cDW7YAGo08zsZD605EROStJCGEcNebx8XFYdCgQVi+fDkAwGQyISYmBs888wzmmudXqmLVqlV488038csvv0Cj0TTqPQsKChASEoL8/HwEO/FGeRl6PdokJ8ME4Pe4OHTw8wO++w4YOhQwGIBly4Bnn3Xa+xMRESmJPd/fbuuWMhgMOH78OBISEq5XRqVCQkICkpOTa91n+/btiI+Px4wZMxAREYFevXrh1VdfhdForPN99Ho9CgoKrBZX2JydDROAuKAgOdjk58vzRRkMwJgxwDPPuKQeREREzY3bwk1OTg6MRiMiIiKs1kdERCAjI6PWfX7//Xds3rwZRqMRO3fuxEsvvYS3334b//d//1fn+yxevBghISGWJSYmxqHHURfLVVIREfI4m8ceA37/HYiN5TgbIiIiJ3L7gGJ7mEwmhIeH41//+hcGDhyI8ePH44UXXsCqVavq3GfevHnIz8+3LGlpaU6vZ2pZGQ4XFEAC8EDr1sB77wGbN8vjbDZuBFq0cHodiIiImiu3DSgOCwuDWq1GZmam1frMzExERkbWuk9UVBQ0Gg3UarVlXffu3ZGRkQGDwQCtVltjH51OB51O59jKN2BjZavNLaGhiP7pJ2DWLPmF118HBg92aV2IiIiaG7e13Gi1WgwcOBBJSUmWdSaTCUlJSYiPj691n6FDh+LXX3+FyWSyrDt37hyioqJqDTbu8F1BARZdvAgAeDAoSL6fjcEAjBoFzJzp3soRERE1A27tlpo1axbef/99fPTRRzhz5gymT5+O4uJiTJ06FQDw8MMPY968eZbtp0+fjmvXruG5557DuXPnsGPHDrz66quY4Sk3wTMa8Y8TJ1BkNEISAvctXAj89hvQrh2wZg3H2RAREbmAW+9zM378eGRnZ2P+/PnIyMhAv379sGvXLssg49TUVKhU1/NXTEwMdu/ejeeffx59+vRBmzZt8Nxzz2HOnDnuOgQAwMWyMuTs3g3pzTex5YUXAD8/aCoqkHr0KC527YqwNWvQvmVLt9aRiIiouXDrfW7cwXKd/AcfILhTJ2DYMKDKGJ7GkA4cuP5ECLmFxvzTvPrWW5v0HkRERM2ZV9znxu0eewy47Tb50uwtWxpfjtGI9z/4AJJ5HJA50FT+9KmowH9WrgTquRcPEREROU7zbbkBEAxcDyObN8uTWNalogK4dg3IybFadqWl4YlevZBW7X49ZsefeAIDzp8H9u8H2HpDRETUKPa03Lh1zI1HMGe7xx8Hzp2rNcAgJwfIzbXaLTcwELOeegprhw8HALTJysLl8HCoTCaYVCrLT4v0dFcdERERUbPGcGN27RpQ5cqsOrVsie23345pkyYhPTgYkhB4bvNmTN++HbcsXYqY7Gw8unMnPhwxAmmtWyPcHIqiopxbfyIiIgLAbilrw4YBgwYBYWG1LlcDA/FsSgrWVd6kr6ufH1Z36YIhffoAly9D7+MDbXk5JAACgEGjga6iAmjbFkhJafLAZSIioubKqd1SaWlpkCQJbdu2BQAcO3YM69atQ48ePfDEE080rsaeYtGiOsfFbM7KwowTJ5BVXg4VgNkxMVgYGws/tVqe4fv+++UgU0kCrj9fupTBhoiIyEXsvlrqoYcewv79+wEAGRkZuPPOO3Hs2DG88MILWLRokcMr6BKSBMTEyC031WQaDHjgp5/wwM8/I6u8HD39/fHNgAF4vVMnOdgA8kDkzZuBNm2sd27btuGBykRERORQdoeb06dPY3Dl/EiffPIJevXqhSNHjuC///0v1q5d6+j6OZ/5aqlqrStCCKzLzETPY8ewOTsbagAvtm+P4zfeiEG1NYeNHQtcuCBfFbVunfwzJYXBhoiIyMXs7pYqLy+3TES5d+9ejBo1CgDQrVs3pHvjFUFt28rBpkoIuaLXY9q5c/j86lUAQL/AQKzu2hX9g4LqL0ut5uXeREREbmZ3uOnZsydWrVqFe+65B3v27MErr7wCALhy5QpatWrl8Ao6zQcfANXuUCyEwEcZGXj+t9+QV1EBjSRhfvv2mNOuHTSq5nu/QyIiIm9id7h5/fXXMWbMGLz55puYPHky+vbtCwDYvn27pbvKKzzwAFCleym1rAxPnjuHXdeuAQBuDArCmq5d0Ssw0F01JCIiokZo1KXgRqMRBQUFaNGihWXdhQsX4O/vj/DwcIdW0NHMl5INO3QIS/r0wcCgIPwrPR1/+e03FBqN0EkSFnXogFlt28KHrTVEREQewamXgpeWlkIIYQk2Fy9exNatW9G9e3ckJiY2rsZucCg/H8svX0aaXo99eXkAgPjgYKzu2hXdAgLcWzkiIiJqNLvDzb333ouxY8di2rRpyMvLQ1xcHDQaDXJycrBkyRJMnz7dGfV0io8yMwEAOknCX2NisKBDB6irzORNRERE3sfufpcTJ05gWOX9YDZv3oyIiAhcvHgRH3/8Mf7xj384vIKuoBcCr6SmMtgQEREpgN3hpqSkBEGVl0T/73//w9ixY6FSqXDTTTfh4sWLDq+gK/hIEv7Tvbu7q0FEREQOYHe4ueGGG7Bt2zakpaVh9+7duOuuuwAAWVlZDQ7w8VRHBwzAxIgId1eDiIiIHMDucDN//nzMnj0bsbGxGDx4MOLj4wHIrTj9+/d3eAWdiddCERERKU+jLgXPyMhAeno6+vbtC1Xl5dLHjh1DcHAwunXr5vBKOpL5UrJ3fvkF64qKkFZWhm8HDkRbX193V42IiIjqYM+l4I0KN2aXLl0CAMsM4d6g6i8nKCgIBiGg4/1siIiIPJo94cbub3WTyYRFixYhJCQE7du3R/v27REaGopXXnkFJpOp0ZV2B0mSGGyIiIgUxu773Lzwwgv48MMP8dprr2Ho0KEAgK+//hoLFy5EWVkZ/v73vzu8kkRERES2srtbKjo6GqtWrbLMBm722Wef4amnnsLly5cdWkFHs6dZi4iIiDyDU7ulrl27Vuug4W7duuFa5aSTRERERO5id7jp27cvli9fXmP98uXLLTOEExEREbmL3WNu3njjDdxzzz3Yu3ev5R43ycnJSEtLw86dOx1eQSIiIiJ72N1yc8stt+DcuXMYM2YM8vLykJeXh7Fjx+Ls2bOWOaeIiIiI3KVJ97mp6tKlS1i0aBH+9a9/OaI4p+GAYiIiIu/j1AHFdbl69So+/PBDRxVHRERE1Ci8gx0REREpCsMNERERKQrDDRERESmKzZeCjx07tt7X8/LymloXIiIioiazOdyEhIQ0+PrDDz/c5AoRERERNYXN4WbNmjXOrAcRERGRQ3DMDRERESkKww0REREpCsMNERERKQrDDRERESmKQ8NNaWmpI4sjIiIisptDwo1er8fbb7+NDh06OKI4IiIiokazOdzo9XrMmzcPN954I4YMGYJt27YBkC8R79ChA5YuXYrnn3/eWfUkIiIisonN97mZP38+/vnPfyIhIQFHjhzBAw88gKlTp+Kbb77BkiVL8MADD0CtVjuzrkREREQNsjncbNq0CR9//DFGjRqF06dPo0+fPqioqMAPP/wASZKcWUciIiIim9ncLXXp0iUMHDgQANCrVy/odDo8//zzDDZERETkUWwON0ajEVqt1vLcx8cHgYGBTqkUERERUWPZ3C0lhMCUKVOg0+kAAGVlZZg2bRoCAgKsttuyZYtja0hERERkB5vDzeTJk62e/+lPf3J4ZYiIiIiairOCExERkaJw+gUiIiJSFJtbbh555BGbtlu9enWjK0NERETUVDaHm7Vr16J9+/bo378/hBDOrBMRERFRo9kcbqZPn47169cjJSUFU6dOxZ/+9Ce0bNnSmXUjIiIispvNY25WrFiB9PR0/PWvf8Xnn3+OmJgYjBs3Drt372ZLDhEREXkMSTQymVy8eBFr167Fxx9/jIqKCvz0009ecVO/goIChISEID8/H8HBwe6uDhEREdnAnu/vRl8tpVKpIEkShBAwGo2NLYaIiIjIoewKN3q9HuvXr8edd96JLl264NSpU1i+fDlSU1O9otWGiIiIlM/mAcVPPfUUNmzYgJiYGDzyyCNYv349wsLCnFk3IiIiIrvZPOZGpVKhXbt26N+/f70zgXv63FIcc0NEROR97Pn+trnl5uGHH6431BARERF5Artu4kdERETk6Ti3FBERESkKww0REREpikeEmxUrViA2Nha+vr6Ii4vDsWPHbNpvw4YNkCQJo0ePdm4FiYiIyGu4Pdxs3LgRs2bNwoIFC3DixAn07dsXiYmJyMrKqne/CxcuYPbs2Rg2bJiLakpERETewO3hZsmSJXj88ccxdepU9OjRA6tWrYK/vz9Wr15d5z5GoxETJ07Eyy+/jI4dO7qwtkREROTp3BpuDAYDjh8/joSEBMs6lUqFhIQEJCcn17nfokWLEB4ejkcffbTB99Dr9SgoKLBaiIiISLncGm5ycnJgNBoRERFhtT4iIgIZGRm17vP111/jww8/xPvvv2/TeyxevBghISGWJSYmpsn1JiIiIs/l9m4pexQWFmLSpEl4//33bZ76Yd68ecjPz7csaWlpTq4lERERuZPNN/FzhrCwMKjVamRmZlqtz8zMRGRkZI3tf/vtN1y4cAEjR460rDOZTAAAHx8fnD17Fp06dbLaR6fTQafTOaH2RERE5Inc2nKj1WoxcOBAJCUlWdaZTCYkJSUhPj6+xvbdunXDqVOn8P3331uWUaNG4bbbbsP333/PLiciIiJyb8sNAMyaNQuTJ0/GjTfeiMGDB2Pp0qUoLi7G1KlTAchzWrVp0waLFy+Gr68vevXqZbV/aGgoANRYT0RERM2T28PN+PHjkZ2djfnz5yMjIwP9+vXDrl27LIOMU1NToVJ51dAgIiIiciNJCCHcXQlXsmfKdCIiIvIM9nx/s0mEiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBSF4YaIiIgUheGGiIiIFIXhhoiIiBTFI8LNihUrEBsbC19fX8TFxeHYsWN1bvv+++9j2LBhaNGiBVq0aIGEhIR6tyciIqLmxe3hZuPGjZg1axYWLFiAEydOoG/fvkhMTERWVlat2x84cAATJkzA/v37kZycjJiYGNx11124fPmyi2tOREREnkgSQgh3ViAuLg6DBg3C8uXLAQAmkwkxMTF45plnMHfu3Ab3NxqNaNGiBZYvX46HH364we0LCgoQEhKC/Px8BAcHN7n+RERE5Hz2fH+7teXGYDDg+PHjSEhIsKxTqVRISEhAcnKyTWWUlJSgvLwcLVu2rPV1vV6PgoICq4WIiIiUy63hJicnB0ajEREREVbrIyIikJGRYVMZc+bMQXR0tFVAqmrx4sUICQmxLDExMU2uNxEREXkut4+5aYrXXnsNGzZswNatW+Hr61vrNvPmzUN+fr5lSUtLc3EtiYiIyJV83PnmYWFhUKvVyMzMtFqfmZmJyMjIevd966238Nprr2Hv3r3o06dPndvpdDrodDqH1JeIiIg8n1tbbrRaLQYOHIikpCTLOpPJhKSkJMTHx9e53xtvvIFXXnkFu3btwo033uiKqhIREZGXcGvLDQDMmjULkydPxo033ojBgwdj6dKlKC4uxtSpUwEADz/8MNq0aYPFixcDAF5//XXMnz8f69atQ2xsrGVsTmBgIAIDA912HEREROQZ3B5uxo8fj+zsbMyfPx8ZGRno168fdu3aZRlknJqaCpXqegPTypUrYTAYcP/991uVs2DBAixcuNCVVSciIiIP5Pb73Lga73NDRETkfbzmPjdEREREjsZwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIriEeFmxYoViI2Nha+vL+Li4nDs2LF6t9+0aRO6desGX19f9O7dGzt37nRRTYmIiMjTuT3cbNy4EbNmzcKCBQtw4sQJ9O3bF4mJicjKyqp1+yNHjmDChAl49NFHcfLkSYwePRqjR4/G6dOnXVxzIiIi8kSSEEK4swJxcXEYNGgQli9fDgAwmUyIiYnBM888g7lz59bYfvz48SguLsYXX3xhWXfTTTehX79+WLVqVYPvV1BQgJCQEOTn5yM4ONhxB0JEREROY8/3t1tbbgwGA44fP46EhATLOpVKhYSEBCQnJ9e6T3JystX2AJCYmFjn9nq9HgUFBVYLERERKZdbw01OTg6MRiMiIiKs1kdERCAjI6PWfTIyMuzafvHixQgJCbEsMTExjqk8EREReSS3j7lxtnnz5iE/P9+ypKWlubtKRERE5EQ+7nzzsLAwqNVqZGZmWq3PzMxEZGRkrftERkbatb1Op4NOp3NMhYmIiMjjuTXcaLVaDBw4EElJSRg9ejQAeUBxUlISnn766Vr3iY+PR1JSEmbOnGlZt2fPHsTHx9v0nubx0xx7Q0RE5D3M39s2XQcl3GzDhg1Cp9OJtWvXip9//lk88cQTIjQ0VGRkZAghhJg0aZKYO3euZfvDhw8LHx8f8dZbb4kzZ86IBQsWCI1GI06dOmXT+6WlpQkAXLhw4cKFCxcvXNLS0hr8rndryw0gX9qdnZ2N+fPnIyMjA/369cOuXbssg4ZTU1OhUl0fGjRkyBCsW7cOL774Iv72t7+hc+fO2LZtG3r16mXT+0VHR+Pnn39Gjx49kJaWpvjLwQsKChATE8NjVRgeqzLxWJWJx+oYQggUFhYiOjq6wW3dfp8bd2hO97rhsSoTj1WZeKzKxGN1PcVfLUVERETNC8MNERERKUqzDDc6nQ4LFixoFpeI81iViceqTDxWZeKxul6zHHNDREREytUsW26IiIhIuRhuiIiISFEYboiIiEhRGG6IiIhIURQZblasWIHY2Fj4+voiLi4Ox44dq3f7TZs2oVu3bvD19UXv3r2xc+dOF9W0aRYvXoxBgwYhKCgI4eHhGD16NM6ePVvvPmvXroUkSVaLr6+vi2rceAsXLqxR727dutW7j7ee19jY2BrHKkkSZsyYUev23nROv/rqK4wcORLR0dGQJAnbtm2zel0Igfnz5yMqKgp+fn5ISEjA+fPnGyzX3s+8K9R3rOXl5ZgzZw569+6NgIAAREdH4+GHH8aVK1fqLbMxnwNXaOi8TpkypUa977777gbL9bbzCqDWz64kSXjzzTfrLNMTz6st3y9lZWWYMWMGWrVqhcDAQNx33301JraurrGfcXspLtxs3LgRs2bNwoIFC3DixAn07dsXiYmJyMrKqnX7I0eOYMKECXj00Udx8uRJjB49GqNHj8bp06ddXHP7HTx4EDNmzMA333yDPXv2oLy8HHfddReKi4vr3S84OBjp6emW5eLFiy6qcdP07NnTqt5ff/11ndt683n99ttvrY5zz549AIAHHnigzn285ZwWFxejb9++WLFiRa2vv/HGG/jHP/6BVatW4ejRowgICEBiYiLKysrqLNPez7yr1HesJSUlOHHiBF566SWcOHECW7ZswdmzZzFq1KgGy7Xnc+AqDZ1XALj77rut6r1+/fp6y/TG8wrA6hjT09OxevVqSJKE++67r95yPe282vL98vzzz+Pzzz/Hpk2bcPDgQVy5cgVjx46tt9zGfMYbxc55Lj3e4MGDxYwZMyzPjUajiI6OFosXL651+3Hjxol77rnHal1cXJx48sknnVpPZ8jKyhIAxMGDB+vcZs2aNSIkJMR1lXKQBQsWiL59+9q8vZLO63PPPSc6deokTCZTra976zkFILZu3Wp5bjKZRGRkpHjzzTct6/Ly8oROpxPr16+vsxx7P/PuUP1Ya3Ps2DEBQFy8eLHObez9HLhDbcc6efJkce+999pVjlLO67333ituv/32erfxhvNa/fslLy9PaDQasWnTJss2Z86cEQBEcnJyrWU09jPeGIpquTEYDDh+/DgSEhIs61QqFRISEpCcnFzrPsnJyVbbA0BiYmKd23uy/Px8AEDLli3r3a6oqAjt27dHTEwM7r33Xvz000+uqF6TnT9/HtHR0ejYsSMmTpyI1NTUOrdVynk1GAz4z3/+g0ceeQSSJNW5nbee06pSUlKQkZFhdd5CQkIQFxdX53lrzGfeU+Xn50OSJISGhta7nT2fA09y4MABhIeHo2vXrpg+fTquXr1a57ZKOa+ZmZnYsWMHHn300Qa39fTzWv375fjx4ygvL7c6R926dUO7du3qPEeN+Yw3lqLCTU5ODoxGo2VGcbOIiAhkZGTUuk9GRoZd23sqk8mEmTNnYujQofXOkN61a1esXr0an332Gf7zn//AZDJhyJAhuHTpkgtra7+4uDisXbsWu3btwsqVK5GSkoJhw4ahsLCw1u2Vcl63bduGvLw8TJkypc5tvPWcVmc+N/act8Z85j1RWVkZ5syZgwkTJtQ72aC9nwNPcffdd+Pjjz9GUlISXn/9dRw8eBDDhw+H0WisdXulnNePPvoIQUFBDXbVePp5re37JSMjA1qttkYYb+j71ryNrfs0lo9DSyO3mTFjBk6fPt1gP218fDzi4+Mtz4cMGYLu3bvjn//8J1555RVnV7PRhg8fbnncp08fxMXFoX379vjkk09s+qvIW3344YcYPnw4oqOj69zGW88pycrLyzFu3DgIIbBy5cp6t/XWz8GDDz5oedy7d2/06dMHnTp1woEDB3DHHXe4sWbOtXr1akycOLHBAf6efl5t/X7xJIpquQkLC4Nara4xWjszMxORkZG17hMZGWnX9p7o6aefxhdffIH9+/ejbdu2du2r0WjQv39//Prrr06qnXOEhoaiS5cuddZbCef14sWL2Lt3Lx577DG79vPWc2o+N/act8Z85j2JOdhcvHgRe/bsqbfVpjYNfQ48VceOHREWFlZnvb39vALAoUOHcPbsWbs/v4Bnnde6vl8iIyNhMBiQl5dntX1D37fmbWzdp7EUFW60Wi0GDhyIpKQkyzqTyYSkpCSrv2yrio+Pt9oeAPbs2VPn9p5ECIGnn34aW7duxb59+9ChQwe7yzAajTh16hSioqKcUEPnKSoqwm+//VZnvb35vJqtWbMG4eHhuOeee+zaz1vPaYcOHRAZGWl13goKCnD06NE6z1tjPvOewhxszp8/j71796JVq1Z2l9HQ58BTXbp0CVevXq2z3t58Xs0+/PBDDBw4EH379rV7X084rw19vwwcOBAajcbqHJ09exapqal1nqPGfMabcgCKsmHDBqHT6cTatWvFzz//LJ544gkRGhoqMjIyhBBCTJo0ScydO9ey/eHDh4WPj4946623xJkzZ8SCBQuERqMRp06dctch2Gz69OkiJCREHDhwQKSnp1uWkpISyzbVj/fll18Wu3fvFr/99ps4fvy4ePDBB4Wvr6/46aef3HEINvvzn/8sDhw4IFJSUsThw4dFQkKCCAsLE1lZWUIIZZ1XIeQrQ9q1ayfmzJlT4zVvPqeFhYXi5MmT4uTJkwKAWLJkiTh58qTlCqHXXntNhIaGis8++0z8+OOP4t577xUdOnQQpaWlljJuv/128e6771qeN/SZd5f6jtVgMIhRo0aJtm3biu+//97q86vX6y1lVD/Whj4H7lLfsRYWForZs2eL5ORkkZKSIvbu3SsGDBggOnfuLMrKyixlKOG8muXn5wt/f3+xcuXKWsvwhvNqy/fLtGnTRLt27cS+ffvEd999J+Lj40V8fLxVOV27dhVbtmyxPLflM+4Iigs3Qgjx7rvvinbt2gmtVisGDx4svvnmG8trt9xyi5g8ebLV9p988ono0qWL0Gq1omfPnmLHjh0urnHjAKh1WbNmjWWb6sc7c+ZMy+8mIiJCjBgxQpw4ccL1lbfT+PHjRVRUlNBqtaJNmzZi/Pjx4tdff7W8rqTzKoQQu3fvFgDE2bNna7zmzed0//79tf6bNR+PyWQSL730koiIiBA6nU7ccccdNX4H7du3FwsWLLBaV99n3l3qO9aUlJQ6P7/79++3lFH9WBv6HLhLfcdaUlIi7rrrLtG6dWuh0WhE+/btxeOPP14jpCjhvJr985//FH5+fiIvL6/WMrzhvNry/VJaWiqeeuop0aJFC+Hv7y/GjBkj0tPTa5RTdR9bPuOOIFW+OREREZEiKGrMDRERERHDDRERESkKww0REREpCsMNERERKQrDDRERESkKww0REREpCsMNERERKQrDDRE1e5IkYdu2be6uBhE5CMMNEbnVlClTIElSjeXuu+92d9WIyEv5uLsCRER333031qxZY7VOp9O5qTZE5O3YckNEbqfT6RAZGWm1tGjRAoDcZbRy5UoMHz4cfn5+6NixIzZv3my1/6lTp3D77bfDz88PrVq1whNPPIGioiKrbVavXo2ePXtCp9MhKioKTz/9tNXrOTk5GDNmDPz9/dG5c2ds377duQdNRE7DcENEHu+ll17Cfffdhx9++AETJ07Egw8+iDNnzgAAiouLkZiYiBYtWuDbb7/Fpk2bsHfvXqvwsnLlSsyYMQNPPPEETp06he3bt+OGG26weo+XX34Z48aNw48//ogRI0Zg4sSJuHbtmkuPk4gcxOFTcRIR2WHy5MlCrVaLgIAAq+Xvf/+7EEKeVXjatGlW+8TFxYnp06cLIYT417/+JVq0aCGKioosr+/YsUOoVCrLzNPR0dHihRdeqLMOAMSLL75oeV5UVCQAiC+//NJhx0lErsMxN0TkdrfddhtWrlxpta5ly5aWx/Hx8VavxcfH4/vvvwcAnDlzBn379kVAQIDl9aFDh8JkMuHs2bOQJAlXrlzBHXfcUW8d+vTpY3kcEBCA4OBgZGVlNfaQiMiNGG6IyO0CAgJqdBM5ip+fn03baTQaq+eSJMFkMjmjSkTkZBxzQ0Qe75tvvqnxvHv37gCA7t2744cffkBxcbHl9cOHD0OlUqFr164ICgpCbGwskpKSXFpnInIfttwQkdvp9XpkZGRYrfPx8UFYWBgAYNOmTbjxxhvxhz/8Af/9739x7NgxfPjhhwCAiRMnYsGCBZg8eTIWLlyI7OxsPPPMM5g0aRIiIiIAAAsXLsS0adMQHh6O4cOHo7CwEIcPH8Yzzzzj2gMlIpdguCEit9u1axeioqKs1nXt2hW//PILAPlKpg0bNuCpp55CVFQU1q9fjx49egAA/P39sXv3bjz33HMYNGgQ/P39cd9992HJkiWWsiZPnoyysjK88847mD17NsLCwnD//fe77gCJyKUkIYRwdyWIiOoiSRK2bt2K0aNHu7sqROQlOOaGiIiIFIXhhoiIiBSFY26IyKOx55yI7MWWGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUpT/B9s9zp+t2okhAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'MPQA'\n",
    "N_EPOCHS = 21\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: MPQA\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5568, 100])\n",
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "# print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 5、池化 ================\n",
    "\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2\n",
    "    \n",
    "# ===================== 02 Model_best_copy8672_cnn_diagonal =====================\n",
    "\n",
    "print(\"Model_best_copy8672_cnn_diagonal\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim-2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_is_sentiment = self.phase_embedding(text)\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.self_attention2(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、取对角线 ================\n",
    "        diagonal_elements_real = Conv_real[:, 0, torch.arange(Conv_real.size(2)), torch.arange(Conv_real.size(3))]\n",
    "        diagonal_elements_imag = Conv_imag[:, 0, torch.arange(Conv_imag.size(2)), torch.arange(Conv_imag.size(3))]\n",
    "\n",
    "        diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "        diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "        fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "        fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "        return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_diagonal\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "source": [
    "# ===================== 03 Model_best_copy8672_diagonal =====================\n",
    "# print(\"Model_best_copy8672_diagonal\")\n",
    "    \n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、取对角线 ================\n",
    "#         diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "#         diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 5、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "source": [
    "# ===================== 04 Model_best_copy8672_maxpooling =====================\n",
    "# print(\"Model_best_copy8672_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、池化 ================\n",
    "#         # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 5、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(MatrixReal))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(MatrixImag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 932,401 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.473 | Train Acc: 81.05%\n",
      "\t test  Loss: 0.410 | test  Acc: 83.77%\n",
      "\t best  test acc: 83.77%\n",
      "Epoch: 02 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.328 | Train Acc: 88.68%\n",
      "\t test  Loss: 0.368 | test  Acc: 85.82%\n",
      "\t best  test acc: 85.82%\n",
      "Epoch: 03 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.259 | Train Acc: 91.41%\n",
      "\t test  Loss: 0.383 | test  Acc: 83.96%\n",
      "\t best  test acc: 85.82%\n",
      "Epoch: 04 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.209 | Train Acc: 93.63%\n",
      "\t test  Loss: 0.377 | test  Acc: 85.45%\n",
      "\t best  test acc: 85.82%\n",
      "Epoch: 05 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.176 | Train Acc: 94.82%\n",
      "\t test  Loss: 0.352 | test  Acc: 86.75%\n",
      "\t best  test acc: 86.75%\n",
      "Epoch: 06 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.149 | Train Acc: 95.35%\n",
      "\t test  Loss: 0.374 | test  Acc: 87.59%\n",
      "\t best  test acc: 87.59%\n",
      "Epoch: 07 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.127 | Train Acc: 96.20%\n",
      "\t test  Loss: 0.403 | test  Acc: 85.54%\n",
      "\t best  test acc: 87.59%\n",
      "Epoch: 08 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.106 | Train Acc: 96.93%\n",
      "\t test  Loss: 0.444 | test  Acc: 84.70%\n",
      "\t best  test acc: 87.59%\n",
      "Epoch: 09 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.092 | Train Acc: 97.32%\n",
      "\t test  Loss: 0.474 | test  Acc: 83.49%\n",
      "\t best  test acc: 87.59%\n",
      "Epoch: 10 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.086 | Train Acc: 97.43%\n",
      "\t test  Loss: 0.506 | test  Acc: 83.68%\n",
      "\t best  test acc: 87.59%\n",
      "Epoch: 11 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.178 | Train Acc: 93.81%\n",
      "\t test  Loss: 0.451 | test  Acc: 80.97%\n",
      "\t best  test acc: 87.59%\n",
      "Epoch: 12 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.176 | Train Acc: 93.00%\n",
      "\t test  Loss: 0.401 | test  Acc: 83.58%\n",
      "\t best  test acc: 87.59%\n",
      "Epoch: 13 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.134 | Train Acc: 95.08%\n",
      "\t test  Loss: 0.411 | test  Acc: 84.51%\n",
      "\t best  test acc: 87.59%\n",
      "Epoch: 14 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.113 | Train Acc: 95.99%\n",
      "\t test  Loss: 0.411 | test  Acc: 84.33%\n",
      "\t best  test acc: 87.59%\n",
      "Epoch: 15 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.102 | Train Acc: 96.06%\n",
      "\t test  Loss: 0.487 | test  Acc: 82.84%\n",
      "\t best  test acc: 87.59%\n",
      "Epoch: 16 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.108 | Train Acc: 96.15%\n",
      "\t test  Loss: 0.427 | test  Acc: 84.24%\n",
      "\t best  test acc: 87.59%\n",
      "Epoch: 17 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.104 | Train Acc: 96.37%\n",
      "\t test  Loss: 0.468 | test  Acc: 84.05%\n",
      "\t best  test acc: 87.59%\n",
      "Epoch: 18 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.088 | Train Acc: 97.38%\n",
      "\t test  Loss: 0.458 | test  Acc: 84.42%\n",
      "\t best  test acc: 87.59%\n",
      "Epoch: 19 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.079 | Train Acc: 97.61%\n",
      "\t test  Loss: 0.465 | test  Acc: 85.45%\n",
      "\t best  test acc: 87.59%\n",
      "Epoch: 20 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.078 | Train Acc: 97.58%\n",
      "\t test  Loss: 0.482 | test  Acc: 84.79%\n",
      "\t best  test acc: 87.59%\n",
      "Epoch: 21 | Epoch Time: 0m 9s\n",
      "\t Train Loss: 0.071 | Train Acc: 97.69%\n",
      "\t test  Loss: 0.508 | test  Acc: 85.07%\n",
      "\t best  test acc: 87.59%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'SUBJ'\n",
    "N_EPOCHS = 21\n",
    "\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.0+cu118\n",
      "DATA_SET: SUBJ\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "source": [
    "word_dim = 100 # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        #并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = [] # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0: #第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp) #每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls) #将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))#word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([18512, 100])\n",
      "18512\n",
      "18512\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    if len(tmp_sen) != 0:\n",
    "        # # 补齐\n",
    "        # for _ in range(batch_size - len(tmp_sen)):\n",
    "        #     tmp_sen.append(sentence[0])\n",
    "        #     tmp_label.append(sentence[2])\n",
    "        #     tmp_sentiment.append(array_sentiment[1])\n",
    "        sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "        # # OR去掉\n",
    "        # break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "# 下载 SentiWordNet 数据\n",
    "# nltk.download('sentiwordnet')\n",
    "# 加载 SentiWordNet 数据\n",
    "swn_file_path = nltk.data.find('corpora/sentiwordnet/SentiWordNet_3.0.0.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        batch_word_scores.append(get_word_sentiment_scores(sentence))\n",
    "    return batch_word_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED) # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED) # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.rnn = nn.GRU(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.rnn(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "source": [
    "# -------------------- 01 Model_best_copy8672_cnn_maxpooling ------------------------\n",
    "# print(\"Model_best_copy8672_cnn_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、卷积 ================\n",
    "#         self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "#         self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "#         # ================ 5、池化 ================\n",
    "\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 6、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、卷积操作 ================\n",
    "#         # 5.1 --对于【实部】进行卷积\n",
    "#         Conv_real = self.Conv2dOne(MatrixReal)\n",
    "#         # 5.2 --对于【虚部】进行卷积\n",
    "#         Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2\n",
    "    \n",
    "# ===================== 02 Model_best_copy8672_cnn_diagonal =====================\n",
    "\n",
    "print(\"Model_best_copy8672_cnn_diagonal\")\n",
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim-2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "        # phase_is_sentiment = self.phase_embedding(text)\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.self_attention2(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、取对角线 ================\n",
    "        diagonal_elements_real = Conv_real[:, 0, torch.arange(Conv_real.size(2)), torch.arange(Conv_real.size(3))]\n",
    "        diagonal_elements_imag = Conv_imag[:, 0, torch.arange(Conv_imag.size(2)), torch.arange(Conv_imag.size(3))]\n",
    "\n",
    "        diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "        diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "        fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "        fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "        return fc2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model_best_copy8672_cnn_diagonal\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "source": [
    "# ===================== 03 Model_best_copy8672_diagonal =====================\n",
    "# print(\"Model_best_copy8672_diagonal\")\n",
    "    \n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 4、取对角线 ================\n",
    "#         diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "#         diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "#         diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "#         diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "#         # ================ 5、全连接 ================\n",
    "#         diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "#         fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "#         fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "source": [
    "# ===================== 04 Model_best_copy8672_maxpooling =====================\n",
    "# print(\"Model_best_copy8672_maxpooling\")\n",
    "# class run_complex_network(nn.Module):\n",
    "#     def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # ================ 1、词嵌入模块 ================\n",
    "#         # ------ 实部，预训练模型 -------\n",
    "#         self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ------ 虚部，传统模型 -------\n",
    "#         # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "#         # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "#         # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "#         # ================ 2、GRU模块 信息提取 ================\n",
    "#         # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "#         self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "#         # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "#         self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "#         self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "#         self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "#         # ================ 4、池化 ================\n",
    "#         # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "#         self.MaxPool1 = nn.MaxPool2d((embedding_dim, 1), 1)  # 实部\n",
    "#         self.MaxPool2 = nn.MaxPool2d((embedding_dim, 1), 1)  # 虚部\n",
    "\n",
    "#         # ================ 5、全连接层 ================\n",
    "#         self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "#         self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "#     def forward(self, text, sentiment):\n",
    "#         # ================ 1、文本嵌入到向量 ================\n",
    "#         amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "#         sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "#                                expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "#         phase_is_sentiment = sentiment_unsqueeze\n",
    "#         # phase_is_sentiment = self.phase_embedding(text)\n",
    "#         # ================ 2、实部进行GRU处理 ================\n",
    "#         amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "#         amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "#         amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "#         phase_plus = self.gru2(phase_is_sentiment)\n",
    "#         # phase_plus2 = self.self_attention2(phase_plus)\n",
    "#         # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "#         # ================ 3、计算密度矩阵 ================\n",
    "#         embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "#         Euler_realAimag = self.projection_Euler(embedded)\n",
    "#         Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "#         Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "#         MatrixReal = Project_realAimag[0]\n",
    "#         MatrixImag = Project_realAimag[1]\n",
    "\n",
    "#         # ================ 5、池化操作 ================\n",
    "#         # 6.1 --对于【实部】进行池化\n",
    "#         Max_real = self.MaxPool1(torch.sigmoid(MatrixReal))\n",
    "#         # 6.2 --对于【虚部】进行池化\n",
    "#         Max_imag = self.MaxPool2(torch.sigmoid(MatrixImag))\n",
    "\n",
    "#         # ================ 6、全连接 ================\n",
    "#         fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "#         fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "#         return fc2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "#     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "    \n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')\n",
    "\n",
    "# 定义训练流程\n",
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "print(\"num_layers\",num_layers)\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "#\n",
    "colors1 = '#00CED1' \n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), acc_train[0:N_EPOCHS], 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), acc_test[0:N_EPOCHS], 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('pic' + DATA_SET + '.pdf', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num_layers 2\n",
      "pad_idx 1\n",
      "The model has 2,226,801 trainable parameters\n",
      "True\n",
      "Epoch: 01 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.606 | Train Acc: 66.53%\n",
      "\t test  Loss: 0.392 | test  Acc: 87.60%\n",
      "\t best  test acc: 87.60%\n",
      "Epoch: 02 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.310 | Train Acc: 90.55%\n",
      "\t test  Loss: 0.284 | test  Acc: 89.78%\n",
      "\t best  test acc: 89.78%\n",
      "Epoch: 03 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.188 | Train Acc: 94.76%\n",
      "\t test  Loss: 0.248 | test  Acc: 91.77%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 04 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.118 | Train Acc: 97.19%\n",
      "\t test  Loss: 0.309 | test  Acc: 90.38%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 05 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.090 | Train Acc: 98.02%\n",
      "\t test  Loss: 0.241 | test  Acc: 91.77%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 06 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.069 | Train Acc: 98.55%\n",
      "\t test  Loss: 0.337 | test  Acc: 88.10%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 07 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.053 | Train Acc: 99.01%\n",
      "\t test  Loss: 0.296 | test  Acc: 91.37%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 08 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.039 | Train Acc: 99.19%\n",
      "\t test  Loss: 0.305 | test  Acc: 91.47%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 09 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.032 | Train Acc: 99.41%\n",
      "\t test  Loss: 0.344 | test  Acc: 91.57%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 10 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.026 | Train Acc: 99.54%\n",
      "\t test  Loss: 0.350 | test  Acc: 91.57%\n",
      "\t best  test acc: 91.77%\n",
      "Epoch: 11 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.021 | Train Acc: 99.61%\n",
      "\t test  Loss: 0.376 | test  Acc: 91.87%\n",
      "\t best  test acc: 91.87%\n",
      "Epoch: 12 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.013 | Train Acc: 99.78%\n",
      "\t test  Loss: 0.424 | test  Acc: 89.88%\n",
      "\t best  test acc: 91.87%\n",
      "Epoch: 13 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.021 | Train Acc: 99.55%\n",
      "\t test  Loss: 0.498 | test  Acc: 90.28%\n",
      "\t best  test acc: 91.87%\n",
      "Epoch: 14 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.020 | Train Acc: 99.64%\n",
      "\t test  Loss: 0.402 | test  Acc: 90.18%\n",
      "\t best  test acc: 91.87%\n",
      "Epoch: 15 | Epoch Time: 0m 11s\n",
      "\t Train Loss: 0.011 | Train Acc: 99.84%\n",
      "\t test  Loss: 0.430 | test  Acc: 91.17%\n",
      "\t best  test acc: 91.87%\n",
      "Epoch: 16 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.015 | Train Acc: 99.66%\n",
      "\t test  Loss: 0.375 | test  Acc: 91.47%\n",
      "\t best  test acc: 91.87%\n",
      "Epoch: 17 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.013 | Train Acc: 99.67%\n",
      "\t test  Loss: 0.365 | test  Acc: 92.16%\n",
      "\t best  test acc: 92.16%\n",
      "Epoch: 18 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.007 | Train Acc: 99.91%\n",
      "\t test  Loss: 0.363 | test  Acc: 92.66%\n",
      "\t best  test acc: 92.66%\n",
      "Epoch: 19 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.008 | Train Acc: 99.86%\n",
      "\t test  Loss: 0.368 | test  Acc: 92.16%\n",
      "\t best  test acc: 92.66%\n",
      "Epoch: 20 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.005 | Train Acc: 99.95%\n",
      "\t test  Loss: 0.391 | test  Acc: 92.06%\n",
      "\t best  test acc: 92.66%\n",
      "Epoch: 21 | Epoch Time: 0m 10s\n",
      "\t Train Loss: 0.004 | Train Acc: 99.95%\n",
      "\t test  Loss: 0.402 | test  Acc: 92.06%\n",
      "\t best  test acc: 92.66%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABOHUlEQVR4nO3deXxTVf4//tdt2qR7SildgEJBdoGy14K4USigCKIDIj+2cRkUGbEf5gvMyKqCK4MCwgyKyDgCwgCiIgqVAmIBLaCopbKUtkAXSmnSfUnO74/Q2LRpm7RJk9y+no/HfSS5uffkndwk95V7z72RhBACRERERDLh5ugCiIiIiGyJ4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGTFoeHm6NGjGDduHNq2bQtJkrB3794G50lISMCAAQOgUqnQpUsXbNmyxe51EhERketwaLgpKipCZGQk1q9fb9H0qampePDBB3H//ffj7NmzmDdvHp566il8/fXXdq6UiIiIXIXkLH+cKUkS9uzZgwkTJtQ5zYIFC/Dll1/il19+MY57/PHHkZ+fjwMHDjRDlUREROTs3B1dgDUSExMRExNjMi42Nhbz5s2rc56ysjKUlZUZb+v1euTl5aF169aQJMlepRIREZENCSFQUFCAtm3bws2t/h1PLhVusrKyEBISYjIuJCQEWq0WJSUl8PLyqjXPqlWrsHz58uYqkYiIiOwoIyMD7du3r3calwo3jbFo0SLExcUZb2s0GnTo0AEZGRnw9/d3YGVkM/v2AQsWANev/zGubVvg9deBhx9uWrvTptV9/3/+0/j2dTqgd2/TmmsKCQE+/xwoLwdKS4GSEssuL18GDh5suIY2bQB3d6CiAqisNFxWDc6xt5qag5cX4OkJ6PWARtPw9H5+gJsbUFZmGFz9veLh8cdr4O1teunlZRgKCoAjRxpu67HHgHbtDK9l9UGI2uOqhtRUIDGx4bbvuQfo2tXwmXVzM1wqFH9cVh+qj0tNBTZsaLj9v/0N6N694elqSkkB3nyz4em++AIYPtz69qvRarUIDw+Hn59fg9O6VLgJDQ1Fdna2ybjs7Gz4+/ub3WoDACqVCiqVqtZ4f39/hpvmpNMBx44BmZlAWJjhTa5QNL3d3buB6dNrf8FmZhrG79oFTJxofbuVlcDChfVPM3euIZxUVPzxRW/pkJdXf7ABgOxsYMgQ62u31I0b1k3v7m5YEQCGINWQTp2A4ODaX7wNDenphvdKQ6ZNA4YOBZRKQKUyXFa/bu7yxx+BSZMabnvzZkP4LCmxbkhJAU6ebLj9O+8E2rc3XRE1dJmZaXg/N2TZMmDgQMPz9fSsf3B3B6p2zyckAPff33D7+/YB9933x+3Kyvrf6+Xlhssffmj4MwUA8+cDPXsarlfV1tDl+fPAypUNt/3RR8C99xoCi7e34dKS7yGdDoiIAK5dMx/mJMmwPLdvt/57zdLXffly09fdUjqd4UdSQ7WvWtW472SdDti2reH2R4+2zXc+YFGXEpfrULx//36cO3fOOO6JJ55AXl6exR2KtVot1Go1NBoNw01z2b0beOEF4OrVP8a1bw+8807jgkeVqi+c6u1WV/Wh+uUXID/fECjy8oCbN00vzV3PzTW072heXoBa/ccvyJpD9V+XVUNWlmHl3JD164G77jIEloaGxqwEDx9u3JexPdu3dCWVmtq4L2JXrt2V27d37YDhe+yxxwzXqz9G1eeisT+kXLn25mr/NqvW38KBCgoKxJkzZ8SZM2cEALF69Wpx5swZkZaWJoQQYuHChWLatGnG6S9fviy8vb3F3/72N5GcnCzWr18vFAqFOHDggMWPqdFoBACh0Whs/nzIjP/9TwhJEsLwlv9jkCTD8L//Wd6WXi9EQYEQly8LceqUEKtW1W63uYe77xbiqaeEmDNHiLg4IRYtEmLZMkNtb78txLp1QmzaJMTWrULs2CHE3r1CfPWVEKtXW9b+4cPWv+aVlUK0b2/+da967cPDDdM1hqu3X/WerNl+Y96Tcqrd1du3d+1Vj9G+vWn74eHO/brYu/bmal9Yt/52aLg5fPiwAFBrmDFjhhBCiBkzZoh777231jz9+vUTSqVSdO7cWXz44YdWPSbDTR0qKw0r0k8+MVw29su3Zps13+w1P7jt2gnx669CHDsmxJ49Qvz730K8+qoQ8+YJMXWqEKNGCTFggOFD4unZ+BDi4SFEaKgQvXoJMXy4EOPHCzFrlhDz5wuxcqUQGzcKsXOnEPHxQpw5Ywgi9gof1V8brgQd1769vohduXZXb78ZVrB2+a4UwrVrb6b2XSbcOALDjRnmPlTt2zftQ1VRYXiDNzaM1DeoVIb6unSxbPr9+w1bfaxh7/AhBFeCjm7fnl/Erly7q7dv79rtyZVrbwbWrL+dps9Nc2Gfmxqq9pXWfBs0tK9UCCAnx7AfuGq4fPmP6+nplvdZ8fQ0HN3Upo3pEBRUe1ybNoCPj6E+e++rbo79yOb6I4WHA2vW2GQftd06csulfXty5dqJnJA162+Gm5bMkg65wcHAe+8Zwkr18JKaChQX19++u7vhSIqGNLbjKdA8HeXsGT4ArgSJiCzAcFMPhptqLD2yoy6SZDinQ6dOQOfOhsuqoXNnQzDq3Nm+RwEArr/1g4iIGmTN+tulznNDNnbtmmXTdeoEDBpUO7x06GA4l0Z93nnHsGVFksxvWVmzpulBYeJEYPx4+wUQhaLxW5aIiKjZMdy0RJcuGU5m9a9/WTb95s2NX7lPnGjYNWTuPDe23LXDAEJERLdxt1RLUVAA7NwJbNlievbXmltUqrPVbiOAu3aIiKhJuFuKDPR6w/+hbNli2HpS1QFYkoBRo4CZMw3BZupUw3h77TYCuGWFiIiaDcONK7F068fly8DWrYZdT1eu/DG+WzdDoJk2zbBFpopKZf/dRkRERM2E4cZVNPT/TIWFhq0zW7aY/nutvz/w+OOGUHPXXX9skanO3h1yiYiImhHDjSuo60R7164Bjz5qOJz71CmgqMgwXpKAmBhDoJkwwfDvtw3hbiMiIpIJhhtnp9MZttiY6/RbNe7wYcNlly6GQDN9uuE8L0RERC0Qw42zO3as7jMIV/fuu8Dzz5vf7URERNSCuDm6AGpAZqZl0wUFMdgQERGB4cb55edbNl1YmF3LICIichUMN86quBj429+AOXPqn06SDP1rhg9vnrqIiIicHMONMzp6FIiMBN56y9BpePhwQ4ipudvJ1ifaIyIikgGGG2dSUAA89xxw773AxYuGf9z+4gtD2Nm1y3C7uvbtDeN5oj0iombzo1aLB86exY9araNLoTrwaClnceAA8MwzQEaG4fYzzwBvvAGo1YbbPNEeEZFT2JqdjcP5+fhPdjYGtaT/KHQh3HLjaHl5hnPTjBljCDadOgHx8YZ/7K4KNlWqTrQ3ZYrhksGGiKgWe2xZSSstRVJBAU4XFGB7Tg4AYHtODk4XFCCpoABppaU2eRx7bxVy9fYtxS03jrR7t2E3VHa2of/MCy8Ar7wC+PjUOcuPWi3+3+XLeKNzZ5f7xeDKtZPj8H1D1rJmy0qJToebFRXIvT3crKz843q18Qdv3ao1b05FBQYmJRlvzwgJQZCHB1p7eCDo9lD9eqC7O9zd6t+mYO+tQq7evqUYbhwhO9twwr1duwy3e/YEPvgAiI5ucFZneeM0hivXbm/2XIHbOxzYu32+b+TJ1u+btNJS3CgvR5Fej/9mZwMAtmRlwcvNDbcqK1Gm16NciFqhpVivb/JjV/no9uPWJ8Dd/Y/gc/u6UpKgdHNDgLs7tmZlAQD+k52NgX5+UABo7eGBDp6ecJckiwa3GgefpJWWIreiAhKAHdW2Os0IDYUAEOThgY6eno1+3vZuvzEYbpqTEMDHHwPz5hl2RykUwMKFwEsvAfUseGd841jKlWuvzpVX4K74S+1ScTGulpejVKfDJ7dXGK74vnFlzvae1wuBnPJyXCsvx9WyMlwrKzO5/NbMOcG0Oh1er+rHWA93SaoVOMxtgcmtqMCM8+drzf9W584IuH1/zfBUdT2vshIAkF9ZifzKSlwsKam3pluVlWYfyxLS7eekuB12CnW6WtPU3OrUUaVq1GMBQFpZWa1xN2q0L5r5vwsZbppLRgbwl78AX31luN2vH7B5M9C/f4OzRpw4UWtczTdmc79xLGWudke/6RvDHitwewa/1JIS5JSXQ3e7TQD4JCcHE4OCIAAEurujQxPCQXppKfIqKyEB2Ha7/f9mZyPa3x/Fej08JAk+CgUKdToU6XQorDGYHafXG6+Xmvk17Srveblozvf8E8HByKmoQLkQqBSiVnC5VlaG6+XlqDD3H3sWkACMa90a9wUEmA0t/goFJAvO8H66oACAobOqvtrl/a1aYYCfX73zVur1uFVZaXYX2NH8fHyVl4e6np2/QgEPSUKlENABqLz9OlXW8XoIABVCWPV6mQsoTVH1yO6ShC09eti0bUtIQjTy3eKitFot1Go1NBoN/G39a0Snq300kyQBmzYZTshXUAAolcDSpYbbHh51NyUETmi1+Cw3F//JykJWRUWd03b29MTY1q0R5eeHKH9/dPHysuiDamtlej3OFhbipFZrHC7V08mu6k0/NSSkGau0XPUv4lE//YSblZXwVyjwYvv20AkBTzc3qN3djV8yNb90Gho+tmAT9mA/P4vb01W7brsN7c5pgK8v5rRrh4dat0awUunocmSj+nt+zM8/I6eiAsEeHviqb1+zgVsvhElQrRlaqwfWQp0Or6SlNak+CUCoUon2KhXaqVRof3tod3tcfmUlHvn111rzJQ0c2GD4sMTV0lIMTkpCuKcnngwLwweZmcgoLcUPAweifRO3JJ4uKDAJ71Xqq13c/qxb8v1wrrAQf/rtt1ptbO3RAz28vZtUOwCcLy7GdDNbmmz12gPWrb+55cZWdu82dAiu/ieXoaFA69ZA1YctOtrQt6ZnT7NNFOt0OHjrFj7LzcUXN2/iRrVA4w6gso6HvlxainXXrmHd7duB7u6I8vc3DH5+GOLvj8B6glQVazZDCyFwubTUGGJOaLU4W1iIcjNZuaNKZfZXQaC74e2nF6LWPmJnYG6rk1anw/ImfkFb44fbvxRdTbhKhXCVCr4KhcngU+N2XeN8FQr8XlyMoWfOmG3/dGEhnkxJgQQg2t8f44OC8HDr1uhRT2d8qp8QwqKtxJ08PY1Bxpb9VQCgjYcHenh7mw0u7VQqhCqV8KinQ25dW1Zspb2nJ65ER0MpSZAkCc+EhaFcCKga6CRsDWtqlyQJCgAKSUJDO5WKbu+aqtn+nT4+Ngkfitvf4fZ67a3FcGMLu3cDjz1m6FNTXVaWYVAqDeesef75WodvZ5eX44ubN/FZbi4O3rplsjk+wN0dYwMDMT4oCKFKJe49e7bWG2df794o0ulwQqvFyYICnCkoQF5lJb7Ky8NXeXnGtrp6eRnDTpS/PyJ9faGs8YGsbzP0rYoKnCooMIaZUwUFyDWzNal19WDl748hfn5ILS3FwKQkY80SDJsscyoq8P8lJ2Pt1av4Z5cuiK556LsDXSkpwb1qNY5oNGbvlwAM9PVFhJeXxZ38zA3XS0vxhpl/fX+9Uyd08/a2qA1FHeN/LSrC/T/9VKvtE/37o78NvszOFBTgLjPhw1a/1KpWGDXf89t69sTvJSX4LDcXpwsL8b1Wi++1Wiy4fBndvLwwPigI44OCcJe/v/EL11GcsaN4uV6PSyUlOF9cjJTiYqRUu26JVDNbY90Ai4OrpqICG8z8IfCPAwZgYBNfo2APD4R6eNTashJswY87S1UPMpIkQWWj95i9a3f19q3F3VJNpdMBERGmW2xqCgsz9Lm5HWzOFxXhs5s3sS83F4larcl+1o4qlfHLebhabfyVYunm0HK9Hj9V7Rq6HUYumOm4ppIkDPDzQ09vb9zh6Yk+vr54KiUFORUVaOPhgX926YJzhYX4vaQEvxYV4XczbSglCf19fU3CTGdPz1q7xMzVnl5aipmhoVh//bqxs9uU4GC81rlzk/qCNFVGaSleTUvDB1lZde7PBmy3Aq/aFF1zBW6L9u3ZdnO0b8l7PqO0FJ/f/nFwOD/fpI9BGw8PPNS6NcYHBWFkq1bwNnNeKHt3mv3rhQtYe+0a/tquHd7p2rXZ2hZC4EZFhSG8FBcbwktJCVKKi3G5pAS1u5caVO32ySwvr3XfW507I9LX12xw8XRzs3hXuL3fN2V6vXHLihDC5ltW7Mnetbt6+9asvxlumiohAbj/fuPNH7t1w//7y1/wxr/+hUG//w4A0Lm5ITE+Hp+Fh2Nfbm6toDDQ19cYaPr4+NT5JdHYN87NigqcquoHczvw3KqsaydX3e7w9DQJMv18fS1+49ZVe2ZZGV5KTcWHWVkQADzd3DA/PBwLwsPh6958GxavlZVhVVoaNmVmGnetxbRqhSeCg/HnlBSHrsCdse3maB+w7j2vqazE13l5+Cw3F1/evAlNtSNEvNzcMLJVKzwcFIRx1frp2DJ8lOv10FRW4teiIqSXlaGoshILU1Oh1emgViiwNCICbpKEQHd3tFOpLN66V33L3PWyMuRXVsJdkvDQuXPIqahAoLs7FnXogLTSUmRVVOBqWRlSiovr/Yz7KhTo7uWFHt7e6O7tbbzs6uWF5OJih4dWInMYbuph83CzbRvwxBPGm3+dOxdrJ07Es3v3YtSPP2LfsGH44q67cKNVK+M0HpKEBwICMP72F21zf6CFELhYUoKTWi0+ysrCITOHUAKGX3ETWrfGU23bYoifH4Ls2HHzTEEBXrx40bgbKEypxKrOnTEtJMSu/XGyysrwWno6Nl6/jrLbH4V71Wqs6NQJ9wQEON0K3Jnabo72G6tCr8dRjQb7cnPxWW5urT5ffX18cF9AAD7OzkZeZSWCPTywp3dvFNwODj4KhfGQ3fzKSmh0OtPb1a5XDSU27n/SVBKAjp6e6O7lZRJgenh7I0yprPNHlKu/50m+GG7qYY8tN2mPP45ctRoFXl54+NVXUeDjY+h/U+3LIwDA2OBgjA8KwujAQPg341aJhjSml749CCGwJzcXf7t0CZdv79cf6OuLNV264O6AAJs+Vk55Od5IT8d7168bV0p3q9VYERGB+6sFUYBfxK5OCIGfi4qMQSepsNCuj+cpSSit52u1g0oFP4Wi/iPf0PDhvjVJACYGBWFScDB63N4K49XIv2jhe56cEcNNPWwdbjRlZQhITGxwuvJhw+DhoI5VDbH3PnBrlen1ePfqVbycloaC27sW/tSmDV7v3BmdvLya1HZueTneysjA2mvXjEd63OXvjxUREYhp1cohh9BT81p79SrmXbxY55Ec3m5uCFEqEeDuDrW7OwKqDWqFwvR2jev+CgXc3dxs+oOh5uG+PxYU4L6zZ23SNpEr4aHgdlZQWYkvbt7EjpwcHKh2RJI57pWV2FJa6rTBBnC+Xu4qNzf8rUMHTA8NxZLUVLyfmYmdN25gX24uXgwPx6IOHaze8pVXUYG3MzLw7rVrxg7Mg/38sDwiAqMDAxlqWpC57dtjmFptNnzY4oid6mxxWGzNw339bm+NcZZDbomcEcONhYp0Onx58yY+zcnBl3l5Jods9/D2xj2XLuHfYWG15jtZVIQB48c3Z6lWa45zNzRGiFKJf3Xvjjnt2iHu4kXE5+fjtfR0fJiZiVc6dcKssLAGD/XNr6jAP69exZqrV6G9HWr6+/piRUQEHmzdmqGmhasZEGz1frDnDwZn+zFC5Iy4W6oeJTodvsrLw6c5Ofj85k2TE1Z18fLC5DZtMDk4GL19fHDmjTcwMCoKbno99G5uDt+1IzdCCHx+8ybmX7pkPLQ90scH/+zSxdhHpvphvd28vfHO1at4OyPDeNRMXx8fLI+IwPigIIaaFs7VO82yTwy1ROxzU4+GXpwyvR5f3w40n928afKHY508PTHpdqDp5+trsoK8OmoUBv/lLwj39cWTffrw8EY7Kdfrsf7aNSy/csUYWiYEBeHNzp3x7rVrWHvtGqL9/ZFSXGz8o7pe3t5YHhGBiW3aOOWZkMkxGBCIXAvDTT2qXpzhx45hdd++GOTvj3K9Hodu3cKOnBzszc017r4ADEc2TAoOxqQ2bTDIz8/8L/5bt4CgIJQpFFBevgypfXt+WdpZbnk5ll25gg3Xr0MPw/5VhSQZD+cGDCdE/L/wcDzXrp3Dz1RLRERNw3BTj6oXB198gQkdOiDQwwN7cnNNTnjVTqnEn24Hmih//4Z/7e/eDTz6qOE/o8z8MRnZj5SQ0OA0/PdoIiLXx6OlLLT35k3j9TYeHpgcHIzJbdpgqFpt3e6LgwcNlzExNq6QGvJxz56Yef682XOBVP3rOBERtSwtOtxUd6OiAmsbe/r1qnAzcqTtCiKLTA0JQU9vb7OH9Z4cMICduYmIWiB2CIHhF/7HPXs2bubUVODSJcDdHeDuD4dyq3FJREQtE7fcoIm/8A8dMlzedRfArQQOwfN+EBFRdS063NjkzJ7sb+NwznoSQiIicowW++3/zy5dMNDPD6EeHo3/ha/TAfHxhuvsb+NQKjc342H6kiQx2BARtWAtdsvNn8PC8IKfX9N+4Z89C+TlAf7+wJAhNq2PiIiIGqfFhhvg9i/8ppzcrWqX1P33GzoUExERkcNx231TsL8NERGR02G4aaziYuC77wzX2d+GiIjIaTDcNNZ33wHl5UB4ONCtm6OrISIiotsYbhqr+lmJ+aeMREREToPhprHY34aIiMgpMdw0RnY28NNPhusjRji2FiIiIjLBcNMY335ruOzXDwgOdmgpREREZIrhpjH4L+BEREROi+HGWkKwvw0REZETY7ixVkoKcPUqoFIBw4c7uhoiIiKqgeHGWocOGS7vvhvw8nJsLURERFQLw421uEuKiIjIqTHcWKOiAjh82HCdnYmJiIicEsONNU6dAgoKgNatgf79HV0NERERmcFwY42q/jYjRgBufOmIiIicEdfQ1mB/GyIiIqfHcGMprRY4ccJwnf1tiIiInJbDw8369esREREBT09PREVF4dSpU/VOv2bNGnTv3h1eXl4IDw/Hiy++iNLSUvsXmpAA6HRAly5ARIT9H4+IiIgaxaHhZseOHYiLi8PSpUtx+vRpREZGIjY2Fjk5OWan/+STT7Bw4UIsXboUycnJ+OCDD7Bjxw78/e9/t3+xVf1tuNWGiIjIqTk03KxevRpPP/00Zs2ahV69emHjxo3w9vbG5s2bzU7//fffY9iwYXjiiScQERGBUaNGYcqUKQ1u7bEJ9rchIiJyCQ4LN+Xl5UhKSkJMtbDg5uaGmJgYJCYmmp1n6NChSEpKMoaZy5cvY//+/Rg7dmydj1NWVgatVmsyWO3qVeD8ecMRUg88YP38RERE1GzcHfXAubm50Ol0CAkJMRkfEhKC8+fPm53niSeeQG5uLu6++24IIVBZWYnZs2fXu1tq1apVWL58edOKrdpqM3gwEBDQtLaIiIjIrhzeodgaCQkJWLlyJd577z2cPn0au3fvxpdffomXX365znkWLVoEjUZjHDIyMqx/YPa3ISIichkO23ITFBQEhUKB7Oxsk/HZ2dkIDQ01O8/ixYsxbdo0PPXUUwCAPn36oKioCM888wz+8Y9/wM3MifVUKhVUKlXjC9Xr/wg37G9DRETk9By25UapVGLgwIGIj483jtPr9YiPj0d0dLTZeYqLi2sFGIVCAQAQQtin0HPngJwcwMcHqKMuIiIich4O23IDAHFxcZgxYwYGDRqEIUOGYM2aNSgqKsKsWbMAANOnT0e7du2watUqAMC4ceOwevVq9O/fH1FRUbh48SIWL16McePGGUOOzVVttbn3XkCptM9jEBERkc04NNxMnjwZN27cwJIlS5CVlYV+/frhwIEDxk7G6enpJltqXnrpJUiShJdeegnXrl1DmzZtMG7cOLz66qv2K7KqMzH72xAREbkESdhtf45z0mq1UKvV0Gg08Pf3r3/i0lIgMBAoKTHsnurdu3mKJCIiIhPWrL9d6mipZvf994ZgExYG3Hmno6shIiIiCzDc1Kf6UVKS5NhaiIiIyCIMN/XhXy4QERG5HIabuty8CSQlGa4z3BAREbkMhpu6fPstIIShr03bto6uhoiIiCzEcFMX/uUCERGRS2K4qQv72xAREbkkhhtzLl0CUlMBDw/DmYmJiIjIZTDcmFO11SY6GvD1dWwtREREZBWGG3PY34aIiMhlMdzUpNMZjpQC2N+GiIjIBTHc1JSUBNy6BajVwKBBjq6GiIiIrMRwU1NVf5sHHgDcHfqn6URERNQIDDc1sb8NERGRS2O4qa6oCDh+3HCd/W2IiIhcEsNNdUePAhUVQMeOQJcujq6GiIiIGoHhprqq/jYjRwKS5NhaiIiIqFEYbqpjfxsiIiKXx3BTJSsLOHfOsMXmgQccXQ0RERE1EsNNlaqtNv37A0FBjq2FiIiIGo3hpkr1/jZERETkshhuAEAI9rchIiKSCYYbAEhOBq5fBzw9gWHDHF0NERERNQHDDfDHLqnhww0Bh4iIiFwWww3A/jZEREQywnBTUQEkJBiu8y8XiIiIXB7DzYkThv+UatMGiIx0dDVERETURAw3VbukRowA3PhyEBERuTquzdnfhoiISFZadrjRaIBTpwzX2d+GiIhIFlp2uDl8GNDrgW7dgA4dHF0NERER2UDLDjfcJUVERCQ7DDcAww0REZGMtNxwk54OXLgAKBTAffc5uhoiIiKykZYbbqpO3DdkCKBWO7QUIiIisp2WG24OHzZccpcUERGRrLTccFO15YbhhoiISFZabrjJywN8fYGoKEdXQkRERDbUcsMNAPTuzb9cICIikpmWvWY/cQKIiAB273Z0JURERGQjLTvcAMC1a8BjjzHgEBERyQTDjRCGy3nzAJ3OoaUQERFR0zHcAIaAk5EBHDvm6EqIiIioiRhuqsvMdHQFRERE1EQMN9WFhTm6AiIiImoid0cX4BQkCWjfHhg+3NGVEBERURNxy40kGS7XrDH8iSYRERG5NIab9u2BXbuAiRMdXQkRERHZQMvdLfX++8Addxh2RXGLDRERkWy03HDzpz8B/v6OroKIiIhsjLuliIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhwebtavX4+IiAh4enoiKioKp06dqnf6/Px8zJkzB2FhYVCpVOjWrRv279/fTNUSERGRs3Pov4Lv2LEDcXFx2LhxI6KiorBmzRrExsYiJSUFwcHBtaYvLy/HyJEjERwcjF27dqFdu3ZIS0tDQEBA8xdPRERETkkSQghHPXhUVBQGDx6MdevWAQD0ej3Cw8Mxd+5cLFy4sNb0GzduxJtvvonz58/Dw8OjUY+p1WqhVquh0Wjg7+/fpPqJiIioeViz/nbYbqny8nIkJSUhJibmj2Lc3BATE4PExESz8+zbtw/R0dGYM2cOQkJC0Lt3b6xcuRI6na7OxykrK4NWqzUZiIiISL4cFm5yc3Oh0+kQEhJiMj4kJARZWVlm57l8+TJ27doFnU6H/fv3Y/HixXj77bfxyiuv1Pk4q1atglqtNg7h4eE2fR5ERETkXBzeodgaer0ewcHB+Pe//42BAwdi8uTJ+Mc//oGNGzfWOc+iRYug0WiMQ0ZGRjNWTERERM3NYR2Kg4KCoFAokJ2dbTI+OzsboaGhZucJCwuDh4cHFAqFcVzPnj2RlZWF8vJyKJXKWvOoVCqoVCrbFk9EREROy2FbbpRKJQYOHIj4+HjjOL1ej/j4eERHR5udZ9iwYbh48SL0er1x3O+//46wsDCzwYaIiIhaHofuloqLi8OmTZvw0UcfITk5Gc8++yyKioowa9YsAMD06dOxaNEi4/TPPvss8vLy8MILL+D333/Hl19+iZUrV2LOnDmOegpERETkZBx6npvJkyfjxo0bWLJkCbKystCvXz8cOHDA2Mk4PT0dbm5/5K/w8HB8/fXXePHFF9G3b1+0a9cOL7zwAhYsWOCop0BEREROxqHnuXEEnueGiIjI9dj1PDclJSUoLi423k5LS8OaNWvwzTffWF8pERERkY1ZHW7Gjx+PrVu3AjD8z1NUVBTefvttjB8/Hhs2bLB5gURERETWsDrcnD59GsOHDwcA7Nq1CyEhIUhLS8PWrVvx7rvv2rxAIiIiImtYHW6Ki4vh5+cHAPjmm28wceJEuLm54a677kJaWprNCyQiIiKyhtXhpkuXLti7dy8yMjLw9ddfY9SoUQCAnJwcdtAlIiIih7M63CxZsgTz589HREQEoqKijCfc++abb9C/f3+bF0hERERkjUYdCp6VlYXMzExERkYaz0Nz6tQp+Pv7o0ePHjYv0pZ4KDgREZHrsWb93aiT+IWGhhr//0mr1eLbb79F9+7dnT7YEBERkfxZvVtq0qRJWLduHQDDOW8GDRqESZMmoW/fvvjf//5n8wKJiIiIrGF1uDl69KjxUPA9e/ZACIH8/Hy8++67eOWVV2xeIBEREZE1rA43Go0GgYGBAIADBw7g0Ucfhbe3Nx588EFcuHDB5gUSERERWcPqcBMeHo7ExEQUFRXhwIEDxkPBb926BU9PT5sXSERERGQNqzsUz5s3D1OnToWvry86duyI++67D4Bhd1WfPn1sXR8RERGRVawON8899xyGDBmCjIwMjBw50ngoeOfOndnnhoiIiByuUee5qVI1qyRJNivI3nieGyIiItdjzfrb6j43ALB161b06dMHXl5e8PLyQt++ffGf//ynUcUSERER2ZLVu6VWr16NxYsX4/nnn8ewYcMAAN999x1mz56N3NxcvPjiizYvkoiIiMhSVu+W6tSpE5YvX47p06ebjP/oo4+wbNkypKam2rRAW+NuKSIiItdj191SmZmZGDp0aK3xQ4cORWZmprXNEREREdmU1eGmS5cu+PTTT2uN37FjB7p27WqTooiIiIgay+o+N8uXL8fkyZNx9OhRY5+b48ePIz4+3mzoISIiImpOVm+5efTRR3Hy5EkEBQVh79692Lt3L4KCgnDq1Ck88sgj9qiRiIiIyGJNOs9NdTk5OXj//ffx97//3RbN2Q07FBMREbkeu5/nxpzMzEwsXrzYVs0RERERNYrNwg0RERGRM2C4ISIiIllhuCEiIiJZsfhQ8Li4uHrvv3HjRpOLISIiImoqi8PNmTNnGpzmnnvuaVIxRERERE1lcbg5fPiwPesgIiIisgn2uSEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWbH4aKmff/654cbc3REaGorAwMAmFUVERETUWBaHm379+kGSJDT0J+KSJCEyMhJbt25F7969m1wgERERkTUsDjepqakNTqPX65GdnY0333wTzz77LI4dO9ak4oiIiIisJYmGNsU0wsWLFxEZGYmioiJbN91kWq0WarUaGo0G/v7+ji6HiIiILGDN+tviLTfmFBUVYceOHSgpKcGoUaPQtWtXAECnTp3w/fffN6VpIiIiokax+Gip9PR03HvvvfDz88PIkSORnp6OAQMG4KmnnsLcuXPRr18/HD16FACgUCgQGRlpt6KJiIiI6mJxuJk/fz7Ky8uxceNGeHt7IzY2Fl27dkVmZiays7MxZswYLFu2zI6lEhERETXM4j43oaGh2LdvH4YMGYK8vDwEBQXh+PHjiI6OBgD89NNPGDFiBHJzc+1acFOxzw0REZHrsWb9bfGWm5ycHHTs2BEAEBgYCG9vb4SEhBjvDw0Nxa1btxpZMhEREZFtWHWGYkmSzF4nIiIichZWHS21ZMkSeHt7AwDKy8vx6quvQq1WAwCKi4ttXx0RERGRlSzuc3PfffdZtLXm8OHDTS7KntjnhoiIyPXY5Tw3CQkJTa2LiIiIyO74r+BEREQkKxZvuZk4caLZ8Wq1Gt26dcNTTz2FNm3a2KwwIiIiosaweMuNWq02O+Tn52PTpk3o3r07fvnlF3vWSkRERNQgm/xxpl6vx9NPP42cnBx8/vnntqjLbtihmIiIyPXY5SR+9Tbi5oa//vWvSEpKskVzRERERI1msw7FPj4+PNcNEREROZzNws3BgwfRrVs3WzVHRERE1CgWHy21b98+s+M1Gg2SkpLw/vvv4/3337dZYURERESNYXG4mTBhgtnxfn5+6N69O95//308/vjjtqqLiIiIqFEsDjd6vd6edRARERHZBM9QTERERLJicbhJTEzEF198YTJu69at6NSpE4KDg/HMM8+grKzM5gUSERERWcPicLNixQr8+uuvxtvnzp3Dk08+iZiYGCxcuBCff/45Vq1aZZciiYiIiCxlcbg5e/YsRowYYby9fft2REVFYdOmTYiLi8O7776LTz/91C5FEhEREVnK4nBz69YthISEGG8fOXIEY8aMMd4ePHgwMjIybFsdERERkZUsDjchISFITU0FAJSXl+P06dO46667jPcXFBTAw8OjUUWsX78eERER8PT0RFRUFE6dOmXRfNu3b4ckSXUepk5EREQtj8XhZuzYsVi4cCGOHTuGRYsWwdvbG8OHDzfe//PPP+OOO+6wuoAdO3YgLi4OS5cuxenTpxEZGYnY2Fjk5OTUO9+VK1cwf/58kxqIiIiILA43L7/8Mtzd3XHvvfdi06ZN2LRpE5RKpfH+zZs3Y9SoUVYXsHr1ajz99NOYNWsWevXqhY0bN8Lb2xubN2+ucx6dToepU6di+fLl6Ny5s9WPSURERPJl8Un8goKCcPToUWg0Gvj6+kKhUJjcv3PnTvj6+lr14OXl5UhKSsKiRYuM49zc3BATE4PExMQ651uxYgWCg4Px5JNP4tixY/U+RllZmckh6lqt1qoaiYiIyLVYfRI/tVpdK9gAQGBgoMmWHEvk5uZCp9OZdFQGDP17srKyzM7z3Xff4YMPPsCmTZsseoxVq1ZBrVYbh/DwcKtqJCIiItfiUmcoLigowLRp07Bp0yYEBQVZNM+iRYug0WiMA4/oIiIikjeLd0vZQ1BQEBQKBbKzs03GZ2dnIzQ0tNb0ly5dwpUrVzBu3DjjuKr/vHJ3d0dKSkqtTs0qlQoqlcoO1RMREZEzcuiWG6VSiYEDByI+Pt44Tq/XIz4+HtHR0bWm79GjB86dO4ezZ88ah4cffhj3338/zp49y11ORERE5NgtNwAQFxeHGTNmYNCgQRgyZAjWrFmDoqIizJo1CwAwffp0tGvXDqtWrYKnpyd69+5tMn9AQAAA1BpPRERELZPDw83kyZNx48YNLFmyBFlZWejXrx8OHDhg7GScnp4ONzeX6hpEREREDiQJIYSji2hOWq0WarUaGo0G/v7+ji6HiIiILGDN+pubRIiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVpwi3Kxfvx4RERHw9PREVFQUTp06Vee0mzZtwvDhw9GqVSu0atUKMTEx9U5PRERELYvDw82OHTsQFxeHpUuX4vTp04iMjERsbCxycnLMTp+QkIApU6bg8OHDSExMRHh4OEaNGoVr1641c+VERETkjCQhhHBkAVFRURg8eDDWrVsHANDr9QgPD8fcuXOxcOHCBufX6XRo1aoV1q1bh+nTpzc4vVarhVqthkajgb+/f5PrJyIiIvuzZv3t0C035eXlSEpKQkxMjHGcm5sbYmJikJiYaFEbxcXFqKioQGBgoNn7y8rKoNVqTQYiIiKSL4eGm9zcXOh0OoSEhJiMDwkJQVZWlkVtLFiwAG3btjUJSNWtWrUKarXaOISHhze5biIiInJeDu9z0xSvvfYatm/fjj179sDT09PsNIsWLYJGozEOGRkZzVwlERERNSd3Rz54UFAQFAoFsrOzTcZnZ2cjNDS03nnfeustvPbaazh06BD69u1b53QqlQoqlcom9RIREZHzc+iWG6VSiYEDByI+Pt44Tq/XIz4+HtHR0XXO98Ybb+Dll1/GgQMHMGjQoOYolYiIiFyEQ7fcAEBcXBxmzJiBQYMGYciQIVizZg2Kioowa9YsAMD06dPRrl07rFq1CgDw+uuvY8mSJfjkk08QERFh7Jvj6+sLX19fhz0PIiIicg4ODzeTJ0/GjRs3sGTJEmRlZaFfv344cOCAsZNxeno63Nz+2MC0YcMGlJeX47HHHjNpZ+nSpVi2bFlzlk5EREROyOHnuWluPM8NERGR63GZ89wQERER2RrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJirujC3BWOp0OFRUVji6DmkCpVMLNjfmdiKilYbipQQiBrKws5OfnO7oUaiI3Nzd06tQJSqXS0aUQEVEzYripoSrYBAcHw9vbG5IkObokagS9Xo/r168jMzMTHTp04HIkImpBGG6q0el0xmDTunVrR5dDTdSmTRtcv34dlZWV8PDwcHQ5RETUTNghoZqqPjbe3t4OroRsoWp3lE6nc3AlRETUnBhuzOAuDHngciQiapkYboiIiEhWGG6IiIhIVhhu7EWnAxISgG3bDJcu1O8jIiICa9assUlbCQkJkCSJh9YTEVGz4dFS9rB7N/DCC8DVq3+Ma98eeOcdYOJEuzzkfffdh379+tkklPzwww/w8fFpelFEREQOwC03trZ7N/DYY6bBBgCuXTOM373bIWUJIVBZWWnRtG3atOERY0RE5LIYbhoiBFBUZNmg1QJ//athHnPtAIYtOlqtZe2Za8eMmTNn4siRI3jnnXcgSRIkScKWLVsgSRK++uorDBw4ECqVCt999x0uXbqE8ePHIyQkBL6+vhg8eDAOHTpk0l7N3VKSJOH999/HI488Am9vb3Tt2hX79u1r7CuK//3vf7jzzjuhUqkQERGBt99+2+T+9957D127doWnpydCQkLw2GOPGe/btWsX+vTpAy8vL7Ru3RoxMTEoKipqdC1ERCQ/DDcNKS4GfH0tG9Rqwxaaughh2KKjVlvWXnGxRSW+8847iI6OxtNPP43MzExkZmYiPDwcALBw4UK89tprSE5ORt++fVFYWIixY8ciPj4eZ86cwejRozFu3Dikp6fX+xjLly/HpEmT8PPPP2Ps2LGYOnUq8vLyLH4ZqyQlJWHSpEl4/PHHce7cOSxbtgyLFy/Gli1bAAA//vgj/vrXv2LFihVISUnBgQMHcM899wAAMjMzMWXKFPz5z39GcnIyEhISMHHiRAgLQyAREbUM7HMjA2q1GkqlEt7e3ggNDQUAnD9/HgCwYsUKjBw50jhtYGAgIiMjjbdffvll7NmzB/v27cPzzz9f52PMnDkTU6ZMAQCsXLkS7777Lk6dOoXRo0dbVevq1asxYsQILF68GADQrVs3/Pbbb3jzzTcxc+ZMpKenw8fHBw899BD8/PzQsWNH9O/fH4Ah3FRWVmLixIno2LEjAKBPnz5WPT4REckft9w0xNsbKCy0bNi/37I29++3rD0b9HsZNGiQye3CwkLMnz8fPXv2REBAAHx9fZGcnNzglpu+ffsar/v4+MDf3x85OTlW15OcnIxhw4aZjBs2bBguXLgAnU6HkSNHomPHjujcuTOmTZuG//73vyi+vQUrMjISI0aMQJ8+ffCnP/0JmzZtwq1bt6yugYiI5I3hpiGSBPj4WDaMGmU4KqquM+NKEhAebpjOkvZscIbdmkc9zZ8/H3v27MHKlStx7NgxnD17Fn369EF5eXm97dT8byZJkqDX65tcX01+fn44ffo0tm3bhrCwMCxZsgSRkZHIz8+HQqHAwYMH8dVXX6FXr15Yu3YtunfvjtTUVJvXQURErovhxpYUCsPh3kDtYFJ1e80aw3Q2plQqLfoPpePHj2PmzJl45JFH0KdPH4SGhuLKlSs2r6cuPXv2xPHjx2vV1K1bNyhuvy7u7u6IiYnBG2+8gZ9//hlXrlzBt99+C8AQqoYNG4bly5fjzJkzUCqV2LNnT7PVT0REzo99bmxt4kRg1y7z57lZs8Zu57mJiIjAyZMnceXKFfj6+ta5VaVr167YvXs3xo0bB0mSsHjxYrtsganL//3f/2Hw4MF4+eWXMXnyZCQmJmLdunV47733AABffPEFLl++jHvuuQetWrXC/v37odfr0b17d5w8eRLx8fEYNWoUgoODcfLkSdy4cQM9e/ZstvqJiMj5ccuNPUycCFy5Ahw+DHzyieEyNdVuwQYw7G5SKBTo1asX2rRpU2cfmtWrV6NVq1YYOnQoxo0bh9jYWAwYMMBuddU0YMAAfPrpp9i+fTt69+6NJUuWYMWKFZg5cyYAICAgALt378YDDzyAnj17YuPGjdi2bRvuvPNO+Pv74+jRoxg7diy6deuGl156CW+//TbGjBnTbPUTEZHzk0QLO45Wq9VCrVZDo9HA39/f5L7S0lKkpqaiU6dO8PT0dFCFZCtcnkRE8lHf+rsmbrkhIiIiWWG4oSaZPXs2fH19zQ6zZ892dHlERNQCsUMxNcmKFSswf/58s/c1tNmQiIjIHhhuqEmCg4MRHBzs6DKIiIiMuFuKiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YZs4sqVK5AkCWfPnnV0KURE1MIx3NjRj1otHjh7Fj9qtXZ/rPvuuw/z5s2zWXszZ87EhAkTbNYeERFRc2G4saOt2dk4nJ+P/2RnO7oUIiKiFoPhpgFCCBTpdBYPyUVF+C4/H8c1GmzPyQEAbMvJwXGNBt/l5yO5qMjitiz9T9OZM2fiyJEjeOeddyBJEiRJwpUrV/DLL79gzJgx8PX1RUhICKZNm4bc3FzjfLt27UKfPn3g5eWF1q1bIyYmBkVFRVi2bBk++ugjfPbZZ8b2EhISrH7tjhw5giFDhkClUiEsLAwLFy5EZWVlg48PAAkJCRgyZAh8fHwQEBCAYcOGIS0tzeoaiIio5eEZihtQrNfD99ixJrVxo6ICd585Y/V8hcOHw0ehaHC6d955B7///jt69+6NFStWAAA8PDwwZMgQPPXUU/jnP/+JkpISLFiwAJMmTcK3336LzMxMTJkyBW+88QYeeeQRFBQU4NixYxBCYP78+UhOToZWq8WHH34IAAgMDLSq9mvXrmHs2LGYOXMmtm7divPnz+Ppp5+Gp6cnli1bVu/jV1ZWYsKECXj66aexbds2lJeX49SpU5AkyerXkIiIWh6GGxlQq9VQKpXw9vZGaGgoAOCVV15B//79sXLlSuN0mzdvRnh4OH7//XcUFhaisrISEydORMeOHQEAffr0MU7r5eWFsrIyY3vWeu+99xAeHo5169ZBkiT06NED169fx4IFC7BkyRJkZmbW+fh5eXnQaDR46KGHcMcddwAAevbs2ag6iIio5WG4aYC3mxsKhw+3ap6zhYVmt9R8178/+vn6WvXYjfXTTz/h8OHD8DXzeJcuXcKoUaMwYsQI9OnTB7GxsRg1ahQee+wxtGrVqtGPWV1ycjKio6NNtrYMGzYMhYWFuHr1KiIjI+t8/MDAQMycOROxsbEYOXIkYmJiMGnSJISFhdmkNiIikjf2uWmAJEnwUSisGrxuh5KqF7fq0svNzap2mrIbprCwEOPGjcPZs2dNhgsXLuCee+6BQqHAwYMH8dVXX6FXr15Yu3YtunfvjtTU1Ka9YBZq6PE//PBDJCYmYujQodixYwe6deuGEydONEttRETk2hhu7CDYwwOhHh4Y6OeHjd26YaCfH0I9PBDs4WG3x1QqldDpdMbbAwYMwK+//oqIiAh06dLFZPDx8QFgCG7Dhg3D8uXLcebMGSiVSuzZs8dse9bq2bMnEhMTTTpFHz9+HH5+fmjfvn2Djw8A/fv3x6JFi/D999+jd+/e+OSTTxpdDxERtRwMN3bQ3tMTV6KjcXLAAPylbVucHDAAV6Kj0d7T026PGRERgZMnT+LKlSvIzc3FnDlzkJeXhylTpuCHH37ApUuX8PXXX2PWrFnQ6XQ4efIkVq5ciR9//BHp6enYvXs3bty4YezbEhERgZ9//hkpKSnIzc1FRUWFVfU899xzyMjIwNy5c3H+/Hl89tlnWLp0KeLi4uDm5lbv46empmLRokVITExEWloavvnmG1y4cIH9boiIyDKihdFoNAKA0Gg0te4rKSkRv/32mygpKXFAZU2TkpIi7rrrLuHl5SUAiNTUVPH777+LRx55RAQEBAgvLy/Ro0cPMW/ePKHX68Vvv/0mYmNjRZs2bYRKpRLdunUTa9euNbaXk5MjRo4cKXx9fQUAcfjw4XofPzU1VQAQZ86cMY5LSEgQgwcPFkqlUoSGhooFCxaIiooKIYSo9/GzsrLEhAkTRFhYmFAqlaJjx45iyZIlQqfTWfWauPLyJCIiU/Wtv2uShLDwZCoyodVqoVarodFo4O/vb3JfaWkpUlNT0alTJ3jacSsLNQ8uTyIi+ahv/V0Td0sRERGRrDDckEVWrlwJX19fs8OYMWMcXR4REZERz3NDFpk9ezYmTZpk9j4vL69mroaIiKhuDDdkkcDAQKv/goGIiMgRuFvKjBbWx1q2uByJiFomhptqPG6fZK+4uNjBlZAtlJeXAzCcDZmIiFoOp9gttX79erz55pvIyspCZGQk1q5diyFDhtQ5/c6dO7F48WJcuXIFXbt2xeuvv46xY8c2uQ6FQoGAgADk5OQAALy9vflP1C5Kr9fjxo0b8Pb2hru7U7zNiYiomTj8W3/Hjh2Ii4vDxo0bERUVhTVr1iA2NhYpKSkIDg6uNf3333+PKVOmYNWqVXjooYfwySefYMKECTh9+jR69+7d5Hqq/gW7KuCQ63Jzc0OHDh0YUImIWhiHn8QvKioKgwcPxrp16wAYfnGHh4dj7ty5WLhwYa3pJ0+ejKKiInzxxRfGcXfddRf69euHjRs3Nvh4lp4ESKfTWf2XA+RclEol3Jrwz+pEROQ8rDmJn0O33JSXlyMpKQmLFi0yjnNzc0NMTAwSExPNzpOYmIi4uDiTcbGxsdi7d6/Z6cvKylBWVma8rdVqLapNoVCwrwYREZELcujP2tzcXOh0OoSEhJiMDwkJQVZWltl5srKyrJp+1apVUKvVxiE8PNw2xRMREZFTkv02+0WLFkGj0RiHjIwMR5dEREREduTQ3VJBQUFQKBTIzs42GZ+dnW3s2FtTaGioVdOrVCqoVCrbFExEREROz6HhRqlUYuDAgYiPj8eECRMAGDoUx8fH4/nnnzc7T3R0NOLj4zFv3jzjuIMHDyI6Otqix6zqP21p3xsiIiJyvKr1tkXHQQkH2759u1CpVGLLli3it99+E88884wICAgQWVlZQgghpk2bJhYuXGic/vjx48Ld3V289dZbIjk5WSxdulR4eHiIc+fOWfR4GRkZAgAHDhw4cODAwQWHjIyMBtf1Dj/PzeTJk3Hjxg0sWbIEWVlZ6NevHw4cOGDsNJyenm5yOO/QoUPxySef4KWXXsLf//53dO3aFXv37rX4HDdt27bFb7/9hl69eiEjI6PBw8lcnVarRXh4OJ+rzPC5yhOfqzzxudqGEAIFBQVo27Ztg9M6/Dw3jmDNsfKujs9Vnvhc5YnPVZ74XJuf7I+WIiIiopaF4YaIiIhkpUWGG5VKhaVLl7aIQ8T5XOWJz1We+Fzlic+1+bXIPjdEREQkXy1yyw0RERHJF8MNERERyQrDDREREckKww0RERHJiizDzfr16xEREQFPT09ERUXh1KlT9U6/c+dO9OjRA56enujTpw/279/fTJU2zapVqzB48GD4+fkhODgYEyZMQEpKSr3zbNmyBZIkmQyenp7NVHHjLVu2rFbdPXr0qHceV12uERERtZ6rJEmYM2eO2eldaZkePXoU48aNQ9u2bSFJEvbu3WtyvxACS5YsQVhYGLy8vBATE4MLFy402K61n/nmUN9zraiowIIFC9CnTx/4+Pigbdu2mD59Oq5fv15vm435HDSHhpbrzJkza9U9evToBtt1teUKwOxnV5IkvPnmm3W26YzL1ZL1S2lpKebMmYPWrVvD19cXjz76aK0/tq6psZ9xa8ku3OzYsQNxcXFYunQpTp8+jcjISMTGxiInJ8fs9N9//z2mTJmCJ598EmfOnMGECRMwYcIE/PLLL81cufWOHDmCOXPm4MSJEzh48CAqKiowatQoFBUV1Tufv78/MjMzjUNaWlozVdw0d955p0nd3333XZ3TuvJy/eGHH0ye58GDBwEAf/rTn+qcx1WWaVFRESIjI7F+/Xqz97/xxht49913sXHjRpw8eRI+Pj6IjY1FaWlpnW1a+5lvLvU91+LiYpw+fRqLFy/G6dOnsXv3bqSkpODhhx9usF1rPgfNpaHlCgCjR482qXvbtm31tumKyxWAyXPMzMzE5s2bIUkSHn300Xrbdbblasn65cUXX8Tnn3+OnTt34siRI7h+/TomTpxYb7uN+Yw3ipX/c+n0hgwZIubMmWO8rdPpRNu2bcWqVavMTj9p0iTx4IMPmoyLiooSf/nLX+xapz3k5OQIAOLIkSN1TvPhhx8KtVrdfEXZyNKlS0VkZKTF08tpub7wwgvijjvuEHq93uz9rrpMAYg9e/YYb+v1ehEaGirefPNN47j8/HyhUqnEtm3b6mzH2s+8I9R8ruacOnVKABBpaWl1TmPt58ARzD3XGTNmiPHjx1vVjlyW6/jx48UDDzxQ7zSusFxrrl/y8/OFh4eH2Llzp3Ga5ORkAUAkJiaabaOxn/HGkNWWm/LyciQlJSEmJsY4zs3NDTExMUhMTDQ7T2Jiosn0ABAbG1vn9M5Mo9EAAAIDA+udrrCwEB07dkR4eDjGjx+PX3/9tTnKa7ILFy6gbdu26Ny5M6ZOnYr09PQ6p5XLci0vL8fHH3+MP//5z5Akqc7pXHWZVpeamoqsrCyT5aZWqxEVFVXncmvMZ95ZaTQaSJKEgICAeqez5nPgTBISEhAcHIzu3bvj2Wefxc2bN+ucVi7LNTs7G19++SWefPLJBqd19uVac/2SlJSEiooKk2XUo0cPdOjQoc5l1JjPeGPJKtzk5uZCp9MZ/1G8SkhICLKysszOk5WVZdX0zkqv12PevHkYNmxYvf+Q3r17d2zevBmfffYZPv74Y+j1egwdOhRXr15txmqtFxUVhS1btuDAgQPYsGEDUlNTMXz4cBQUFJidXi7Lde/evcjPz8fMmTPrnMZVl2lNVcvGmuXWmM+8MyotLcWCBQswZcqUev9s0NrPgbMYPXo0tm7divj4eLz++us4cuQIxowZA51OZ3Z6uSzXjz76CH5+fg3uqnH25Wpu/ZKVlQWlUlkrjDe0vq2axtJ5Gsvdpq2Rw8yZMwe//PJLg/tpo6OjER0dbbw9dOhQ9OzZE//617/w8ssv27vMRhszZozxet++fREVFYWOHTvi008/tehXkav64IMPMGbMGLRt27bOaVx1mZJBRUUFJk2aBCEENmzYUO+0rvo5ePzxx43X+/Tpg759++KOO+5AQkICRowY4cDK7Gvz5s2YOnVqgx38nX25Wrp+cSay2nITFBQEhUJRq7d2dnY2QkNDzc4TGhpq1fTO6Pnnn8cXX3yBw4cPo3379lbN6+Hhgf79++PixYt2qs4+AgIC0K1btzrrlsNyTUtLw6FDh/DUU09ZNZ+rLtOqZWPNcmvMZ96ZVAWbtLQ0HDx4sN6tNuY09DlwVp07d0ZQUFCddbv6cgWAY8eOISUlxerPL+Bcy7Wu9UtoaCjKy8uRn59vMn1D69uqaSydp7FkFW6USiUGDhyI+Ph44zi9Xo/4+HiTX7bVRUdHm0wPAAcPHqxzemcihMDzzz+PPXv24Ntvv0WnTp2sbkOn0+HcuXMICwuzQ4X2U1hYiEuXLtVZtysv1yoffvghgoOD8eCDD1o1n6su006dOiE0NNRkuWm1Wpw8ebLO5daYz7yzqAo2Fy5cwKFDh9C6dWur22joc+Csrl69ips3b9ZZtysv1yoffPABBg4ciMjISKvndYbl2tD6ZeDAgfDw8DBZRikpKUhPT69zGTXmM96UJyAr27dvFyqVSmzZskX89ttv4plnnhEBAQEiKytLCCHEtGnTxMKFC43THz9+XLi7u4u33npLJCcni6VLlwoPDw9x7tw5Rz0Fiz377LNCrVaLhIQEkZmZaRyKi4uN09R8vsuXLxdff/21uHTpkkhKShKPP/648PT0FL/++qsjnoLF/u///k8kJCSI1NRUcfz4cRETEyOCgoJETk6OEEJey1UIw5EhHTp0EAsWLKh1nysv04KCAnHmzBlx5swZAUCsXr1anDlzxniE0GuvvSYCAgLEZ599Jn7++Wcxfvx40alTJ1FSUmJs44EHHhBr16413m7oM+8o9T3X8vJy8fDDD4v27duLs2fPmnx+y8rKjG3UfK4NfQ4cpb7nWlBQIObPny8SExNFamqqOHTokBgwYIDo2rWrKC0tNbYhh+VaRaPRCG9vb7FhwwazbbjCcrVk/TJ79mzRoUMH8e2334off/xRREdHi+joaJN2unfvLnbv3m28bcln3BZkF26EEGLt2rWiQ4cOQqlUiiFDhogTJ04Y77v33nvFjBkzTKb/9NNPRbdu3YRSqRR33nmn+PLLL5u54sYBYHb48MMPjdPUfL7z5s0zvjYhISFi7Nix4vTp081fvJUmT54swsLChFKpFO3atROTJ08WFy9eNN4vp+UqhBBff/21ACBSUlJq3efKy/Tw4cNm37NVz0ev14vFixeLkJAQoVKpxIgRI2q9Bh07dhRLly41GVffZ95R6nuuqampdX5+Dx8+bGyj5nNt6HPgKPU91+LiYjFq1CjRpk0b4eHhITp27CiefvrpWiFFDsu1yr/+9S/h5eUl8vPzzbbhCsvVkvVLSUmJeO6550SrVq2Et7e3eOSRR0RmZmatdqrPY8ln3Bak2w9OREREJAuy6nNDRERExHBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDRC2eJEnYu3evo8sgIhthuCEih5o5cyYkSao1jB492tGlEZGLcnd0AUREo0ePxocffmgyTqVSOagaInJ13HJDRA6nUqkQGhpqMrRq1QqAYZfRhg0bMGbMGHh5eaFz587YtWuXyfznzp3DAw88AC8vL7Ru3RrPPPMMCgsLTabZvHkz7rzzTqhUKoSFheH55583uT83NxePPPIIvL290bVrV+zbt8++T5qI7Ibhhoic3uLFi/Hoo4/ip59+wtSpU/H4448jOTkZAFBUVITY2Fi0atUKP/zwA3bu3IlDhw6ZhJcNGzZgzpw5eOaZZ3Du3Dns27cPXbp0MXmM5cuXY9KkSfj5558xduxYTJ06FXl5ec36PInIRmz+V5xERFaYMWOGUCgUwsfHx2R49dVXhRCGfxWePXu2yTxRUVHi2WefFUII8e9//1u0atVKFBYWGu//8ssvhZubm/Gfp9u2bSv+8Y9/1FkDAPHSSy8ZbxcWFgoA4quvvrLZ8ySi5sM+N0TkcPfffz82bNhgMi4wMNB4PTo62uS+6OhonD17FgCQnJyMyMhI+Pj4GO8fNmwY9Ho9UlJSIEkSrl+/jhEjRtRbQ9++fY3XfXx84O/vj5ycnMY+JSJyIIYbInI4Hx+fWruJbMXLy8ui6Tw8PExuS5IEvV5vj5KIyM7Y54aInN6JEydq3e7ZsycAoGfPnvjpp59QVFRkvP/48eNwc3ND9+7d4efnh4iICMTHxzdrzUTkONxyQ0QOV1ZWhqysLJNx7u7uCAoKAgDs3LkTgwYNwt13343//ve/OHXqFD744AMAwNSpU7F06VLMmDEDy5Ytw40bNzB37lxMmzYNISEhAIBly5Zh9uzZCA4OxpgxY1BQUIDjx49j7ty5zftEiahZMNwQkcMdOHAAYWFhJuO6d++O8+fPAzAcybR9+3Y899xzCAsLw7Zt29CrVy8AgLe3N77++mu88MILGDx4MLy9vfHoo49i9erVxrZmzJiB0tJS/POf/8T8+fMRFBSExx57rPmeIBE1K0kIIRxdBBFRXSRJwp49ezBhwgRHl0JELoJ9boiIiEhWGG6IiIhIVtjnhoicGvecE5G1uOWGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhk5f8HilnjScTbIR8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}