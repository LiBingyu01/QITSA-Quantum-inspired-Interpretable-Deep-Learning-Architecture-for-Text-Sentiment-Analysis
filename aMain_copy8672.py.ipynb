{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_SET: CR\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'CR'\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "N_EPOCHS = 26\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4749, 100])\n",
      "4749\n",
      "4749\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100  # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        # 并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = []  # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0:  # 第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp)  # 每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls)  # 将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))  # word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_weight_matrix[3]\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "\n",
    "\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    # if len(tmp_sen) != 0:\n",
    "    #     # 补齐\n",
    "    #     for _ in range(batch_size - len(tmp_sen)):\n",
    "    #         tmp_sen.append(sentence[0])\n",
    "    #         tmp_label.append(sentence[2])\n",
    "    #         tmp_sentiment.append(array_sentiment[1])\n",
    "    #\n",
    "    #     sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "    #     # OR去掉\n",
    "    #     break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "import nltk\n",
    "\n",
    "\n",
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "def negate_sequence(words):\n",
    "    \"\"\"\n",
    "    处理否定词\n",
    "    \"\"\"\n",
    "    negation = False\n",
    "    result = []\n",
    "    for word in words:\n",
    "        if any(neg in word for neg in [\"not\", \"n't\", \"no\"]):\n",
    "            negation = not negation\n",
    "        elif negation:\n",
    "            word = \"not_\" + word\n",
    "        result.append(word)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    # sentences_negated = negate_sequence(tokenized_sentence)\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        xx = sentence\n",
    "        ss = get_word_sentiment_scores(xx)\n",
    "        batch_word_scores.append(ss)\n",
    "    # batch_word_scores = [get_word_sentiment_scores(sentence) for sentence in batch_tokenized_sentences[0]]\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)  # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED)  # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.gru = nn.LSTM(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.gru(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "        # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "        # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "        # # ================ 7、全连接层 ================\n",
    "        # self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "        # self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.self_attention2(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        # # ================ 5、取对角线 ================\n",
    "        # diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "        # diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "        # diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "        # diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "        #\n",
    "        # # ================ 6、全连接 ================\n",
    "        # diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "        # fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "        # fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "        return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_idx 1\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 931,301 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), 0.001)  # 优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    # round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "    #     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float()  # convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "\n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(\n",
    "        pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.656 | Train Acc: 63.62%\n",
      "\t test  Loss: 0.649 | test  Acc: 64.06%\n",
      "\t best  test acc: 64.06%\n",
      "Epoch: 02 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.640 | Train Acc: 63.62%\n",
      "\t test  Loss: 0.645 | test  Acc: 64.06%\n",
      "\t best  test acc: 64.06%\n",
      "Epoch: 03 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.630 | Train Acc: 63.62%\n",
      "\t test  Loss: 0.631 | test  Acc: 64.06%\n",
      "\t best  test acc: 64.06%\n",
      "Epoch: 04 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.611 | Train Acc: 64.02%\n",
      "\t test  Loss: 0.622 | test  Acc: 65.36%\n",
      "\t best  test acc: 65.36%\n",
      "Epoch: 05 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.619 | Train Acc: 65.31%\n",
      "\t test  Loss: 0.657 | test  Acc: 64.06%\n",
      "\t best  test acc: 65.36%\n",
      "Epoch: 06 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.610 | Train Acc: 65.94%\n",
      "\t test  Loss: 0.571 | test  Acc: 71.88%\n",
      "\t best  test acc: 71.88%\n",
      "Epoch: 07 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.540 | Train Acc: 74.83%\n",
      "\t test  Loss: 0.554 | test  Acc: 71.09%\n",
      "\t best  test acc: 71.88%\n",
      "Epoch: 08 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.449 | Train Acc: 82.04%\n",
      "\t test  Loss: 0.447 | test  Acc: 81.51%\n",
      "\t best  test acc: 81.51%\n",
      "Epoch: 09 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.437 | Train Acc: 81.51%\n",
      "\t test  Loss: 0.570 | test  Acc: 71.61%\n",
      "\t best  test acc: 81.51%\n",
      "Epoch: 10 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.369 | Train Acc: 85.98%\n",
      "\t test  Loss: 0.456 | test  Acc: 81.51%\n",
      "\t best  test acc: 81.51%\n",
      "Epoch: 11 | Epoch Time: 0m 2s\n",
      "\t Train Loss: 0.313 | Train Acc: 88.49%\n",
      "\t test  Loss: 0.437 | test  Acc: 82.81%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 12 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.265 | Train Acc: 90.91%\n",
      "\t test  Loss: 0.447 | test  Acc: 82.81%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 13 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.231 | Train Acc: 92.56%\n",
      "\t test  Loss: 0.459 | test  Acc: 82.55%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 14 | Epoch Time: 0m 2s\n",
      "\t Train Loss: 0.202 | Train Acc: 94.15%\n",
      "\t test  Loss: 0.473 | test  Acc: 82.29%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 15 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.177 | Train Acc: 95.11%\n",
      "\t test  Loss: 0.501 | test  Acc: 80.99%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 16 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.174 | Train Acc: 95.01%\n",
      "\t test  Loss: 0.560 | test  Acc: 79.69%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 17 | Epoch Time: 0m 13s\n",
      "\t Train Loss: 0.136 | Train Acc: 96.69%\n",
      "\t test  Loss: 0.511 | test  Acc: 82.55%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 18 | Epoch Time: 0m 8s\n",
      "\t Train Loss: 0.130 | Train Acc: 96.59%\n",
      "\t test  Loss: 0.591 | test  Acc: 81.51%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 19 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.123 | Train Acc: 96.92%\n",
      "\t test  Loss: 0.550 | test  Acc: 82.29%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 20 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.111 | Train Acc: 97.32%\n",
      "\t test  Loss: 0.651 | test  Acc: 79.17%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 21 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.109 | Train Acc: 97.32%\n",
      "\t test  Loss: 0.709 | test  Acc: 79.17%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 22 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.100 | Train Acc: 97.62%\n",
      "\t test  Loss: 0.688 | test  Acc: 80.21%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 23 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.093 | Train Acc: 97.92%\n",
      "\t test  Loss: 0.714 | test  Acc: 79.43%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 24 | Epoch Time: 0m 2s\n",
      "\t Train Loss: 0.089 | Train Acc: 98.15%\n",
      "\t test  Loss: 0.695 | test  Acc: 80.99%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 25 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.086 | Train Acc: 98.18%\n",
      "\t test  Loss: 0.702 | test  Acc: 80.47%\n",
      "\t best  test acc: 82.81%\n",
      "Epoch: 26 | Epoch Time: 0m 3s\n",
      "\t Train Loss: 0.081 | Train Acc: 98.25%\n",
      "\t test  Loss: 0.765 | test  Acc: 79.17%\n",
      "\t best  test acc: 82.81%\n"
     ]
    }
   ],
   "source": [
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors1 = '#00CED1'\n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 设置字体大小\n",
    "plt.rc('font', size=12)\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), loss_train, 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), loss_test, 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1.2)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('Loss' + DATA_SET + '.png', dpi=1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 设置字体大小\n",
    "plt.rc('font', size=12)\n",
    "# 画初始点\n",
    "plt.figure(2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Acc')\n",
    "plt.plot(range(N_EPOCHS), acc_train, 'r-o', label='acc_train')\n",
    "plt.plot(range(N_EPOCHS), acc_test, 'c-*', label='acc_test')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1.2)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('Acc' + DATA_SET + '.png', dpi=1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "print(torch.__version__)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_SET: SST\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "DATA_SET = 'SST'\n",
    "print(\"DATA_SET:\", DATA_SET)\n",
    "CUDA_NUMBER = 0\n",
    "N_EPOCHS = 26\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = float('-inf')\n",
    "print(0.5 > best_test_acc)\n",
    "\n",
    "# 0-->MR ||  1-->CR ||  2-->SST  ||  3-->SUBJ ||  4-->MPQA\n",
    "dataset_dict = {}\n",
    "dataset_dict['MR'] = 0\n",
    "dataset_dict['CR'] = 1\n",
    "dataset_dict['SST'] = 2\n",
    "dataset_dict['SUBJ'] = 3\n",
    "dataset_dict['MPQA'] = 4\n",
    "\n",
    "# 设置要训练的数据集\n",
    "DATASET_NUMBER = dataset_dict[DATA_SET]\n",
    "\n",
    "train_path_ls = []\n",
    "test_path_ls = []\n",
    "word_vector_path_ls = []\n",
    "train_path_ls.append(\"./DataSet/MR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/CR/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SST/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/SUBJ/train.tsv\")\n",
    "train_path_ls.append(\"./DataSet/MPQA/train.tsv\")\n",
    "\n",
    "test_path_ls.append(\"./DataSet/MR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/CR/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SST/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/SUBJ/test.tsv\")\n",
    "test_path_ls.append(\"./DataSet/MPQA/test.tsv\")\n",
    "\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/CR_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SST_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/SUBJ_word_vector.txt\")\n",
    "word_vector_path_ls.append(\"./sub_word_vector/MPQA_word_vector.txt\")\n",
    "\n",
    "# 要训练的任务级路径\n",
    "train_path = train_path_ls[DATASET_NUMBER]\n",
    "test_path = test_path_ls[DATASET_NUMBER]\n",
    "\n",
    "# 词向量和W2Idx的路径\n",
    "word_vector_path = word_vector_path_ls[DATASET_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13772, 100])\n",
      "13772\n",
      "13772\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100  # 词向量维度\n",
    "# 获取单词到索引的映射表以及每个单词的词向量表\n",
    "\n",
    "word_to_index = {'<unknown>': 0, '<padded>': 1}  # 根据筛选出来的词向量文件\"word_vector.txt\" 生成单词和索引的字典\n",
    "zero_ls = [0.0 for i in range(word_dim)]\n",
    "ls = [zero_ls, zero_ls]  # 用一个列表ls来存储词向量 前两个分别是 100 维的0向量，用来表示unknown_token和pad_token\n",
    "index_to_word = {}\n",
    "with open(word_vector_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # 将刑如 \"the -0.038194 -0.24487 0.72812 -0.39961...\"的字符串分成对应的词和词向量，比如\"the\"， \"-0.038194 -0.24487 0.72812 -0.39961...\"\n",
    "        # 并且构建单词映射到整数的字典，word_to_index。 eg. 'the' : 2  ，PS：0和1分别是两个特殊字符串 unknown 和 padded的索引，the作为词向量文件中的第一个单词，所以下标为2\n",
    "        word_vector = line.split()\n",
    "        word_to_index[word_vector[0]] = i + 2  # 前两位由unknown和 padded分别占据\n",
    "        tmp = []  # 存储一个单词的词向量，总共是100个数字\n",
    "        for j, word in enumerate(word_vector):\n",
    "            if j == 0:  # 第一个是单词，所以跳过，只需要每个单词后面的词向量\n",
    "                continue\n",
    "            tmp.append(float(word))\n",
    "        ls.append(tmp)  # 每个单词的词向量又存到列表ls当中\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "word_vector_weight_matrix = torch.FloatTensor(ls)  # 将词向量列表转换为Tensor\n",
    "print(word_vector_weight_matrix.size())\n",
    "print(word_vector_weight_matrix.shape[0])\n",
    "print(len(word_to_index))  # word_to_index字典的关键字是英语单词，值是单词索引，例如{'<unknown>': 0,'<padded>': 1,'the': 2,',': 3,'.': 4,...}\n",
    "VOCAB_SIZE = len(word_to_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_weight_matrix[3]\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "\n",
    "\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# 导入AFINN情感词典\n",
    "# from afinn import Afinn\n",
    "\n",
    "# 创建Afinn对象\n",
    "# afinn = Afinn()\n",
    "\n",
    "\n",
    "# 1、【将句子分词，并且求句子长度】\n",
    "def get_sentences(path):\n",
    "    sentences = []\n",
    "    batch_sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # 跳过第一行的test label\n",
    "            if i == 0:\n",
    "                continue\n",
    "            words = line.split()[:-1]  # 需要将末尾的0或者1去掉\n",
    "            label = float(line.split()[-1])\n",
    "            count = 0  # 统计每个句子的长度\n",
    "            for word in words:\n",
    "                count += 1\n",
    "            tmp = (words, count, label)\n",
    "            sentences.append(tmp)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 根据上面得到的word_to_index,将单词转换为数字,列表形式为[ ([words_list1], len1, label1), ([words_list2], len2, label2),......],\n",
    "# word_list是多个单词组成的序列\n",
    "\n",
    "# 2、【将分词之后的单词序列变成数字序列】\n",
    "def lookup_table(array_ls, word_to_index):\n",
    "    sentences_tensor = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tensor_ls = []\n",
    "        # sentence[0]是一个包含多个单词的列表。sentence[0]是一个列表，里面的元素是单词。\n",
    "        for word in sentence[0]:\n",
    "            # word_to_index 是一个单词到索引的字典\n",
    "            if word in word_to_index.keys():\n",
    "                tensor_ls.append(word_to_index[word])  # 将单词转换为索引，并且索引存入张量当中\n",
    "            else:\n",
    "                tensor_ls.append(1)  # 如果在索引表中没找到单词，则“不认识”单词,用1下标代替, 此时unknown_token和padded_token下标都是1\n",
    "        sentences_tensor.append((tensor_ls, sentence[1], sentence[2]))\n",
    "    return sentences_tensor  # 得到的列表形式为[([3,8,12,123,2,9],6,1),([6,45,652345,634,2342,4],6,0)]\n",
    "\n",
    "\n",
    "# 对句子进行填充，eg:16个句子组成一个batch,【每个batch的句子长度必须相等】，这里的做法是，获取batch中长度最长的句子,然后句子长度不够的append 1\n",
    "# 输入 [([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. [([1, 2, 3],3, 0), ([2, 3], 2, 1), ...]\n",
    "# 输出，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# eg. 假设batch_size = 2\n",
    "# [([1, 2, 3], 3), ([2, 3, 1], 2),...] 第二个句子列表 append 1，但是实际长度为2\n",
    "\n",
    "# 3、【将句子进行分batch，并且将数字列表（句子）进行填充】\n",
    "def pad_sentence_plus(array_ls, array_sentiment, batch_size):  # 这里的array_ls是上面函数的输出，即sentences_tensor。\n",
    "    ans = 0  # j记录每个batch的第一条数据的下标\n",
    "    max = array_ls[0][1]  # max为每个batch的句子最大长度.\n",
    "    # 第一维为列表的第几个元素（即一个句子元组），第二维为一个元组的第一个元素（即一个元组里面的word_list），这里max初始化为第一个句子的长度。\n",
    "    for i in range(len(array_ls)):\n",
    "        # 需要考虑最后一个batch可能长度不够batch_size\n",
    "        if (i + 1) % batch_size == 0 or i == len(array_ls) - 1:\n",
    "            if array_ls[i][1] > max:\n",
    "                max = array_ls[i][1]\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                index = batch_size\n",
    "            else:\n",
    "                index = i - ans + 1\n",
    "            for j in range(index):\n",
    "                while len(array_ls[j + ans][0]) < max:\n",
    "                    array_ls[j + ans][0].append(1)\n",
    "                    array_sentiment[j + ans] += [0]\n",
    "            # 每一次填充完毕后，需要更新标记，并再次初始化最大值\n",
    "            ans = i + 1\n",
    "            if ans != len(array_ls):\n",
    "                max = array_ls[ans][1]\n",
    "        else:\n",
    "            if array_ls[i][1] > max:  # 取句子的最大长度\n",
    "                max = array_ls[i][1]\n",
    "    return array_ls, array_sentiment\n",
    "\n",
    "\n",
    "# 输入，[([单词下标]，句子长度1, 标签1), ([单词下标]，句子长度2, 标签2), ....]\n",
    "# [([1, 2, 3],3), ([2, 3, 1], 2),...]\n",
    "# shuffle表示是否将每个batch打乱\n",
    "# batch_first if false 表示返回的张量形状为(sentence_len,batch_size)\n",
    "# if true 表示返回的张量形状为(batch_size,sentence_len)\n",
    "# 这里默认采用batch_first = False,主要是为了适应nn.Embedding层的输入形状\n",
    "\n",
    "# 4、【获得embedding的一个个batch（调整batch的的形状）的数据迭代器】\n",
    "def iterator(array_ls, array_sentiment, batch_size, shuffle=True, batch_first=False):\n",
    "    sentences_index_label_sentiment = []  # 存放填充后的语句列表【句子的indx表示】\n",
    "    tmp_sen = []\n",
    "    tmp_label = []\n",
    "    tmp_sentiment = []\n",
    "    for i, sentence in enumerate(array_ls):\n",
    "        tmp_sen.append(sentence[0])  # 存放一个batch的【数据】\n",
    "        tmp_label.append(sentence[2])  # 存放一个batch的【标签】\n",
    "        tmp_sentiment.append(array_sentiment[i])\n",
    "        if (i + 1) % batch_size == 0:  #\n",
    "            sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "            tmp_sen = []  # 清空数据\n",
    "            tmp_label = []  # 清空标签\n",
    "            tmp_sentiment = []\n",
    "\n",
    "    # # 最后几个样本可能不够一个batch,需要额外判断\n",
    "    # if len(tmp_sen) != 0:\n",
    "    #     # 补齐\n",
    "    #     for _ in range(batch_size - len(tmp_sen)):\n",
    "    #         tmp_sen.append(sentence[0])\n",
    "    #         tmp_label.append(sentence[2])\n",
    "    #         tmp_sentiment.append(array_sentiment[1])\n",
    "    #\n",
    "    #     sentences_index_label_sentiment.append((tmp_sen, tmp_label, tmp_sentiment))\n",
    "    #     # OR去掉\n",
    "    #     break\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(sentences_index_label_sentiment)  # 打乱列表中各个batch的顺序\n",
    "    res = []\n",
    "    # 2D张量转置\n",
    "    # 2D张量转置\n",
    "    if batch_first == False:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]),\n",
    "                        torch.FloatTensor(batch[2]).t()))  # 函数t()求矩阵的转置\n",
    "    else:\n",
    "        for batch in sentences_index_label_sentiment:\n",
    "            res.append((torch.LongTensor(batch[0]).t(), torch.FloatTensor(batch[1]), torch.FloatTensor(batch[2]).t()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from nltk.corpus import wordnet, sentiwordnet\n",
    "import nltk\n",
    "\n",
    "\n",
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# ================================= sentiwordnet ======================================\n",
    "# =====================================================================================\n",
    "def negate_sequence(words):\n",
    "    \"\"\"\n",
    "    处理否定词\n",
    "    \"\"\"\n",
    "    negation = False\n",
    "    result = []\n",
    "    for word in words:\n",
    "        if any(neg in word for neg in [\"not\", \"n't\", \"no\"]):\n",
    "            negation = not negation\n",
    "        elif negation:\n",
    "            word = \"not_\" + word\n",
    "        result.append(word)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_sentiment_score(word):\n",
    "    \"\"\"获取WordNet情感分数\"\"\"\n",
    "\n",
    "    synsets = list(wordnet.synsets(word))\n",
    "    if synsets:\n",
    "        sentiment_scores = [\n",
    "            sentiwordnet.senti_synset(s.name()).pos_score() - sentiwordnet.senti_synset(s.name()).neg_score()\n",
    "            for s in synsets\n",
    "        ]\n",
    "        avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        return avg_sentiment_score\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_word_sentiment_scores(tokenized_sentence):\n",
    "    \"\"\"计算已分词句子中每个单词的情感极性分数\"\"\"\n",
    "    # 处理否定词\n",
    "    # sentences_negated = negate_sequence(tokenized_sentence)\n",
    "    word_scores = [get_sentiment_score(word) for word in tokenized_sentence]\n",
    "    return word_scores\n",
    "\n",
    "\n",
    "def get_batch_word_sentiment_scores(batch_tokenized_sentences):\n",
    "    \"\"\"处理一批已分词的文本并返回其中每个单词的情感极性分数\"\"\"\n",
    "    batch_word_scores = []\n",
    "    for sentence, _, _ in batch_tokenized_sentences:\n",
    "        xx = sentence\n",
    "        ss = get_word_sentiment_scores(xx)\n",
    "        batch_word_scores.append(ss)\n",
    "    # batch_word_scores = [get_word_sentiment_scores(sentence) for sentence in batch_tokenized_sentences[0]]\n",
    "    return batch_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)  # 为CPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.cuda.manual_seed(SEED)  # 为GPU设置随机种子，生成随机数，使得每次运行程序时，生成的随机数相同\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_NUMBER}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(path, batch_size, word_to_index):\n",
    "    # ['another', 'thing', 'i', 'don', \"'t\", 'like', 'is', 'that', 'some', 'of', 'the',\n",
    "    # 'features', 'take', '1-2', 'seconds', 'to', 'load', 'up', '.']\n",
    "    sentences = get_sentences(path)\n",
    "    # ([2, 3, 4, 5, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
    "    # 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 19, 0.0)\n",
    "    # 将单词变成indx\n",
    "    sentences_indx = lookup_table(sentences, word_to_index)\n",
    "\n",
    "    # get sentiment polarity by 【AFINN】\n",
    "    # afinn = Afinn()\n",
    "    # sentiment_sentences_AFINN = get_batch_word_sentiment_scores_AFINN(sentences,afinn)\n",
    "    # sentiment_sentences_AFINN = calculate_sentiment_for_phrases(sentences, afinn, n=3)\n",
    "\n",
    "    # get sentiment polarity by 【sentiwordnet】\n",
    "    sentiment_sentences_sentiwordnet = get_batch_word_sentiment_scores(sentences)\n",
    "    sentences_padded, sentiment_sentences_padded = pad_sentence_plus(sentences_indx, sentiment_sentences_sentiwordnet,\n",
    "                                                                     batch_size)\n",
    "\n",
    "    # 把分成一个个batch，然后每个list之内有数据和标签\n",
    "    Iterator_with_sentiments = iterator(sentences_padded, sentiment_sentences_padded, batch_size)\n",
    "\n",
    "    return Iterator_with_sentiments\n",
    "\n",
    "\n",
    "# 2、生成对应任务的句子的词向量\n",
    "train_iterator = get_iterator(train_path, BATCH_SIZE, word_to_index)\n",
    "test_iterator = get_iterator(test_path, BATCH_SIZE, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class projection_Euler(nn.Module):\n",
    "    def __init__(self, Embedding, num_layers):\n",
    "        super(projection_Euler, self).__init__()  # projection是子类名\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        amplitude = inputs[0]\n",
    "        phase = inputs[1]\n",
    "        # ================ 变换形状和归一化处理 ================\n",
    "        # -----\n",
    "        amplitude_permute = amplitude.permute(1, 0, 2)\n",
    "        amplitude_norm = F.normalize(amplitude_permute, 2, 2)\n",
    "        # ----\n",
    "        phase_permute = phase.permute(1, 0, 2)\n",
    "\n",
    "        # ================ 计算Am和Ph分别计算实部和虚部 ================\n",
    "        # --- 求欧拉展开式\n",
    "        real_part = amplitude_norm * torch.cos(phase_permute)\n",
    "        imag_part = amplitude_norm * torch.sin(phase_permute)\n",
    "\n",
    "        return [real_part, imag_part]\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixMean(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixMean, self).__init__()\n",
    "        self.mapping_Diagonal_q = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.mapping_Diagonal_k = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.embed_size = Embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        Diagonal1 = inputs[0]\n",
    "        Diagonal2 = inputs[1]\n",
    "        Matrix = inputs[2]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attention_scores = Diagonal1 * Diagonal2\n",
    "        # 迹求和\n",
    "        attention_weight = torch.sum(attention_scores, dim=-1)\n",
    "\n",
    "        # 归一化\n",
    "        attention = F.softmax(attention_weight, dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # 加权求和\n",
    "        Matrix_output = torch.sum(Matrix * attention, dim=1)\n",
    "\n",
    "        return Matrix_output\n",
    "\n",
    "\n",
    "class projection_CalculateMatrixQ(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_CalculateMatrixQ, self).__init__()\n",
    "        self.Q_Linear_real1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag1 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.Q_Linear_real2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "        self.Q_Linear_imag2 = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "        self.AttentionReal = projection_CalculateMatrixMean(Embedding_dim)\n",
    "        self.AttentionImag = projection_CalculateMatrixMean(Embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_real = inputs[0]  # 实部\n",
    "        input_imag = inputs[1]  # 虚部\n",
    "        # ==================== 1 计算对角线和密度矩阵 ====================\n",
    "\n",
    "        # ======= 1.1 计算对角线 =======\n",
    "        input_real1 = self.Q_Linear_real1(input_real)\n",
    "        input_imag1 = self.Q_Linear_imag1(input_imag)\n",
    "\n",
    "        # 获得[实部/虚部]对角线向量\n",
    "        diagonal_real1 = input_real1 * input_real1 - input_imag1 * input_imag1\n",
    "        diagonal_imag1 = input_real1 * input_imag1 + input_imag1 * input_real1\n",
    "\n",
    "        # ======= 1.2 计算密度矩阵 =======\n",
    "        input_real2 = self.Q_Linear_real2(input_real)\n",
    "        input_imag2 = self.Q_Linear_imag2(input_imag)\n",
    "\n",
    "        diagonal_real2 = input_real2 * input_real2 - input_imag2 * input_imag2\n",
    "        diagonal_imag2 = input_real2 * input_imag2 + input_imag2 * input_real2\n",
    "\n",
    "        real_part_expand = torch.unsqueeze(input_real2, dim=3)\n",
    "        imag_part_expand = torch.unsqueeze(input_imag2, dim=3)\n",
    "\n",
    "        real_part_expand_transpose = real_part_expand.permute(0, 1, 3, 2)\n",
    "        imag_part_expand_transpose = imag_part_expand.permute(0, 1, 3, 2)\n",
    "\n",
    "        # real 密度矩阵\n",
    "        Matrix_real = torch.matmul(real_part_expand, real_part_expand_transpose) - torch.matmul(imag_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "        # imag 密度矩阵\n",
    "        Matrix_imag = torch.matmul(imag_part_expand, real_part_expand_transpose) + torch.matmul(real_part_expand,\n",
    "                                                                                                imag_part_expand_transpose)\n",
    "\n",
    "        Matrix_Real_output = self.AttentionReal([diagonal_real1, diagonal_real2, Matrix_real])\n",
    "        Matrix_imag_output = self.AttentionImag([diagonal_imag1, diagonal_imag2, Matrix_imag])\n",
    "\n",
    "        return [Matrix_Real_output, Matrix_imag_output]\n",
    "\n",
    "\n",
    "class projection_Measurement(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(projection_Measurement, self).__init__()  # projection是子类名\n",
    "        # 使得tensor是正交的,正交初始化,projector是子类projection的新属性。\n",
    "        self.projector = nn.init.orthogonal_(Parameter(torch.Tensor(2, Embedding_dim, 1)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v_real_avg = inputs[0]\n",
    "        v_imag_avg = inputs[1]\n",
    "\n",
    "        p_real = self.projector[0]\n",
    "        p_imag = self.projector[1]\n",
    "\n",
    "        p_real_norm = p_real / torch.norm(p_real, dim=0)\n",
    "        p_imag_norm = p_imag / torch.norm(p_imag, dim=0)\n",
    "\n",
    "        p_real_mat = torch.matmul(p_real_norm, p_real_norm.permute(1, 0))\n",
    "        p_imag_mat = torch.matmul(p_imag_norm, p_imag_norm.permute(1, 0))\n",
    "\n",
    "        Pv_real = torch.matmul(v_real_avg, p_real_mat) - torch.matmul(v_imag_avg, p_imag_mat)\n",
    "        Pv_imag = torch.matmul(v_real_avg, p_imag_mat) + torch.matmul(v_imag_avg, p_real_mat)\n",
    "\n",
    "        Pv_real_plus = torch.unsqueeze(Pv_real, dim=1)\n",
    "        Pv_imag_plus = torch.unsqueeze(Pv_imag, dim=1)\n",
    "\n",
    "        return [Pv_real_plus, Pv_imag_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射成三个不同的向量的自注意力机制\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, Embedding_dim):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.mapping_query = nn.init.uniform_(\n",
    "            Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))  # 从均匀分布U(a, b)中生成值（随机生成），填充输入的张量或变量\n",
    "        self.mapping_key = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "        self.mapping_value = nn.init.uniform_(Parameter(torch.Tensor(Embedding_dim, Embedding_dim)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query = torch.matmul(inputs.permute(1, 0, 2), self.mapping_query)  # permute函数为换维函数，参数为(0，1，2)\n",
    "        key = torch.matmul(inputs.permute(1, 0, 2), self.mapping_key)  # matmul是tensor矩阵乘法\n",
    "        value = torch.matmul(inputs.permute(1, 0, 2), self.mapping_value)\n",
    "\n",
    "        query = query / torch.norm(query, dim=2).reshape(query.shape[0], query.shape[1],\n",
    "                                                         1)  # query.shape[0]=16,query.shape[1]=sentence_length.\n",
    "        key = key / torch.norm(key, dim=2).reshape(key.shape[0], key.shape[1],\n",
    "                                                   1)  # shape of tensor:[16,sentence_length,1]\n",
    "\n",
    "        value = value / torch.norm(value, dim=2).reshape(value.shape[0], value.shape[1], 1)  # query,key,value的形状是一样的\n",
    "\n",
    "        xx = torch.matmul(query, torch.transpose(key, 1, 2)) / np.sqrt(inputs.shape[1])\n",
    "        xx1 = torch.softmax(xx, dim=2)\n",
    "        out = torch.matmul(xx1, value)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUWithSkipConnection(nn.Module):\n",
    "    def __init__(self, Embedding_dim, num_layers):\n",
    "        super(GRUWithSkipConnection, self).__init__()\n",
    "\n",
    "        # GRU layer\n",
    "        self.gru = nn.LSTM(Embedding_dim, Embedding_dim, num_layers=num_layers, dropout=0.1)\n",
    "\n",
    "        # self.scale_layer = nn.Linear(2 * Embedding_dim, Embedding_dim)\n",
    "\n",
    "        # Linear layer for skip connection\n",
    "        self.middle_layer = nn.Linear(Embedding_dim, Embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU layer\n",
    "        output, _ = self.gru(x)\n",
    "\n",
    "        # Skip connection: Add output of middle layer to GRU layer output\n",
    "        output = output + self.middle_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class run_complex_network(nn.Module):\n",
    "    def __init__(self, weight_matrix, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, VOCAB_SIZE, batch):\n",
    "        super().__init__()\n",
    "\n",
    "        # ================ 1、词嵌入模块 ================\n",
    "        # ------ 实部，预训练模型 -------\n",
    "        self.amplitude_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.amplitude_embedding2 = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ------ 虚部，传统模型 -------\n",
    "        # self.phase_embedding = nn.Embedding.from_pretrained(weight_matrix, padding_idx=pad_idx, freeze=False)\n",
    "        # self.phase_embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "        # self.phase_embedding_sentiment = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # ================ 2、GRU模块 信息提取 ================\n",
    "        # 输出张量的维度(L:sequence_length,N:batch_size,hidden_size)\n",
    "        self.gru1 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.gru2 = GRUWithSkipConnection(embedding_dim, num_layers)\n",
    "        self.self_attention1 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # self.self_attention2 = self_attention(Embedding_dim=embedding_dim)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "\n",
    "        self.projection_Euler = projection_Euler(Embedding=embedding_dim, num_layers=num_layers)\n",
    "        self.projection_CalculateMatrixattension = projection_CalculateMatrixQ(Embedding_dim=embedding_dim)\n",
    "        self.projection_measurement = projection_Measurement(embedding_dim)\n",
    "\n",
    "        # ================ 4、卷积 ================\n",
    "        self.Conv2dOne = nn.Conv2d(1, 1, 3)  # 实部\n",
    "        self.Conv2dTwo = nn.Conv2d(1, 1, 3)  # 虚部\n",
    "\n",
    "        # ================ 5、池化 ================\n",
    "        # self.avgPool1 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "        # self.avgPool2 = nn.AvgPool2d((embedding_dim - 2, 1), 1)\n",
    "        self.MaxPool1 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 实部\n",
    "        self.MaxPool2 = nn.MaxPool2d((embedding_dim - 2, 1), 1)  # 虚部\n",
    "\n",
    "        # ================ 6、全连接层 ================\n",
    "        self.fc1 = nn.Linear(2 * (embedding_dim - 2), 10)\n",
    "        self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "        # # ================ 7、全连接层 ================\n",
    "        # self.fc1 = nn.Linear(2 * embedding_dim, 10)\n",
    "        # self.fc2 = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, text, sentiment):\n",
    "        # ================ 1、文本嵌入到向量 ================\n",
    "        amplitude_is_WordEmbedding = self.amplitude_embedding(text)\n",
    "\n",
    "        sentiment_unsqueeze = (torch.unsqueeze(sentiment, dim=-1).\n",
    "                               expand(*sentiment.shape, amplitude_is_WordEmbedding.size(2)))\n",
    "\n",
    "        phase_is_sentiment = sentiment_unsqueeze\n",
    "\n",
    "        # ================ 2、实部进行GRU处理 ================\n",
    "        amplitude_plus = self.gru1(amplitude_is_WordEmbedding)\n",
    "        amplitude_plus2 = self.self_attention1(amplitude_plus)\n",
    "        amplitude_plus2 = amplitude_plus2.permute(1, 0, 2)\n",
    "\n",
    "        phase_plus = self.gru2(phase_is_sentiment)\n",
    "        # phase_plus2 = self.self_attention2(phase_plus)\n",
    "        # phase_plus2 = phase_plus2.permute(1, 0, 2)\n",
    "        # ================ 3、计算密度矩阵 ================\n",
    "        embedded = [amplitude_plus2, phase_plus]\n",
    "\n",
    "        Euler_realAimag = self.projection_Euler(embedded)\n",
    "        Matrix_realAimag = self.projection_CalculateMatrixattension(Euler_realAimag)\n",
    "        Project_realAimag = self.projection_measurement(Matrix_realAimag)\n",
    "\n",
    "        MatrixReal = Project_realAimag[0]\n",
    "        MatrixImag = Project_realAimag[1]\n",
    "\n",
    "        # ================ 4、卷积操作 ================\n",
    "        # 5.1 --对于【实部】进行卷积\n",
    "        Conv_real = self.Conv2dOne(MatrixReal)\n",
    "        # 5.2 --对于【虚部】进行卷积\n",
    "        Conv_imag = self.Conv2dTwo(MatrixImag)\n",
    "\n",
    "        # ================ 5、池化操作 ================\n",
    "        # 6.1 --对于【实部】进行池化\n",
    "        Max_real = self.MaxPool1(torch.sigmoid(Conv_real))\n",
    "        # 6.2 --对于【虚部】进行池化\n",
    "        Max_imag = self.MaxPool2(torch.sigmoid(Conv_imag))\n",
    "\n",
    "        # ================ 6、全连接 ================\n",
    "        fc1 = self.fc1(torch.cat((Max_real, Max_imag), dim=3))\n",
    "        fc2 = torch.sigmoid(self.fc2(torch.sigmoid(fc1)))\n",
    "\n",
    "        # # ================ 5、取对角线 ================\n",
    "        # diagonal_elements_real = MatrixReal[:, 0, torch.arange(MatrixReal.size(2)), torch.arange(MatrixReal.size(3))]\n",
    "        # diagonal_elements_imag = MatrixImag[:, 0, torch.arange(MatrixImag.size(2)), torch.arange(MatrixImag.size(3))]\n",
    "        # diagonal_elements_real = diagonal_elements_real.unsqueeze(1).unsqueeze(1)\n",
    "        # diagonal_elements_imag = diagonal_elements_imag.unsqueeze(1).unsqueeze(1)\n",
    "        #\n",
    "        # # ================ 6、全连接 ================\n",
    "        # diagonal_elements_cat = torch.cat((diagonal_elements_real, diagonal_elements_imag), dim=3)\n",
    "        # fc1 = torch.sigmoid(self.fc1(diagonal_elements_cat))\n",
    "        # fc2 = torch.sigmoid(self.fc2(fc1))\n",
    "\n",
    "        return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_idx 1\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "num_layers = 2\n",
    "# vocab_size = 19192, embedding_dim = 100, hidden_dim = 3, output_dim = 1, dropout = 0.5, pad_idx = 1\n",
    "PAD_IDX = 1\n",
    "print('pad_idx', PAD_IDX)\n",
    "\n",
    "model = run_complex_network(word_vector_weight_matrix,\n",
    "                            EMBEDDING_DIM,\n",
    "                            HIDDEN_DIM,\n",
    "                            OUTPUT_DIM,\n",
    "                            num_layers,\n",
    "                            PAD_IDX,\n",
    "                            VOCAB_SIZE,\n",
    "                            BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,833,601 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), 0.001)  # 优化器使用的是Adam\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def multiply(input1, input2):\n",
    "    return torch.sum(torch.mul(input1, input2)).item()\n",
    "\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    # round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "    #     print(f'preds:{preds}, y:{y}')\n",
    "    correct = (rounded_preds == y).float()  # convert into float for division\n",
    "    # print('batch: 模型预测值', rounded_preds,'真实标签', y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def calculation_recall(preds, y):\n",
    "    pre = preds.detach()\n",
    "    pre_y = y.detach()\n",
    "    rounded_preds = torch.round(pre)\n",
    "\n",
    "    TP = (torch.from_numpy(rounded_preds.cpu().numpy().astype(int)) & torch.from_numpy(\n",
    "        pre_y.cpu().numpy().astype(int))).sum()\n",
    "    recall = TP / (y.cpu().sum())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1_score_avg(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    f1_score(y, rounded_preds, 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把训练数据投入模型进行训练\n",
    "def train(model, iterator, optimizer, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        text = batch[0].cuda(CUDA_NUMBER)\n",
    "        label = batch[1].cuda(CUDA_NUMBER)\n",
    "        sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text, sentiment).squeeze(1)\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "        acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "        recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "        label_score = label.tolist()\n",
    "\n",
    "        y_true = label_score.copy()\n",
    "\n",
    "        predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "\n",
    "        y_pred = predictions_score.copy()\n",
    "\n",
    "        F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        epoch_recall += recall.item()\n",
    "\n",
    "        epoch_f1_score += F1Score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)\n",
    "\n",
    "\n",
    "# 评价\n",
    "def evaluate(model, iterator, criterion, CUDA_NUMBER):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1_score = 0\n",
    "    epoch_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].cuda(CUDA_NUMBER)\n",
    "            label = batch[1].cuda(CUDA_NUMBER)\n",
    "            sentiment = batch[2].cuda(CUDA_NUMBER)\n",
    "\n",
    "            predictions = model(text, sentiment).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.reshape(len(label)), label)\n",
    "\n",
    "            acc = binary_accuracy(predictions.reshape(len(label)), label)\n",
    "\n",
    "            recall = calculation_recall(predictions.reshape(len(label)), label)\n",
    "\n",
    "            label_score = label.tolist()\n",
    "            y_true = label_score.copy()\n",
    "            predictions_score = torch.round(predictions.reshape(len(label))).tolist()\n",
    "            y_pred = predictions_score.copy()\n",
    "            F1Score = f1_score(y_true, y_pred)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1_score += F1Score.item()\n",
    "            epoch_recall += recall.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1_score / len(\n",
    "        iterator), epoch_recall / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 1m 23s\n",
      "\t Train Loss: 0.494 | Train Acc: 74.88%\n",
      "\t test  Loss: 0.423 | test  Acc: 81.36%\n",
      "\t best  test acc: 81.36%\n",
      "Epoch: 02 | Epoch Time: 1m 23s\n",
      "\t Train Loss: 0.238 | Train Acc: 91.00%\n",
      "\t test  Loss: 0.420 | test  Acc: 83.96%\n",
      "\t best  test acc: 83.96%\n",
      "Epoch: 03 | Epoch Time: 1m 6s\n",
      "\t Train Loss: 0.173 | Train Acc: 93.68%\n",
      "\t test  Loss: 0.507 | test  Acc: 82.96%\n",
      "\t best  test acc: 83.96%\n",
      "Epoch: 04 | Epoch Time: 1m 22s\n",
      "\t Train Loss: 0.137 | Train Acc: 95.13%\n",
      "\t test  Loss: 0.506 | test  Acc: 83.19%\n",
      "\t best  test acc: 83.96%\n",
      "Epoch: 05 | Epoch Time: 1m 21s\n",
      "\t Train Loss: 0.113 | Train Acc: 95.94%\n",
      "\t test  Loss: 0.545 | test  Acc: 83.85%\n",
      "\t best  test acc: 83.96%\n",
      "Epoch: 06 | Epoch Time: 1m 6s\n",
      "\t Train Loss: 0.098 | Train Acc: 96.47%\n",
      "\t test  Loss: 0.537 | test  Acc: 82.85%\n",
      "\t best  test acc: 83.96%\n",
      "Epoch: 07 | Epoch Time: 1m 23s\n",
      "\t Train Loss: 0.083 | Train Acc: 97.01%\n",
      "\t test  Loss: 0.617 | test  Acc: 82.41%\n",
      "\t best  test acc: 83.96%\n",
      "Epoch: 08 | Epoch Time: 1m 23s\n",
      "\t Train Loss: 0.071 | Train Acc: 97.43%\n",
      "\t test  Loss: 0.621 | test  Acc: 82.58%\n",
      "\t best  test acc: 83.96%\n",
      "Epoch: 09 | Epoch Time: 1m 4s\n",
      "\t Train Loss: 0.064 | Train Acc: 97.69%\n",
      "\t test  Loss: 0.631 | test  Acc: 82.91%\n",
      "\t best  test acc: 83.96%\n",
      "Epoch: 10 | Epoch Time: 1m 21s\n",
      "\t Train Loss: 0.060 | Train Acc: 97.83%\n",
      "\t test  Loss: 0.665 | test  Acc: 82.58%\n",
      "\t best  test acc: 83.96%\n",
      "Epoch: 11 | Epoch Time: 1m 4s\n",
      "\t Train Loss: 0.053 | Train Acc: 98.06%\n",
      "\t test  Loss: 0.718 | test  Acc: 82.96%\n",
      "\t best  test acc: 83.96%\n"
     ]
    }
   ],
   "source": [
    "best_acc = -1\n",
    "best_f1_score = -1\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_score_test = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f1_score, train_recall \\\n",
    "        = train(model, train_iterator, optimizer, criterion, CUDA_NUMBER)\n",
    "\n",
    "    test_loss, test_acc, test_f1_score, test_recall \\\n",
    "        = evaluate(model, test_iterator, criterion, CUDA_NUMBER)\n",
    "\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    f1_score_test.append(test_f1_score)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'SST_GRU_Conv_model.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(\n",
    "    #     f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train f1_score: {train_f1_score * 100:.2f}% | Train recall: {train_recall * 100:.2f}%')\n",
    "    # print(\n",
    "    #     f'\\t test. Loss: {test_loss:.3f} |  test. Acc: {test_acc * 100:.2f}% | Test f1_score: {test_f1_score * 100:.2f}%| best_acc: {best_acc * 100:.2f}% | Test recall: {test_recall * 100:.2f}%')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t test  Loss: {test_loss:.3f} | test  Acc: {test_acc * 100:.2f}%')\n",
    "    print(f'\\t best  test acc: {best_test_acc * 100:.2f}%')\n",
    "\n",
    "with open('./train/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_train:\n",
    "        f.write(str(i))\n",
    "    f.close()\n",
    "\n",
    "with open('./test/loss/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in loss_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/F1_Score/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in f1_score_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/acc/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in acc_test:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "with open('./test/recall/' + DATA_SET + '.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in test_path_ls:\n",
    "        f.write(str(i) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors1 = '#00CED1'\n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#FFA500'\n",
    "colors4 = '#0000aFF'\n",
    "colors5 = '#FF0000'\n",
    "\n",
    "# 设置字体大小\n",
    "plt.rc('font', size=12)\n",
    "\n",
    "# 画初始点\n",
    "plt.figure(1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Loss')\n",
    "plt.plot(range(N_EPOCHS), loss_train, 'r-o', label='train_loss')\n",
    "plt.plot(range(N_EPOCHS), loss_test, 'c-*', label='test_loss')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1.2)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('Loss' + DATA_SET + '.png', dpi=1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置字体大小\n",
    "plt.rc('font', size=12)\n",
    "# 画初始点\n",
    "plt.figure(2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(DATA_SET + ' Acc')\n",
    "plt.plot(range(N_EPOCHS), acc_train, 'r-o', label='acc_train')\n",
    "plt.plot(range(N_EPOCHS), acc_test, 'c-*', label='acc_test')\n",
    "plt.xlim(-0.01, N_EPOCHS)\n",
    "plt.ylim(-0.01, 1.2)\n",
    "# plt.plot(range(2), sp, c=colors3)\n",
    "plt.legend()\n",
    "plt.savefig('Acc' + DATA_SET + '.png', dpi=1500)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ForUVSam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
